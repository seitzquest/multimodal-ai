[06/30 16:39:50] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 16:39:50] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 16:39:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 16:39:50] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 16:39:50] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 16:39:50] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 16:39:51] d2.utils.env INFO: Using a generated random seed 51131574
[06/30 16:39:52] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 16:39:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:39:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:39:54] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 16:39:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 16:39:54] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 16:39:56] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 16:39:56] detectron2 INFO: Following metrics will be use for evaluation
[06/30 16:39:56] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 16:39:56] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 16:39:56] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 16:39:56] d2.data.datasets.coco INFO: Converting annotations of dataset 'VG_test' to COCO format ...)
[06/30 16:39:56] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[06/30 16:40:59] d2.data.datasets.coco INFO: Conversion finished, #images: 26446, #annotations: 325570
[06/30 16:40:59] d2.data.datasets.coco INFO: Caching COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json' ...
[06/30 16:41:06] detectron2 INFO: Loading zero shot triplets
[06/30 16:41:06] detectron2 INFO: Start inference on 26446 images
[06/30 16:41:46] detectron2 INFO: Inference done 1/26446. 25.4826 s / img. ETA=12 days, 9:19:11
[06/30 16:49:54] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 16:49:55] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 16:49:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 16:49:55] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 16:49:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 16:49:55] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 16:49:55] d2.utils.env INFO: Using a generated random seed 55324258
[06/30 16:49:56] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 16:49:56] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:49:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:49:58] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 16:49:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 16:49:58] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 16:50:00] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 16:50:00] detectron2 INFO: Following metrics will be use for evaluation
[06/30 16:50:00] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 16:50:00] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 16:50:00] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 16:50:00] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 16:50:02] detectron2 INFO: Loading zero shot triplets
[06/30 16:50:02] detectron2 INFO: Start inference on 26446 images
[06/30 16:54:07] detectron2 INFO: Inference done 1/26446. 230.9427 s / img. ETA=75 days, 2:43:54
[06/30 16:54:43] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 16:54:44] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 16:54:44] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 16:54:44] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 16:54:44] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 16:54:44] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 16:54:44] d2.utils.env INFO: Using a generated random seed 44954188
[06/30 16:54:46] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 16:54:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:54:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:54:48] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 16:54:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 16:54:48] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 16:54:49] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 16:54:49] detectron2 INFO: Following metrics will be use for evaluation
[06/30 16:54:49] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 16:54:49] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 16:54:49] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 16:54:49] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 16:54:51] detectron2 INFO: Loading zero shot triplets
[06/30 16:54:51] detectron2 INFO: Start inference on 26446 images
[06/30 16:55:31] detectron2 INFO: Inference done 1/26446. 26.5273 s / img. ETA=12 days, 3:24:43
[06/30 16:56:10] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 16:56:10] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 16:56:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 16:56:10] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 16:56:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 16:56:10] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 16:56:11] d2.utils.env INFO: Using a generated random seed 11129578
[06/30 16:56:12] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 16:56:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:56:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 16:56:14] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 16:56:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 16:56:14] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 16:56:16] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 16:56:16] detectron2 INFO: Following metrics will be use for evaluation
[06/30 16:56:16] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 16:56:16] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 16:56:16] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 16:56:16] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 16:56:17] detectron2 INFO: Loading zero shot triplets
[06/30 16:56:17] detectron2 INFO: Start inference on 26446 images
[06/30 16:56:34] detectron2 INFO: Inference done 11/26446. 0.1819 s / img. ETA=1:21:22
[06/30 16:56:39] detectron2 INFO: Inference done 47/26446. 0.1448 s / img. ETA=1:05:00
[06/30 16:56:44] detectron2 INFO: Inference done 81/26446. 0.1449 s / img. ETA=1:04:59
[06/30 16:56:49] detectron2 INFO: Inference done 122/26446. 0.1365 s / img. ETA=1:01:09
[06/30 16:56:54] detectron2 INFO: Inference done 161/26446. 0.1343 s / img. ETA=1:00:07
[06/30 16:56:59] detectron2 INFO: Inference done 203/26446. 0.1308 s / img. ETA=0:58:30
[06/30 16:57:04] detectron2 INFO: Inference done 242/26446. 0.1300 s / img. ETA=0:58:03
[06/30 16:57:09] detectron2 INFO: Inference done 281/26446. 0.1294 s / img. ETA=0:57:43
[06/30 16:57:14] detectron2 INFO: Inference done 321/26446. 0.1288 s / img. ETA=0:57:22
[06/30 16:57:19] detectron2 INFO: Inference done 364/26446. 0.1271 s / img. ETA=0:56:32
[06/30 16:57:24] detectron2 INFO: Inference done 402/26446. 0.1273 s / img. ETA=0:56:32
[06/30 16:57:30] detectron2 INFO: Inference done 443/26446. 0.1267 s / img. ETA=0:56:11
[06/30 16:57:35] detectron2 INFO: Inference done 482/26446. 0.1267 s / img. ETA=0:56:05
[06/30 16:57:40] detectron2 INFO: Inference done 525/26446. 0.1257 s / img. ETA=0:55:35
[06/30 16:57:45] detectron2 INFO: Inference done 566/26446. 0.1254 s / img. ETA=0:55:21
[06/30 16:57:50] detectron2 INFO: Inference done 608/26446. 0.1249 s / img. ETA=0:55:02
[06/30 16:57:55] detectron2 INFO: Inference done 649/26446. 0.1246 s / img. ETA=0:54:50
[06/30 16:58:00] detectron2 INFO: Inference done 691/26446. 0.1242 s / img. ETA=0:54:35
[06/30 16:58:05] detectron2 INFO: Inference done 734/26446. 0.1237 s / img. ETA=0:54:16
[06/30 16:58:10] detectron2 INFO: Inference done 776/26446. 0.1233 s / img. ETA=0:54:01
[06/30 16:58:15] detectron2 INFO: Inference done 819/26446. 0.1229 s / img. ETA=0:53:43
[06/30 16:58:20] detectron2 INFO: Inference done 863/26446. 0.1223 s / img. ETA=0:53:24
[06/30 16:58:25] detectron2 INFO: Inference done 904/26446. 0.1222 s / img. ETA=0:53:15
[06/30 16:58:30] detectron2 INFO: Inference done 947/26446. 0.1218 s / img. ETA=0:53:00
[06/30 16:58:35] detectron2 INFO: Inference done 990/26446. 0.1215 s / img. ETA=0:52:47
[06/30 16:58:40] detectron2 INFO: Inference done 1032/26446. 0.1213 s / img. ETA=0:52:38
[06/30 16:58:45] detectron2 INFO: Inference done 1075/26446. 0.1211 s / img. ETA=0:52:25
[06/30 16:58:50] detectron2 INFO: Inference done 1119/26446. 0.1207 s / img. ETA=0:52:10
[06/30 16:58:56] detectron2 INFO: Inference done 1162/26446. 0.1205 s / img. ETA=0:52:00
[06/30 16:59:01] detectron2 INFO: Inference done 1205/26446. 0.1203 s / img. ETA=0:51:50
[06/30 16:59:06] detectron2 INFO: Inference done 1248/26446. 0.1201 s / img. ETA=0:51:39
[06/30 16:59:11] detectron2 INFO: Inference done 1290/26446. 0.1200 s / img. ETA=0:51:33
[06/30 16:59:16] detectron2 INFO: Inference done 1333/26446. 0.1198 s / img. ETA=0:51:23
[06/30 16:59:21] detectron2 INFO: Inference done 1377/26446. 0.1196 s / img. ETA=0:51:12
[06/30 16:59:26] detectron2 INFO: Inference done 1419/26446. 0.1196 s / img. ETA=0:51:05
[06/30 16:59:31] detectron2 INFO: Inference done 1461/26446. 0.1195 s / img. ETA=0:50:58
[06/30 16:59:36] detectron2 INFO: Inference done 1503/26446. 0.1194 s / img. ETA=0:50:52
[06/30 16:59:41] detectron2 INFO: Inference done 1546/26446. 0.1193 s / img. ETA=0:50:42
[06/30 16:59:46] detectron2 INFO: Inference done 1580/26446. 0.1198 s / img. ETA=0:50:52
[06/30 16:59:51] detectron2 INFO: Inference done 1623/26446. 0.1197 s / img. ETA=0:50:44
[06/30 16:59:56] detectron2 INFO: Inference done 1665/26446. 0.1196 s / img. ETA=0:50:37
[06/30 17:00:01] detectron2 INFO: Inference done 1706/26446. 0.1197 s / img. ETA=0:50:33
[06/30 17:00:06] detectron2 INFO: Inference done 1745/26446. 0.1198 s / img. ETA=0:50:31
[06/30 17:00:11] detectron2 INFO: Inference done 1788/26446. 0.1197 s / img. ETA=0:50:22
[06/30 17:00:16] detectron2 INFO: Inference done 1832/26446. 0.1195 s / img. ETA=0:50:13
[06/30 17:00:21] detectron2 INFO: Inference done 1874/26446. 0.1194 s / img. ETA=0:50:06
[06/30 17:00:26] detectron2 INFO: Inference done 1917/26446. 0.1193 s / img. ETA=0:49:58
[06/30 17:00:32] detectron2 INFO: Inference done 1960/26446. 0.1192 s / img. ETA=0:49:51
[06/30 17:00:37] detectron2 INFO: Inference done 2004/26446. 0.1191 s / img. ETA=0:49:41
[06/30 17:00:42] detectron2 INFO: Inference done 2047/26446. 0.1190 s / img. ETA=0:49:34
[06/30 17:00:47] detectron2 INFO: Inference done 2091/26446. 0.1188 s / img. ETA=0:49:25
[06/30 17:00:52] detectron2 INFO: Inference done 2133/26446. 0.1188 s / img. ETA=0:49:20
[06/30 17:00:57] detectron2 INFO: Inference done 2176/26446. 0.1187 s / img. ETA=0:49:13
[06/30 17:01:02] detectron2 INFO: Inference done 2219/26446. 0.1186 s / img. ETA=0:49:05
[06/30 17:01:07] detectron2 INFO: Inference done 2262/26446. 0.1185 s / img. ETA=0:48:57
[06/30 17:01:12] detectron2 INFO: Inference done 2304/26446. 0.1185 s / img. ETA=0:48:52
[06/30 17:01:17] detectron2 INFO: Inference done 2348/26446. 0.1184 s / img. ETA=0:48:44
[06/30 17:01:22] detectron2 INFO: Inference done 2389/26446. 0.1185 s / img. ETA=0:48:40
[06/30 17:01:27] detectron2 INFO: Inference done 2433/26446. 0.1184 s / img. ETA=0:48:32
[06/30 17:01:32] detectron2 INFO: Inference done 2477/26446. 0.1183 s / img. ETA=0:48:25
[06/30 17:01:37] detectron2 INFO: Inference done 2519/26446. 0.1182 s / img. ETA=0:48:19
[06/30 17:01:42] detectron2 INFO: Inference done 2562/26446. 0.1182 s / img. ETA=0:48:12
[06/30 17:01:47] detectron2 INFO: Inference done 2604/26446. 0.1181 s / img. ETA=0:48:07
[06/30 17:01:53] detectron2 INFO: Inference done 2645/26446. 0.1182 s / img. ETA=0:48:03
[06/30 17:01:58] detectron2 INFO: Inference done 2688/26446. 0.1181 s / img. ETA=0:47:56
[06/30 17:02:03] detectron2 INFO: Inference done 2729/26446. 0.1182 s / img. ETA=0:47:53
[06/30 17:02:08] detectron2 INFO: Inference done 2773/26446. 0.1181 s / img. ETA=0:47:45
[06/30 17:02:13] detectron2 INFO: Inference done 2816/26446. 0.1180 s / img. ETA=0:47:39
[06/30 17:02:18] detectron2 INFO: Inference done 2860/26446. 0.1179 s / img. ETA=0:47:31
[06/30 17:02:23] detectron2 INFO: Inference done 2903/26446. 0.1179 s / img. ETA=0:47:24
[06/30 17:02:28] detectron2 INFO: Inference done 2946/26446. 0.1178 s / img. ETA=0:47:18
[06/30 17:02:33] detectron2 INFO: Inference done 2986/26446. 0.1179 s / img. ETA=0:47:14
[06/30 17:02:38] detectron2 INFO: Inference done 3029/26446. 0.1178 s / img. ETA=0:47:08
[06/30 17:02:43] detectron2 INFO: Inference done 3073/26446. 0.1177 s / img. ETA=0:47:00
[06/30 17:02:48] detectron2 INFO: Inference done 3117/26446. 0.1177 s / img. ETA=0:46:53
[06/30 17:02:53] detectron2 INFO: Inference done 3161/26446. 0.1176 s / img. ETA=0:46:46
[06/30 17:02:58] detectron2 INFO: Inference done 3205/26446. 0.1175 s / img. ETA=0:46:39
[06/30 17:03:03] detectron2 INFO: Inference done 3248/26446. 0.1175 s / img. ETA=0:46:33
[06/30 17:03:08] detectron2 INFO: Inference done 3292/26446. 0.1174 s / img. ETA=0:46:26
[06/30 17:03:13] detectron2 INFO: Inference done 3337/26446. 0.1173 s / img. ETA=0:46:18
[06/30 17:03:19] detectron2 INFO: Inference done 3381/26446. 0.1172 s / img. ETA=0:46:12
[06/30 17:03:24] detectron2 INFO: Inference done 3425/26446. 0.1172 s / img. ETA=0:46:05
[06/30 17:03:29] detectron2 INFO: Inference done 3469/26446. 0.1171 s / img. ETA=0:45:58
[06/30 17:03:34] detectron2 INFO: Inference done 3514/26446. 0.1170 s / img. ETA=0:45:51
[06/30 17:03:39] detectron2 INFO: Inference done 3558/26446. 0.1170 s / img. ETA=0:45:44
[06/30 17:03:44] detectron2 INFO: Inference done 3602/26446. 0.1169 s / img. ETA=0:45:38
[06/30 17:03:49] detectron2 INFO: Inference done 3645/26446. 0.1169 s / img. ETA=0:45:32
[06/30 17:03:54] detectron2 INFO: Inference done 3689/26446. 0.1168 s / img. ETA=0:45:26
[06/30 17:03:59] detectron2 INFO: Inference done 3733/26446. 0.1168 s / img. ETA=0:45:19
[06/30 17:04:04] detectron2 INFO: Inference done 3776/26446. 0.1168 s / img. ETA=0:45:13
[06/30 17:04:09] detectron2 INFO: Inference done 3818/26446. 0.1168 s / img. ETA=0:45:08
[06/30 17:04:14] detectron2 INFO: Inference done 3862/26446. 0.1167 s / img. ETA=0:45:02
[06/30 17:04:19] detectron2 INFO: Inference done 3904/26446. 0.1167 s / img. ETA=0:44:57
[06/30 17:04:24] detectron2 INFO: Inference done 3948/26446. 0.1167 s / img. ETA=0:44:51
[06/30 17:04:29] detectron2 INFO: Inference done 3991/26446. 0.1166 s / img. ETA=0:44:45
[06/30 17:04:34] detectron2 INFO: Inference done 4035/26446. 0.1166 s / img. ETA=0:44:38
[06/30 17:04:39] detectron2 INFO: Inference done 4079/26446. 0.1165 s / img. ETA=0:44:32
[06/30 17:04:44] detectron2 INFO: Inference done 4122/26446. 0.1165 s / img. ETA=0:44:26
[06/30 17:04:50] detectron2 INFO: Inference done 4166/26446. 0.1164 s / img. ETA=0:44:20
[06/30 17:04:55] detectron2 INFO: Inference done 4209/26446. 0.1164 s / img. ETA=0:44:14
[06/30 17:05:00] detectron2 INFO: Inference done 4253/26446. 0.1164 s / img. ETA=0:44:08
[06/30 17:05:05] detectron2 INFO: Inference done 4297/26446. 0.1163 s / img. ETA=0:44:02
[06/30 17:05:10] detectron2 INFO: Inference done 4341/26446. 0.1163 s / img. ETA=0:43:56
[06/30 17:05:15] detectron2 INFO: Inference done 4384/26446. 0.1163 s / img. ETA=0:43:51
[06/30 17:05:20] detectron2 INFO: Inference done 4428/26446. 0.1163 s / img. ETA=0:43:44
[06/30 17:05:25] detectron2 INFO: Inference done 4472/26446. 0.1162 s / img. ETA=0:43:38
[06/30 17:05:30] detectron2 INFO: Inference done 4515/26446. 0.1162 s / img. ETA=0:43:33
[06/30 17:05:35] detectron2 INFO: Inference done 4559/26446. 0.1162 s / img. ETA=0:43:27
[06/30 17:05:40] detectron2 INFO: Inference done 4602/26446. 0.1161 s / img. ETA=0:43:21
[06/30 17:05:45] detectron2 INFO: Inference done 4645/26446. 0.1161 s / img. ETA=0:43:16
[06/30 17:05:50] detectron2 INFO: Inference done 4686/26446. 0.1162 s / img. ETA=0:43:12
[06/30 17:05:55] detectron2 INFO: Inference done 4725/26446. 0.1162 s / img. ETA=0:43:09
[06/30 17:06:01] detectron2 INFO: Inference done 4769/26446. 0.1162 s / img. ETA=0:43:03
[06/30 17:06:06] detectron2 INFO: Inference done 4813/26446. 0.1162 s / img. ETA=0:42:57
[06/30 17:06:11] detectron2 INFO: Inference done 4857/26446. 0.1162 s / img. ETA=0:42:51
[06/30 17:06:16] detectron2 INFO: Inference done 4898/26446. 0.1162 s / img. ETA=0:42:48
[06/30 17:06:21] detectron2 INFO: Inference done 4933/26446. 0.1164 s / img. ETA=0:42:47
[06/30 17:06:26] detectron2 INFO: Inference done 4974/26446. 0.1164 s / img. ETA=0:42:43
[06/30 17:06:31] detectron2 INFO: Inference done 5016/26446. 0.1164 s / img. ETA=0:42:38
[06/30 17:06:36] detectron2 INFO: Inference done 5058/26446. 0.1164 s / img. ETA=0:42:34
[06/30 17:06:41] detectron2 INFO: Inference done 5100/26446. 0.1164 s / img. ETA=0:42:29
[06/30 17:06:46] detectron2 INFO: Inference done 5142/26446. 0.1165 s / img. ETA=0:42:24
[06/30 17:06:51] detectron2 INFO: Inference done 5183/26446. 0.1165 s / img. ETA=0:42:20
[06/30 17:06:56] detectron2 INFO: Inference done 5225/26446. 0.1165 s / img. ETA=0:42:15
[06/30 17:07:02] detectron2 INFO: Inference done 5267/26446. 0.1165 s / img. ETA=0:42:10
[06/30 17:07:07] detectron2 INFO: Inference done 5310/26446. 0.1165 s / img. ETA=0:42:05
[06/30 17:07:12] detectron2 INFO: Inference done 5353/26446. 0.1165 s / img. ETA=0:42:00
[06/30 17:07:17] detectron2 INFO: Inference done 5396/26446. 0.1165 s / img. ETA=0:41:54
[06/30 17:07:22] detectron2 INFO: Inference done 5438/26446. 0.1165 s / img. ETA=0:41:50
[06/30 17:07:27] detectron2 INFO: Inference done 5481/26446. 0.1165 s / img. ETA=0:41:44
[06/30 17:07:32] detectron2 INFO: Inference done 5522/26446. 0.1165 s / img. ETA=0:41:40
[06/30 17:07:37] detectron2 INFO: Inference done 5564/26446. 0.1165 s / img. ETA=0:41:35
[06/30 17:07:42] detectron2 INFO: Inference done 5605/26446. 0.1166 s / img. ETA=0:41:31
[06/30 17:07:47] detectron2 INFO: Inference done 5647/26446. 0.1166 s / img. ETA=0:41:26
[06/30 17:07:52] detectron2 INFO: Inference done 5689/26446. 0.1166 s / img. ETA=0:41:21
[06/30 17:07:57] detectron2 INFO: Inference done 5731/26446. 0.1166 s / img. ETA=0:41:17
[06/30 17:08:03] detectron2 INFO: Inference done 5773/26446. 0.1166 s / img. ETA=0:41:12
[06/30 17:08:08] detectron2 INFO: Inference done 5814/26446. 0.1166 s / img. ETA=0:41:07
[06/30 17:08:13] detectron2 INFO: Inference done 5856/26446. 0.1166 s / img. ETA=0:41:03
[06/30 17:08:18] detectron2 INFO: Inference done 5898/26446. 0.1166 s / img. ETA=0:40:58
[06/30 17:08:23] detectron2 INFO: Inference done 5940/26446. 0.1167 s / img. ETA=0:40:53
[06/30 17:08:28] detectron2 INFO: Inference done 5981/26446. 0.1167 s / img. ETA=0:40:48
[06/30 17:08:33] detectron2 INFO: Inference done 6023/26446. 0.1167 s / img. ETA=0:40:44
[06/30 17:08:38] detectron2 INFO: Inference done 6065/26446. 0.1167 s / img. ETA=0:40:38
[06/30 17:08:43] detectron2 INFO: Inference done 6108/26446. 0.1167 s / img. ETA=0:40:33
[06/30 17:08:48] detectron2 INFO: Inference done 6149/26446. 0.1167 s / img. ETA=0:40:29
[06/30 17:08:53] detectron2 INFO: Inference done 6189/26446. 0.1167 s / img. ETA=0:40:25
[06/30 17:08:58] detectron2 INFO: Inference done 6230/26446. 0.1168 s / img. ETA=0:40:21
[06/30 17:09:03] detectron2 INFO: Inference done 6271/26446. 0.1168 s / img. ETA=0:40:16
[06/30 17:09:08] detectron2 INFO: Inference done 6312/26446. 0.1168 s / img. ETA=0:40:12
[06/30 17:09:13] detectron2 INFO: Inference done 6354/26446. 0.1168 s / img. ETA=0:40:07
[06/30 17:09:19] detectron2 INFO: Inference done 6396/26446. 0.1168 s / img. ETA=0:40:02
[06/30 17:09:24] detectron2 INFO: Inference done 6437/26446. 0.1168 s / img. ETA=0:39:58
[06/30 17:09:29] detectron2 INFO: Inference done 6478/26446. 0.1169 s / img. ETA=0:39:53
[06/30 17:09:34] detectron2 INFO: Inference done 6520/26446. 0.1169 s / img. ETA=0:39:48
[06/30 17:09:39] detectron2 INFO: Inference done 6560/26446. 0.1169 s / img. ETA=0:39:44
[06/30 17:09:44] detectron2 INFO: Inference done 6600/26446. 0.1170 s / img. ETA=0:39:40
[06/30 17:09:49] detectron2 INFO: Inference done 6642/26446. 0.1170 s / img. ETA=0:39:35
[06/30 17:09:54] detectron2 INFO: Inference done 6683/26446. 0.1170 s / img. ETA=0:39:31
[06/30 17:09:59] detectron2 INFO: Inference done 6725/26446. 0.1170 s / img. ETA=0:39:26
[06/30 17:10:04] detectron2 INFO: Inference done 6766/26446. 0.1170 s / img. ETA=0:39:21
[06/30 17:10:09] detectron2 INFO: Inference done 6808/26446. 0.1170 s / img. ETA=0:39:16
[06/30 17:10:14] detectron2 INFO: Inference done 6849/26446. 0.1170 s / img. ETA=0:39:11
[06/30 17:10:19] detectron2 INFO: Inference done 6891/26446. 0.1170 s / img. ETA=0:39:06
[06/30 17:10:24] detectron2 INFO: Inference done 6933/26446. 0.1170 s / img. ETA=0:39:02
[06/30 17:10:29] detectron2 INFO: Inference done 6974/26446. 0.1170 s / img. ETA=0:38:57
[06/30 17:10:34] detectron2 INFO: Inference done 7016/26446. 0.1170 s / img. ETA=0:38:52
[06/30 17:10:39] detectron2 INFO: Inference done 7058/26446. 0.1170 s / img. ETA=0:38:47
[06/30 17:10:44] detectron2 INFO: Inference done 7100/26446. 0.1170 s / img. ETA=0:38:42
[06/30 17:10:50] detectron2 INFO: Inference done 7142/26446. 0.1170 s / img. ETA=0:38:37
[06/30 17:10:55] detectron2 INFO: Inference done 7185/26446. 0.1170 s / img. ETA=0:38:32
[06/30 17:11:00] detectron2 INFO: Inference done 7228/26446. 0.1170 s / img. ETA=0:38:26
[06/30 17:11:05] detectron2 INFO: Inference done 7270/26446. 0.1170 s / img. ETA=0:38:22
[06/30 17:11:10] detectron2 INFO: Inference done 7311/26446. 0.1170 s / img. ETA=0:38:17
[06/30 17:11:15] detectron2 INFO: Inference done 7353/26446. 0.1171 s / img. ETA=0:38:12
[06/30 17:11:20] detectron2 INFO: Inference done 7395/26446. 0.1171 s / img. ETA=0:38:07
[06/30 17:11:25] detectron2 INFO: Inference done 7437/26446. 0.1171 s / img. ETA=0:38:02
[06/30 17:11:30] detectron2 INFO: Inference done 7479/26446. 0.1171 s / img. ETA=0:37:57
[06/30 17:11:35] detectron2 INFO: Inference done 7510/26446. 0.1171 s / img. ETA=0:37:57
[06/30 17:11:40] detectron2 INFO: Inference done 7552/26446. 0.1171 s / img. ETA=0:37:52
[06/30 17:11:45] detectron2 INFO: Inference done 7594/26446. 0.1171 s / img. ETA=0:37:47
[06/30 17:11:51] detectron2 INFO: Inference done 7635/26446. 0.1171 s / img. ETA=0:37:42
[06/30 17:11:56] detectron2 INFO: Inference done 7677/26446. 0.1171 s / img. ETA=0:37:37
[06/30 17:12:01] detectron2 INFO: Inference done 7719/26446. 0.1171 s / img. ETA=0:37:32
[06/30 17:12:06] detectron2 INFO: Inference done 7760/26446. 0.1171 s / img. ETA=0:37:28
[06/30 17:12:11] detectron2 INFO: Inference done 7802/26446. 0.1171 s / img. ETA=0:37:23
[06/30 17:12:16] detectron2 INFO: Inference done 7843/26446. 0.1171 s / img. ETA=0:37:18
[06/30 17:12:21] detectron2 INFO: Inference done 7885/26446. 0.1171 s / img. ETA=0:37:13
[06/30 17:12:26] detectron2 INFO: Inference done 7927/26446. 0.1171 s / img. ETA=0:37:08
[06/30 17:12:31] detectron2 INFO: Inference done 7969/26446. 0.1171 s / img. ETA=0:37:03
[06/30 17:12:36] detectron2 INFO: Inference done 8010/26446. 0.1172 s / img. ETA=0:36:58
[06/30 17:12:41] detectron2 INFO: Inference done 8051/26446. 0.1172 s / img. ETA=0:36:53
[06/30 17:12:46] detectron2 INFO: Inference done 8092/26446. 0.1172 s / img. ETA=0:36:49
[06/30 17:12:51] detectron2 INFO: Inference done 8132/26446. 0.1172 s / img. ETA=0:36:45
[06/30 17:12:56] detectron2 INFO: Inference done 8174/26446. 0.1172 s / img. ETA=0:36:40
[06/30 17:13:02] detectron2 INFO: Inference done 8216/26446. 0.1172 s / img. ETA=0:36:35
[06/30 17:13:07] detectron2 INFO: Inference done 8258/26446. 0.1172 s / img. ETA=0:36:30
[06/30 17:13:12] detectron2 INFO: Inference done 8300/26446. 0.1172 s / img. ETA=0:36:25
[06/30 17:13:17] detectron2 INFO: Inference done 8342/26446. 0.1172 s / img. ETA=0:36:20
[06/30 17:13:22] detectron2 INFO: Inference done 8383/26446. 0.1173 s / img. ETA=0:36:15
[06/30 17:13:27] detectron2 INFO: Inference done 8425/26446. 0.1173 s / img. ETA=0:36:10
[06/30 17:13:32] detectron2 INFO: Inference done 8466/26446. 0.1173 s / img. ETA=0:36:05
[06/30 17:13:37] detectron2 INFO: Inference done 8508/26446. 0.1173 s / img. ETA=0:36:00
[06/30 17:13:42] detectron2 INFO: Inference done 8550/26446. 0.1173 s / img. ETA=0:35:55
[06/30 17:13:47] detectron2 INFO: Inference done 8592/26446. 0.1173 s / img. ETA=0:35:50
[06/30 17:13:52] detectron2 INFO: Inference done 8633/26446. 0.1173 s / img. ETA=0:35:45
[06/30 17:13:57] detectron2 INFO: Inference done 8666/26446. 0.1174 s / img. ETA=0:35:44
[06/30 17:14:02] detectron2 INFO: Inference done 8700/26446. 0.1175 s / img. ETA=0:35:42
[06/30 17:14:07] detectron2 INFO: Inference done 8740/26446. 0.1176 s / img. ETA=0:35:37
[06/30 17:14:13] detectron2 INFO: Inference done 8782/26446. 0.1176 s / img. ETA=0:35:32
[06/30 17:14:18] detectron2 INFO: Inference done 8824/26446. 0.1176 s / img. ETA=0:35:27
[06/30 17:14:23] detectron2 INFO: Inference done 8866/26446. 0.1176 s / img. ETA=0:35:22
[06/30 17:14:28] detectron2 INFO: Inference done 8908/26446. 0.1176 s / img. ETA=0:35:17
[06/30 17:14:33] detectron2 INFO: Inference done 8950/26446. 0.1176 s / img. ETA=0:35:12
[06/30 17:14:38] detectron2 INFO: Inference done 8992/26446. 0.1176 s / img. ETA=0:35:07
[06/30 17:14:43] detectron2 INFO: Inference done 9034/26446. 0.1175 s / img. ETA=0:35:02
[06/30 17:14:48] detectron2 INFO: Inference done 9076/26446. 0.1175 s / img. ETA=0:34:57
[06/30 17:14:53] detectron2 INFO: Inference done 9117/26446. 0.1176 s / img. ETA=0:34:52
[06/30 17:14:58] detectron2 INFO: Inference done 9159/26446. 0.1176 s / img. ETA=0:34:47
[06/30 17:15:03] detectron2 INFO: Inference done 9201/26446. 0.1176 s / img. ETA=0:34:42
[06/30 17:15:08] detectron2 INFO: Inference done 9243/26446. 0.1176 s / img. ETA=0:34:37
[06/30 17:15:13] detectron2 INFO: Inference done 9285/26446. 0.1176 s / img. ETA=0:34:32
[06/30 17:15:18] detectron2 INFO: Inference done 9326/26446. 0.1176 s / img. ETA=0:34:27
[06/30 17:15:23] detectron2 INFO: Inference done 9368/26446. 0.1176 s / img. ETA=0:34:22
[06/30 17:15:28] detectron2 INFO: Inference done 9409/26446. 0.1176 s / img. ETA=0:34:17
[06/30 17:15:33] detectron2 INFO: Inference done 9451/26446. 0.1176 s / img. ETA=0:34:12
[06/30 17:15:38] detectron2 INFO: Inference done 9493/26446. 0.1176 s / img. ETA=0:34:07
[06/30 17:15:43] detectron2 INFO: Inference done 9535/26446. 0.1176 s / img. ETA=0:34:01
[06/30 17:15:49] detectron2 INFO: Inference done 9577/26446. 0.1176 s / img. ETA=0:33:56
[06/30 17:15:54] detectron2 INFO: Inference done 9619/26446. 0.1176 s / img. ETA=0:33:51
[06/30 17:15:59] detectron2 INFO: Inference done 9661/26446. 0.1176 s / img. ETA=0:33:46
[06/30 17:16:04] detectron2 INFO: Inference done 9703/26446. 0.1176 s / img. ETA=0:33:41
[06/30 17:16:09] detectron2 INFO: Inference done 9744/26446. 0.1176 s / img. ETA=0:33:37
[06/30 17:16:14] detectron2 INFO: Inference done 9785/26446. 0.1176 s / img. ETA=0:33:32
[06/30 17:16:19] detectron2 INFO: Inference done 9825/26446. 0.1176 s / img. ETA=0:33:27
[06/30 17:16:24] detectron2 INFO: Inference done 9867/26446. 0.1176 s / img. ETA=0:33:22
[06/30 17:16:29] detectron2 INFO: Inference done 9909/26446. 0.1176 s / img. ETA=0:33:17
[06/30 17:16:34] detectron2 INFO: Inference done 9949/26446. 0.1176 s / img. ETA=0:33:13
[06/30 17:16:39] detectron2 INFO: Inference done 9990/26446. 0.1176 s / img. ETA=0:33:08
[06/30 17:16:44] detectron2 INFO: Inference done 10032/26446. 0.1177 s / img. ETA=0:33:03
[06/30 17:16:49] detectron2 INFO: Inference done 10072/26446. 0.1177 s / img. ETA=0:32:58
[06/30 17:16:54] detectron2 INFO: Inference done 10114/26446. 0.1177 s / img. ETA=0:32:53
[06/30 17:16:59] detectron2 INFO: Inference done 10155/26446. 0.1177 s / img. ETA=0:32:48
[06/30 17:17:05] detectron2 INFO: Inference done 10196/26446. 0.1177 s / img. ETA=0:32:44
[06/30 17:17:10] detectron2 INFO: Inference done 10238/26446. 0.1177 s / img. ETA=0:32:39
[06/30 17:17:15] detectron2 INFO: Inference done 10279/26446. 0.1177 s / img. ETA=0:32:34
[06/30 17:17:20] detectron2 INFO: Inference done 10321/26446. 0.1177 s / img. ETA=0:32:29
[06/30 17:17:25] detectron2 INFO: Inference done 10363/26446. 0.1177 s / img. ETA=0:32:24
[06/30 17:17:30] detectron2 INFO: Inference done 10403/26446. 0.1177 s / img. ETA=0:32:19
[06/30 17:17:35] detectron2 INFO: Inference done 10442/26446. 0.1178 s / img. ETA=0:32:15
[06/30 17:17:40] detectron2 INFO: Inference done 10482/26446. 0.1178 s / img. ETA=0:32:10
[06/30 17:17:45] detectron2 INFO: Inference done 10522/26446. 0.1178 s / img. ETA=0:32:06
[06/30 17:17:50] detectron2 INFO: Inference done 10564/26446. 0.1178 s / img. ETA=0:32:01
[06/30 17:17:55] detectron2 INFO: Inference done 10606/26446. 0.1178 s / img. ETA=0:31:56
[06/30 17:18:00] detectron2 INFO: Inference done 10647/26446. 0.1178 s / img. ETA=0:31:51
[06/30 17:18:05] detectron2 INFO: Inference done 10689/26446. 0.1178 s / img. ETA=0:31:46
[06/30 17:18:10] detectron2 INFO: Inference done 10731/26446. 0.1178 s / img. ETA=0:31:41
[06/30 17:18:15] detectron2 INFO: Inference done 10773/26446. 0.1178 s / img. ETA=0:31:35
[06/30 17:18:20] detectron2 INFO: Inference done 10815/26446. 0.1178 s / img. ETA=0:31:30
[06/30 17:18:25] detectron2 INFO: Inference done 10857/26446. 0.1178 s / img. ETA=0:31:25
[06/30 17:18:31] detectron2 INFO: Inference done 10899/26446. 0.1178 s / img. ETA=0:31:20
[06/30 17:18:36] detectron2 INFO: Inference done 10940/26446. 0.1178 s / img. ETA=0:31:15
[06/30 17:18:41] detectron2 INFO: Inference done 10981/26446. 0.1178 s / img. ETA=0:31:11
[06/30 17:18:46] detectron2 INFO: Inference done 11023/26446. 0.1178 s / img. ETA=0:31:05
[06/30 17:18:51] detectron2 INFO: Inference done 11065/26446. 0.1178 s / img. ETA=0:31:00
[06/30 17:18:56] detectron2 INFO: Inference done 11107/26446. 0.1178 s / img. ETA=0:30:55
[06/30 17:19:01] detectron2 INFO: Inference done 11148/26446. 0.1178 s / img. ETA=0:30:50
[06/30 17:19:06] detectron2 INFO: Inference done 11190/26446. 0.1178 s / img. ETA=0:30:45
[06/30 17:19:11] detectron2 INFO: Inference done 11232/26446. 0.1178 s / img. ETA=0:30:40
[06/30 17:19:16] detectron2 INFO: Inference done 11273/26446. 0.1178 s / img. ETA=0:30:35
[06/30 17:19:21] detectron2 INFO: Inference done 11315/26446. 0.1178 s / img. ETA=0:30:30
[06/30 17:19:26] detectron2 INFO: Inference done 11356/26446. 0.1178 s / img. ETA=0:30:25
[06/30 17:19:31] detectron2 INFO: Inference done 11398/26446. 0.1178 s / img. ETA=0:30:20
[06/30 17:19:36] detectron2 INFO: Inference done 11440/26446. 0.1178 s / img. ETA=0:30:15
[06/30 17:19:41] detectron2 INFO: Inference done 11481/26446. 0.1178 s / img. ETA=0:30:10
[06/30 17:19:46] detectron2 INFO: Inference done 11523/26446. 0.1178 s / img. ETA=0:30:05
[06/30 17:19:52] detectron2 INFO: Inference done 11565/26446. 0.1178 s / img. ETA=0:30:00
[06/30 17:19:57] detectron2 INFO: Inference done 11606/26446. 0.1178 s / img. ETA=0:29:55
[06/30 17:20:02] detectron2 INFO: Inference done 11648/26446. 0.1178 s / img. ETA=0:29:50
[06/30 17:20:07] detectron2 INFO: Inference done 11689/26446. 0.1178 s / img. ETA=0:29:45
[06/30 17:20:12] detectron2 INFO: Inference done 11731/26446. 0.1178 s / img. ETA=0:29:40
[06/30 17:20:17] detectron2 INFO: Inference done 11772/26446. 0.1178 s / img. ETA=0:29:35
[06/30 17:20:22] detectron2 INFO: Inference done 11813/26446. 0.1178 s / img. ETA=0:29:30
[06/30 17:20:27] detectron2 INFO: Inference done 11855/26446. 0.1178 s / img. ETA=0:29:25
[06/30 17:20:32] detectron2 INFO: Inference done 11897/26446. 0.1178 s / img. ETA=0:29:20
[06/30 17:20:37] detectron2 INFO: Inference done 11939/26446. 0.1178 s / img. ETA=0:29:15
[06/30 17:20:42] detectron2 INFO: Inference done 11980/26446. 0.1178 s / img. ETA=0:29:10
[06/30 17:20:47] detectron2 INFO: Inference done 12023/26446. 0.1178 s / img. ETA=0:29:05
[06/30 17:20:52] detectron2 INFO: Inference done 12066/26446. 0.1178 s / img. ETA=0:29:00
[06/30 17:20:57] detectron2 INFO: Inference done 12108/26446. 0.1178 s / img. ETA=0:28:54
[06/30 17:21:02] detectron2 INFO: Inference done 12149/26446. 0.1178 s / img. ETA=0:28:50
[06/30 17:21:07] detectron2 INFO: Inference done 12191/26446. 0.1178 s / img. ETA=0:28:44
[06/30 17:21:12] detectron2 INFO: Inference done 12234/26446. 0.1178 s / img. ETA=0:28:39
[06/30 17:21:18] detectron2 INFO: Inference done 12276/26446. 0.1178 s / img. ETA=0:28:34
[06/30 17:21:23] detectron2 INFO: Inference done 12318/26446. 0.1178 s / img. ETA=0:28:29
[06/30 17:21:28] detectron2 INFO: Inference done 12360/26446. 0.1178 s / img. ETA=0:28:24
[06/30 17:21:33] detectron2 INFO: Inference done 12401/26446. 0.1178 s / img. ETA=0:28:19
[06/30 17:21:38] detectron2 INFO: Inference done 12442/26446. 0.1178 s / img. ETA=0:28:14
[06/30 17:21:43] detectron2 INFO: Inference done 12483/26446. 0.1178 s / img. ETA=0:28:09
[06/30 17:21:48] detectron2 INFO: Inference done 12524/26446. 0.1179 s / img. ETA=0:28:05
[06/30 17:21:53] detectron2 INFO: Inference done 12565/26446. 0.1179 s / img. ETA=0:28:00
[06/30 17:21:58] detectron2 INFO: Inference done 12607/26446. 0.1179 s / img. ETA=0:27:55
[06/30 17:22:03] detectron2 INFO: Inference done 12649/26446. 0.1179 s / img. ETA=0:27:49
[06/30 17:22:08] detectron2 INFO: Inference done 12691/26446. 0.1179 s / img. ETA=0:27:44
[06/30 17:22:13] detectron2 INFO: Inference done 12733/26446. 0.1179 s / img. ETA=0:27:39
[06/30 17:22:18] detectron2 INFO: Inference done 12775/26446. 0.1179 s / img. ETA=0:27:34
[06/30 17:22:23] detectron2 INFO: Inference done 12817/26446. 0.1179 s / img. ETA=0:27:29
[06/30 17:22:28] detectron2 INFO: Inference done 12859/26446. 0.1179 s / img. ETA=0:27:24
[06/30 17:22:34] detectron2 INFO: Inference done 12901/26446. 0.1179 s / img. ETA=0:27:19
[06/30 17:22:39] detectron2 INFO: Inference done 12943/26446. 0.1179 s / img. ETA=0:27:14
[06/30 17:22:44] detectron2 INFO: Inference done 12984/26446. 0.1179 s / img. ETA=0:27:09
[06/30 17:22:49] detectron2 INFO: Inference done 13027/26446. 0.1179 s / img. ETA=0:27:04
[06/30 17:22:54] detectron2 INFO: Inference done 13069/26446. 0.1178 s / img. ETA=0:26:58
[06/30 17:22:59] detectron2 INFO: Inference done 13111/26446. 0.1178 s / img. ETA=0:26:53
[06/30 17:23:04] detectron2 INFO: Inference done 13153/26446. 0.1178 s / img. ETA=0:26:48
[06/30 17:23:09] detectron2 INFO: Inference done 13195/26446. 0.1178 s / img. ETA=0:26:43
[06/30 17:23:14] detectron2 INFO: Inference done 13237/26446. 0.1178 s / img. ETA=0:26:38
[06/30 17:23:19] detectron2 INFO: Inference done 13279/26446. 0.1178 s / img. ETA=0:26:33
[06/30 17:23:24] detectron2 INFO: Inference done 13321/26446. 0.1178 s / img. ETA=0:26:28
[06/30 17:23:29] detectron2 INFO: Inference done 13361/26446. 0.1179 s / img. ETA=0:26:23
[06/30 17:23:34] detectron2 INFO: Inference done 13403/26446. 0.1179 s / img. ETA=0:26:18
[06/30 17:23:39] detectron2 INFO: Inference done 13445/26446. 0.1179 s / img. ETA=0:26:13
[06/30 17:23:44] detectron2 INFO: Inference done 13487/26446. 0.1179 s / img. ETA=0:26:08
[06/30 17:23:49] detectron2 INFO: Inference done 13529/26446. 0.1179 s / img. ETA=0:26:03
[06/30 17:23:55] detectron2 INFO: Inference done 13571/26446. 0.1179 s / img. ETA=0:25:58
[06/30 17:24:00] detectron2 INFO: Inference done 13611/26446. 0.1179 s / img. ETA=0:25:53
[06/30 17:24:05] detectron2 INFO: Inference done 13654/26446. 0.1179 s / img. ETA=0:25:48
[06/30 17:24:10] detectron2 INFO: Inference done 13696/26446. 0.1179 s / img. ETA=0:25:43
[06/30 17:24:15] detectron2 INFO: Inference done 13736/26446. 0.1179 s / img. ETA=0:25:38
[06/30 17:24:20] detectron2 INFO: Inference done 13776/26446. 0.1179 s / img. ETA=0:25:33
[06/30 17:24:25] detectron2 INFO: Inference done 13817/26446. 0.1179 s / img. ETA=0:25:28
[06/30 17:24:30] detectron2 INFO: Inference done 13858/26446. 0.1179 s / img. ETA=0:25:24
[06/30 17:24:35] detectron2 INFO: Inference done 13899/26446. 0.1179 s / img. ETA=0:25:19
[06/30 17:24:40] detectron2 INFO: Inference done 13941/26446. 0.1179 s / img. ETA=0:25:14
[06/30 17:24:45] detectron2 INFO: Inference done 13983/26446. 0.1179 s / img. ETA=0:25:08
[06/30 17:24:50] detectron2 INFO: Inference done 14025/26446. 0.1179 s / img. ETA=0:25:03
[06/30 17:24:55] detectron2 INFO: Inference done 14067/26446. 0.1179 s / img. ETA=0:24:58
[06/30 17:25:00] detectron2 INFO: Inference done 14108/26446. 0.1179 s / img. ETA=0:24:53
[06/30 17:25:05] detectron2 INFO: Inference done 14150/26446. 0.1179 s / img. ETA=0:24:48
[06/30 17:25:10] detectron2 INFO: Inference done 14192/26446. 0.1179 s / img. ETA=0:24:43
[06/30 17:25:16] detectron2 INFO: Inference done 14234/26446. 0.1179 s / img. ETA=0:24:38
[06/30 17:25:21] detectron2 INFO: Inference done 14276/26446. 0.1179 s / img. ETA=0:24:33
[06/30 17:25:26] detectron2 INFO: Inference done 14318/26446. 0.1179 s / img. ETA=0:24:28
[06/30 17:25:31] detectron2 INFO: Inference done 14359/26446. 0.1179 s / img. ETA=0:24:23
[06/30 17:25:36] detectron2 INFO: Inference done 14400/26446. 0.1179 s / img. ETA=0:24:18
[06/30 17:25:41] detectron2 INFO: Inference done 14442/26446. 0.1179 s / img. ETA=0:24:13
[06/30 17:25:46] detectron2 INFO: Inference done 14484/26446. 0.1179 s / img. ETA=0:24:08
[06/30 17:25:51] detectron2 INFO: Inference done 14526/26446. 0.1179 s / img. ETA=0:24:03
[06/30 17:25:56] detectron2 INFO: Inference done 14568/26446. 0.1179 s / img. ETA=0:23:58
[06/30 17:26:01] detectron2 INFO: Inference done 14610/26446. 0.1179 s / img. ETA=0:23:52
[06/30 17:26:06] detectron2 INFO: Inference done 14651/26446. 0.1179 s / img. ETA=0:23:48
[06/30 17:26:11] detectron2 INFO: Inference done 14693/26446. 0.1179 s / img. ETA=0:23:42
[06/30 17:26:16] detectron2 INFO: Inference done 14735/26446. 0.1179 s / img. ETA=0:23:37
[06/30 17:26:21] detectron2 INFO: Inference done 14776/26446. 0.1179 s / img. ETA=0:23:32
[06/30 17:26:26] detectron2 INFO: Inference done 14806/26446. 0.1180 s / img. ETA=0:23:30
[06/30 17:26:31] detectron2 INFO: Inference done 14848/26446. 0.1180 s / img. ETA=0:23:25
[06/30 17:26:36] detectron2 INFO: Inference done 14889/26446. 0.1180 s / img. ETA=0:23:20
[06/30 17:26:42] detectron2 INFO: Inference done 14931/26446. 0.1180 s / img. ETA=0:23:15
[06/30 17:26:47] detectron2 INFO: Inference done 14973/26446. 0.1180 s / img. ETA=0:23:10
[06/30 17:26:52] detectron2 INFO: Inference done 15015/26446. 0.1180 s / img. ETA=0:23:05
[06/30 17:26:57] detectron2 INFO: Inference done 15056/26446. 0.1180 s / img. ETA=0:23:00
[06/30 17:27:02] detectron2 INFO: Inference done 15097/26446. 0.1180 s / img. ETA=0:22:55
[06/30 17:27:07] detectron2 INFO: Inference done 15139/26446. 0.1180 s / img. ETA=0:22:50
[06/30 17:27:12] detectron2 INFO: Inference done 15181/26446. 0.1180 s / img. ETA=0:22:45
[06/30 17:27:17] detectron2 INFO: Inference done 15224/26446. 0.1180 s / img. ETA=0:22:39
[06/30 17:27:22] detectron2 INFO: Inference done 15266/26446. 0.1180 s / img. ETA=0:22:34
[06/30 17:27:27] detectron2 INFO: Inference done 15308/26446. 0.1180 s / img. ETA=0:22:29
[06/30 17:27:32] detectron2 INFO: Inference done 15350/26446. 0.1180 s / img. ETA=0:22:24
[06/30 17:27:37] detectron2 INFO: Inference done 15392/26446. 0.1180 s / img. ETA=0:22:19
[06/30 17:27:42] detectron2 INFO: Inference done 15434/26446. 0.1180 s / img. ETA=0:22:14
[06/30 17:27:47] detectron2 INFO: Inference done 15477/26446. 0.1180 s / img. ETA=0:22:08
[06/30 17:27:52] detectron2 INFO: Inference done 15519/26446. 0.1180 s / img. ETA=0:22:03
[06/30 17:27:57] detectron2 INFO: Inference done 15561/26446. 0.1180 s / img. ETA=0:21:58
[06/30 17:28:02] detectron2 INFO: Inference done 15602/26446. 0.1180 s / img. ETA=0:21:53
[06/30 17:28:08] detectron2 INFO: Inference done 15644/26446. 0.1180 s / img. ETA=0:21:48
[06/30 17:28:13] detectron2 INFO: Inference done 15686/26446. 0.1180 s / img. ETA=0:21:43
[06/30 17:28:18] detectron2 INFO: Inference done 15728/26446. 0.1180 s / img. ETA=0:21:38
[06/30 17:28:23] detectron2 INFO: Inference done 15769/26446. 0.1180 s / img. ETA=0:21:33
[06/30 17:28:28] detectron2 INFO: Inference done 15811/26446. 0.1180 s / img. ETA=0:21:28
[06/30 17:28:33] detectron2 INFO: Inference done 15852/26446. 0.1180 s / img. ETA=0:21:23
[06/30 17:28:38] detectron2 INFO: Inference done 15894/26446. 0.1180 s / img. ETA=0:21:18
[06/30 17:28:43] detectron2 INFO: Inference done 15935/26446. 0.1180 s / img. ETA=0:21:13
[06/30 17:28:48] detectron2 INFO: Inference done 15976/26446. 0.1180 s / img. ETA=0:21:08
[06/30 17:28:53] detectron2 INFO: Inference done 16017/26446. 0.1180 s / img. ETA=0:21:03
[06/30 17:28:58] detectron2 INFO: Inference done 16059/26446. 0.1180 s / img. ETA=0:20:58
[06/30 17:29:03] detectron2 INFO: Inference done 16102/26446. 0.1180 s / img. ETA=0:20:53
[06/30 17:29:08] detectron2 INFO: Inference done 16143/26446. 0.1180 s / img. ETA=0:20:48
[06/30 17:29:13] detectron2 INFO: Inference done 16185/26446. 0.1180 s / img. ETA=0:20:43
[06/30 17:29:18] detectron2 INFO: Inference done 16227/26446. 0.1180 s / img. ETA=0:20:38
[06/30 17:29:24] detectron2 INFO: Inference done 16269/26446. 0.1180 s / img. ETA=0:20:33
[06/30 17:29:29] detectron2 INFO: Inference done 16311/26446. 0.1180 s / img. ETA=0:20:28
[06/30 17:29:34] detectron2 INFO: Inference done 16353/26446. 0.1180 s / img. ETA=0:20:23
[06/30 17:29:39] detectron2 INFO: Inference done 16395/26446. 0.1180 s / img. ETA=0:20:17
[06/30 17:29:44] detectron2 INFO: Inference done 16437/26446. 0.1180 s / img. ETA=0:20:12
[06/30 17:29:49] detectron2 INFO: Inference done 16479/26446. 0.1180 s / img. ETA=0:20:07
[06/30 17:29:54] detectron2 INFO: Inference done 16520/26446. 0.1180 s / img. ETA=0:20:02
[06/30 17:29:59] detectron2 INFO: Inference done 16561/26446. 0.1180 s / img. ETA=0:19:57
[06/30 17:30:04] detectron2 INFO: Inference done 16598/26446. 0.1181 s / img. ETA=0:19:53
[06/30 17:30:09] detectron2 INFO: Inference done 16640/26446. 0.1181 s / img. ETA=0:19:48
[06/30 17:30:14] detectron2 INFO: Inference done 16682/26446. 0.1181 s / img. ETA=0:19:43
[06/30 17:30:19] detectron2 INFO: Inference done 16725/26446. 0.1180 s / img. ETA=0:19:38
[06/30 17:30:24] detectron2 INFO: Inference done 16766/26446. 0.1181 s / img. ETA=0:19:33
[06/30 17:30:29] detectron2 INFO: Inference done 16807/26446. 0.1181 s / img. ETA=0:19:28
[06/30 17:30:34] detectron2 INFO: Inference done 16848/26446. 0.1181 s / img. ETA=0:19:23
[06/30 17:30:40] detectron2 INFO: Inference done 16890/26446. 0.1181 s / img. ETA=0:19:18
[06/30 17:30:45] detectron2 INFO: Inference done 16931/26446. 0.1181 s / img. ETA=0:19:13
[06/30 17:30:50] detectron2 INFO: Inference done 16973/26446. 0.1181 s / img. ETA=0:19:08
[06/30 17:30:55] detectron2 INFO: Inference done 17015/26446. 0.1181 s / img. ETA=0:19:03
[06/30 17:31:00] detectron2 INFO: Inference done 17057/26446. 0.1181 s / img. ETA=0:18:58
[06/30 17:31:05] detectron2 INFO: Inference done 17099/26446. 0.1181 s / img. ETA=0:18:53
[06/30 17:31:10] detectron2 INFO: Inference done 17141/26446. 0.1181 s / img. ETA=0:18:47
[06/30 17:31:15] detectron2 INFO: Inference done 17182/26446. 0.1181 s / img. ETA=0:18:43
[06/30 17:31:20] detectron2 INFO: Inference done 17225/26446. 0.1181 s / img. ETA=0:18:37
[06/30 17:31:25] detectron2 INFO: Inference done 17267/26446. 0.1181 s / img. ETA=0:18:32
[06/30 17:31:30] detectron2 INFO: Inference done 17308/26446. 0.1181 s / img. ETA=0:18:27
[06/30 17:31:35] detectron2 INFO: Inference done 17350/26446. 0.1181 s / img. ETA=0:18:22
[06/30 17:31:40] detectron2 INFO: Inference done 17390/26446. 0.1181 s / img. ETA=0:18:17
[06/30 17:31:45] detectron2 INFO: Inference done 17431/26446. 0.1181 s / img. ETA=0:18:12
[06/30 17:31:50] detectron2 INFO: Inference done 17473/26446. 0.1181 s / img. ETA=0:18:07
[06/30 17:31:56] detectron2 INFO: Inference done 17516/26446. 0.1181 s / img. ETA=0:18:02
[06/30 17:32:01] detectron2 INFO: Inference done 17558/26446. 0.1181 s / img. ETA=0:17:57
[06/30 17:32:06] detectron2 INFO: Inference done 17600/26446. 0.1181 s / img. ETA=0:17:52
[06/30 17:32:11] detectron2 INFO: Inference done 17640/26446. 0.1181 s / img. ETA=0:17:47
[06/30 17:32:16] detectron2 INFO: Inference done 17682/26446. 0.1181 s / img. ETA=0:17:42
[06/30 17:32:21] detectron2 INFO: Inference done 17723/26446. 0.1181 s / img. ETA=0:17:37
[06/30 17:32:26] detectron2 INFO: Inference done 17764/26446. 0.1181 s / img. ETA=0:17:32
[06/30 17:32:31] detectron2 INFO: Inference done 17804/26446. 0.1181 s / img. ETA=0:17:27
[06/30 17:32:36] detectron2 INFO: Inference done 17844/26446. 0.1181 s / img. ETA=0:17:23
[06/30 17:32:41] detectron2 INFO: Inference done 17885/26446. 0.1181 s / img. ETA=0:17:18
[06/30 17:32:46] detectron2 INFO: Inference done 17927/26446. 0.1181 s / img. ETA=0:17:13
[06/30 17:32:51] detectron2 INFO: Inference done 17968/26446. 0.1181 s / img. ETA=0:17:08
[06/30 17:32:56] detectron2 INFO: Inference done 18010/26446. 0.1181 s / img. ETA=0:17:02
[06/30 17:33:01] detectron2 INFO: Inference done 18052/26446. 0.1181 s / img. ETA=0:16:57
[06/30 17:33:06] detectron2 INFO: Inference done 18094/26446. 0.1181 s / img. ETA=0:16:52
[06/30 17:33:11] detectron2 INFO: Inference done 18136/26446. 0.1181 s / img. ETA=0:16:47
[06/30 17:33:16] detectron2 INFO: Inference done 18178/26446. 0.1181 s / img. ETA=0:16:42
[06/30 17:33:21] detectron2 INFO: Inference done 18220/26446. 0.1181 s / img. ETA=0:16:37
[06/30 17:33:26] detectron2 INFO: Inference done 18262/26446. 0.1181 s / img. ETA=0:16:32
[06/30 17:33:31] detectron2 INFO: Inference done 18304/26446. 0.1181 s / img. ETA=0:16:27
[06/30 17:33:37] detectron2 INFO: Inference done 18346/26446. 0.1181 s / img. ETA=0:16:22
[06/30 17:33:42] detectron2 INFO: Inference done 18388/26446. 0.1181 s / img. ETA=0:16:16
[06/30 17:33:47] detectron2 INFO: Inference done 18430/26446. 0.1181 s / img. ETA=0:16:11
[06/30 17:33:52] detectron2 INFO: Inference done 18472/26446. 0.1181 s / img. ETA=0:16:06
[06/30 17:33:57] detectron2 INFO: Inference done 18515/26446. 0.1181 s / img. ETA=0:16:01
[06/30 17:34:02] detectron2 INFO: Inference done 18556/26446. 0.1181 s / img. ETA=0:15:56
[06/30 17:34:07] detectron2 INFO: Inference done 18598/26446. 0.1181 s / img. ETA=0:15:51
[06/30 17:34:12] detectron2 INFO: Inference done 18639/26446. 0.1181 s / img. ETA=0:15:46
[06/30 17:34:17] detectron2 INFO: Inference done 18681/26446. 0.1181 s / img. ETA=0:15:41
[06/30 17:34:22] detectron2 INFO: Inference done 18722/26446. 0.1181 s / img. ETA=0:15:36
[06/30 17:34:27] detectron2 INFO: Inference done 18763/26446. 0.1181 s / img. ETA=0:15:31
[06/30 17:34:32] detectron2 INFO: Inference done 18805/26446. 0.1181 s / img. ETA=0:15:26
[06/30 17:34:37] detectron2 INFO: Inference done 18848/26446. 0.1181 s / img. ETA=0:15:21
[06/30 17:34:42] detectron2 INFO: Inference done 18890/26446. 0.1181 s / img. ETA=0:15:16
[06/30 17:34:47] detectron2 INFO: Inference done 18932/26446. 0.1181 s / img. ETA=0:15:10
[06/30 17:34:52] detectron2 INFO: Inference done 18974/26446. 0.1181 s / img. ETA=0:15:05
[06/30 17:34:58] detectron2 INFO: Inference done 19017/26446. 0.1181 s / img. ETA=0:15:00
[06/30 17:35:03] detectron2 INFO: Inference done 19059/26446. 0.1181 s / img. ETA=0:14:55
[06/30 17:35:08] detectron2 INFO: Inference done 19102/26446. 0.1181 s / img. ETA=0:14:50
[06/30 17:35:13] detectron2 INFO: Inference done 19144/26446. 0.1181 s / img. ETA=0:14:45
[06/30 17:35:18] detectron2 INFO: Inference done 19186/26446. 0.1181 s / img. ETA=0:14:40
[06/30 17:35:23] detectron2 INFO: Inference done 19229/26446. 0.1181 s / img. ETA=0:14:34
[06/30 17:35:28] detectron2 INFO: Inference done 19271/26446. 0.1181 s / img. ETA=0:14:29
[06/30 17:35:33] detectron2 INFO: Inference done 19312/26446. 0.1181 s / img. ETA=0:14:24
[06/30 17:35:38] detectron2 INFO: Inference done 19353/26446. 0.1181 s / img. ETA=0:14:19
[06/30 17:35:43] detectron2 INFO: Inference done 19395/26446. 0.1181 s / img. ETA=0:14:14
[06/30 17:35:48] detectron2 INFO: Inference done 19436/26446. 0.1181 s / img. ETA=0:14:09
[06/30 17:35:53] detectron2 INFO: Inference done 19478/26446. 0.1181 s / img. ETA=0:14:04
[06/30 17:35:58] detectron2 INFO: Inference done 19521/26446. 0.1181 s / img. ETA=0:13:59
[06/30 17:36:03] detectron2 INFO: Inference done 19564/26446. 0.1180 s / img. ETA=0:13:54
[06/30 17:36:08] detectron2 INFO: Inference done 19607/26446. 0.1180 s / img. ETA=0:13:48
[06/30 17:36:14] detectron2 INFO: Inference done 19649/26446. 0.1180 s / img. ETA=0:13:43
[06/30 17:36:19] detectron2 INFO: Inference done 19690/26446. 0.1180 s / img. ETA=0:13:38
[06/30 17:36:24] detectron2 INFO: Inference done 19732/26446. 0.1180 s / img. ETA=0:13:33
[06/30 17:36:29] detectron2 INFO: Inference done 19773/26446. 0.1180 s / img. ETA=0:13:28
[06/30 17:36:34] detectron2 INFO: Inference done 19815/26446. 0.1180 s / img. ETA=0:13:23
[06/30 17:36:39] detectron2 INFO: Inference done 19857/26446. 0.1180 s / img. ETA=0:13:18
[06/30 17:36:44] detectron2 INFO: Inference done 19899/26446. 0.1180 s / img. ETA=0:13:13
[06/30 17:36:49] detectron2 INFO: Inference done 19941/26446. 0.1180 s / img. ETA=0:13:08
[06/30 17:36:54] detectron2 INFO: Inference done 19982/26446. 0.1180 s / img. ETA=0:13:03
[06/30 17:36:59] detectron2 INFO: Inference done 20024/26446. 0.1180 s / img. ETA=0:12:58
[06/30 17:37:04] detectron2 INFO: Inference done 20065/26446. 0.1180 s / img. ETA=0:12:53
[06/30 17:37:09] detectron2 INFO: Inference done 20108/26446. 0.1180 s / img. ETA=0:12:48
[06/30 17:37:14] detectron2 INFO: Inference done 20150/26446. 0.1180 s / img. ETA=0:12:43
[06/30 17:37:19] detectron2 INFO: Inference done 20192/26446. 0.1180 s / img. ETA=0:12:37
[06/30 17:37:24] detectron2 INFO: Inference done 20234/26446. 0.1180 s / img. ETA=0:12:32
[06/30 17:37:29] detectron2 INFO: Inference done 20276/26446. 0.1180 s / img. ETA=0:12:27
[06/30 17:37:34] detectron2 INFO: Inference done 20318/26446. 0.1180 s / img. ETA=0:12:22
[06/30 17:37:39] detectron2 INFO: Inference done 20360/26446. 0.1180 s / img. ETA=0:12:17
[06/30 17:37:45] detectron2 INFO: Inference done 20403/26446. 0.1180 s / img. ETA=0:12:12
[06/30 17:37:50] detectron2 INFO: Inference done 20445/26446. 0.1180 s / img. ETA=0:12:07
[06/30 17:37:55] detectron2 INFO: Inference done 20487/26446. 0.1180 s / img. ETA=0:12:02
[06/30 17:38:00] detectron2 INFO: Inference done 20530/26446. 0.1180 s / img. ETA=0:11:56
[06/30 17:38:05] detectron2 INFO: Inference done 20572/26446. 0.1180 s / img. ETA=0:11:51
[06/30 17:38:10] detectron2 INFO: Inference done 20614/26446. 0.1180 s / img. ETA=0:11:46
[06/30 17:38:15] detectron2 INFO: Inference done 20656/26446. 0.1180 s / img. ETA=0:11:41
[06/30 17:38:20] detectron2 INFO: Inference done 20698/26446. 0.1180 s / img. ETA=0:11:36
[06/30 17:38:25] detectron2 INFO: Inference done 20740/26446. 0.1180 s / img. ETA=0:11:31
[06/30 17:38:30] detectron2 INFO: Inference done 20781/26446. 0.1180 s / img. ETA=0:11:26
[06/30 17:38:35] detectron2 INFO: Inference done 20823/26446. 0.1180 s / img. ETA=0:11:21
[06/30 17:38:40] detectron2 INFO: Inference done 20865/26446. 0.1180 s / img. ETA=0:11:16
[06/30 17:38:45] detectron2 INFO: Inference done 20907/26446. 0.1180 s / img. ETA=0:11:11
[06/30 17:38:50] detectron2 INFO: Inference done 20950/26446. 0.1180 s / img. ETA=0:11:05
[06/30 17:38:55] detectron2 INFO: Inference done 20992/26446. 0.1180 s / img. ETA=0:11:00
[06/30 17:39:00] detectron2 INFO: Inference done 21034/26446. 0.1180 s / img. ETA=0:10:55
[06/30 17:39:05] detectron2 INFO: Inference done 21076/26446. 0.1180 s / img. ETA=0:10:50
[06/30 17:39:10] detectron2 INFO: Inference done 21118/26446. 0.1180 s / img. ETA=0:10:45
[06/30 17:39:16] detectron2 INFO: Inference done 21160/26446. 0.1180 s / img. ETA=0:10:40
[06/30 17:39:21] detectron2 INFO: Inference done 21202/26446. 0.1180 s / img. ETA=0:10:35
[06/30 17:39:26] detectron2 INFO: Inference done 21243/26446. 0.1180 s / img. ETA=0:10:30
[06/30 17:39:31] detectron2 INFO: Inference done 21285/26446. 0.1180 s / img. ETA=0:10:25
[06/30 17:39:36] detectron2 INFO: Inference done 21327/26446. 0.1180 s / img. ETA=0:10:20
[06/30 17:39:41] detectron2 INFO: Inference done 21369/26446. 0.1180 s / img. ETA=0:10:15
[06/30 17:39:46] detectron2 INFO: Inference done 21411/26446. 0.1180 s / img. ETA=0:10:09
[06/30 17:39:51] detectron2 INFO: Inference done 21453/26446. 0.1180 s / img. ETA=0:10:04
[06/30 17:39:56] detectron2 INFO: Inference done 21495/26446. 0.1180 s / img. ETA=0:09:59
[06/30 17:40:01] detectron2 INFO: Inference done 21536/26446. 0.1180 s / img. ETA=0:09:54
[06/30 17:40:06] detectron2 INFO: Inference done 21578/26446. 0.1180 s / img. ETA=0:09:49
[06/30 17:40:11] detectron2 INFO: Inference done 21620/26446. 0.1180 s / img. ETA=0:09:44
[06/30 17:40:16] detectron2 INFO: Inference done 21662/26446. 0.1180 s / img. ETA=0:09:39
[06/30 17:40:21] detectron2 INFO: Inference done 21704/26446. 0.1180 s / img. ETA=0:09:34
[06/30 17:40:26] detectron2 INFO: Inference done 21746/26446. 0.1180 s / img. ETA=0:09:29
[06/30 17:40:31] detectron2 INFO: Inference done 21787/26446. 0.1180 s / img. ETA=0:09:24
[06/30 17:40:36] detectron2 INFO: Inference done 21829/26446. 0.1180 s / img. ETA=0:09:19
[06/30 17:40:42] detectron2 INFO: Inference done 21871/26446. 0.1180 s / img. ETA=0:09:14
[06/30 17:40:47] detectron2 INFO: Inference done 21913/26446. 0.1180 s / img. ETA=0:09:09
[06/30 17:40:52] detectron2 INFO: Inference done 21955/26446. 0.1180 s / img. ETA=0:09:03
[06/30 17:40:57] detectron2 INFO: Inference done 21997/26446. 0.1180 s / img. ETA=0:08:58
[06/30 17:41:02] detectron2 INFO: Inference done 22039/26446. 0.1180 s / img. ETA=0:08:53
[06/30 17:41:07] detectron2 INFO: Inference done 22081/26446. 0.1180 s / img. ETA=0:08:48
[06/30 17:41:12] detectron2 INFO: Inference done 22123/26446. 0.1180 s / img. ETA=0:08:43
[06/30 17:41:17] detectron2 INFO: Inference done 22165/26446. 0.1180 s / img. ETA=0:08:38
[06/30 17:41:22] detectron2 INFO: Inference done 22207/26446. 0.1180 s / img. ETA=0:08:33
[06/30 17:41:27] detectron2 INFO: Inference done 22248/26446. 0.1180 s / img. ETA=0:08:28
[06/30 17:41:32] detectron2 INFO: Inference done 22290/26446. 0.1180 s / img. ETA=0:08:23
[06/30 17:41:37] detectron2 INFO: Inference done 22332/26446. 0.1180 s / img. ETA=0:08:18
[06/30 17:41:42] detectron2 INFO: Inference done 22374/26446. 0.1180 s / img. ETA=0:08:13
[06/30 17:41:47] detectron2 INFO: Inference done 22413/26446. 0.1180 s / img. ETA=0:08:08
[06/30 17:41:52] detectron2 INFO: Inference done 22452/26446. 0.1180 s / img. ETA=0:08:03
[06/30 17:41:57] detectron2 INFO: Inference done 22489/26446. 0.1180 s / img. ETA=0:07:59
[06/30 17:42:03] detectron2 INFO: Inference done 22527/26446. 0.1181 s / img. ETA=0:07:55
[06/30 17:42:08] detectron2 INFO: Inference done 22568/26446. 0.1181 s / img. ETA=0:07:50
[06/30 17:42:13] detectron2 INFO: Inference done 22609/26446. 0.1181 s / img. ETA=0:07:45
[06/30 17:42:18] detectron2 INFO: Inference done 22650/26446. 0.1181 s / img. ETA=0:07:40
[06/30 17:42:23] detectron2 INFO: Inference done 22692/26446. 0.1181 s / img. ETA=0:07:35
[06/30 17:42:28] detectron2 INFO: Inference done 22732/26446. 0.1181 s / img. ETA=0:07:30
[06/30 17:42:33] detectron2 INFO: Inference done 22771/26446. 0.1181 s / img. ETA=0:07:25
[06/30 17:42:38] detectron2 INFO: Inference done 22813/26446. 0.1181 s / img. ETA=0:07:20
[06/30 17:42:43] detectron2 INFO: Inference done 22855/26446. 0.1181 s / img. ETA=0:07:15
[06/30 17:42:48] detectron2 INFO: Inference done 22898/26446. 0.1181 s / img. ETA=0:07:10
[06/30 17:42:53] detectron2 INFO: Inference done 22940/26446. 0.1181 s / img. ETA=0:07:05
[06/30 17:42:58] detectron2 INFO: Inference done 22982/26446. 0.1181 s / img. ETA=0:06:59
[06/30 17:43:03] detectron2 INFO: Inference done 23023/26446. 0.1181 s / img. ETA=0:06:54
[06/30 17:43:08] detectron2 INFO: Inference done 23065/26446. 0.1181 s / img. ETA=0:06:49
[06/30 17:43:14] detectron2 INFO: Inference done 23107/26446. 0.1181 s / img. ETA=0:06:44
[06/30 17:43:19] detectron2 INFO: Inference done 23149/26446. 0.1181 s / img. ETA=0:06:39
[06/30 17:43:24] detectron2 INFO: Inference done 23190/26446. 0.1181 s / img. ETA=0:06:34
[06/30 17:43:29] detectron2 INFO: Inference done 23232/26446. 0.1181 s / img. ETA=0:06:29
[06/30 17:43:34] detectron2 INFO: Inference done 23274/26446. 0.1181 s / img. ETA=0:06:24
[06/30 17:43:39] detectron2 INFO: Inference done 23315/26446. 0.1181 s / img. ETA=0:06:19
[06/30 17:43:44] detectron2 INFO: Inference done 23356/26446. 0.1181 s / img. ETA=0:06:14
[06/30 17:43:49] detectron2 INFO: Inference done 23398/26446. 0.1181 s / img. ETA=0:06:09
[06/30 17:43:54] detectron2 INFO: Inference done 23440/26446. 0.1181 s / img. ETA=0:06:04
[06/30 17:43:59] detectron2 INFO: Inference done 23482/26446. 0.1181 s / img. ETA=0:05:59
[06/30 17:44:04] detectron2 INFO: Inference done 23524/26446. 0.1181 s / img. ETA=0:05:54
[06/30 17:44:09] detectron2 INFO: Inference done 23566/26446. 0.1181 s / img. ETA=0:05:49
[06/30 17:44:14] detectron2 INFO: Inference done 23607/26446. 0.1181 s / img. ETA=0:05:44
[06/30 17:44:19] detectron2 INFO: Inference done 23646/26446. 0.1181 s / img. ETA=0:05:39
[06/30 17:44:24] detectron2 INFO: Inference done 23688/26446. 0.1181 s / img. ETA=0:05:34
[06/30 17:44:29] detectron2 INFO: Inference done 23730/26446. 0.1181 s / img. ETA=0:05:29
[06/30 17:44:35] detectron2 INFO: Inference done 23773/26446. 0.1181 s / img. ETA=0:05:24
[06/30 17:44:40] detectron2 INFO: Inference done 23815/26446. 0.1181 s / img. ETA=0:05:18
[06/30 17:44:45] detectron2 INFO: Inference done 23857/26446. 0.1181 s / img. ETA=0:05:13
[06/30 17:44:50] detectron2 INFO: Inference done 23899/26446. 0.1181 s / img. ETA=0:05:08
[06/30 17:44:55] detectron2 INFO: Inference done 23926/26446. 0.1181 s / img. ETA=0:05:05
[06/30 17:45:00] detectron2 INFO: Inference done 23968/26446. 0.1181 s / img. ETA=0:05:00
[06/30 17:45:05] detectron2 INFO: Inference done 24010/26446. 0.1181 s / img. ETA=0:04:55
[06/30 17:45:10] detectron2 INFO: Inference done 24052/26446. 0.1181 s / img. ETA=0:04:50
[06/30 17:45:15] detectron2 INFO: Inference done 24093/26446. 0.1181 s / img. ETA=0:04:45
[06/30 17:45:20] detectron2 INFO: Inference done 24135/26446. 0.1181 s / img. ETA=0:04:40
[06/30 17:45:25] detectron2 INFO: Inference done 24176/26446. 0.1181 s / img. ETA=0:04:35
[06/30 17:45:30] detectron2 INFO: Inference done 24219/26446. 0.1181 s / img. ETA=0:04:30
[06/30 17:45:36] detectron2 INFO: Inference done 24261/26446. 0.1181 s / img. ETA=0:04:25
[06/30 17:45:41] detectron2 INFO: Inference done 24303/26446. 0.1181 s / img. ETA=0:04:19
[06/30 17:45:46] detectron2 INFO: Inference done 24344/26446. 0.1181 s / img. ETA=0:04:15
[06/30 17:45:51] detectron2 INFO: Inference done 24386/26446. 0.1181 s / img. ETA=0:04:09
[06/30 17:45:56] detectron2 INFO: Inference done 24428/26446. 0.1181 s / img. ETA=0:04:04
[06/30 17:46:01] detectron2 INFO: Inference done 24469/26446. 0.1181 s / img. ETA=0:03:59
[06/30 17:46:06] detectron2 INFO: Inference done 24511/26446. 0.1181 s / img. ETA=0:03:54
[06/30 17:46:11] detectron2 INFO: Inference done 24553/26446. 0.1181 s / img. ETA=0:03:49
[06/30 17:46:16] detectron2 INFO: Inference done 24595/26446. 0.1181 s / img. ETA=0:03:44
[06/30 17:46:21] detectron2 INFO: Inference done 24634/26446. 0.1181 s / img. ETA=0:03:39
[06/30 17:46:26] detectron2 INFO: Inference done 24675/26446. 0.1181 s / img. ETA=0:03:34
[06/30 17:46:31] detectron2 INFO: Inference done 24717/26446. 0.1181 s / img. ETA=0:03:29
[06/30 17:46:36] detectron2 INFO: Inference done 24758/26446. 0.1181 s / img. ETA=0:03:24
[06/30 17:46:41] detectron2 INFO: Inference done 24800/26446. 0.1181 s / img. ETA=0:03:19
[06/30 17:46:46] detectron2 INFO: Inference done 24842/26446. 0.1181 s / img. ETA=0:03:14
[06/30 17:46:51] detectron2 INFO: Inference done 24882/26446. 0.1181 s / img. ETA=0:03:09
[06/30 17:46:56] detectron2 INFO: Inference done 24923/26446. 0.1181 s / img. ETA=0:03:04
[06/30 17:47:01] detectron2 INFO: Inference done 24963/26446. 0.1181 s / img. ETA=0:02:59
[06/30 17:47:06] detectron2 INFO: Inference done 25005/26446. 0.1181 s / img. ETA=0:02:54
[06/30 17:47:11] detectron2 INFO: Inference done 25046/26446. 0.1181 s / img. ETA=0:02:49
[06/30 17:47:17] detectron2 INFO: Inference done 25088/26446. 0.1181 s / img. ETA=0:02:44
[06/30 17:47:22] detectron2 INFO: Inference done 25130/26446. 0.1181 s / img. ETA=0:02:39
[06/30 17:47:27] detectron2 INFO: Inference done 25171/26446. 0.1181 s / img. ETA=0:02:34
[06/30 17:47:32] detectron2 INFO: Inference done 25211/26446. 0.1181 s / img. ETA=0:02:29
[06/30 17:47:37] detectron2 INFO: Inference done 25252/26446. 0.1181 s / img. ETA=0:02:24
[06/30 17:47:42] detectron2 INFO: Inference done 25293/26446. 0.1181 s / img. ETA=0:02:19
[06/30 17:47:47] detectron2 INFO: Inference done 25335/26446. 0.1181 s / img. ETA=0:02:14
[06/30 17:47:52] detectron2 INFO: Inference done 25377/26446. 0.1181 s / img. ETA=0:02:09
[06/30 17:47:57] detectron2 INFO: Inference done 25419/26446. 0.1181 s / img. ETA=0:02:04
[06/30 17:48:02] detectron2 INFO: Inference done 25460/26446. 0.1181 s / img. ETA=0:01:59
[06/30 17:48:07] detectron2 INFO: Inference done 25497/26446. 0.1182 s / img. ETA=0:01:55
[06/30 17:48:12] detectron2 INFO: Inference done 25538/26446. 0.1182 s / img. ETA=0:01:50
[06/30 17:48:17] detectron2 INFO: Inference done 25580/26446. 0.1182 s / img. ETA=0:01:45
[06/30 17:48:22] detectron2 INFO: Inference done 25621/26446. 0.1182 s / img. ETA=0:01:40
[06/30 17:48:27] detectron2 INFO: Inference done 25663/26446. 0.1182 s / img. ETA=0:01:35
[06/30 17:48:32] detectron2 INFO: Inference done 25705/26446. 0.1182 s / img. ETA=0:01:29
[06/30 17:48:38] detectron2 INFO: Inference done 25747/26446. 0.1182 s / img. ETA=0:01:24
[06/30 17:48:43] detectron2 INFO: Inference done 25788/26446. 0.1182 s / img. ETA=0:01:19
[06/30 17:48:48] detectron2 INFO: Inference done 25829/26446. 0.1182 s / img. ETA=0:01:14
[06/30 17:48:53] detectron2 INFO: Inference done 25869/26446. 0.1182 s / img. ETA=0:01:10
[06/30 17:48:58] detectron2 INFO: Inference done 25910/26446. 0.1182 s / img. ETA=0:01:05
[06/30 17:49:03] detectron2 INFO: Inference done 25952/26446. 0.1182 s / img. ETA=0:00:59
[06/30 17:49:08] detectron2 INFO: Inference done 25994/26446. 0.1182 s / img. ETA=0:00:54
[06/30 17:49:13] detectron2 INFO: Inference done 26035/26446. 0.1182 s / img. ETA=0:00:49
[06/30 17:49:18] detectron2 INFO: Inference done 26077/26446. 0.1182 s / img. ETA=0:00:44
[06/30 17:49:23] detectron2 INFO: Inference done 26118/26446. 0.1182 s / img. ETA=0:00:39
[06/30 17:49:28] detectron2 INFO: Inference done 26159/26446. 0.1182 s / img. ETA=0:00:34
[06/30 17:49:33] detectron2 INFO: Inference done 26200/26446. 0.1182 s / img. ETA=0:00:29
[06/30 17:49:38] detectron2 INFO: Inference done 26241/26446. 0.1182 s / img. ETA=0:00:24
[06/30 17:49:43] detectron2 INFO: Inference done 26283/26446. 0.1182 s / img. ETA=0:00:19
[06/30 17:49:48] detectron2 INFO: Inference done 26323/26446. 0.1182 s / img. ETA=0:00:14
[06/30 17:49:53] detectron2 INFO: Inference done 26365/26446. 0.1182 s / img. ETA=0:00:09
[06/30 17:49:58] detectron2 INFO: Inference done 26405/26446. 0.1182 s / img. ETA=0:00:04
[06/30 17:50:03] detectron2 INFO: Inference done 26446/26446. 0.1182 s / img. ETA=0:00:00
[06/30 17:50:04] detectron2 INFO: Total inference time: 0:53:31.484573 (0.121459 s / img per device, on 1 devices)
[06/30 17:50:04] detectron2 INFO: Total inference pure compute time: 0:52:05 (0.118205 s / img per device, on 1 devices)
[06/30 17:50:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 17:50:13] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 17:50:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 17:50:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[06/30 18:01:07] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 18:01:07] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 18:01:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '2', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 18:01:07] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 18:01:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 2
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 18:01:07] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 18:01:07] d2.utils.env INFO: Using a generated random seed 8044553
[06/30 18:01:09] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 18:01:09] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 18:01:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 18:01:11] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 18:01:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 18:01:11] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 18:01:12] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 18:01:12] detectron2 INFO: Following metrics will be use for evaluation
[06/30 18:01:12] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 18:01:12] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 18:01:12] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 18:01:12] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 18:01:14] detectron2 INFO: Loading zero shot triplets
[06/30 18:01:14] detectron2 INFO: Start inference on 26446 images
[06/30 18:01:31] detectron2 INFO: Inference done 11/26446. 0.1571 s / img. ETA=1:10:18
[06/30 18:01:36] detectron2 INFO: Inference done 47/26446. 0.1409 s / img. ETA=1:03:14
[06/30 18:01:41] detectron2 INFO: Inference done 81/26446. 0.1425 s / img. ETA=1:03:53
[06/30 18:01:46] detectron2 INFO: Inference done 121/26446. 0.1365 s / img. ETA=1:01:08
[06/30 18:01:51] detectron2 INFO: Inference done 159/26446. 0.1348 s / img. ETA=1:00:18
[06/30 18:01:56] detectron2 INFO: Inference done 201/26446. 0.1313 s / img. ETA=0:58:41
[06/30 18:02:01] detectron2 INFO: Inference done 240/26446. 0.1303 s / img. ETA=0:58:11
[06/30 18:02:06] detectron2 INFO: Inference done 279/26446. 0.1297 s / img. ETA=0:57:50
[06/30 18:02:11] detectron2 INFO: Inference done 318/26446. 0.1293 s / img. ETA=0:57:33
[06/30 18:02:17] detectron2 INFO: Inference done 360/26446. 0.1279 s / img. ETA=0:56:52
[06/30 18:02:22] detectron2 INFO: Inference done 400/26446. 0.1276 s / img. ETA=0:56:38
[06/30 18:02:27] detectron2 INFO: Inference done 439/26446. 0.1274 s / img. ETA=0:56:30
[06/30 18:02:32] detectron2 INFO: Inference done 478/26446. 0.1274 s / img. ETA=0:56:26
[06/30 18:02:37] detectron2 INFO: Inference done 519/26446. 0.1269 s / img. ETA=0:56:06
[06/30 18:02:42] detectron2 INFO: Inference done 559/26446. 0.1267 s / img. ETA=0:55:55
[06/30 18:02:47] detectron2 INFO: Inference done 602/26446. 0.1259 s / img. ETA=0:55:28
[06/30 18:02:52] detectron2 INFO: Inference done 642/26446. 0.1257 s / img. ETA=0:55:18
[06/30 18:02:57] detectron2 INFO: Inference done 683/26446. 0.1254 s / img. ETA=0:55:05
[06/30 18:03:02] detectron2 INFO: Inference done 725/26446. 0.1250 s / img. ETA=0:54:52
[06/30 18:03:07] detectron2 INFO: Inference done 768/26446. 0.1246 s / img. ETA=0:54:35
[06/30 18:03:12] detectron2 INFO: Inference done 810/26446. 0.1242 s / img. ETA=0:54:19
[06/30 18:03:17] detectron2 INFO: Inference done 853/26446. 0.1237 s / img. ETA=0:54:02
[06/30 18:03:23] detectron2 INFO: Inference done 893/26446. 0.1237 s / img. ETA=0:53:55
[06/30 18:03:28] detectron2 INFO: Inference done 936/26446. 0.1232 s / img. ETA=0:53:38
[06/30 18:03:33] detectron2 INFO: Inference done 979/26446. 0.1228 s / img. ETA=0:53:21
[06/30 18:03:38] detectron2 INFO: Inference done 1021/26446. 0.1226 s / img. ETA=0:53:12
[06/30 18:03:43] detectron2 INFO: Inference done 1064/26446. 0.1223 s / img. ETA=0:52:58
[06/30 18:03:48] detectron2 INFO: Inference done 1108/26446. 0.1218 s / img. ETA=0:52:41
[06/30 18:03:53] detectron2 INFO: Inference done 1151/26446. 0.1216 s / img. ETA=0:52:29
[06/30 18:03:58] detectron2 INFO: Inference done 1194/26446. 0.1213 s / img. ETA=0:52:18
[06/30 18:04:03] detectron2 INFO: Inference done 1236/26446. 0.1212 s / img. ETA=0:52:09
[06/30 18:04:08] detectron2 INFO: Inference done 1279/26446. 0.1210 s / img. ETA=0:51:59
[06/30 18:04:13] detectron2 INFO: Inference done 1322/26446. 0.1208 s / img. ETA=0:51:49
[06/30 18:04:18] detectron2 INFO: Inference done 1363/26446. 0.1208 s / img. ETA=0:51:44
[06/30 18:04:23] detectron2 INFO: Inference done 1406/26446. 0.1206 s / img. ETA=0:51:33
[06/30 18:04:28] detectron2 INFO: Inference done 1447/26446. 0.1206 s / img. ETA=0:51:28
[06/30 18:04:33] detectron2 INFO: Inference done 1489/26446. 0.1205 s / img. ETA=0:51:21
[06/30 18:04:38] detectron2 INFO: Inference done 1532/26446. 0.1204 s / img. ETA=0:51:12
[06/30 18:04:43] detectron2 INFO: Inference done 1566/26446. 0.1209 s / img. ETA=0:51:21
[06/30 18:04:48] detectron2 INFO: Inference done 1608/26446. 0.1208 s / img. ETA=0:51:14
[06/30 18:04:54] detectron2 INFO: Inference done 1650/26446. 0.1207 s / img. ETA=0:51:06
[06/30 18:04:59] detectron2 INFO: Inference done 1692/26446. 0.1206 s / img. ETA=0:50:58
[06/30 18:05:04] detectron2 INFO: Inference done 1734/26446. 0.1206 s / img. ETA=0:50:54
[06/30 18:05:09] detectron2 INFO: Inference done 1777/26446. 0.1205 s / img. ETA=0:50:44
[06/30 18:05:14] detectron2 INFO: Inference done 1820/26446. 0.1204 s / img. ETA=0:50:36
[06/30 18:05:19] detectron2 INFO: Inference done 1864/26446. 0.1202 s / img. ETA=0:50:26
[06/30 18:05:24] detectron2 INFO: Inference done 1908/26446. 0.1200 s / img. ETA=0:50:15
[06/30 18:05:29] detectron2 INFO: Inference done 1950/26446. 0.1199 s / img. ETA=0:50:08
[06/30 18:05:34] detectron2 INFO: Inference done 1992/26446. 0.1198 s / img. ETA=0:50:02
[06/30 18:05:39] detectron2 INFO: Inference done 2035/26446. 0.1197 s / img. ETA=0:49:54
[06/30 18:05:44] detectron2 INFO: Inference done 2078/26446. 0.1196 s / img. ETA=0:49:46
[06/30 18:05:49] detectron2 INFO: Inference done 2118/26446. 0.1197 s / img. ETA=0:49:43
[06/30 18:05:54] detectron2 INFO: Inference done 2156/26446. 0.1198 s / img. ETA=0:49:42
[06/30 18:05:59] detectron2 INFO: Inference done 2197/26446. 0.1199 s / img. ETA=0:49:38
[06/30 18:06:04] detectron2 INFO: Inference done 2240/26446. 0.1198 s / img. ETA=0:49:30
[06/30 18:06:09] detectron2 INFO: Inference done 2283/26446. 0.1197 s / img. ETA=0:49:23
[06/30 18:06:15] detectron2 INFO: Inference done 2326/26446. 0.1196 s / img. ETA=0:49:16
[06/30 18:06:20] detectron2 INFO: Inference done 2369/26446. 0.1196 s / img. ETA=0:49:09
[06/30 18:06:25] detectron2 INFO: Inference done 2409/26446. 0.1196 s / img. ETA=0:49:07
[06/30 18:06:30] detectron2 INFO: Inference done 2447/26446. 0.1198 s / img. ETA=0:49:06
[06/30 18:06:35] detectron2 INFO: Inference done 2489/26446. 0.1198 s / img. ETA=0:49:00
[06/30 18:06:40] detectron2 INFO: Inference done 2533/26446. 0.1196 s / img. ETA=0:48:51
[06/30 18:06:45] detectron2 INFO: Inference done 2575/26446. 0.1196 s / img. ETA=0:48:44
[06/30 18:06:50] detectron2 INFO: Inference done 2617/26446. 0.1195 s / img. ETA=0:48:38
[06/30 18:06:55] detectron2 INFO: Inference done 2659/26446. 0.1195 s / img. ETA=0:48:32
[06/30 18:07:00] detectron2 INFO: Inference done 2701/26446. 0.1195 s / img. ETA=0:48:27
[06/30 18:07:05] detectron2 INFO: Inference done 2744/26446. 0.1194 s / img. ETA=0:48:20
[06/30 18:07:10] detectron2 INFO: Inference done 2787/26446. 0.1193 s / img. ETA=0:48:12
[06/30 18:07:15] detectron2 INFO: Inference done 2831/26446. 0.1192 s / img. ETA=0:48:05
[06/30 18:07:20] detectron2 INFO: Inference done 2875/26446. 0.1191 s / img. ETA=0:47:57
[06/30 18:07:25] detectron2 INFO: Inference done 2918/26446. 0.1190 s / img. ETA=0:47:50
[06/30 18:07:30] detectron2 INFO: Inference done 2961/26446. 0.1190 s / img. ETA=0:47:43
[06/30 18:07:35] detectron2 INFO: Inference done 3004/26446. 0.1189 s / img. ETA=0:47:36
[06/30 18:07:40] detectron2 INFO: Inference done 3047/26446. 0.1188 s / img. ETA=0:47:29
[06/30 18:07:46] detectron2 INFO: Inference done 3090/26446. 0.1187 s / img. ETA=0:47:22
[06/30 18:07:51] detectron2 INFO: Inference done 3134/26446. 0.1187 s / img. ETA=0:47:15
[06/30 18:07:56] detectron2 INFO: Inference done 3178/26446. 0.1186 s / img. ETA=0:47:07
[06/30 18:08:01] detectron2 INFO: Inference done 3220/26446. 0.1185 s / img. ETA=0:47:02
[06/30 18:08:06] detectron2 INFO: Inference done 3264/26446. 0.1185 s / img. ETA=0:46:55
[06/30 18:08:11] detectron2 INFO: Inference done 3309/26446. 0.1184 s / img. ETA=0:46:46
[06/30 18:08:16] detectron2 INFO: Inference done 3353/26446. 0.1183 s / img. ETA=0:46:39
[06/30 18:08:21] detectron2 INFO: Inference done 3397/26446. 0.1182 s / img. ETA=0:46:32
[06/30 18:08:26] detectron2 INFO: Inference done 3440/26446. 0.1182 s / img. ETA=0:46:26
[06/30 18:08:31] detectron2 INFO: Inference done 3483/26446. 0.1181 s / img. ETA=0:46:20
[06/30 18:08:36] detectron2 INFO: Inference done 3526/26446. 0.1181 s / img. ETA=0:46:14
[06/30 18:08:41] detectron2 INFO: Inference done 3569/26446. 0.1180 s / img. ETA=0:46:08
[06/30 18:08:46] detectron2 INFO: Inference done 3612/26446. 0.1180 s / img. ETA=0:46:01
[06/30 18:08:51] detectron2 INFO: Inference done 3655/26446. 0.1180 s / img. ETA=0:45:55
[06/30 18:08:57] detectron2 INFO: Inference done 3699/26446. 0.1179 s / img. ETA=0:45:49
[06/30 18:09:02] detectron2 INFO: Inference done 3741/26446. 0.1179 s / img. ETA=0:45:43
[06/30 18:09:07] detectron2 INFO: Inference done 3784/26446. 0.1179 s / img. ETA=0:45:37
[06/30 18:09:12] detectron2 INFO: Inference done 3826/26446. 0.1179 s / img. ETA=0:45:32
[06/30 18:09:17] detectron2 INFO: Inference done 3869/26446. 0.1178 s / img. ETA=0:45:26
[06/30 18:09:22] detectron2 INFO: Inference done 3912/26446. 0.1178 s / img. ETA=0:45:20
[06/30 18:09:27] detectron2 INFO: Inference done 3955/26446. 0.1177 s / img. ETA=0:45:14
[06/30 18:09:32] detectron2 INFO: Inference done 3997/26446. 0.1177 s / img. ETA=0:45:09
[06/30 18:09:37] detectron2 INFO: Inference done 4040/26446. 0.1177 s / img. ETA=0:45:02
[06/30 18:09:42] detectron2 INFO: Inference done 4080/26446. 0.1177 s / img. ETA=0:44:59
[06/30 18:09:47] detectron2 INFO: Inference done 4123/26446. 0.1177 s / img. ETA=0:44:53
[06/30 18:09:52] detectron2 INFO: Inference done 4164/26446. 0.1177 s / img. ETA=0:44:49
[06/30 18:09:57] detectron2 INFO: Inference done 4207/26446. 0.1177 s / img. ETA=0:44:42
[06/30 18:10:02] detectron2 INFO: Inference done 4250/26446. 0.1176 s / img. ETA=0:44:37
[06/30 18:10:07] detectron2 INFO: Inference done 4293/26446. 0.1176 s / img. ETA=0:44:31
[06/30 18:10:12] detectron2 INFO: Inference done 4337/26446. 0.1176 s / img. ETA=0:44:24
[06/30 18:10:17] detectron2 INFO: Inference done 4379/26446. 0.1176 s / img. ETA=0:44:19
[06/30 18:10:22] detectron2 INFO: Inference done 4422/26446. 0.1176 s / img. ETA=0:44:14
[06/30 18:10:27] detectron2 INFO: Inference done 4466/26446. 0.1175 s / img. ETA=0:44:07
[06/30 18:10:32] detectron2 INFO: Inference done 4510/26446. 0.1174 s / img. ETA=0:44:00
[06/30 18:10:38] detectron2 INFO: Inference done 4553/26446. 0.1174 s / img. ETA=0:43:55
[06/30 18:10:43] detectron2 INFO: Inference done 4596/26446. 0.1174 s / img. ETA=0:43:49
[06/30 18:10:48] detectron2 INFO: Inference done 4639/26446. 0.1174 s / img. ETA=0:43:43
[06/30 18:10:53] detectron2 INFO: Inference done 4682/26446. 0.1173 s / img. ETA=0:43:38
[06/30 18:10:58] detectron2 INFO: Inference done 4725/26446. 0.1173 s / img. ETA=0:43:32
[06/30 18:11:03] detectron2 INFO: Inference done 4768/26446. 0.1173 s / img. ETA=0:43:26
[06/30 18:11:08] detectron2 INFO: Inference done 4811/26446. 0.1172 s / img. ETA=0:43:20
[06/30 18:11:13] detectron2 INFO: Inference done 4854/26446. 0.1172 s / img. ETA=0:43:14
[06/30 18:11:18] detectron2 INFO: Inference done 4897/26446. 0.1172 s / img. ETA=0:43:08
[06/30 18:11:23] detectron2 INFO: Inference done 4940/26446. 0.1172 s / img. ETA=0:43:03
[06/30 18:11:28] detectron2 INFO: Inference done 4984/26446. 0.1171 s / img. ETA=0:42:57
[06/30 18:11:33] detectron2 INFO: Inference done 5027/26446. 0.1171 s / img. ETA=0:42:51
[06/30 18:11:38] detectron2 INFO: Inference done 5071/26446. 0.1171 s / img. ETA=0:42:45
[06/30 18:11:43] detectron2 INFO: Inference done 5113/26446. 0.1171 s / img. ETA=0:42:40
[06/30 18:11:48] detectron2 INFO: Inference done 5156/26446. 0.1170 s / img. ETA=0:42:35
[06/30 18:11:53] detectron2 INFO: Inference done 5199/26446. 0.1170 s / img. ETA=0:42:29
[06/30 18:11:58] detectron2 INFO: Inference done 5242/26446. 0.1170 s / img. ETA=0:42:24
[06/30 18:12:03] detectron2 INFO: Inference done 5285/26446. 0.1170 s / img. ETA=0:42:18
[06/30 18:12:09] detectron2 INFO: Inference done 5322/26446. 0.1171 s / img. ETA=0:42:16
[06/30 18:12:14] detectron2 INFO: Inference done 5362/26446. 0.1172 s / img. ETA=0:42:12
[06/30 18:12:19] detectron2 INFO: Inference done 5403/26446. 0.1172 s / img. ETA=0:42:08
[06/30 18:12:24] detectron2 INFO: Inference done 5442/26446. 0.1173 s / img. ETA=0:42:05
[06/30 18:12:29] detectron2 INFO: Inference done 5481/26446. 0.1173 s / img. ETA=0:42:02
[06/30 18:12:34] detectron2 INFO: Inference done 5521/26446. 0.1174 s / img. ETA=0:41:58
[06/30 18:12:39] detectron2 INFO: Inference done 5561/26446. 0.1174 s / img. ETA=0:41:54
[06/30 18:12:44] detectron2 INFO: Inference done 5598/26446. 0.1175 s / img. ETA=0:41:52
[06/30 18:12:49] detectron2 INFO: Inference done 5639/26446. 0.1175 s / img. ETA=0:41:47
[06/30 18:12:54] detectron2 INFO: Inference done 5680/26446. 0.1176 s / img. ETA=0:41:43
[06/30 18:12:59] detectron2 INFO: Inference done 5721/26446. 0.1176 s / img. ETA=0:41:38
[06/30 18:13:04] detectron2 INFO: Inference done 5764/26446. 0.1176 s / img. ETA=0:41:33
[06/30 18:13:09] detectron2 INFO: Inference done 5808/26446. 0.1175 s / img. ETA=0:41:27
[06/30 18:13:14] detectron2 INFO: Inference done 5850/26446. 0.1175 s / img. ETA=0:41:21
[06/30 18:13:19] detectron2 INFO: Inference done 5894/26446. 0.1175 s / img. ETA=0:41:15
[06/30 18:13:25] detectron2 INFO: Inference done 5937/26446. 0.1175 s / img. ETA=0:41:10
[06/30 18:13:30] detectron2 INFO: Inference done 5980/26446. 0.1174 s / img. ETA=0:41:04
[06/30 18:13:35] detectron2 INFO: Inference done 6023/26446. 0.1174 s / img. ETA=0:40:59
[06/30 18:13:40] detectron2 INFO: Inference done 6066/26446. 0.1174 s / img. ETA=0:40:53
[06/30 18:13:45] detectron2 INFO: Inference done 6110/26446. 0.1174 s / img. ETA=0:40:47
[06/30 18:13:50] detectron2 INFO: Inference done 6153/26446. 0.1173 s / img. ETA=0:40:41
[06/30 18:13:55] detectron2 INFO: Inference done 6195/26446. 0.1173 s / img. ETA=0:40:36
[06/30 18:14:00] detectron2 INFO: Inference done 6238/26446. 0.1173 s / img. ETA=0:40:31
[06/30 18:14:05] detectron2 INFO: Inference done 6282/26446. 0.1173 s / img. ETA=0:40:25
[06/30 18:14:10] detectron2 INFO: Inference done 6325/26446. 0.1173 s / img. ETA=0:40:19
[06/30 18:14:15] detectron2 INFO: Inference done 6368/26446. 0.1173 s / img. ETA=0:40:14
[06/30 18:14:20] detectron2 INFO: Inference done 6410/26446. 0.1173 s / img. ETA=0:40:09
[06/30 18:14:25] detectron2 INFO: Inference done 6453/26446. 0.1173 s / img. ETA=0:40:03
[06/30 18:14:30] detectron2 INFO: Inference done 6496/26446. 0.1172 s / img. ETA=0:39:58
[06/30 18:14:35] detectron2 INFO: Inference done 6539/26446. 0.1172 s / img. ETA=0:39:52
[06/30 18:14:41] detectron2 INFO: Inference done 6582/26446. 0.1172 s / img. ETA=0:39:47
[06/30 18:14:46] detectron2 INFO: Inference done 6624/26446. 0.1172 s / img. ETA=0:39:42
[06/30 18:14:51] detectron2 INFO: Inference done 6667/26446. 0.1172 s / img. ETA=0:39:36
[06/30 18:14:56] detectron2 INFO: Inference done 6709/26446. 0.1172 s / img. ETA=0:39:32
[06/30 18:15:01] detectron2 INFO: Inference done 6752/26446. 0.1172 s / img. ETA=0:39:26
[06/30 18:15:06] detectron2 INFO: Inference done 6796/26446. 0.1172 s / img. ETA=0:39:20
[06/30 18:15:11] detectron2 INFO: Inference done 6839/26446. 0.1171 s / img. ETA=0:39:15
[06/30 18:15:16] detectron2 INFO: Inference done 6882/26446. 0.1171 s / img. ETA=0:39:09
[06/30 18:15:21] detectron2 INFO: Inference done 6925/26446. 0.1171 s / img. ETA=0:39:04
[06/30 18:15:26] detectron2 INFO: Inference done 6966/26446. 0.1171 s / img. ETA=0:38:59
[06/30 18:15:31] detectron2 INFO: Inference done 7009/26446. 0.1171 s / img. ETA=0:38:54
[06/30 18:15:36] detectron2 INFO: Inference done 7052/26446. 0.1171 s / img. ETA=0:38:49
[06/30 18:15:41] detectron2 INFO: Inference done 7094/26446. 0.1171 s / img. ETA=0:38:44
[06/30 18:15:47] detectron2 INFO: Inference done 7133/26446. 0.1172 s / img. ETA=0:38:40
[06/30 18:15:52] detectron2 INFO: Inference done 7175/26446. 0.1172 s / img. ETA=0:38:35
[06/30 18:15:57] detectron2 INFO: Inference done 7218/26446. 0.1171 s / img. ETA=0:38:30
[06/30 18:16:02] detectron2 INFO: Inference done 7261/26446. 0.1171 s / img. ETA=0:38:24
[06/30 18:16:07] detectron2 INFO: Inference done 7304/26446. 0.1171 s / img. ETA=0:38:19
[06/30 18:16:12] detectron2 INFO: Inference done 7347/26446. 0.1171 s / img. ETA=0:38:13
[06/30 18:16:17] detectron2 INFO: Inference done 7390/26446. 0.1171 s / img. ETA=0:38:08
[06/30 18:16:22] detectron2 INFO: Inference done 7434/26446. 0.1171 s / img. ETA=0:38:02
[06/30 18:16:27] detectron2 INFO: Inference done 7477/26446. 0.1171 s / img. ETA=0:37:57
[06/30 18:16:32] detectron2 INFO: Inference done 7508/26446. 0.1171 s / img. ETA=0:37:56
[06/30 18:16:37] detectron2 INFO: Inference done 7551/26446. 0.1170 s / img. ETA=0:37:51
[06/30 18:16:42] detectron2 INFO: Inference done 7594/26446. 0.1170 s / img. ETA=0:37:46
[06/30 18:16:47] detectron2 INFO: Inference done 7636/26446. 0.1170 s / img. ETA=0:37:41
[06/30 18:16:52] detectron2 INFO: Inference done 7679/26446. 0.1170 s / img. ETA=0:37:35
[06/30 18:16:57] detectron2 INFO: Inference done 7722/26446. 0.1170 s / img. ETA=0:37:30
[06/30 18:17:03] detectron2 INFO: Inference done 7766/26446. 0.1170 s / img. ETA=0:37:24
[06/30 18:17:08] detectron2 INFO: Inference done 7810/26446. 0.1170 s / img. ETA=0:37:18
[06/30 18:17:13] detectron2 INFO: Inference done 7853/26446. 0.1169 s / img. ETA=0:37:13
[06/30 18:17:18] detectron2 INFO: Inference done 7896/26446. 0.1169 s / img. ETA=0:37:07
[06/30 18:17:23] detectron2 INFO: Inference done 7939/26446. 0.1169 s / img. ETA=0:37:02
[06/30 18:17:28] detectron2 INFO: Inference done 7983/26446. 0.1169 s / img. ETA=0:36:56
[06/30 18:17:33] detectron2 INFO: Inference done 8023/26446. 0.1169 s / img. ETA=0:36:52
[06/30 18:17:38] detectron2 INFO: Inference done 8066/26446. 0.1169 s / img. ETA=0:36:46
[06/30 18:17:43] detectron2 INFO: Inference done 8109/26446. 0.1169 s / img. ETA=0:36:41
[06/30 18:17:48] detectron2 INFO: Inference done 8153/26446. 0.1169 s / img. ETA=0:36:35
[06/30 18:17:53] detectron2 INFO: Inference done 8196/26446. 0.1169 s / img. ETA=0:36:30
[06/30 18:17:58] detectron2 INFO: Inference done 8239/26446. 0.1168 s / img. ETA=0:36:24
[06/30 18:18:03] detectron2 INFO: Inference done 8282/26446. 0.1168 s / img. ETA=0:36:19
[06/30 18:18:08] detectron2 INFO: Inference done 8325/26446. 0.1168 s / img. ETA=0:36:13
[06/30 18:18:13] detectron2 INFO: Inference done 8368/26446. 0.1168 s / img. ETA=0:36:08
[06/30 18:18:18] detectron2 INFO: Inference done 8411/26446. 0.1168 s / img. ETA=0:36:02
[06/30 18:18:23] detectron2 INFO: Inference done 8453/26446. 0.1168 s / img. ETA=0:35:57
[06/30 18:18:28] detectron2 INFO: Inference done 8496/26446. 0.1168 s / img. ETA=0:35:52
[06/30 18:18:33] detectron2 INFO: Inference done 8539/26446. 0.1168 s / img. ETA=0:35:46
[06/30 18:18:38] detectron2 INFO: Inference done 8582/26446. 0.1167 s / img. ETA=0:35:41
[06/30 18:18:43] detectron2 INFO: Inference done 8626/26446. 0.1167 s / img. ETA=0:35:36
[06/30 18:18:48] detectron2 INFO: Inference done 8668/26446. 0.1167 s / img. ETA=0:35:31
[06/30 18:18:54] detectron2 INFO: Inference done 8711/26446. 0.1167 s / img. ETA=0:35:25
[06/30 18:18:59] detectron2 INFO: Inference done 8754/26446. 0.1167 s / img. ETA=0:35:20
[06/30 18:19:04] detectron2 INFO: Inference done 8796/26446. 0.1167 s / img. ETA=0:35:15
[06/30 18:19:09] detectron2 INFO: Inference done 8839/26446. 0.1167 s / img. ETA=0:35:09
[06/30 18:19:14] detectron2 INFO: Inference done 8883/26446. 0.1167 s / img. ETA=0:35:04
[06/30 18:19:19] detectron2 INFO: Inference done 8926/26446. 0.1167 s / img. ETA=0:34:58
[06/30 18:19:24] detectron2 INFO: Inference done 8969/26446. 0.1167 s / img. ETA=0:34:53
[06/30 18:19:29] detectron2 INFO: Inference done 9013/26446. 0.1166 s / img. ETA=0:34:47
[06/30 18:19:34] detectron2 INFO: Inference done 9056/26446. 0.1166 s / img. ETA=0:34:42
[06/30 18:19:39] detectron2 INFO: Inference done 9100/26446. 0.1166 s / img. ETA=0:34:36
[06/30 18:19:44] detectron2 INFO: Inference done 9143/26446. 0.1166 s / img. ETA=0:34:31
[06/30 18:19:49] detectron2 INFO: Inference done 9185/26446. 0.1166 s / img. ETA=0:34:26
[06/30 18:19:54] detectron2 INFO: Inference done 9228/26446. 0.1166 s / img. ETA=0:34:21
[06/30 18:19:59] detectron2 INFO: Inference done 9272/26446. 0.1166 s / img. ETA=0:34:15
[06/30 18:20:04] detectron2 INFO: Inference done 9315/26446. 0.1166 s / img. ETA=0:34:10
[06/30 18:20:09] detectron2 INFO: Inference done 9359/26446. 0.1165 s / img. ETA=0:34:04
[06/30 18:20:15] detectron2 INFO: Inference done 9402/26446. 0.1165 s / img. ETA=0:33:59
[06/30 18:20:20] detectron2 INFO: Inference done 9445/26446. 0.1165 s / img. ETA=0:33:54
[06/30 18:20:25] detectron2 INFO: Inference done 9488/26446. 0.1165 s / img. ETA=0:33:48
[06/30 18:20:30] detectron2 INFO: Inference done 9532/26446. 0.1165 s / img. ETA=0:33:43
[06/30 18:20:35] detectron2 INFO: Inference done 9575/26446. 0.1165 s / img. ETA=0:33:38
[06/30 18:20:40] detectron2 INFO: Inference done 9618/26446. 0.1165 s / img. ETA=0:33:32
[06/30 18:20:45] detectron2 INFO: Inference done 9661/26446. 0.1165 s / img. ETA=0:33:27
[06/30 18:20:50] detectron2 INFO: Inference done 9703/26446. 0.1165 s / img. ETA=0:33:22
[06/30 18:20:55] detectron2 INFO: Inference done 9746/26446. 0.1165 s / img. ETA=0:33:16
[06/30 18:21:00] detectron2 INFO: Inference done 9789/26446. 0.1164 s / img. ETA=0:33:11
[06/30 18:21:05] detectron2 INFO: Inference done 9833/26446. 0.1164 s / img. ETA=0:33:06
[06/30 18:21:10] detectron2 INFO: Inference done 9876/26446. 0.1164 s / img. ETA=0:33:00
[06/30 18:21:15] detectron2 INFO: Inference done 9919/26446. 0.1164 s / img. ETA=0:32:55
[06/30 18:21:20] detectron2 INFO: Inference done 9963/26446. 0.1164 s / img. ETA=0:32:49
[06/30 18:21:25] detectron2 INFO: Inference done 10006/26446. 0.1164 s / img. ETA=0:32:44
[06/30 18:21:30] detectron2 INFO: Inference done 10049/26446. 0.1164 s / img. ETA=0:32:39
[06/30 18:21:35] detectron2 INFO: Inference done 10092/26446. 0.1164 s / img. ETA=0:32:34
[06/30 18:21:40] detectron2 INFO: Inference done 10134/26446. 0.1164 s / img. ETA=0:32:29
[06/30 18:21:46] detectron2 INFO: Inference done 10176/26446. 0.1164 s / img. ETA=0:32:24
[06/30 18:21:51] detectron2 INFO: Inference done 10218/26446. 0.1164 s / img. ETA=0:32:19
[06/30 18:21:56] detectron2 INFO: Inference done 10261/26446. 0.1164 s / img. ETA=0:32:14
[06/30 18:22:01] detectron2 INFO: Inference done 10304/26446. 0.1164 s / img. ETA=0:32:08
[06/30 18:22:06] detectron2 INFO: Inference done 10347/26446. 0.1164 s / img. ETA=0:32:03
[06/30 18:22:11] detectron2 INFO: Inference done 10390/26446. 0.1164 s / img. ETA=0:31:58
[06/30 18:22:16] detectron2 INFO: Inference done 10433/26446. 0.1164 s / img. ETA=0:31:53
[06/30 18:22:21] detectron2 INFO: Inference done 10476/26446. 0.1164 s / img. ETA=0:31:47
[06/30 18:22:26] detectron2 INFO: Inference done 10518/26446. 0.1164 s / img. ETA=0:31:42
[06/30 18:22:31] detectron2 INFO: Inference done 10561/26446. 0.1163 s / img. ETA=0:31:37
[06/30 18:22:36] detectron2 INFO: Inference done 10605/26446. 0.1163 s / img. ETA=0:31:32
[06/30 18:22:41] detectron2 INFO: Inference done 10648/26446. 0.1163 s / img. ETA=0:31:26
[06/30 18:22:46] detectron2 INFO: Inference done 10691/26446. 0.1163 s / img. ETA=0:31:21
[06/30 18:22:51] detectron2 INFO: Inference done 10734/26446. 0.1163 s / img. ETA=0:31:16
[06/30 18:22:56] detectron2 INFO: Inference done 10777/26446. 0.1163 s / img. ETA=0:31:10
[06/30 18:23:01] detectron2 INFO: Inference done 10821/26446. 0.1163 s / img. ETA=0:31:05
[06/30 18:23:06] detectron2 INFO: Inference done 10864/26446. 0.1163 s / img. ETA=0:31:00
[06/30 18:23:11] detectron2 INFO: Inference done 10907/26446. 0.1163 s / img. ETA=0:30:54
[06/30 18:23:17] detectron2 INFO: Inference done 10950/26446. 0.1163 s / img. ETA=0:30:49
[06/30 18:23:22] detectron2 INFO: Inference done 10994/26446. 0.1162 s / img. ETA=0:30:44
[06/30 18:23:27] detectron2 INFO: Inference done 11037/26446. 0.1162 s / img. ETA=0:30:39
[06/30 18:23:32] detectron2 INFO: Inference done 11080/26446. 0.1162 s / img. ETA=0:30:33
[06/30 18:23:37] detectron2 INFO: Inference done 11123/26446. 0.1162 s / img. ETA=0:30:28
[06/30 18:23:42] detectron2 INFO: Inference done 11166/26446. 0.1162 s / img. ETA=0:30:23
[06/30 18:23:47] detectron2 INFO: Inference done 11209/26446. 0.1162 s / img. ETA=0:30:17
[06/30 18:23:52] detectron2 INFO: Inference done 11251/26446. 0.1162 s / img. ETA=0:30:12
[06/30 18:23:57] detectron2 INFO: Inference done 11294/26446. 0.1162 s / img. ETA=0:30:07
[06/30 18:24:02] detectron2 INFO: Inference done 11336/26446. 0.1162 s / img. ETA=0:30:02
[06/30 18:24:07] detectron2 INFO: Inference done 11379/26446. 0.1162 s / img. ETA=0:29:57
[06/30 18:24:12] detectron2 INFO: Inference done 11421/26446. 0.1162 s / img. ETA=0:29:52
[06/30 18:24:17] detectron2 INFO: Inference done 11461/26446. 0.1162 s / img. ETA=0:29:48
[06/30 18:24:22] detectron2 INFO: Inference done 11505/26446. 0.1162 s / img. ETA=0:29:42
[06/30 18:24:27] detectron2 INFO: Inference done 11548/26446. 0.1162 s / img. ETA=0:29:37
[06/30 18:24:32] detectron2 INFO: Inference done 11591/26446. 0.1162 s / img. ETA=0:29:32
[06/30 18:24:37] detectron2 INFO: Inference done 11634/26446. 0.1162 s / img. ETA=0:29:26
[06/30 18:24:42] detectron2 INFO: Inference done 11677/26446. 0.1162 s / img. ETA=0:29:21
[06/30 18:24:47] detectron2 INFO: Inference done 11719/26446. 0.1162 s / img. ETA=0:29:16
[06/30 18:24:52] detectron2 INFO: Inference done 11761/26446. 0.1162 s / img. ETA=0:29:11
[06/30 18:24:57] detectron2 INFO: Inference done 11804/26446. 0.1162 s / img. ETA=0:29:06
[06/30 18:25:03] detectron2 INFO: Inference done 11847/26446. 0.1162 s / img. ETA=0:29:01
[06/30 18:25:08] detectron2 INFO: Inference done 11890/26446. 0.1162 s / img. ETA=0:28:56
[06/30 18:25:13] detectron2 INFO: Inference done 11933/26446. 0.1162 s / img. ETA=0:28:50
[06/30 18:25:18] detectron2 INFO: Inference done 11976/26446. 0.1162 s / img. ETA=0:28:45
[06/30 18:25:23] detectron2 INFO: Inference done 12019/26446. 0.1161 s / img. ETA=0:28:40
[06/30 18:25:28] detectron2 INFO: Inference done 12063/26446. 0.1161 s / img. ETA=0:28:34
[06/30 18:25:33] detectron2 INFO: Inference done 12107/26446. 0.1161 s / img. ETA=0:28:29
[06/30 18:25:38] detectron2 INFO: Inference done 12150/26446. 0.1161 s / img. ETA=0:28:24
[06/30 18:25:43] detectron2 INFO: Inference done 12193/26446. 0.1161 s / img. ETA=0:28:19
[06/30 18:25:48] detectron2 INFO: Inference done 12235/26446. 0.1161 s / img. ETA=0:28:14
[06/30 18:25:53] detectron2 INFO: Inference done 12279/26446. 0.1161 s / img. ETA=0:28:08
[06/30 18:25:58] detectron2 INFO: Inference done 12323/26446. 0.1161 s / img. ETA=0:28:03
[06/30 18:26:03] detectron2 INFO: Inference done 12366/26446. 0.1161 s / img. ETA=0:27:58
[06/30 18:26:08] detectron2 INFO: Inference done 12408/26446. 0.1161 s / img. ETA=0:27:53
[06/30 18:26:13] detectron2 INFO: Inference done 12451/26446. 0.1161 s / img. ETA=0:27:47
[06/30 18:26:18] detectron2 INFO: Inference done 12494/26446. 0.1161 s / img. ETA=0:27:42
[06/30 18:26:23] detectron2 INFO: Inference done 12537/26446. 0.1161 s / img. ETA=0:27:37
[06/30 18:26:28] detectron2 INFO: Inference done 12579/26446. 0.1161 s / img. ETA=0:27:32
[06/30 18:26:33] detectron2 INFO: Inference done 12622/26446. 0.1161 s / img. ETA=0:27:27
[06/30 18:26:38] detectron2 INFO: Inference done 12666/26446. 0.1160 s / img. ETA=0:27:21
[06/30 18:26:44] detectron2 INFO: Inference done 12710/26446. 0.1160 s / img. ETA=0:27:16
[06/30 18:26:49] detectron2 INFO: Inference done 12753/26446. 0.1160 s / img. ETA=0:27:11
[06/30 18:26:54] detectron2 INFO: Inference done 12797/26446. 0.1160 s / img. ETA=0:27:05
[06/30 18:26:59] detectron2 INFO: Inference done 12840/26446. 0.1160 s / img. ETA=0:27:00
[06/30 18:27:04] detectron2 INFO: Inference done 12883/26446. 0.1160 s / img. ETA=0:26:55
[06/30 18:27:09] detectron2 INFO: Inference done 12926/26446. 0.1160 s / img. ETA=0:26:50
[06/30 18:27:14] detectron2 INFO: Inference done 12968/26446. 0.1160 s / img. ETA=0:26:45
[06/30 18:27:19] detectron2 INFO: Inference done 13012/26446. 0.1160 s / img. ETA=0:26:39
[06/30 18:27:24] detectron2 INFO: Inference done 13055/26446. 0.1160 s / img. ETA=0:26:34
[06/30 18:27:29] detectron2 INFO: Inference done 13098/26446. 0.1160 s / img. ETA=0:26:29
[06/30 18:27:34] detectron2 INFO: Inference done 13141/26446. 0.1160 s / img. ETA=0:26:24
[06/30 18:27:39] detectron2 INFO: Inference done 13185/26446. 0.1160 s / img. ETA=0:26:18
[06/30 18:27:44] detectron2 INFO: Inference done 13229/26446. 0.1160 s / img. ETA=0:26:13
[06/30 18:27:49] detectron2 INFO: Inference done 13271/26446. 0.1160 s / img. ETA=0:26:08
[06/30 18:27:54] detectron2 INFO: Inference done 13314/26446. 0.1160 s / img. ETA=0:26:03
[06/30 18:27:59] detectron2 INFO: Inference done 13358/26446. 0.1159 s / img. ETA=0:25:57
[06/30 18:28:04] detectron2 INFO: Inference done 13401/26446. 0.1159 s / img. ETA=0:25:52
[06/30 18:28:10] detectron2 INFO: Inference done 13444/26446. 0.1159 s / img. ETA=0:25:47
[06/30 18:28:15] detectron2 INFO: Inference done 13487/26446. 0.1159 s / img. ETA=0:25:42
[06/30 18:28:20] detectron2 INFO: Inference done 13531/26446. 0.1159 s / img. ETA=0:25:36
[06/30 18:28:25] detectron2 INFO: Inference done 13574/26446. 0.1159 s / img. ETA=0:25:31
[06/30 18:28:30] detectron2 INFO: Inference done 13616/26446. 0.1159 s / img. ETA=0:25:26
[06/30 18:28:35] detectron2 INFO: Inference done 13660/26446. 0.1159 s / img. ETA=0:25:21
[06/30 18:28:40] detectron2 INFO: Inference done 13703/26446. 0.1159 s / img. ETA=0:25:16
[06/30 18:28:45] detectron2 INFO: Inference done 13747/26446. 0.1159 s / img. ETA=0:25:10
[06/30 18:28:50] detectron2 INFO: Inference done 13790/26446. 0.1159 s / img. ETA=0:25:05
[06/30 18:28:55] detectron2 INFO: Inference done 13832/26446. 0.1159 s / img. ETA=0:25:00
[06/30 18:29:00] detectron2 INFO: Inference done 13875/26446. 0.1159 s / img. ETA=0:24:55
[06/30 18:29:05] detectron2 INFO: Inference done 13919/26446. 0.1159 s / img. ETA=0:24:50
[06/30 18:29:10] detectron2 INFO: Inference done 13962/26446. 0.1159 s / img. ETA=0:24:45
[06/30 18:29:15] detectron2 INFO: Inference done 14005/26446. 0.1159 s / img. ETA=0:24:39
[06/30 18:29:20] detectron2 INFO: Inference done 14048/26446. 0.1159 s / img. ETA=0:24:34
[06/30 18:29:25] detectron2 INFO: Inference done 14092/26446. 0.1158 s / img. ETA=0:24:29
[06/30 18:29:30] detectron2 INFO: Inference done 14135/26446. 0.1158 s / img. ETA=0:24:24
[06/30 18:29:35] detectron2 INFO: Inference done 14178/26446. 0.1158 s / img. ETA=0:24:18
[06/30 18:29:40] detectron2 INFO: Inference done 14221/26446. 0.1158 s / img. ETA=0:24:13
[06/30 18:29:46] detectron2 INFO: Inference done 14264/26446. 0.1158 s / img. ETA=0:24:08
[06/30 18:29:51] detectron2 INFO: Inference done 14308/26446. 0.1158 s / img. ETA=0:24:03
[06/30 18:29:56] detectron2 INFO: Inference done 14351/26446. 0.1158 s / img. ETA=0:23:58
[06/30 18:30:01] detectron2 INFO: Inference done 14393/26446. 0.1158 s / img. ETA=0:23:53
[06/30 18:30:06] detectron2 INFO: Inference done 14436/26446. 0.1158 s / img. ETA=0:23:47
[06/30 18:30:11] detectron2 INFO: Inference done 14479/26446. 0.1158 s / img. ETA=0:23:42
[06/30 18:30:16] detectron2 INFO: Inference done 14522/26446. 0.1158 s / img. ETA=0:23:37
[06/30 18:30:21] detectron2 INFO: Inference done 14565/26446. 0.1158 s / img. ETA=0:23:32
[06/30 18:30:26] detectron2 INFO: Inference done 14608/26446. 0.1158 s / img. ETA=0:23:27
[06/30 18:30:31] detectron2 INFO: Inference done 14651/26446. 0.1158 s / img. ETA=0:23:22
[06/30 18:30:36] detectron2 INFO: Inference done 14694/26446. 0.1158 s / img. ETA=0:23:16
[06/30 18:30:41] detectron2 INFO: Inference done 14737/26446. 0.1158 s / img. ETA=0:23:11
[06/30 18:30:46] detectron2 INFO: Inference done 14779/26446. 0.1158 s / img. ETA=0:23:06
[06/30 18:30:51] detectron2 INFO: Inference done 14809/26446. 0.1159 s / img. ETA=0:23:04
[06/30 18:30:56] detectron2 INFO: Inference done 14853/26446. 0.1159 s / img. ETA=0:22:59
[06/30 18:31:01] detectron2 INFO: Inference done 14897/26446. 0.1159 s / img. ETA=0:22:53
[06/30 18:31:06] detectron2 INFO: Inference done 14941/26446. 0.1159 s / img. ETA=0:22:48
[06/30 18:31:11] detectron2 INFO: Inference done 14984/26446. 0.1159 s / img. ETA=0:22:43
[06/30 18:31:17] detectron2 INFO: Inference done 15028/26446. 0.1158 s / img. ETA=0:22:37
[06/30 18:31:22] detectron2 INFO: Inference done 15072/26446. 0.1158 s / img. ETA=0:22:32
[06/30 18:31:27] detectron2 INFO: Inference done 15116/26446. 0.1158 s / img. ETA=0:22:27
[06/30 18:31:32] detectron2 INFO: Inference done 15159/26446. 0.1158 s / img. ETA=0:22:21
[06/30 18:31:37] detectron2 INFO: Inference done 15203/26446. 0.1158 s / img. ETA=0:22:16
[06/30 18:31:42] detectron2 INFO: Inference done 15246/26446. 0.1158 s / img. ETA=0:22:11
[06/30 18:31:47] detectron2 INFO: Inference done 15288/26446. 0.1158 s / img. ETA=0:22:06
[06/30 18:31:52] detectron2 INFO: Inference done 15332/26446. 0.1158 s / img. ETA=0:22:01
[06/30 18:31:57] detectron2 INFO: Inference done 15376/26446. 0.1158 s / img. ETA=0:21:55
[06/30 18:32:02] detectron2 INFO: Inference done 15420/26446. 0.1158 s / img. ETA=0:21:50
[06/30 18:32:07] detectron2 INFO: Inference done 15463/26446. 0.1158 s / img. ETA=0:21:45
[06/30 18:32:12] detectron2 INFO: Inference done 15506/26446. 0.1158 s / img. ETA=0:21:40
[06/30 18:32:17] detectron2 INFO: Inference done 15549/26446. 0.1158 s / img. ETA=0:21:34
[06/30 18:32:22] detectron2 INFO: Inference done 15592/26446. 0.1158 s / img. ETA=0:21:29
[06/30 18:32:27] detectron2 INFO: Inference done 15636/26446. 0.1157 s / img. ETA=0:21:24
[06/30 18:32:32] detectron2 INFO: Inference done 15677/26446. 0.1158 s / img. ETA=0:21:19
[06/30 18:32:37] detectron2 INFO: Inference done 15718/26446. 0.1158 s / img. ETA=0:21:14
[06/30 18:32:42] detectron2 INFO: Inference done 15761/26446. 0.1158 s / img. ETA=0:21:09
[06/30 18:32:47] detectron2 INFO: Inference done 15804/26446. 0.1158 s / img. ETA=0:21:04
[06/30 18:32:53] detectron2 INFO: Inference done 15848/26446. 0.1158 s / img. ETA=0:20:59
[06/30 18:32:58] detectron2 INFO: Inference done 15892/26446. 0.1157 s / img. ETA=0:20:53
[06/30 18:33:03] detectron2 INFO: Inference done 15936/26446. 0.1157 s / img. ETA=0:20:48
[06/30 18:33:08] detectron2 INFO: Inference done 15979/26446. 0.1157 s / img. ETA=0:20:43
[06/30 18:33:13] detectron2 INFO: Inference done 16022/26446. 0.1157 s / img. ETA=0:20:38
[06/30 18:33:18] detectron2 INFO: Inference done 16066/26446. 0.1157 s / img. ETA=0:20:33
[06/30 18:33:23] detectron2 INFO: Inference done 16109/26446. 0.1157 s / img. ETA=0:20:27
[06/30 18:33:28] detectron2 INFO: Inference done 16152/26446. 0.1157 s / img. ETA=0:20:22
[06/30 18:33:33] detectron2 INFO: Inference done 16196/26446. 0.1157 s / img. ETA=0:20:17
[06/30 18:33:38] detectron2 INFO: Inference done 16240/26446. 0.1157 s / img. ETA=0:20:12
[06/30 18:33:43] detectron2 INFO: Inference done 16283/26446. 0.1157 s / img. ETA=0:20:06
[06/30 18:33:48] detectron2 INFO: Inference done 16326/26446. 0.1157 s / img. ETA=0:20:01
[06/30 18:33:53] detectron2 INFO: Inference done 16369/26446. 0.1157 s / img. ETA=0:19:56
[06/30 18:33:58] detectron2 INFO: Inference done 16413/26446. 0.1157 s / img. ETA=0:19:51
[06/30 18:34:04] detectron2 INFO: Inference done 16457/26446. 0.1157 s / img. ETA=0:19:46
[06/30 18:34:09] detectron2 INFO: Inference done 16501/26446. 0.1157 s / img. ETA=0:19:40
[06/30 18:34:14] detectron2 INFO: Inference done 16544/26446. 0.1157 s / img. ETA=0:19:35
[06/30 18:34:19] detectron2 INFO: Inference done 16588/26446. 0.1157 s / img. ETA=0:19:30
[06/30 18:34:24] detectron2 INFO: Inference done 16632/26446. 0.1156 s / img. ETA=0:19:25
[06/30 18:34:29] detectron2 INFO: Inference done 16675/26446. 0.1156 s / img. ETA=0:19:19
[06/30 18:34:34] detectron2 INFO: Inference done 16718/26446. 0.1156 s / img. ETA=0:19:14
[06/30 18:34:39] detectron2 INFO: Inference done 16761/26446. 0.1156 s / img. ETA=0:19:09
[06/30 18:34:44] detectron2 INFO: Inference done 16804/26446. 0.1156 s / img. ETA=0:19:04
[06/30 18:34:49] detectron2 INFO: Inference done 16847/26446. 0.1156 s / img. ETA=0:18:59
[06/30 18:34:54] detectron2 INFO: Inference done 16891/26446. 0.1156 s / img. ETA=0:18:53
[06/30 18:34:59] detectron2 INFO: Inference done 16935/26446. 0.1156 s / img. ETA=0:18:48
[06/30 18:35:04] detectron2 INFO: Inference done 16978/26446. 0.1156 s / img. ETA=0:18:43
[06/30 18:35:09] detectron2 INFO: Inference done 17022/26446. 0.1156 s / img. ETA=0:18:38
[06/30 18:35:14] detectron2 INFO: Inference done 17065/26446. 0.1156 s / img. ETA=0:18:33
[06/30 18:35:19] detectron2 INFO: Inference done 17109/26446. 0.1156 s / img. ETA=0:18:27
[06/30 18:35:24] detectron2 INFO: Inference done 17153/26446. 0.1156 s / img. ETA=0:18:22
[06/30 18:35:29] detectron2 INFO: Inference done 17196/26446. 0.1156 s / img. ETA=0:18:17
[06/30 18:35:35] detectron2 INFO: Inference done 17240/26446. 0.1156 s / img. ETA=0:18:12
[06/30 18:35:40] detectron2 INFO: Inference done 17284/26446. 0.1155 s / img. ETA=0:18:06
[06/30 18:35:45] detectron2 INFO: Inference done 17328/26446. 0.1155 s / img. ETA=0:18:01
[06/30 18:35:50] detectron2 INFO: Inference done 17371/26446. 0.1155 s / img. ETA=0:17:56
[06/30 18:35:55] detectron2 INFO: Inference done 17415/26446. 0.1155 s / img. ETA=0:17:50
[06/30 18:36:00] detectron2 INFO: Inference done 17460/26446. 0.1155 s / img. ETA=0:17:45
[06/30 18:36:05] detectron2 INFO: Inference done 17503/26446. 0.1155 s / img. ETA=0:17:40
[06/30 18:36:10] detectron2 INFO: Inference done 17547/26446. 0.1155 s / img. ETA=0:17:35
[06/30 18:36:15] detectron2 INFO: Inference done 17591/26446. 0.1155 s / img. ETA=0:17:29
[06/30 18:36:20] detectron2 INFO: Inference done 17634/26446. 0.1155 s / img. ETA=0:17:24
[06/30 18:36:25] detectron2 INFO: Inference done 17678/26446. 0.1155 s / img. ETA=0:17:19
[06/30 18:36:30] detectron2 INFO: Inference done 17722/26446. 0.1155 s / img. ETA=0:17:14
[06/30 18:36:35] detectron2 INFO: Inference done 17765/26446. 0.1155 s / img. ETA=0:17:09
[06/30 18:36:40] detectron2 INFO: Inference done 17807/26446. 0.1155 s / img. ETA=0:17:04
[06/30 18:36:45] detectron2 INFO: Inference done 17850/26446. 0.1155 s / img. ETA=0:16:58
[06/30 18:36:50] detectron2 INFO: Inference done 17894/26446. 0.1155 s / img. ETA=0:16:53
[06/30 18:36:55] detectron2 INFO: Inference done 17938/26446. 0.1155 s / img. ETA=0:16:48
[06/30 18:37:00] detectron2 INFO: Inference done 17981/26446. 0.1155 s / img. ETA=0:16:43
[06/30 18:37:05] detectron2 INFO: Inference done 18025/26446. 0.1154 s / img. ETA=0:16:37
[06/30 18:37:11] detectron2 INFO: Inference done 18069/26446. 0.1154 s / img. ETA=0:16:32
[06/30 18:37:16] detectron2 INFO: Inference done 18112/26446. 0.1154 s / img. ETA=0:16:27
[06/30 18:37:21] detectron2 INFO: Inference done 18156/26446. 0.1154 s / img. ETA=0:16:22
[06/30 18:37:26] detectron2 INFO: Inference done 18200/26446. 0.1154 s / img. ETA=0:16:16
[06/30 18:37:31] detectron2 INFO: Inference done 18243/26446. 0.1154 s / img. ETA=0:16:11
[06/30 18:37:36] detectron2 INFO: Inference done 18286/26446. 0.1154 s / img. ETA=0:16:06
[06/30 18:37:41] detectron2 INFO: Inference done 18329/26446. 0.1154 s / img. ETA=0:16:01
[06/30 18:37:46] detectron2 INFO: Inference done 18373/26446. 0.1154 s / img. ETA=0:15:56
[06/30 18:37:51] detectron2 INFO: Inference done 18417/26446. 0.1154 s / img. ETA=0:15:51
[06/30 18:37:56] detectron2 INFO: Inference done 18460/26446. 0.1154 s / img. ETA=0:15:45
[06/30 18:38:01] detectron2 INFO: Inference done 18503/26446. 0.1154 s / img. ETA=0:15:40
[06/30 18:38:06] detectron2 INFO: Inference done 18547/26446. 0.1154 s / img. ETA=0:15:35
[06/30 18:38:11] detectron2 INFO: Inference done 18591/26446. 0.1154 s / img. ETA=0:15:30
[06/30 18:38:16] detectron2 INFO: Inference done 18634/26446. 0.1154 s / img. ETA=0:15:25
[06/30 18:38:21] detectron2 INFO: Inference done 18678/26446. 0.1154 s / img. ETA=0:15:19
[06/30 18:38:27] detectron2 INFO: Inference done 18722/26446. 0.1154 s / img. ETA=0:15:14
[06/30 18:38:32] detectron2 INFO: Inference done 18765/26446. 0.1154 s / img. ETA=0:15:09
[06/30 18:38:37] detectron2 INFO: Inference done 18808/26446. 0.1154 s / img. ETA=0:15:04
[06/30 18:38:42] detectron2 INFO: Inference done 18853/26446. 0.1153 s / img. ETA=0:14:59
[06/30 18:38:47] detectron2 INFO: Inference done 18897/26446. 0.1153 s / img. ETA=0:14:53
[06/30 18:38:52] detectron2 INFO: Inference done 18941/26446. 0.1153 s / img. ETA=0:14:48
[06/30 18:38:57] detectron2 INFO: Inference done 18978/26446. 0.1154 s / img. ETA=0:14:44
[06/30 18:39:02] detectron2 INFO: Inference done 19020/26446. 0.1154 s / img. ETA=0:14:39
[06/30 18:39:07] detectron2 INFO: Inference done 19062/26446. 0.1154 s / img. ETA=0:14:34
[06/30 18:39:12] detectron2 INFO: Inference done 19105/26446. 0.1154 s / img. ETA=0:14:29
[06/30 18:39:17] detectron2 INFO: Inference done 19149/26446. 0.1154 s / img. ETA=0:14:24
[06/30 18:39:22] detectron2 INFO: Inference done 19193/26446. 0.1154 s / img. ETA=0:14:18
[06/30 18:39:27] detectron2 INFO: Inference done 19233/26446. 0.1154 s / img. ETA=0:14:14
[06/30 18:39:32] detectron2 INFO: Inference done 19277/26446. 0.1154 s / img. ETA=0:14:08
[06/30 18:39:37] detectron2 INFO: Inference done 19320/26446. 0.1154 s / img. ETA=0:14:03
[06/30 18:39:43] detectron2 INFO: Inference done 19363/26446. 0.1154 s / img. ETA=0:13:58
[06/30 18:39:48] detectron2 INFO: Inference done 19407/26446. 0.1154 s / img. ETA=0:13:53
[06/30 18:39:53] detectron2 INFO: Inference done 19450/26446. 0.1154 s / img. ETA=0:13:48
[06/30 18:39:58] detectron2 INFO: Inference done 19494/26446. 0.1154 s / img. ETA=0:13:43
[06/30 18:40:03] detectron2 INFO: Inference done 19538/26446. 0.1153 s / img. ETA=0:13:37
[06/30 18:40:08] detectron2 INFO: Inference done 19580/26446. 0.1154 s / img. ETA=0:13:32
[06/30 18:40:13] detectron2 INFO: Inference done 19622/26446. 0.1154 s / img. ETA=0:13:28
[06/30 18:40:18] detectron2 INFO: Inference done 19665/26446. 0.1154 s / img. ETA=0:13:22
[06/30 18:40:23] detectron2 INFO: Inference done 19708/26446. 0.1153 s / img. ETA=0:13:17
[06/30 18:40:28] detectron2 INFO: Inference done 19752/26446. 0.1153 s / img. ETA=0:13:12
[06/30 18:40:33] detectron2 INFO: Inference done 19795/26446. 0.1153 s / img. ETA=0:13:07
[06/30 18:40:38] detectron2 INFO: Inference done 19839/26446. 0.1153 s / img. ETA=0:13:02
[06/30 18:40:43] detectron2 INFO: Inference done 19883/26446. 0.1153 s / img. ETA=0:12:56
[06/30 18:40:48] detectron2 INFO: Inference done 19926/26446. 0.1153 s / img. ETA=0:12:51
[06/30 18:40:53] detectron2 INFO: Inference done 19970/26446. 0.1153 s / img. ETA=0:12:46
[06/30 18:40:58] detectron2 INFO: Inference done 20014/26446. 0.1153 s / img. ETA=0:12:41
[06/30 18:41:03] detectron2 INFO: Inference done 20058/26446. 0.1153 s / img. ETA=0:12:36
[06/30 18:41:08] detectron2 INFO: Inference done 20101/26446. 0.1153 s / img. ETA=0:12:30
[06/30 18:41:13] detectron2 INFO: Inference done 20144/26446. 0.1153 s / img. ETA=0:12:25
[06/30 18:41:18] detectron2 INFO: Inference done 20188/26446. 0.1153 s / img. ETA=0:12:20
[06/30 18:41:23] detectron2 INFO: Inference done 20231/26446. 0.1153 s / img. ETA=0:12:15
[06/30 18:41:28] detectron2 INFO: Inference done 20274/26446. 0.1153 s / img. ETA=0:12:10
[06/30 18:41:34] detectron2 INFO: Inference done 20317/26446. 0.1153 s / img. ETA=0:12:05
[06/30 18:41:39] detectron2 INFO: Inference done 20361/26446. 0.1153 s / img. ETA=0:11:59
[06/30 18:41:44] detectron2 INFO: Inference done 20404/26446. 0.1153 s / img. ETA=0:11:54
[06/30 18:41:49] detectron2 INFO: Inference done 20447/26446. 0.1153 s / img. ETA=0:11:49
[06/30 18:41:54] detectron2 INFO: Inference done 20491/26446. 0.1153 s / img. ETA=0:11:44
[06/30 18:41:59] detectron2 INFO: Inference done 20534/26446. 0.1153 s / img. ETA=0:11:39
[06/30 18:42:04] detectron2 INFO: Inference done 20578/26446. 0.1153 s / img. ETA=0:11:34
[06/30 18:42:09] detectron2 INFO: Inference done 20622/26446. 0.1152 s / img. ETA=0:11:28
[06/30 18:42:14] detectron2 INFO: Inference done 20665/26446. 0.1152 s / img. ETA=0:11:23
[06/30 18:42:19] detectron2 INFO: Inference done 20709/26446. 0.1152 s / img. ETA=0:11:18
[06/30 18:42:24] detectron2 INFO: Inference done 20752/26446. 0.1152 s / img. ETA=0:11:13
[06/30 18:42:29] detectron2 INFO: Inference done 20794/26446. 0.1152 s / img. ETA=0:11:08
[06/30 18:42:34] detectron2 INFO: Inference done 20837/26446. 0.1152 s / img. ETA=0:11:03
[06/30 18:42:39] detectron2 INFO: Inference done 20880/26446. 0.1152 s / img. ETA=0:10:58
[06/30 18:42:44] detectron2 INFO: Inference done 20924/26446. 0.1152 s / img. ETA=0:10:53
[06/30 18:42:49] detectron2 INFO: Inference done 20968/26446. 0.1152 s / img. ETA=0:10:47
[06/30 18:42:54] detectron2 INFO: Inference done 21011/26446. 0.1152 s / img. ETA=0:10:42
[06/30 18:42:59] detectron2 INFO: Inference done 21054/26446. 0.1152 s / img. ETA=0:10:37
[06/30 18:43:04] detectron2 INFO: Inference done 21098/26446. 0.1152 s / img. ETA=0:10:32
[06/30 18:43:09] detectron2 INFO: Inference done 21142/26446. 0.1152 s / img. ETA=0:10:27
[06/30 18:43:15] detectron2 INFO: Inference done 21186/26446. 0.1152 s / img. ETA=0:10:21
[06/30 18:43:20] detectron2 INFO: Inference done 21230/26446. 0.1152 s / img. ETA=0:10:16
[06/30 18:43:25] detectron2 INFO: Inference done 21272/26446. 0.1152 s / img. ETA=0:10:11
[06/30 18:43:30] detectron2 INFO: Inference done 21315/26446. 0.1152 s / img. ETA=0:10:06
[06/30 18:43:35] detectron2 INFO: Inference done 21358/26446. 0.1152 s / img. ETA=0:10:01
[06/30 18:43:40] detectron2 INFO: Inference done 21401/26446. 0.1152 s / img. ETA=0:09:56
[06/30 18:43:45] detectron2 INFO: Inference done 21444/26446. 0.1152 s / img. ETA=0:09:51
[06/30 18:43:50] detectron2 INFO: Inference done 21488/26446. 0.1152 s / img. ETA=0:09:46
[06/30 18:43:55] detectron2 INFO: Inference done 21531/26446. 0.1152 s / img. ETA=0:09:41
[06/30 18:44:00] detectron2 INFO: Inference done 21575/26446. 0.1152 s / img. ETA=0:09:35
[06/30 18:44:05] detectron2 INFO: Inference done 21618/26446. 0.1152 s / img. ETA=0:09:30
[06/30 18:44:10] detectron2 INFO: Inference done 21662/26446. 0.1152 s / img. ETA=0:09:25
[06/30 18:44:15] detectron2 INFO: Inference done 21704/26446. 0.1152 s / img. ETA=0:09:20
[06/30 18:44:20] detectron2 INFO: Inference done 21747/26446. 0.1152 s / img. ETA=0:09:15
[06/30 18:44:25] detectron2 INFO: Inference done 21787/26446. 0.1152 s / img. ETA=0:09:10
[06/30 18:44:30] detectron2 INFO: Inference done 21830/26446. 0.1152 s / img. ETA=0:09:05
[06/30 18:44:35] detectron2 INFO: Inference done 21873/26446. 0.1152 s / img. ETA=0:09:00
[06/30 18:44:41] detectron2 INFO: Inference done 21917/26446. 0.1152 s / img. ETA=0:08:55
[06/30 18:44:46] detectron2 INFO: Inference done 21961/26446. 0.1152 s / img. ETA=0:08:50
[06/30 18:44:51] detectron2 INFO: Inference done 22004/26446. 0.1152 s / img. ETA=0:08:45
[06/30 18:44:56] detectron2 INFO: Inference done 22047/26446. 0.1152 s / img. ETA=0:08:40
[06/30 18:45:01] detectron2 INFO: Inference done 22089/26446. 0.1152 s / img. ETA=0:08:35
[06/30 18:45:06] detectron2 INFO: Inference done 22133/26446. 0.1152 s / img. ETA=0:08:29
[06/30 18:45:11] detectron2 INFO: Inference done 22177/26446. 0.1152 s / img. ETA=0:08:24
[06/30 18:45:16] detectron2 INFO: Inference done 22221/26446. 0.1152 s / img. ETA=0:08:19
[06/30 18:45:21] detectron2 INFO: Inference done 22265/26446. 0.1151 s / img. ETA=0:08:14
[06/30 18:45:26] detectron2 INFO: Inference done 22308/26446. 0.1151 s / img. ETA=0:08:09
[06/30 18:45:31] detectron2 INFO: Inference done 22351/26446. 0.1151 s / img. ETA=0:08:03
[06/30 18:45:36] detectron2 INFO: Inference done 22394/26446. 0.1151 s / img. ETA=0:07:58
[06/30 18:45:41] detectron2 INFO: Inference done 22438/26446. 0.1151 s / img. ETA=0:07:53
[06/30 18:45:46] detectron2 INFO: Inference done 22481/26446. 0.1151 s / img. ETA=0:07:48
[06/30 18:45:51] detectron2 INFO: Inference done 22525/26446. 0.1151 s / img. ETA=0:07:43
[06/30 18:45:56] detectron2 INFO: Inference done 22569/26446. 0.1151 s / img. ETA=0:07:38
[06/30 18:46:01] detectron2 INFO: Inference done 22613/26446. 0.1151 s / img. ETA=0:07:32
[06/30 18:46:06] detectron2 INFO: Inference done 22656/26446. 0.1151 s / img. ETA=0:07:27
[06/30 18:46:12] detectron2 INFO: Inference done 22700/26446. 0.1151 s / img. ETA=0:07:22
[06/30 18:46:17] detectron2 INFO: Inference done 22743/26446. 0.1151 s / img. ETA=0:07:17
[06/30 18:46:22] detectron2 INFO: Inference done 22787/26446. 0.1151 s / img. ETA=0:07:12
[06/30 18:46:27] detectron2 INFO: Inference done 22830/26446. 0.1151 s / img. ETA=0:07:07
[06/30 18:46:32] detectron2 INFO: Inference done 22874/26446. 0.1151 s / img. ETA=0:07:01
[06/30 18:46:37] detectron2 INFO: Inference done 22917/26446. 0.1151 s / img. ETA=0:06:56
[06/30 18:46:42] detectron2 INFO: Inference done 22960/26446. 0.1151 s / img. ETA=0:06:51
[06/30 18:46:47] detectron2 INFO: Inference done 23004/26446. 0.1151 s / img. ETA=0:06:46
[06/30 18:46:52] detectron2 INFO: Inference done 23048/26446. 0.1151 s / img. ETA=0:06:41
[06/30 18:46:57] detectron2 INFO: Inference done 23092/26446. 0.1151 s / img. ETA=0:06:36
[06/30 18:47:02] detectron2 INFO: Inference done 23136/26446. 0.1151 s / img. ETA=0:06:30
[06/30 18:47:07] detectron2 INFO: Inference done 23180/26446. 0.1151 s / img. ETA=0:06:25
[06/30 18:47:12] detectron2 INFO: Inference done 23223/26446. 0.1151 s / img. ETA=0:06:20
[06/30 18:47:17] detectron2 INFO: Inference done 23267/26446. 0.1151 s / img. ETA=0:06:15
[06/30 18:47:22] detectron2 INFO: Inference done 23310/26446. 0.1151 s / img. ETA=0:06:10
[06/30 18:47:27] detectron2 INFO: Inference done 23353/26446. 0.1151 s / img. ETA=0:06:05
[06/30 18:47:32] detectron2 INFO: Inference done 23394/26446. 0.1151 s / img. ETA=0:06:00
[06/30 18:47:37] detectron2 INFO: Inference done 23437/26446. 0.1151 s / img. ETA=0:05:55
[06/30 18:47:43] detectron2 INFO: Inference done 23480/26446. 0.1151 s / img. ETA=0:05:50
[06/30 18:47:48] detectron2 INFO: Inference done 23524/26446. 0.1151 s / img. ETA=0:05:45
[06/30 18:47:53] detectron2 INFO: Inference done 23568/26446. 0.1151 s / img. ETA=0:05:39
[06/30 18:47:58] detectron2 INFO: Inference done 23611/26446. 0.1151 s / img. ETA=0:05:34
[06/30 18:48:03] detectron2 INFO: Inference done 23654/26446. 0.1151 s / img. ETA=0:05:29
[06/30 18:48:08] detectron2 INFO: Inference done 23698/26446. 0.1150 s / img. ETA=0:05:24
[06/30 18:48:13] detectron2 INFO: Inference done 23742/26446. 0.1150 s / img. ETA=0:05:19
[06/30 18:48:18] detectron2 INFO: Inference done 23786/26446. 0.1150 s / img. ETA=0:05:14
[06/30 18:48:23] detectron2 INFO: Inference done 23830/26446. 0.1150 s / img. ETA=0:05:08
[06/30 18:48:28] detectron2 INFO: Inference done 23873/26446. 0.1150 s / img. ETA=0:05:03
[06/30 18:48:35] detectron2 INFO: Inference done 23913/26446. 0.1150 s / img. ETA=0:04:59
[06/30 18:48:40] detectron2 INFO: Inference done 23957/26446. 0.1150 s / img. ETA=0:04:54
[06/30 18:48:45] detectron2 INFO: Inference done 24001/26446. 0.1150 s / img. ETA=0:04:48
[06/30 18:48:50] detectron2 INFO: Inference done 24045/26446. 0.1150 s / img. ETA=0:04:43
[06/30 18:48:55] detectron2 INFO: Inference done 24089/26446. 0.1150 s / img. ETA=0:04:38
[06/30 18:49:00] detectron2 INFO: Inference done 24132/26446. 0.1150 s / img. ETA=0:04:33
[06/30 18:49:05] detectron2 INFO: Inference done 24177/26446. 0.1150 s / img. ETA=0:04:27
[06/30 18:49:10] detectron2 INFO: Inference done 24220/26446. 0.1150 s / img. ETA=0:04:22
[06/30 18:49:15] detectron2 INFO: Inference done 24264/26446. 0.1150 s / img. ETA=0:04:17
[06/30 18:49:20] detectron2 INFO: Inference done 24308/26446. 0.1150 s / img. ETA=0:04:12
[06/30 18:49:25] detectron2 INFO: Inference done 24351/26446. 0.1150 s / img. ETA=0:04:07
[06/30 18:49:30] detectron2 INFO: Inference done 24395/26446. 0.1150 s / img. ETA=0:04:02
[06/30 18:49:35] detectron2 INFO: Inference done 24439/26446. 0.1150 s / img. ETA=0:03:56
[06/30 18:49:40] detectron2 INFO: Inference done 24483/26446. 0.1150 s / img. ETA=0:03:51
[06/30 18:49:45] detectron2 INFO: Inference done 24527/26446. 0.1150 s / img. ETA=0:03:46
[06/30 18:49:50] detectron2 INFO: Inference done 24571/26446. 0.1150 s / img. ETA=0:03:41
[06/30 18:49:55] detectron2 INFO: Inference done 24615/26446. 0.1150 s / img. ETA=0:03:36
[06/30 18:50:01] detectron2 INFO: Inference done 24659/26446. 0.1149 s / img. ETA=0:03:30
[06/30 18:50:06] detectron2 INFO: Inference done 24703/26446. 0.1149 s / img. ETA=0:03:25
[06/30 18:50:11] detectron2 INFO: Inference done 24746/26446. 0.1149 s / img. ETA=0:03:20
[06/30 18:50:16] detectron2 INFO: Inference done 24790/26446. 0.1149 s / img. ETA=0:03:15
[06/30 18:50:21] detectron2 INFO: Inference done 24834/26446. 0.1149 s / img. ETA=0:03:10
[06/30 18:50:26] detectron2 INFO: Inference done 24877/26446. 0.1149 s / img. ETA=0:03:05
[06/30 18:50:31] detectron2 INFO: Inference done 24920/26446. 0.1149 s / img. ETA=0:03:00
[06/30 18:50:36] detectron2 INFO: Inference done 24963/26446. 0.1149 s / img. ETA=0:02:55
[06/30 18:50:41] detectron2 INFO: Inference done 25006/26446. 0.1149 s / img. ETA=0:02:49
[06/30 18:50:46] detectron2 INFO: Inference done 25050/26446. 0.1149 s / img. ETA=0:02:44
[06/30 18:50:51] detectron2 INFO: Inference done 25093/26446. 0.1149 s / img. ETA=0:02:39
[06/30 18:50:56] detectron2 INFO: Inference done 25137/26446. 0.1149 s / img. ETA=0:02:34
[06/30 18:51:01] detectron2 INFO: Inference done 25180/26446. 0.1149 s / img. ETA=0:02:29
[06/30 18:51:06] detectron2 INFO: Inference done 25223/26446. 0.1149 s / img. ETA=0:02:24
[06/30 18:51:11] detectron2 INFO: Inference done 25265/26446. 0.1149 s / img. ETA=0:02:19
[06/30 18:51:16] detectron2 INFO: Inference done 25308/26446. 0.1149 s / img. ETA=0:02:14
[06/30 18:51:22] detectron2 INFO: Inference done 25352/26446. 0.1149 s / img. ETA=0:02:09
[06/30 18:51:27] detectron2 INFO: Inference done 25396/26446. 0.1149 s / img. ETA=0:02:03
[06/30 18:51:32] detectron2 INFO: Inference done 25440/26446. 0.1149 s / img. ETA=0:01:58
[06/30 18:51:37] detectron2 INFO: Inference done 25483/26446. 0.1149 s / img. ETA=0:01:53
[06/30 18:51:42] detectron2 INFO: Inference done 25526/26446. 0.1149 s / img. ETA=0:01:48
[06/30 18:51:47] detectron2 INFO: Inference done 25569/26446. 0.1149 s / img. ETA=0:01:43
[06/30 18:51:52] detectron2 INFO: Inference done 25612/26446. 0.1149 s / img. ETA=0:01:38
[06/30 18:51:57] detectron2 INFO: Inference done 25655/26446. 0.1149 s / img. ETA=0:01:33
[06/30 18:52:02] detectron2 INFO: Inference done 25699/26446. 0.1149 s / img. ETA=0:01:28
[06/30 18:52:07] detectron2 INFO: Inference done 25743/26446. 0.1149 s / img. ETA=0:01:22
[06/30 18:52:12] detectron2 INFO: Inference done 25787/26446. 0.1149 s / img. ETA=0:01:17
[06/30 18:52:17] detectron2 INFO: Inference done 25830/26446. 0.1149 s / img. ETA=0:01:12
[06/30 18:52:22] detectron2 INFO: Inference done 25874/26446. 0.1149 s / img. ETA=0:01:07
[06/30 18:52:27] detectron2 INFO: Inference done 25918/26446. 0.1149 s / img. ETA=0:01:02
[06/30 18:52:32] detectron2 INFO: Inference done 25962/26446. 0.1149 s / img. ETA=0:00:57
[06/30 18:52:37] detectron2 INFO: Inference done 26006/26446. 0.1149 s / img. ETA=0:00:51
[06/30 18:52:43] detectron2 INFO: Inference done 26050/26446. 0.1149 s / img. ETA=0:00:46
[06/30 18:52:48] detectron2 INFO: Inference done 26094/26446. 0.1149 s / img. ETA=0:00:41
[06/30 18:52:53] detectron2 INFO: Inference done 26137/26446. 0.1149 s / img. ETA=0:00:36
[06/30 18:52:58] detectron2 INFO: Inference done 26180/26446. 0.1149 s / img. ETA=0:00:31
[06/30 18:53:03] detectron2 INFO: Inference done 26224/26446. 0.1149 s / img. ETA=0:00:26
[06/30 18:53:08] detectron2 INFO: Inference done 26267/26446. 0.1149 s / img. ETA=0:00:21
[06/30 18:53:13] detectron2 INFO: Inference done 26310/26446. 0.1149 s / img. ETA=0:00:16
[06/30 18:53:18] detectron2 INFO: Inference done 26354/26446. 0.1148 s / img. ETA=0:00:10
[06/30 18:53:23] detectron2 INFO: Inference done 26398/26446. 0.1148 s / img. ETA=0:00:05
[06/30 18:53:28] detectron2 INFO: Inference done 26441/26446. 0.1148 s / img. ETA=0:00:00
[06/30 18:53:29] detectron2 INFO: Total inference time: 0:51:59.244695 (0.117970 s / img per device, on 1 devices)
[06/30 18:53:29] detectron2 INFO: Total inference pure compute time: 0:50:36 (0.114843 s / img per device, on 1 devices)
[06/30 18:53:38] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 18:53:38] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 18:53:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 18:53:49] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[06/30 19:06:44] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 19:06:45] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 19:06:45] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 19:06:45] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 19:06:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 19:06:45] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 19:06:45] d2.utils.env INFO: Using a generated random seed 45962490
[06/30 19:06:47] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 19:06:47] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 19:06:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 19:06:49] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 19:06:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 19:06:49] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 19:06:51] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 19:06:51] detectron2 INFO: Following metrics will be use for evaluation
[06/30 19:06:51] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 19:06:51] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 19:06:51] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 19:06:51] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 19:06:53] detectron2 INFO: Loading zero shot triplets
[06/30 19:06:53] detectron2 INFO: Start inference on 26446 images
[06/30 19:07:17] detectron2 INFO: Inference done 11/26446. 0.1803 s / img. ETA=1:20:41
[06/30 19:07:22] detectron2 INFO: Inference done 44/26446. 0.1551 s / img. ETA=1:09:36
[06/30 19:07:27] detectron2 INFO: Inference done 76/26446. 0.1548 s / img. ETA=1:09:23
[06/30 19:07:32] detectron2 INFO: Inference done 113/26446. 0.1473 s / img. ETA=1:05:58
[06/30 19:07:37] detectron2 INFO: Inference done 150/26446. 0.1435 s / img. ETA=1:04:13
[06/30 19:07:42] detectron2 INFO: Inference done 190/26446. 0.1389 s / img. ETA=1:02:05
[06/30 19:07:47] detectron2 INFO: Inference done 231/26446. 0.1356 s / img. ETA=1:00:33
[06/30 19:07:52] detectron2 INFO: Inference done 270/26446. 0.1344 s / img. ETA=0:59:57
[06/30 19:07:57] detectron2 INFO: Inference done 308/26446. 0.1338 s / img. ETA=0:59:37
[06/30 19:08:02] detectron2 INFO: Inference done 349/26446. 0.1323 s / img. ETA=0:58:52
[06/30 19:08:07] detectron2 INFO: Inference done 388/26446. 0.1317 s / img. ETA=0:58:30
[06/30 19:08:12] detectron2 INFO: Inference done 427/26446. 0.1311 s / img. ETA=0:58:10
[06/30 19:08:17] detectron2 INFO: Inference done 465/26446. 0.1311 s / img. ETA=0:58:03
[06/30 19:08:22] detectron2 INFO: Inference done 506/26446. 0.1303 s / img. ETA=0:57:37
[06/30 19:08:27] detectron2 INFO: Inference done 547/26446. 0.1295 s / img. ETA=0:57:12
[06/30 19:08:32] detectron2 INFO: Inference done 587/26446. 0.1290 s / img. ETA=0:56:54
[06/30 19:08:37] detectron2 INFO: Inference done 628/26446. 0.1286 s / img. ETA=0:56:36
[06/30 19:08:42] detectron2 INFO: Inference done 668/26446. 0.1283 s / img. ETA=0:56:24
[06/30 19:08:48] detectron2 INFO: Inference done 709/26446. 0.1279 s / img. ETA=0:56:08
[06/30 19:08:53] detectron2 INFO: Inference done 750/26446. 0.1274 s / img. ETA=0:55:50
[06/30 19:08:58] detectron2 INFO: Inference done 791/26446. 0.1270 s / img. ETA=0:55:35
[06/30 19:09:03] detectron2 INFO: Inference done 831/26446. 0.1267 s / img. ETA=0:55:24
[06/30 19:09:08] detectron2 INFO: Inference done 874/26446. 0.1262 s / img. ETA=0:55:05
[06/30 19:09:13] detectron2 INFO: Inference done 915/26446. 0.1260 s / img. ETA=0:54:54
[06/30 19:09:18] detectron2 INFO: Inference done 958/26446. 0.1255 s / img. ETA=0:54:35
[06/30 19:09:23] detectron2 INFO: Inference done 999/26446. 0.1253 s / img. ETA=0:54:25
[06/30 19:09:28] detectron2 INFO: Inference done 1040/26446. 0.1251 s / img. ETA=0:54:14
[06/30 19:09:33] detectron2 INFO: Inference done 1082/26446. 0.1248 s / img. ETA=0:54:01
[06/30 19:09:38] detectron2 INFO: Inference done 1125/26446. 0.1244 s / img. ETA=0:53:46
[06/30 19:09:43] detectron2 INFO: Inference done 1162/26446. 0.1247 s / img. ETA=0:53:50
[06/30 19:09:48] detectron2 INFO: Inference done 1196/26446. 0.1253 s / img. ETA=0:54:01
[06/30 19:09:53] detectron2 INFO: Inference done 1236/26446. 0.1253 s / img. ETA=0:53:55
[06/30 19:09:58] detectron2 INFO: Inference done 1278/26446. 0.1250 s / img. ETA=0:53:43
[06/30 19:10:04] detectron2 INFO: Inference done 1320/26446. 0.1248 s / img. ETA=0:53:31
[06/30 19:10:09] detectron2 INFO: Inference done 1362/26446. 0.1245 s / img. ETA=0:53:20
[06/30 19:10:14] detectron2 INFO: Inference done 1405/26446. 0.1243 s / img. ETA=0:53:08
[06/30 19:10:19] detectron2 INFO: Inference done 1445/26446. 0.1243 s / img. ETA=0:53:03
[06/30 19:10:24] detectron2 INFO: Inference done 1484/26446. 0.1243 s / img. ETA=0:52:59
[06/30 19:10:29] detectron2 INFO: Inference done 1525/26446. 0.1242 s / img. ETA=0:52:51
[06/30 19:10:35] detectron2 INFO: Inference done 1561/26446. 0.1251 s / img. ETA=0:53:08
[06/30 19:10:40] detectron2 INFO: Inference done 1602/26446. 0.1249 s / img. ETA=0:52:59
[06/30 19:10:45] detectron2 INFO: Inference done 1643/26446. 0.1248 s / img. ETA=0:52:51
[06/30 19:10:50] detectron2 INFO: Inference done 1685/26446. 0.1246 s / img. ETA=0:52:40
[06/30 19:10:55] detectron2 INFO: Inference done 1725/26446. 0.1246 s / img. ETA=0:52:34
[06/30 19:11:00] detectron2 INFO: Inference done 1765/26446. 0.1245 s / img. ETA=0:52:29
[06/30 19:11:05] detectron2 INFO: Inference done 1809/26446. 0.1242 s / img. ETA=0:52:16
[06/30 19:11:10] detectron2 INFO: Inference done 1852/26446. 0.1241 s / img. ETA=0:52:06
[06/30 19:11:15] detectron2 INFO: Inference done 1895/26446. 0.1239 s / img. ETA=0:51:55
[06/30 19:11:20] detectron2 INFO: Inference done 1937/26446. 0.1237 s / img. ETA=0:51:46
[06/30 19:11:25] detectron2 INFO: Inference done 1978/26446. 0.1236 s / img. ETA=0:51:39
[06/30 19:11:30] detectron2 INFO: Inference done 2017/26446. 0.1237 s / img. ETA=0:51:36
[06/30 19:11:36] detectron2 INFO: Inference done 2058/26446. 0.1237 s / img. ETA=0:51:30
[06/30 19:11:41] detectron2 INFO: Inference done 2101/26446. 0.1235 s / img. ETA=0:51:21
[06/30 19:11:46] detectron2 INFO: Inference done 2142/26446. 0.1234 s / img. ETA=0:51:14
[06/30 19:11:51] detectron2 INFO: Inference done 2184/26446. 0.1233 s / img. ETA=0:51:05
[06/30 19:11:56] detectron2 INFO: Inference done 2226/26446. 0.1232 s / img. ETA=0:50:57
[06/30 19:12:01] detectron2 INFO: Inference done 2267/26446. 0.1231 s / img. ETA=0:50:51
[06/30 19:12:06] detectron2 INFO: Inference done 2310/26446. 0.1230 s / img. ETA=0:50:41
[06/30 19:12:11] detectron2 INFO: Inference done 2352/26446. 0.1229 s / img. ETA=0:50:34
[06/30 19:12:16] detectron2 INFO: Inference done 2393/26446. 0.1228 s / img. ETA=0:50:28
[06/30 19:12:21] detectron2 INFO: Inference done 2435/26446. 0.1227 s / img. ETA=0:50:20
[06/30 19:12:26] detectron2 INFO: Inference done 2477/26446. 0.1227 s / img. ETA=0:50:13
[06/30 19:12:31] detectron2 INFO: Inference done 2519/26446. 0.1226 s / img. ETA=0:50:05
[06/30 19:12:36] detectron2 INFO: Inference done 2561/26446. 0.1225 s / img. ETA=0:49:58
[06/30 19:12:41] detectron2 INFO: Inference done 2603/26446. 0.1224 s / img. ETA=0:49:51
[06/30 19:12:46] detectron2 INFO: Inference done 2643/26446. 0.1224 s / img. ETA=0:49:47
[06/30 19:12:52] detectron2 INFO: Inference done 2684/26446. 0.1224 s / img. ETA=0:49:40
[06/30 19:12:57] detectron2 INFO: Inference done 2724/26446. 0.1224 s / img. ETA=0:49:35
[06/30 19:13:02] detectron2 INFO: Inference done 2766/26446. 0.1223 s / img. ETA=0:49:28
[06/30 19:13:07] detectron2 INFO: Inference done 2808/26446. 0.1222 s / img. ETA=0:49:22
[06/30 19:13:12] detectron2 INFO: Inference done 2851/26446. 0.1221 s / img. ETA=0:49:13
[06/30 19:13:17] detectron2 INFO: Inference done 2893/26446. 0.1220 s / img. ETA=0:49:06
[06/30 19:13:22] detectron2 INFO: Inference done 2936/26446. 0.1220 s / img. ETA=0:48:59
[06/30 19:13:27] detectron2 INFO: Inference done 2978/26446. 0.1219 s / img. ETA=0:48:52
[06/30 19:13:32] detectron2 INFO: Inference done 3020/26446. 0.1218 s / img. ETA=0:48:45
[06/30 19:13:37] detectron2 INFO: Inference done 3061/26446. 0.1218 s / img. ETA=0:48:39
[06/30 19:13:42] detectron2 INFO: Inference done 3102/26446. 0.1218 s / img. ETA=0:48:33
[06/30 19:13:47] detectron2 INFO: Inference done 3145/26446. 0.1217 s / img. ETA=0:48:26
[06/30 19:13:52] detectron2 INFO: Inference done 3188/26446. 0.1216 s / img. ETA=0:48:19
[06/30 19:13:57] detectron2 INFO: Inference done 3231/26446. 0.1215 s / img. ETA=0:48:11
[06/30 19:14:02] detectron2 INFO: Inference done 3274/26446. 0.1214 s / img. ETA=0:48:04
[06/30 19:14:07] detectron2 INFO: Inference done 3316/26446. 0.1214 s / img. ETA=0:47:57
[06/30 19:14:12] detectron2 INFO: Inference done 3356/26446. 0.1214 s / img. ETA=0:47:53
[06/30 19:14:18] detectron2 INFO: Inference done 3398/26446. 0.1213 s / img. ETA=0:47:47
[06/30 19:14:23] detectron2 INFO: Inference done 3440/26446. 0.1213 s / img. ETA=0:47:40
[06/30 19:14:28] detectron2 INFO: Inference done 3482/26446. 0.1213 s / img. ETA=0:47:34
[06/30 19:14:33] detectron2 INFO: Inference done 3524/26446. 0.1212 s / img. ETA=0:47:28
[06/30 19:14:38] detectron2 INFO: Inference done 3566/26446. 0.1212 s / img. ETA=0:47:22
[06/30 19:14:43] detectron2 INFO: Inference done 3609/26446. 0.1211 s / img. ETA=0:47:15
[06/30 19:14:48] detectron2 INFO: Inference done 3651/26446. 0.1211 s / img. ETA=0:47:09
[06/30 19:14:53] detectron2 INFO: Inference done 3693/26446. 0.1210 s / img. ETA=0:47:02
[06/30 19:14:58] detectron2 INFO: Inference done 3732/26446. 0.1211 s / img. ETA=0:46:59
[06/30 19:15:03] detectron2 INFO: Inference done 3774/26446. 0.1210 s / img. ETA=0:46:53
[06/30 19:15:08] detectron2 INFO: Inference done 3812/26446. 0.1211 s / img. ETA=0:46:50
[06/30 19:15:13] detectron2 INFO: Inference done 3853/26446. 0.1211 s / img. ETA=0:46:45
[06/30 19:15:18] detectron2 INFO: Inference done 3894/26446. 0.1211 s / img. ETA=0:46:40
[06/30 19:15:23] detectron2 INFO: Inference done 3937/26446. 0.1210 s / img. ETA=0:46:33
[06/30 19:15:28] detectron2 INFO: Inference done 3978/26446. 0.1210 s / img. ETA=0:46:28
[06/30 19:15:33] detectron2 INFO: Inference done 4020/26446. 0.1210 s / img. ETA=0:46:21
[06/30 19:15:39] detectron2 INFO: Inference done 4062/26446. 0.1209 s / img. ETA=0:46:15
[06/30 19:15:44] detectron2 INFO: Inference done 4103/26446. 0.1209 s / img. ETA=0:46:10
[06/30 19:15:49] detectron2 INFO: Inference done 4144/26446. 0.1209 s / img. ETA=0:46:05
[06/30 19:15:54] detectron2 INFO: Inference done 4186/26446. 0.1209 s / img. ETA=0:45:59
[06/30 19:15:59] detectron2 INFO: Inference done 4228/26446. 0.1208 s / img. ETA=0:45:53
[06/30 19:16:04] detectron2 INFO: Inference done 4269/26446. 0.1208 s / img. ETA=0:45:47
[06/30 19:16:09] detectron2 INFO: Inference done 4312/26446. 0.1208 s / img. ETA=0:45:41
[06/30 19:16:14] detectron2 INFO: Inference done 4354/26446. 0.1208 s / img. ETA=0:45:35
[06/30 19:16:19] detectron2 INFO: Inference done 4396/26446. 0.1207 s / img. ETA=0:45:29
[06/30 19:16:24] detectron2 INFO: Inference done 4439/26446. 0.1207 s / img. ETA=0:45:23
[06/30 19:16:29] detectron2 INFO: Inference done 4481/26446. 0.1206 s / img. ETA=0:45:17
[06/30 19:16:34] detectron2 INFO: Inference done 4523/26446. 0.1206 s / img. ETA=0:45:11
[06/30 19:16:39] detectron2 INFO: Inference done 4566/26446. 0.1206 s / img. ETA=0:45:04
[06/30 19:16:44] detectron2 INFO: Inference done 4608/26446. 0.1205 s / img. ETA=0:44:59
[06/30 19:16:49] detectron2 INFO: Inference done 4650/26446. 0.1205 s / img. ETA=0:44:53
[06/30 19:16:55] detectron2 INFO: Inference done 4692/26446. 0.1205 s / img. ETA=0:44:47
[06/30 19:17:00] detectron2 INFO: Inference done 4734/26446. 0.1205 s / img. ETA=0:44:42
[06/30 19:17:05] detectron2 INFO: Inference done 4776/26446. 0.1204 s / img. ETA=0:44:36
[06/30 19:17:10] detectron2 INFO: Inference done 4818/26446. 0.1204 s / img. ETA=0:44:30
[06/30 19:17:15] detectron2 INFO: Inference done 4860/26446. 0.1204 s / img. ETA=0:44:24
[06/30 19:17:20] detectron2 INFO: Inference done 4902/26446. 0.1204 s / img. ETA=0:44:19
[06/30 19:17:25] detectron2 INFO: Inference done 4943/26446. 0.1203 s / img. ETA=0:44:13
[06/30 19:17:30] detectron2 INFO: Inference done 4984/26446. 0.1204 s / img. ETA=0:44:09
[06/30 19:17:35] detectron2 INFO: Inference done 5022/26446. 0.1204 s / img. ETA=0:44:06
[06/30 19:17:40] detectron2 INFO: Inference done 5065/26446. 0.1204 s / img. ETA=0:44:00
[06/30 19:17:45] detectron2 INFO: Inference done 5107/26446. 0.1204 s / img. ETA=0:43:54
[06/30 19:17:50] detectron2 INFO: Inference done 5149/26446. 0.1204 s / img. ETA=0:43:48
[06/30 19:17:55] detectron2 INFO: Inference done 5191/26446. 0.1203 s / img. ETA=0:43:42
[06/30 19:18:00] detectron2 INFO: Inference done 5233/26446. 0.1203 s / img. ETA=0:43:37
[06/30 19:18:06] detectron2 INFO: Inference done 5275/26446. 0.1203 s / img. ETA=0:43:31
[06/30 19:18:11] detectron2 INFO: Inference done 5317/26446. 0.1202 s / img. ETA=0:43:25
[06/30 19:18:16] detectron2 INFO: Inference done 5360/26446. 0.1202 s / img. ETA=0:43:19
[06/30 19:18:21] detectron2 INFO: Inference done 5403/26446. 0.1202 s / img. ETA=0:43:13
[06/30 19:18:26] detectron2 INFO: Inference done 5446/26446. 0.1201 s / img. ETA=0:43:07
[06/30 19:18:31] detectron2 INFO: Inference done 5489/26446. 0.1201 s / img. ETA=0:43:01
[06/30 19:18:36] detectron2 INFO: Inference done 5531/26446. 0.1201 s / img. ETA=0:42:55
[06/30 19:18:41] detectron2 INFO: Inference done 5574/26446. 0.1200 s / img. ETA=0:42:49
[06/30 19:18:46] detectron2 INFO: Inference done 5615/26446. 0.1200 s / img. ETA=0:42:44
[06/30 19:18:51] detectron2 INFO: Inference done 5658/26446. 0.1200 s / img. ETA=0:42:38
[06/30 19:18:56] detectron2 INFO: Inference done 5700/26446. 0.1200 s / img. ETA=0:42:32
[06/30 19:19:01] detectron2 INFO: Inference done 5743/26446. 0.1199 s / img. ETA=0:42:26
[06/30 19:19:06] detectron2 INFO: Inference done 5786/26446. 0.1199 s / img. ETA=0:42:20
[06/30 19:19:12] detectron2 INFO: Inference done 5828/26446. 0.1199 s / img. ETA=0:42:15
[06/30 19:19:17] detectron2 INFO: Inference done 5870/26446. 0.1199 s / img. ETA=0:42:09
[06/30 19:19:22] detectron2 INFO: Inference done 5912/26446. 0.1198 s / img. ETA=0:42:04
[06/30 19:19:27] detectron2 INFO: Inference done 5954/26446. 0.1198 s / img. ETA=0:41:58
[06/30 19:19:32] detectron2 INFO: Inference done 5996/26446. 0.1198 s / img. ETA=0:41:53
[06/30 19:19:37] detectron2 INFO: Inference done 6038/26446. 0.1198 s / img. ETA=0:41:47
[06/30 19:19:42] detectron2 INFO: Inference done 6082/26446. 0.1197 s / img. ETA=0:41:41
[06/30 19:19:47] detectron2 INFO: Inference done 6124/26446. 0.1197 s / img. ETA=0:41:35
[06/30 19:19:52] detectron2 INFO: Inference done 6167/26446. 0.1197 s / img. ETA=0:41:29
[06/30 19:19:57] detectron2 INFO: Inference done 6207/26446. 0.1197 s / img. ETA=0:41:25
[06/30 19:20:02] detectron2 INFO: Inference done 6248/26446. 0.1197 s / img. ETA=0:41:20
[06/30 19:20:07] detectron2 INFO: Inference done 6290/26446. 0.1197 s / img. ETA=0:41:14
[06/30 19:20:12] detectron2 INFO: Inference done 6332/26446. 0.1197 s / img. ETA=0:41:08
[06/30 19:20:17] detectron2 INFO: Inference done 6374/26446. 0.1197 s / img. ETA=0:41:03
[06/30 19:20:22] detectron2 INFO: Inference done 6416/26446. 0.1196 s / img. ETA=0:40:57
[06/30 19:20:27] detectron2 INFO: Inference done 6457/26446. 0.1196 s / img. ETA=0:40:52
[06/30 19:20:32] detectron2 INFO: Inference done 6499/26446. 0.1196 s / img. ETA=0:40:47
[06/30 19:20:37] detectron2 INFO: Inference done 6541/26446. 0.1196 s / img. ETA=0:40:41
[06/30 19:20:42] detectron2 INFO: Inference done 6583/26446. 0.1196 s / img. ETA=0:40:36
[06/30 19:20:47] detectron2 INFO: Inference done 6625/26446. 0.1196 s / img. ETA=0:40:30
[06/30 19:20:52] detectron2 INFO: Inference done 6667/26446. 0.1196 s / img. ETA=0:40:25
[06/30 19:20:57] detectron2 INFO: Inference done 6709/26446. 0.1195 s / img. ETA=0:40:19
[06/30 19:21:02] detectron2 INFO: Inference done 6750/26446. 0.1195 s / img. ETA=0:40:14
[06/30 19:21:07] detectron2 INFO: Inference done 6792/26446. 0.1195 s / img. ETA=0:40:09
[06/30 19:21:13] detectron2 INFO: Inference done 6835/26446. 0.1195 s / img. ETA=0:40:03
[06/30 19:21:18] detectron2 INFO: Inference done 6876/26446. 0.1195 s / img. ETA=0:39:58
[06/30 19:21:23] detectron2 INFO: Inference done 6917/26446. 0.1195 s / img. ETA=0:39:53
[06/30 19:21:28] detectron2 INFO: Inference done 6958/26446. 0.1195 s / img. ETA=0:39:48
[06/30 19:21:33] detectron2 INFO: Inference done 7000/26446. 0.1195 s / img. ETA=0:39:42
[06/30 19:21:38] detectron2 INFO: Inference done 7043/26446. 0.1194 s / img. ETA=0:39:37
[06/30 19:21:43] detectron2 INFO: Inference done 7085/26446. 0.1194 s / img. ETA=0:39:31
[06/30 19:21:48] detectron2 INFO: Inference done 7127/26446. 0.1194 s / img. ETA=0:39:26
[06/30 19:21:53] detectron2 INFO: Inference done 7169/26446. 0.1194 s / img. ETA=0:39:20
[06/30 19:21:58] detectron2 INFO: Inference done 7210/26446. 0.1194 s / img. ETA=0:39:15
[06/30 19:22:03] detectron2 INFO: Inference done 7252/26446. 0.1194 s / img. ETA=0:39:10
[06/30 19:22:08] detectron2 INFO: Inference done 7294/26446. 0.1194 s / img. ETA=0:39:05
[06/30 19:22:13] detectron2 INFO: Inference done 7336/26446. 0.1194 s / img. ETA=0:38:59
[06/30 19:22:18] detectron2 INFO: Inference done 7378/26446. 0.1193 s / img. ETA=0:38:54
[06/30 19:22:23] detectron2 INFO: Inference done 7421/26446. 0.1193 s / img. ETA=0:38:48
[06/30 19:22:28] detectron2 INFO: Inference done 7463/26446. 0.1193 s / img. ETA=0:38:43
[06/30 19:22:33] detectron2 INFO: Inference done 7495/26446. 0.1193 s / img. ETA=0:38:42
[06/30 19:22:38] detectron2 INFO: Inference done 7537/26446. 0.1193 s / img. ETA=0:38:36
[06/30 19:22:43] detectron2 INFO: Inference done 7579/26446. 0.1193 s / img. ETA=0:38:31
[06/30 19:22:48] detectron2 INFO: Inference done 7622/26446. 0.1192 s / img. ETA=0:38:25
[06/30 19:22:53] detectron2 INFO: Inference done 7663/26446. 0.1192 s / img. ETA=0:38:20
[06/30 19:22:58] detectron2 INFO: Inference done 7705/26446. 0.1192 s / img. ETA=0:38:14
[06/30 19:23:03] detectron2 INFO: Inference done 7747/26446. 0.1192 s / img. ETA=0:38:09
[06/30 19:23:08] detectron2 INFO: Inference done 7790/26446. 0.1192 s / img. ETA=0:38:03
[06/30 19:23:14] detectron2 INFO: Inference done 7832/26446. 0.1192 s / img. ETA=0:37:58
[06/30 19:23:19] detectron2 INFO: Inference done 7875/26446. 0.1191 s / img. ETA=0:37:52
[06/30 19:23:24] detectron2 INFO: Inference done 7917/26446. 0.1191 s / img. ETA=0:37:47
[06/30 19:23:29] detectron2 INFO: Inference done 7960/26446. 0.1191 s / img. ETA=0:37:41
[06/30 19:23:34] detectron2 INFO: Inference done 8002/26446. 0.1191 s / img. ETA=0:37:36
[06/30 19:23:39] detectron2 INFO: Inference done 8045/26446. 0.1191 s / img. ETA=0:37:30
[06/30 19:23:44] detectron2 INFO: Inference done 8087/26446. 0.1191 s / img. ETA=0:37:25
[06/30 19:23:49] detectron2 INFO: Inference done 8130/26446. 0.1190 s / img. ETA=0:37:19
[06/30 19:23:54] detectron2 INFO: Inference done 8173/26446. 0.1190 s / img. ETA=0:37:14
[06/30 19:23:59] detectron2 INFO: Inference done 8215/26446. 0.1190 s / img. ETA=0:37:08
[06/30 19:24:04] detectron2 INFO: Inference done 8258/26446. 0.1190 s / img. ETA=0:37:03
[06/30 19:24:09] detectron2 INFO: Inference done 8301/26446. 0.1190 s / img. ETA=0:36:57
[06/30 19:24:14] detectron2 INFO: Inference done 8343/26446. 0.1190 s / img. ETA=0:36:52
[06/30 19:24:19] detectron2 INFO: Inference done 8383/26446. 0.1190 s / img. ETA=0:36:47
[06/30 19:24:24] detectron2 INFO: Inference done 8425/26446. 0.1190 s / img. ETA=0:36:42
[06/30 19:24:30] detectron2 INFO: Inference done 8468/26446. 0.1190 s / img. ETA=0:36:36
[06/30 19:24:35] detectron2 INFO: Inference done 8511/26446. 0.1189 s / img. ETA=0:36:31
[06/30 19:24:40] detectron2 INFO: Inference done 8553/26446. 0.1189 s / img. ETA=0:36:25
[06/30 19:24:45] detectron2 INFO: Inference done 8596/26446. 0.1189 s / img. ETA=0:36:20
[06/30 19:24:50] detectron2 INFO: Inference done 8638/26446. 0.1189 s / img. ETA=0:36:15
[06/30 19:24:55] detectron2 INFO: Inference done 8680/26446. 0.1189 s / img. ETA=0:36:09
[06/30 19:25:00] detectron2 INFO: Inference done 8723/26446. 0.1189 s / img. ETA=0:36:04
[06/30 19:25:05] detectron2 INFO: Inference done 8765/26446. 0.1189 s / img. ETA=0:35:58
[06/30 19:25:10] detectron2 INFO: Inference done 8807/26446. 0.1189 s / img. ETA=0:35:53
[06/30 19:25:15] detectron2 INFO: Inference done 8850/26446. 0.1188 s / img. ETA=0:35:48
[06/30 19:25:20] detectron2 INFO: Inference done 8892/26446. 0.1188 s / img. ETA=0:35:42
[06/30 19:25:25] detectron2 INFO: Inference done 8934/26446. 0.1188 s / img. ETA=0:35:37
[06/30 19:25:30] detectron2 INFO: Inference done 8977/26446. 0.1188 s / img. ETA=0:35:31
[06/30 19:25:35] detectron2 INFO: Inference done 9019/26446. 0.1188 s / img. ETA=0:35:26
[06/30 19:25:40] detectron2 INFO: Inference done 9060/26446. 0.1188 s / img. ETA=0:35:21
[06/30 19:25:46] detectron2 INFO: Inference done 9102/26446. 0.1188 s / img. ETA=0:35:16
[06/30 19:25:51] detectron2 INFO: Inference done 9142/26446. 0.1188 s / img. ETA=0:35:11
[06/30 19:25:56] detectron2 INFO: Inference done 9185/26446. 0.1188 s / img. ETA=0:35:06
[06/30 19:26:01] detectron2 INFO: Inference done 9227/26446. 0.1188 s / img. ETA=0:35:00
[06/30 19:26:06] detectron2 INFO: Inference done 9270/26446. 0.1188 s / img. ETA=0:34:55
[06/30 19:26:11] detectron2 INFO: Inference done 9312/26446. 0.1188 s / img. ETA=0:34:50
[06/30 19:26:16] detectron2 INFO: Inference done 9354/26446. 0.1188 s / img. ETA=0:34:44
[06/30 19:26:21] detectron2 INFO: Inference done 9396/26446. 0.1188 s / img. ETA=0:34:39
[06/30 19:26:26] detectron2 INFO: Inference done 9439/26446. 0.1187 s / img. ETA=0:34:34
[06/30 19:26:31] detectron2 INFO: Inference done 9481/26446. 0.1187 s / img. ETA=0:34:28
[06/30 19:26:36] detectron2 INFO: Inference done 9524/26446. 0.1187 s / img. ETA=0:34:23
[06/30 19:26:41] detectron2 INFO: Inference done 9566/26446. 0.1187 s / img. ETA=0:34:18
[06/30 19:26:46] detectron2 INFO: Inference done 9607/26446. 0.1187 s / img. ETA=0:34:13
[06/30 19:26:51] detectron2 INFO: Inference done 9649/26446. 0.1187 s / img. ETA=0:34:08
[06/30 19:26:56] detectron2 INFO: Inference done 9691/26446. 0.1187 s / img. ETA=0:34:02
[06/30 19:27:01] detectron2 INFO: Inference done 9733/26446. 0.1187 s / img. ETA=0:33:57
[06/30 19:27:07] detectron2 INFO: Inference done 9776/26446. 0.1187 s / img. ETA=0:33:52
[06/30 19:27:12] detectron2 INFO: Inference done 9818/26446. 0.1187 s / img. ETA=0:33:46
[06/30 19:27:17] detectron2 INFO: Inference done 9860/26446. 0.1187 s / img. ETA=0:33:41
[06/30 19:27:22] detectron2 INFO: Inference done 9901/26446. 0.1187 s / img. ETA=0:33:36
[06/30 19:27:27] detectron2 INFO: Inference done 9944/26446. 0.1187 s / img. ETA=0:33:31
[06/30 19:27:32] detectron2 INFO: Inference done 9986/26446. 0.1187 s / img. ETA=0:33:25
[06/30 19:27:37] detectron2 INFO: Inference done 10029/26446. 0.1186 s / img. ETA=0:33:20
[06/30 19:27:42] detectron2 INFO: Inference done 10071/26446. 0.1186 s / img. ETA=0:33:15
[06/30 19:27:47] detectron2 INFO: Inference done 10112/26446. 0.1186 s / img. ETA=0:33:10
[06/30 19:27:52] detectron2 INFO: Inference done 10155/26446. 0.1186 s / img. ETA=0:33:04
[06/30 19:27:57] detectron2 INFO: Inference done 10196/26446. 0.1186 s / img. ETA=0:32:59
[06/30 19:28:02] detectron2 INFO: Inference done 10238/26446. 0.1186 s / img. ETA=0:32:54
[06/30 19:28:07] detectron2 INFO: Inference done 10280/26446. 0.1186 s / img. ETA=0:32:49
[06/30 19:28:12] detectron2 INFO: Inference done 10322/26446. 0.1186 s / img. ETA=0:32:44
[06/30 19:28:17] detectron2 INFO: Inference done 10365/26446. 0.1186 s / img. ETA=0:32:38
[06/30 19:28:22] detectron2 INFO: Inference done 10407/26446. 0.1186 s / img. ETA=0:32:33
[06/30 19:28:28] detectron2 INFO: Inference done 10450/26446. 0.1186 s / img. ETA=0:32:28
[06/30 19:28:33] detectron2 INFO: Inference done 10490/26446. 0.1186 s / img. ETA=0:32:23
[06/30 19:28:38] detectron2 INFO: Inference done 10532/26446. 0.1186 s / img. ETA=0:32:18
[06/30 19:28:43] detectron2 INFO: Inference done 10574/26446. 0.1186 s / img. ETA=0:32:13
[06/30 19:28:48] detectron2 INFO: Inference done 10617/26446. 0.1186 s / img. ETA=0:32:07
[06/30 19:28:53] detectron2 INFO: Inference done 10659/26446. 0.1186 s / img. ETA=0:32:02
[06/30 19:28:58] detectron2 INFO: Inference done 10701/26446. 0.1186 s / img. ETA=0:31:57
[06/30 19:29:03] detectron2 INFO: Inference done 10743/26446. 0.1186 s / img. ETA=0:31:52
[06/30 19:29:08] detectron2 INFO: Inference done 10786/26446. 0.1186 s / img. ETA=0:31:46
[06/30 19:29:13] detectron2 INFO: Inference done 10829/26446. 0.1186 s / img. ETA=0:31:41
[06/30 19:29:18] detectron2 INFO: Inference done 10871/26446. 0.1185 s / img. ETA=0:31:36
[06/30 19:29:23] detectron2 INFO: Inference done 10912/26446. 0.1186 s / img. ETA=0:31:31
[06/30 19:29:28] detectron2 INFO: Inference done 10954/26446. 0.1185 s / img. ETA=0:31:26
[06/30 19:29:33] detectron2 INFO: Inference done 10997/26446. 0.1185 s / img. ETA=0:31:20
[06/30 19:29:39] detectron2 INFO: Inference done 11040/26446. 0.1185 s / img. ETA=0:31:15
[06/30 19:29:44] detectron2 INFO: Inference done 11083/26446. 0.1185 s / img. ETA=0:31:09
[06/30 19:29:49] detectron2 INFO: Inference done 11126/26446. 0.1185 s / img. ETA=0:31:04
[06/30 19:29:54] detectron2 INFO: Inference done 11168/26446. 0.1185 s / img. ETA=0:30:58
[06/30 19:29:59] detectron2 INFO: Inference done 11208/26446. 0.1185 s / img. ETA=0:30:54
[06/30 19:30:04] detectron2 INFO: Inference done 11249/26446. 0.1185 s / img. ETA=0:30:49
[06/30 19:30:09] detectron2 INFO: Inference done 11290/26446. 0.1185 s / img. ETA=0:30:44
[06/30 19:30:14] detectron2 INFO: Inference done 11331/26446. 0.1185 s / img. ETA=0:30:39
[06/30 19:30:19] detectron2 INFO: Inference done 11374/26446. 0.1185 s / img. ETA=0:30:34
[06/30 19:30:24] detectron2 INFO: Inference done 11417/26446. 0.1185 s / img. ETA=0:30:28
[06/30 19:30:29] detectron2 INFO: Inference done 11458/26446. 0.1185 s / img. ETA=0:30:23
[06/30 19:30:34] detectron2 INFO: Inference done 11501/26446. 0.1185 s / img. ETA=0:30:18
[06/30 19:30:39] detectron2 INFO: Inference done 11544/26446. 0.1185 s / img. ETA=0:30:12
[06/30 19:30:44] detectron2 INFO: Inference done 11587/26446. 0.1184 s / img. ETA=0:30:07
[06/30 19:30:49] detectron2 INFO: Inference done 11629/26446. 0.1184 s / img. ETA=0:30:02
[06/30 19:30:54] detectron2 INFO: Inference done 11672/26446. 0.1184 s / img. ETA=0:29:56
[06/30 19:31:00] detectron2 INFO: Inference done 11714/26446. 0.1184 s / img. ETA=0:29:51
[06/30 19:31:05] detectron2 INFO: Inference done 11756/26446. 0.1184 s / img. ETA=0:29:46
[06/30 19:31:10] detectron2 INFO: Inference done 11798/26446. 0.1184 s / img. ETA=0:29:41
[06/30 19:31:15] detectron2 INFO: Inference done 11841/26446. 0.1184 s / img. ETA=0:29:36
[06/30 19:31:20] detectron2 INFO: Inference done 11883/26446. 0.1184 s / img. ETA=0:29:30
[06/30 19:31:25] detectron2 INFO: Inference done 11925/26446. 0.1184 s / img. ETA=0:29:25
[06/30 19:31:30] detectron2 INFO: Inference done 11967/26446. 0.1184 s / img. ETA=0:29:20
[06/30 19:31:35] detectron2 INFO: Inference done 12009/26446. 0.1184 s / img. ETA=0:29:15
[06/30 19:31:40] detectron2 INFO: Inference done 12051/26446. 0.1184 s / img. ETA=0:29:10
[06/30 19:31:45] detectron2 INFO: Inference done 12094/26446. 0.1184 s / img. ETA=0:29:04
[06/30 19:31:50] detectron2 INFO: Inference done 12136/26446. 0.1184 s / img. ETA=0:28:59
[06/30 19:31:55] detectron2 INFO: Inference done 12179/26446. 0.1184 s / img. ETA=0:28:54
[06/30 19:32:00] detectron2 INFO: Inference done 12222/26446. 0.1184 s / img. ETA=0:28:48
[06/30 19:32:05] detectron2 INFO: Inference done 12265/26446. 0.1183 s / img. ETA=0:28:43
[06/30 19:32:10] detectron2 INFO: Inference done 12305/26446. 0.1184 s / img. ETA=0:28:38
[06/30 19:32:16] detectron2 INFO: Inference done 12348/26446. 0.1183 s / img. ETA=0:28:33
[06/30 19:32:21] detectron2 INFO: Inference done 12390/26446. 0.1183 s / img. ETA=0:28:28
[06/30 19:32:26] detectron2 INFO: Inference done 12433/26446. 0.1183 s / img. ETA=0:28:22
[06/30 19:32:31] detectron2 INFO: Inference done 12475/26446. 0.1183 s / img. ETA=0:28:17
[06/30 19:32:36] detectron2 INFO: Inference done 12515/26446. 0.1183 s / img. ETA=0:28:13
[06/30 19:32:41] detectron2 INFO: Inference done 12557/26446. 0.1183 s / img. ETA=0:28:07
[06/30 19:32:46] detectron2 INFO: Inference done 12599/26446. 0.1183 s / img. ETA=0:28:02
[06/30 19:32:51] detectron2 INFO: Inference done 12641/26446. 0.1183 s / img. ETA=0:27:57
[06/30 19:32:56] detectron2 INFO: Inference done 12684/26446. 0.1183 s / img. ETA=0:27:52
[06/30 19:33:01] detectron2 INFO: Inference done 12726/26446. 0.1183 s / img. ETA=0:27:47
[06/30 19:33:06] detectron2 INFO: Inference done 12768/26446. 0.1183 s / img. ETA=0:27:41
[06/30 19:33:11] detectron2 INFO: Inference done 12811/26446. 0.1183 s / img. ETA=0:27:36
[06/30 19:33:16] detectron2 INFO: Inference done 12855/26446. 0.1183 s / img. ETA=0:27:30
[06/30 19:33:21] detectron2 INFO: Inference done 12897/26446. 0.1183 s / img. ETA=0:27:25
[06/30 19:33:26] detectron2 INFO: Inference done 12939/26446. 0.1183 s / img. ETA=0:27:20
[06/30 19:33:31] detectron2 INFO: Inference done 12980/26446. 0.1183 s / img. ETA=0:27:15
[06/30 19:33:36] detectron2 INFO: Inference done 13022/26446. 0.1183 s / img. ETA=0:27:10
[06/30 19:33:42] detectron2 INFO: Inference done 13065/26446. 0.1183 s / img. ETA=0:27:05
[06/30 19:33:47] detectron2 INFO: Inference done 13108/26446. 0.1183 s / img. ETA=0:26:59
[06/30 19:33:52] detectron2 INFO: Inference done 13149/26446. 0.1183 s / img. ETA=0:26:54
[06/30 19:33:57] detectron2 INFO: Inference done 13192/26446. 0.1182 s / img. ETA=0:26:49
[06/30 19:34:02] detectron2 INFO: Inference done 13234/26446. 0.1182 s / img. ETA=0:26:44
[06/30 19:34:07] detectron2 INFO: Inference done 13276/26446. 0.1182 s / img. ETA=0:26:39
[06/30 19:34:12] detectron2 INFO: Inference done 13317/26446. 0.1182 s / img. ETA=0:26:34
[06/30 19:34:17] detectron2 INFO: Inference done 13360/26446. 0.1182 s / img. ETA=0:26:28
[06/30 19:34:22] detectron2 INFO: Inference done 13403/26446. 0.1182 s / img. ETA=0:26:23
[06/30 19:34:27] detectron2 INFO: Inference done 13444/26446. 0.1182 s / img. ETA=0:26:18
[06/30 19:34:32] detectron2 INFO: Inference done 13486/26446. 0.1182 s / img. ETA=0:26:13
[06/30 19:34:37] detectron2 INFO: Inference done 13529/26446. 0.1182 s / img. ETA=0:26:08
[06/30 19:34:42] detectron2 INFO: Inference done 13571/26446. 0.1182 s / img. ETA=0:26:02
[06/30 19:34:47] detectron2 INFO: Inference done 13613/26446. 0.1182 s / img. ETA=0:25:57
[06/30 19:34:52] detectron2 INFO: Inference done 13656/26446. 0.1182 s / img. ETA=0:25:52
[06/30 19:34:57] detectron2 INFO: Inference done 13699/26446. 0.1182 s / img. ETA=0:25:47
[06/30 19:35:02] detectron2 INFO: Inference done 13741/26446. 0.1182 s / img. ETA=0:25:41
[06/30 19:35:08] detectron2 INFO: Inference done 13784/26446. 0.1182 s / img. ETA=0:25:36
[06/30 19:35:13] detectron2 INFO: Inference done 13826/26446. 0.1182 s / img. ETA=0:25:31
[06/30 19:35:18] detectron2 INFO: Inference done 13869/26446. 0.1182 s / img. ETA=0:25:26
[06/30 19:35:23] detectron2 INFO: Inference done 13911/26446. 0.1182 s / img. ETA=0:25:20
[06/30 19:35:28] detectron2 INFO: Inference done 13954/26446. 0.1181 s / img. ETA=0:25:15
[06/30 19:35:33] detectron2 INFO: Inference done 13997/26446. 0.1181 s / img. ETA=0:25:10
[06/30 19:35:38] detectron2 INFO: Inference done 14039/26446. 0.1181 s / img. ETA=0:25:05
[06/30 19:35:43] detectron2 INFO: Inference done 14082/26446. 0.1181 s / img. ETA=0:24:59
[06/30 19:35:48] detectron2 INFO: Inference done 14124/26446. 0.1181 s / img. ETA=0:24:54
[06/30 19:35:53] detectron2 INFO: Inference done 14165/26446. 0.1181 s / img. ETA=0:24:49
[06/30 19:35:58] detectron2 INFO: Inference done 14207/26446. 0.1181 s / img. ETA=0:24:44
[06/30 19:36:03] detectron2 INFO: Inference done 14249/26446. 0.1181 s / img. ETA=0:24:39
[06/30 19:36:08] detectron2 INFO: Inference done 14291/26446. 0.1181 s / img. ETA=0:24:34
[06/30 19:36:13] detectron2 INFO: Inference done 14333/26446. 0.1181 s / img. ETA=0:24:29
[06/30 19:36:18] detectron2 INFO: Inference done 14374/26446. 0.1181 s / img. ETA=0:24:24
[06/30 19:36:23] detectron2 INFO: Inference done 14416/26446. 0.1181 s / img. ETA=0:24:19
[06/30 19:36:28] detectron2 INFO: Inference done 14459/26446. 0.1181 s / img. ETA=0:24:13
[06/30 19:36:33] detectron2 INFO: Inference done 14502/26446. 0.1181 s / img. ETA=0:24:08
[06/30 19:36:39] detectron2 INFO: Inference done 14545/26446. 0.1181 s / img. ETA=0:24:03
[06/30 19:36:44] detectron2 INFO: Inference done 14587/26446. 0.1181 s / img. ETA=0:23:58
[06/30 19:36:49] detectron2 INFO: Inference done 14630/26446. 0.1181 s / img. ETA=0:23:52
[06/30 19:36:54] detectron2 INFO: Inference done 14671/26446. 0.1181 s / img. ETA=0:23:47
[06/30 19:36:59] detectron2 INFO: Inference done 14713/26446. 0.1181 s / img. ETA=0:23:42
[06/30 19:37:04] detectron2 INFO: Inference done 14756/26446. 0.1181 s / img. ETA=0:23:37
[06/30 19:37:09] detectron2 INFO: Inference done 14788/26446. 0.1182 s / img. ETA=0:23:34
[06/30 19:37:14] detectron2 INFO: Inference done 14830/26446. 0.1182 s / img. ETA=0:23:29
[06/30 19:37:19] detectron2 INFO: Inference done 14873/26446. 0.1181 s / img. ETA=0:23:23
[06/30 19:37:24] detectron2 INFO: Inference done 14916/26446. 0.1181 s / img. ETA=0:23:18
[06/30 19:37:29] detectron2 INFO: Inference done 14959/26446. 0.1181 s / img. ETA=0:23:13
[06/30 19:37:34] detectron2 INFO: Inference done 15001/26446. 0.1181 s / img. ETA=0:23:08
[06/30 19:37:39] detectron2 INFO: Inference done 15042/26446. 0.1181 s / img. ETA=0:23:03
[06/30 19:37:44] detectron2 INFO: Inference done 15085/26446. 0.1181 s / img. ETA=0:22:57
[06/30 19:37:50] detectron2 INFO: Inference done 15127/26446. 0.1181 s / img. ETA=0:22:52
[06/30 19:37:55] detectron2 INFO: Inference done 15169/26446. 0.1181 s / img. ETA=0:22:47
[06/30 19:38:00] detectron2 INFO: Inference done 15212/26446. 0.1181 s / img. ETA=0:22:42
[06/30 19:38:05] detectron2 INFO: Inference done 15255/26446. 0.1181 s / img. ETA=0:22:37
[06/30 19:38:10] detectron2 INFO: Inference done 15296/26446. 0.1181 s / img. ETA=0:22:32
[06/30 19:38:15] detectron2 INFO: Inference done 15339/26446. 0.1181 s / img. ETA=0:22:26
[06/30 19:38:20] detectron2 INFO: Inference done 15382/26446. 0.1181 s / img. ETA=0:22:21
[06/30 19:38:25] detectron2 INFO: Inference done 15424/26446. 0.1181 s / img. ETA=0:22:16
[06/30 19:38:30] detectron2 INFO: Inference done 15466/26446. 0.1181 s / img. ETA=0:22:11
[06/30 19:38:35] detectron2 INFO: Inference done 15508/26446. 0.1181 s / img. ETA=0:22:06
[06/30 19:38:40] detectron2 INFO: Inference done 15551/26446. 0.1181 s / img. ETA=0:22:00
[06/30 19:38:45] detectron2 INFO: Inference done 15593/26446. 0.1181 s / img. ETA=0:21:55
[06/30 19:38:50] detectron2 INFO: Inference done 15635/26446. 0.1181 s / img. ETA=0:21:50
[06/30 19:38:55] detectron2 INFO: Inference done 15677/26446. 0.1181 s / img. ETA=0:21:45
[06/30 19:39:00] detectron2 INFO: Inference done 15719/26446. 0.1181 s / img. ETA=0:21:40
[06/30 19:39:05] detectron2 INFO: Inference done 15760/26446. 0.1181 s / img. ETA=0:21:35
[06/30 19:39:10] detectron2 INFO: Inference done 15802/26446. 0.1181 s / img. ETA=0:21:30
[06/30 19:39:16] detectron2 INFO: Inference done 15845/26446. 0.1181 s / img. ETA=0:21:25
[06/30 19:39:21] detectron2 INFO: Inference done 15887/26446. 0.1181 s / img. ETA=0:21:20
[06/30 19:39:26] detectron2 INFO: Inference done 15929/26446. 0.1181 s / img. ETA=0:21:14
[06/30 19:39:31] detectron2 INFO: Inference done 15971/26446. 0.1181 s / img. ETA=0:21:09
[06/30 19:39:36] detectron2 INFO: Inference done 16013/26446. 0.1180 s / img. ETA=0:21:04
[06/30 19:39:41] detectron2 INFO: Inference done 16056/26446. 0.1180 s / img. ETA=0:20:59
[06/30 19:39:46] detectron2 INFO: Inference done 16099/26446. 0.1180 s / img. ETA=0:20:54
[06/30 19:39:51] detectron2 INFO: Inference done 16142/26446. 0.1180 s / img. ETA=0:20:48
[06/30 19:39:56] detectron2 INFO: Inference done 16184/26446. 0.1180 s / img. ETA=0:20:43
[06/30 19:40:01] detectron2 INFO: Inference done 16226/26446. 0.1180 s / img. ETA=0:20:38
[06/30 19:40:06] detectron2 INFO: Inference done 16268/26446. 0.1180 s / img. ETA=0:20:33
[06/30 19:40:11] detectron2 INFO: Inference done 16310/26446. 0.1180 s / img. ETA=0:20:28
[06/30 19:40:16] detectron2 INFO: Inference done 16353/26446. 0.1180 s / img. ETA=0:20:22
[06/30 19:40:21] detectron2 INFO: Inference done 16395/26446. 0.1180 s / img. ETA=0:20:17
[06/30 19:40:26] detectron2 INFO: Inference done 16438/26446. 0.1180 s / img. ETA=0:20:12
[06/30 19:40:32] detectron2 INFO: Inference done 16480/26446. 0.1180 s / img. ETA=0:20:07
[06/30 19:40:37] detectron2 INFO: Inference done 16523/26446. 0.1180 s / img. ETA=0:20:02
[06/30 19:40:42] detectron2 INFO: Inference done 16564/26446. 0.1180 s / img. ETA=0:19:57
[06/30 19:40:47] detectron2 INFO: Inference done 16607/26446. 0.1180 s / img. ETA=0:19:51
[06/30 19:40:52] detectron2 INFO: Inference done 16650/26446. 0.1180 s / img. ETA=0:19:46
[06/30 19:40:57] detectron2 INFO: Inference done 16692/26446. 0.1180 s / img. ETA=0:19:41
[06/30 19:41:02] detectron2 INFO: Inference done 16734/26446. 0.1180 s / img. ETA=0:19:36
[06/30 19:41:07] detectron2 INFO: Inference done 16777/26446. 0.1180 s / img. ETA=0:19:31
[06/30 19:41:12] detectron2 INFO: Inference done 16819/26446. 0.1180 s / img. ETA=0:19:26
[06/30 19:41:17] detectron2 INFO: Inference done 16861/26446. 0.1180 s / img. ETA=0:19:20
[06/30 19:41:22] detectron2 INFO: Inference done 16904/26446. 0.1179 s / img. ETA=0:19:15
[06/30 19:41:27] detectron2 INFO: Inference done 16946/26446. 0.1179 s / img. ETA=0:19:10
[06/30 19:41:32] detectron2 INFO: Inference done 16987/26446. 0.1180 s / img. ETA=0:19:05
[06/30 19:41:37] detectron2 INFO: Inference done 17029/26446. 0.1179 s / img. ETA=0:19:00
[06/30 19:41:42] detectron2 INFO: Inference done 17071/26446. 0.1179 s / img. ETA=0:18:55
[06/30 19:41:47] detectron2 INFO: Inference done 17114/26446. 0.1179 s / img. ETA=0:18:50
[06/30 19:41:52] detectron2 INFO: Inference done 17157/26446. 0.1179 s / img. ETA=0:18:44
[06/30 19:41:57] detectron2 INFO: Inference done 17199/26446. 0.1179 s / img. ETA=0:18:39
[06/30 19:42:02] detectron2 INFO: Inference done 17242/26446. 0.1179 s / img. ETA=0:18:34
[06/30 19:42:08] detectron2 INFO: Inference done 17285/26446. 0.1179 s / img. ETA=0:18:29
[06/30 19:42:13] detectron2 INFO: Inference done 17327/26446. 0.1179 s / img. ETA=0:18:24
[06/30 19:42:18] detectron2 INFO: Inference done 17370/26446. 0.1179 s / img. ETA=0:18:18
[06/30 19:42:23] detectron2 INFO: Inference done 17413/26446. 0.1179 s / img. ETA=0:18:13
[06/30 19:42:28] detectron2 INFO: Inference done 17456/26446. 0.1179 s / img. ETA=0:18:08
[06/30 19:42:33] detectron2 INFO: Inference done 17499/26446. 0.1179 s / img. ETA=0:18:02
[06/30 19:42:38] detectron2 INFO: Inference done 17541/26446. 0.1179 s / img. ETA=0:17:57
[06/30 19:42:43] detectron2 INFO: Inference done 17584/26446. 0.1179 s / img. ETA=0:17:52
[06/30 19:42:48] detectron2 INFO: Inference done 17627/26446. 0.1179 s / img. ETA=0:17:47
[06/30 19:42:53] detectron2 INFO: Inference done 17670/26446. 0.1179 s / img. ETA=0:17:42
[06/30 19:42:58] detectron2 INFO: Inference done 17713/26446. 0.1179 s / img. ETA=0:17:36
[06/30 19:43:03] detectron2 INFO: Inference done 17755/26446. 0.1179 s / img. ETA=0:17:31
[06/30 19:43:08] detectron2 INFO: Inference done 17798/26446. 0.1178 s / img. ETA=0:17:26
[06/30 19:43:13] detectron2 INFO: Inference done 17840/26446. 0.1178 s / img. ETA=0:17:21
[06/30 19:43:19] detectron2 INFO: Inference done 17883/26446. 0.1178 s / img. ETA=0:17:16
[06/30 19:43:24] detectron2 INFO: Inference done 17926/26446. 0.1178 s / img. ETA=0:17:10
[06/30 19:43:29] detectron2 INFO: Inference done 17969/26446. 0.1178 s / img. ETA=0:17:05
[06/30 19:43:34] detectron2 INFO: Inference done 18011/26446. 0.1178 s / img. ETA=0:17:00
[06/30 19:43:39] detectron2 INFO: Inference done 18053/26446. 0.1178 s / img. ETA=0:16:55
[06/30 19:43:44] detectron2 INFO: Inference done 18095/26446. 0.1178 s / img. ETA=0:16:50
[06/30 19:43:49] detectron2 INFO: Inference done 18137/26446. 0.1178 s / img. ETA=0:16:45
[06/30 19:43:54] detectron2 INFO: Inference done 18180/26446. 0.1178 s / img. ETA=0:16:39
[06/30 19:43:59] detectron2 INFO: Inference done 18221/26446. 0.1178 s / img. ETA=0:16:34
[06/30 19:44:04] detectron2 INFO: Inference done 18263/26446. 0.1178 s / img. ETA=0:16:29
[06/30 19:44:09] detectron2 INFO: Inference done 18306/26446. 0.1178 s / img. ETA=0:16:24
[06/30 19:44:14] detectron2 INFO: Inference done 18348/26446. 0.1178 s / img. ETA=0:16:19
[06/30 19:44:19] detectron2 INFO: Inference done 18388/26446. 0.1178 s / img. ETA=0:16:14
[06/30 19:44:24] detectron2 INFO: Inference done 18431/26446. 0.1178 s / img. ETA=0:16:09
[06/30 19:44:29] detectron2 INFO: Inference done 18473/26446. 0.1178 s / img. ETA=0:16:04
[06/30 19:44:34] detectron2 INFO: Inference done 18516/26446. 0.1178 s / img. ETA=0:15:59
[06/30 19:44:39] detectron2 INFO: Inference done 18558/26446. 0.1178 s / img. ETA=0:15:54
[06/30 19:44:44] detectron2 INFO: Inference done 18600/26446. 0.1178 s / img. ETA=0:15:48
[06/30 19:44:49] detectron2 INFO: Inference done 18642/26446. 0.1178 s / img. ETA=0:15:43
[06/30 19:44:54] detectron2 INFO: Inference done 18684/26446. 0.1178 s / img. ETA=0:15:38
[06/30 19:44:59] detectron2 INFO: Inference done 18726/26446. 0.1178 s / img. ETA=0:15:33
[06/30 19:45:05] detectron2 INFO: Inference done 18768/26446. 0.1178 s / img. ETA=0:15:28
[06/30 19:45:10] detectron2 INFO: Inference done 18810/26446. 0.1178 s / img. ETA=0:15:23
[06/30 19:45:15] detectron2 INFO: Inference done 18852/26446. 0.1178 s / img. ETA=0:15:18
[06/30 19:45:20] detectron2 INFO: Inference done 18894/26446. 0.1178 s / img. ETA=0:15:13
[06/30 19:45:25] detectron2 INFO: Inference done 18936/26446. 0.1178 s / img. ETA=0:15:08
[06/30 19:45:30] detectron2 INFO: Inference done 18980/26446. 0.1178 s / img. ETA=0:15:02
[06/30 19:45:35] detectron2 INFO: Inference done 19022/26446. 0.1178 s / img. ETA=0:14:57
[06/30 19:45:40] detectron2 INFO: Inference done 19064/26446. 0.1178 s / img. ETA=0:14:52
[06/30 19:45:45] detectron2 INFO: Inference done 19105/26446. 0.1178 s / img. ETA=0:14:47
[06/30 19:45:50] detectron2 INFO: Inference done 19147/26446. 0.1178 s / img. ETA=0:14:42
[06/30 19:45:55] detectron2 INFO: Inference done 19189/26446. 0.1178 s / img. ETA=0:14:37
[06/30 19:46:00] detectron2 INFO: Inference done 19231/26446. 0.1178 s / img. ETA=0:14:32
[06/30 19:46:05] detectron2 INFO: Inference done 19274/26446. 0.1178 s / img. ETA=0:14:27
[06/30 19:46:10] detectron2 INFO: Inference done 19315/26446. 0.1178 s / img. ETA=0:14:22
[06/30 19:46:15] detectron2 INFO: Inference done 19357/26446. 0.1178 s / img. ETA=0:14:17
[06/30 19:46:20] detectron2 INFO: Inference done 19399/26446. 0.1178 s / img. ETA=0:14:12
[06/30 19:46:25] detectron2 INFO: Inference done 19441/26446. 0.1178 s / img. ETA=0:14:06
[06/30 19:46:31] detectron2 INFO: Inference done 19484/26446. 0.1178 s / img. ETA=0:14:01
[06/30 19:46:36] detectron2 INFO: Inference done 19527/26446. 0.1177 s / img. ETA=0:13:56
[06/30 19:46:41] detectron2 INFO: Inference done 19568/26446. 0.1178 s / img. ETA=0:13:51
[06/30 19:46:46] detectron2 INFO: Inference done 19609/26446. 0.1178 s / img. ETA=0:13:46
[06/30 19:46:51] detectron2 INFO: Inference done 19650/26446. 0.1178 s / img. ETA=0:13:41
[06/30 19:46:56] detectron2 INFO: Inference done 19692/26446. 0.1178 s / img. ETA=0:13:36
[06/30 19:47:01] detectron2 INFO: Inference done 19734/26446. 0.1178 s / img. ETA=0:13:31
[06/30 19:47:06] detectron2 INFO: Inference done 19776/26446. 0.1177 s / img. ETA=0:13:26
[06/30 19:47:11] detectron2 INFO: Inference done 19819/26446. 0.1177 s / img. ETA=0:13:21
[06/30 19:47:16] detectron2 INFO: Inference done 19862/26446. 0.1177 s / img. ETA=0:13:15
[06/30 19:47:21] detectron2 INFO: Inference done 19904/26446. 0.1177 s / img. ETA=0:13:10
[06/30 19:47:26] detectron2 INFO: Inference done 19947/26446. 0.1177 s / img. ETA=0:13:05
[06/30 19:47:31] detectron2 INFO: Inference done 19988/26446. 0.1177 s / img. ETA=0:13:00
[06/30 19:47:36] detectron2 INFO: Inference done 20029/26446. 0.1177 s / img. ETA=0:12:55
[06/30 19:47:41] detectron2 INFO: Inference done 20071/26446. 0.1177 s / img. ETA=0:12:50
[06/30 19:47:46] detectron2 INFO: Inference done 20113/26446. 0.1177 s / img. ETA=0:12:45
[06/30 19:47:51] detectron2 INFO: Inference done 20155/26446. 0.1177 s / img. ETA=0:12:40
[06/30 19:47:56] detectron2 INFO: Inference done 20198/26446. 0.1177 s / img. ETA=0:12:35
[06/30 19:48:01] detectron2 INFO: Inference done 20239/26446. 0.1177 s / img. ETA=0:12:30
[06/30 19:48:07] detectron2 INFO: Inference done 20282/26446. 0.1177 s / img. ETA=0:12:25
[06/30 19:48:12] detectron2 INFO: Inference done 20325/26446. 0.1177 s / img. ETA=0:12:19
[06/30 19:48:17] detectron2 INFO: Inference done 20367/26446. 0.1177 s / img. ETA=0:12:14
[06/30 19:48:22] detectron2 INFO: Inference done 20410/26446. 0.1177 s / img. ETA=0:12:09
[06/30 19:48:27] detectron2 INFO: Inference done 20453/26446. 0.1177 s / img. ETA=0:12:04
[06/30 19:48:32] detectron2 INFO: Inference done 20497/26446. 0.1177 s / img. ETA=0:11:58
[06/30 19:48:37] detectron2 INFO: Inference done 20539/26446. 0.1177 s / img. ETA=0:11:53
[06/30 19:48:42] detectron2 INFO: Inference done 20581/26446. 0.1177 s / img. ETA=0:11:48
[06/30 19:48:47] detectron2 INFO: Inference done 20624/26446. 0.1177 s / img. ETA=0:11:43
[06/30 19:48:52] detectron2 INFO: Inference done 20666/26446. 0.1177 s / img. ETA=0:11:38
[06/30 19:48:57] detectron2 INFO: Inference done 20709/26446. 0.1177 s / img. ETA=0:11:33
[06/30 19:49:02] detectron2 INFO: Inference done 20751/26446. 0.1177 s / img. ETA=0:11:28
[06/30 19:49:07] detectron2 INFO: Inference done 20793/26446. 0.1177 s / img. ETA=0:11:23
[06/30 19:49:12] detectron2 INFO: Inference done 20836/26446. 0.1177 s / img. ETA=0:11:17
[06/30 19:49:17] detectron2 INFO: Inference done 20878/26446. 0.1177 s / img. ETA=0:11:12
[06/30 19:49:23] detectron2 INFO: Inference done 20921/26446. 0.1177 s / img. ETA=0:11:07
[06/30 19:49:28] detectron2 INFO: Inference done 20963/26446. 0.1177 s / img. ETA=0:11:02
[06/30 19:49:33] detectron2 INFO: Inference done 21005/26446. 0.1177 s / img. ETA=0:10:57
[06/30 19:49:38] detectron2 INFO: Inference done 21046/26446. 0.1177 s / img. ETA=0:10:52
[06/30 19:49:43] detectron2 INFO: Inference done 21088/26446. 0.1177 s / img. ETA=0:10:47
[06/30 19:49:48] detectron2 INFO: Inference done 21130/26446. 0.1177 s / img. ETA=0:10:42
[06/30 19:49:53] detectron2 INFO: Inference done 21173/26446. 0.1177 s / img. ETA=0:10:37
[06/30 19:49:58] detectron2 INFO: Inference done 21215/26446. 0.1177 s / img. ETA=0:10:32
[06/30 19:50:03] detectron2 INFO: Inference done 21257/26446. 0.1177 s / img. ETA=0:10:26
[06/30 19:50:08] detectron2 INFO: Inference done 21300/26446. 0.1177 s / img. ETA=0:10:21
[06/30 19:50:13] detectron2 INFO: Inference done 21342/26446. 0.1177 s / img. ETA=0:10:16
[06/30 19:50:18] detectron2 INFO: Inference done 21385/26446. 0.1177 s / img. ETA=0:10:11
[06/30 19:50:23] detectron2 INFO: Inference done 21428/26446. 0.1177 s / img. ETA=0:10:06
[06/30 19:50:28] detectron2 INFO: Inference done 21470/26446. 0.1177 s / img. ETA=0:10:01
[06/30 19:50:34] detectron2 INFO: Inference done 21512/26446. 0.1177 s / img. ETA=0:09:56
[06/30 19:50:39] detectron2 INFO: Inference done 21554/26446. 0.1177 s / img. ETA=0:09:50
[06/30 19:50:44] detectron2 INFO: Inference done 21596/26446. 0.1177 s / img. ETA=0:09:45
[06/30 19:50:49] detectron2 INFO: Inference done 21639/26446. 0.1176 s / img. ETA=0:09:40
[06/30 19:50:54] detectron2 INFO: Inference done 21681/26446. 0.1177 s / img. ETA=0:09:35
[06/30 19:50:59] detectron2 INFO: Inference done 21724/26446. 0.1176 s / img. ETA=0:09:30
[06/30 19:51:04] detectron2 INFO: Inference done 21766/26446. 0.1176 s / img. ETA=0:09:25
[06/30 19:51:09] detectron2 INFO: Inference done 21808/26446. 0.1176 s / img. ETA=0:09:20
[06/30 19:51:14] detectron2 INFO: Inference done 21851/26446. 0.1176 s / img. ETA=0:09:15
[06/30 19:51:19] detectron2 INFO: Inference done 21894/26446. 0.1176 s / img. ETA=0:09:09
[06/30 19:51:24] detectron2 INFO: Inference done 21937/26446. 0.1176 s / img. ETA=0:09:04
[06/30 19:51:29] detectron2 INFO: Inference done 21979/26446. 0.1176 s / img. ETA=0:08:59
[06/30 19:51:34] detectron2 INFO: Inference done 22019/26446. 0.1176 s / img. ETA=0:08:54
[06/30 19:51:39] detectron2 INFO: Inference done 22061/26446. 0.1176 s / img. ETA=0:08:49
[06/30 19:51:44] detectron2 INFO: Inference done 22103/26446. 0.1176 s / img. ETA=0:08:44
[06/30 19:51:50] detectron2 INFO: Inference done 22146/26446. 0.1176 s / img. ETA=0:08:39
[06/30 19:51:55] detectron2 INFO: Inference done 22189/26446. 0.1176 s / img. ETA=0:08:34
[06/30 19:52:00] detectron2 INFO: Inference done 22232/26446. 0.1176 s / img. ETA=0:08:28
[06/30 19:52:05] detectron2 INFO: Inference done 22274/26446. 0.1176 s / img. ETA=0:08:23
[06/30 19:52:10] detectron2 INFO: Inference done 22316/26446. 0.1176 s / img. ETA=0:08:18
[06/30 19:52:15] detectron2 INFO: Inference done 22358/26446. 0.1176 s / img. ETA=0:08:13
[06/30 19:52:20] detectron2 INFO: Inference done 22401/26446. 0.1176 s / img. ETA=0:08:08
[06/30 19:52:25] detectron2 INFO: Inference done 22444/26446. 0.1176 s / img. ETA=0:08:03
[06/30 19:52:30] detectron2 INFO: Inference done 22486/26446. 0.1176 s / img. ETA=0:07:58
[06/30 19:52:35] detectron2 INFO: Inference done 22529/26446. 0.1176 s / img. ETA=0:07:52
[06/30 19:52:40] detectron2 INFO: Inference done 22571/26446. 0.1176 s / img. ETA=0:07:47
[06/30 19:52:45] detectron2 INFO: Inference done 22613/26446. 0.1176 s / img. ETA=0:07:42
[06/30 19:52:50] detectron2 INFO: Inference done 22655/26446. 0.1176 s / img. ETA=0:07:37
[06/30 19:52:55] detectron2 INFO: Inference done 22698/26446. 0.1176 s / img. ETA=0:07:32
[06/30 19:53:00] detectron2 INFO: Inference done 22740/26446. 0.1176 s / img. ETA=0:07:27
[06/30 19:53:05] detectron2 INFO: Inference done 22783/26446. 0.1176 s / img. ETA=0:07:22
[06/30 19:53:10] detectron2 INFO: Inference done 22825/26446. 0.1176 s / img. ETA=0:07:17
[06/30 19:53:15] detectron2 INFO: Inference done 22868/26446. 0.1176 s / img. ETA=0:07:11
[06/30 19:53:21] detectron2 INFO: Inference done 22912/26446. 0.1176 s / img. ETA=0:07:06
[06/30 19:53:26] detectron2 INFO: Inference done 22955/26446. 0.1176 s / img. ETA=0:07:01
[06/30 19:53:31] detectron2 INFO: Inference done 22997/26446. 0.1176 s / img. ETA=0:06:56
[06/30 19:53:36] detectron2 INFO: Inference done 23040/26446. 0.1176 s / img. ETA=0:06:51
[06/30 19:53:41] detectron2 INFO: Inference done 23082/26446. 0.1176 s / img. ETA=0:06:46
[06/30 19:53:46] detectron2 INFO: Inference done 23125/26446. 0.1176 s / img. ETA=0:06:40
[06/30 19:53:51] detectron2 INFO: Inference done 23168/26446. 0.1176 s / img. ETA=0:06:35
[06/30 19:53:56] detectron2 INFO: Inference done 23211/26446. 0.1176 s / img. ETA=0:06:30
[06/30 19:54:01] detectron2 INFO: Inference done 23253/26446. 0.1176 s / img. ETA=0:06:25
[06/30 19:54:06] detectron2 INFO: Inference done 23296/26446. 0.1176 s / img. ETA=0:06:20
[06/30 19:54:11] detectron2 INFO: Inference done 23338/26446. 0.1176 s / img. ETA=0:06:15
[06/30 19:54:17] detectron2 INFO: Inference done 23381/26446. 0.1175 s / img. ETA=0:06:09
[06/30 19:54:22] detectron2 INFO: Inference done 23423/26446. 0.1175 s / img. ETA=0:06:04
[06/30 19:54:27] detectron2 INFO: Inference done 23466/26446. 0.1175 s / img. ETA=0:05:59
[06/30 19:54:32] detectron2 INFO: Inference done 23509/26446. 0.1175 s / img. ETA=0:05:54
[06/30 19:54:37] detectron2 INFO: Inference done 23551/26446. 0.1175 s / img. ETA=0:05:49
[06/30 19:54:42] detectron2 INFO: Inference done 23594/26446. 0.1175 s / img. ETA=0:05:44
[06/30 19:54:47] detectron2 INFO: Inference done 23637/26446. 0.1175 s / img. ETA=0:05:38
[06/30 19:54:52] detectron2 INFO: Inference done 23680/26446. 0.1175 s / img. ETA=0:05:33
[06/30 19:54:57] detectron2 INFO: Inference done 23723/26446. 0.1175 s / img. ETA=0:05:28
[06/30 19:55:02] detectron2 INFO: Inference done 23766/26446. 0.1175 s / img. ETA=0:05:23
[06/30 19:55:07] detectron2 INFO: Inference done 23808/26446. 0.1175 s / img. ETA=0:05:18
[06/30 19:55:12] detectron2 INFO: Inference done 23851/26446. 0.1175 s / img. ETA=0:05:13
[06/30 19:55:17] detectron2 INFO: Inference done 23893/26446. 0.1175 s / img. ETA=0:05:08
[06/30 19:55:22] detectron2 INFO: Inference done 23921/26446. 0.1175 s / img. ETA=0:05:04
[06/30 19:55:28] detectron2 INFO: Inference done 23964/26446. 0.1175 s / img. ETA=0:04:59
[06/30 19:55:33] detectron2 INFO: Inference done 24006/26446. 0.1175 s / img. ETA=0:04:54
[06/30 19:55:38] detectron2 INFO: Inference done 24049/26446. 0.1175 s / img. ETA=0:04:49
[06/30 19:55:43] detectron2 INFO: Inference done 24090/26446. 0.1175 s / img. ETA=0:04:44
[06/30 19:55:48] detectron2 INFO: Inference done 24131/26446. 0.1175 s / img. ETA=0:04:39
[06/30 19:55:53] detectron2 INFO: Inference done 24174/26446. 0.1175 s / img. ETA=0:04:34
[06/30 19:55:58] detectron2 INFO: Inference done 24216/26446. 0.1175 s / img. ETA=0:04:29
[06/30 19:56:03] detectron2 INFO: Inference done 24258/26446. 0.1175 s / img. ETA=0:04:24
[06/30 19:56:08] detectron2 INFO: Inference done 24301/26446. 0.1175 s / img. ETA=0:04:18
[06/30 19:56:13] detectron2 INFO: Inference done 24343/26446. 0.1175 s / img. ETA=0:04:13
[06/30 19:56:18] detectron2 INFO: Inference done 24385/26446. 0.1175 s / img. ETA=0:04:08
[06/30 19:56:23] detectron2 INFO: Inference done 24427/26446. 0.1175 s / img. ETA=0:04:03
[06/30 19:56:28] detectron2 INFO: Inference done 24469/26446. 0.1175 s / img. ETA=0:03:58
[06/30 19:56:33] detectron2 INFO: Inference done 24509/26446. 0.1175 s / img. ETA=0:03:53
[06/30 19:56:38] detectron2 INFO: Inference done 24551/26446. 0.1175 s / img. ETA=0:03:48
[06/30 19:56:43] detectron2 INFO: Inference done 24593/26446. 0.1175 s / img. ETA=0:03:43
[06/30 19:56:48] detectron2 INFO: Inference done 24635/26446. 0.1175 s / img. ETA=0:03:38
[06/30 19:56:53] detectron2 INFO: Inference done 24677/26446. 0.1175 s / img. ETA=0:03:33
[06/30 19:56:58] detectron2 INFO: Inference done 24720/26446. 0.1175 s / img. ETA=0:03:28
[06/30 19:57:03] detectron2 INFO: Inference done 24763/26446. 0.1175 s / img. ETA=0:03:23
[06/30 19:57:09] detectron2 INFO: Inference done 24807/26446. 0.1175 s / img. ETA=0:03:17
[06/30 19:57:14] detectron2 INFO: Inference done 24849/26446. 0.1175 s / img. ETA=0:03:12
[06/30 19:57:19] detectron2 INFO: Inference done 24891/26446. 0.1175 s / img. ETA=0:03:07
[06/30 19:57:24] detectron2 INFO: Inference done 24934/26446. 0.1175 s / img. ETA=0:03:02
[06/30 19:57:29] detectron2 INFO: Inference done 24977/26446. 0.1175 s / img. ETA=0:02:57
[06/30 19:57:34] detectron2 INFO: Inference done 25019/26446. 0.1175 s / img. ETA=0:02:52
[06/30 19:57:39] detectron2 INFO: Inference done 25061/26446. 0.1175 s / img. ETA=0:02:47
[06/30 19:57:44] detectron2 INFO: Inference done 25103/26446. 0.1175 s / img. ETA=0:02:42
[06/30 19:57:49] detectron2 INFO: Inference done 25145/26446. 0.1175 s / img. ETA=0:02:36
[06/30 19:57:54] detectron2 INFO: Inference done 25188/26446. 0.1175 s / img. ETA=0:02:31
[06/30 19:57:59] detectron2 INFO: Inference done 25230/26446. 0.1175 s / img. ETA=0:02:26
[06/30 19:58:04] detectron2 INFO: Inference done 25273/26446. 0.1175 s / img. ETA=0:02:21
[06/30 19:58:09] detectron2 INFO: Inference done 25316/26446. 0.1175 s / img. ETA=0:02:16
[06/30 19:58:14] detectron2 INFO: Inference done 25358/26446. 0.1174 s / img. ETA=0:02:11
[06/30 19:58:19] detectron2 INFO: Inference done 25400/26446. 0.1174 s / img. ETA=0:02:06
[06/30 19:58:24] detectron2 INFO: Inference done 25442/26446. 0.1174 s / img. ETA=0:02:01
[06/30 19:58:30] detectron2 INFO: Inference done 25482/26446. 0.1175 s / img. ETA=0:01:56
[06/30 19:58:35] detectron2 INFO: Inference done 25524/26446. 0.1175 s / img. ETA=0:01:51
[06/30 19:58:40] detectron2 INFO: Inference done 25566/26446. 0.1175 s / img. ETA=0:01:46
[06/30 19:58:45] detectron2 INFO: Inference done 25608/26446. 0.1175 s / img. ETA=0:01:41
[06/30 19:58:50] detectron2 INFO: Inference done 25650/26446. 0.1175 s / img. ETA=0:01:36
[06/30 19:58:55] detectron2 INFO: Inference done 25690/26446. 0.1175 s / img. ETA=0:01:31
[06/30 19:59:00] detectron2 INFO: Inference done 25730/26446. 0.1175 s / img. ETA=0:01:26
[06/30 19:59:05] detectron2 INFO: Inference done 25772/26446. 0.1175 s / img. ETA=0:01:21
[06/30 19:59:10] detectron2 INFO: Inference done 25814/26446. 0.1175 s / img. ETA=0:01:16
[06/30 19:59:15] detectron2 INFO: Inference done 25856/26446. 0.1175 s / img. ETA=0:01:11
[06/30 19:59:20] detectron2 INFO: Inference done 25899/26446. 0.1175 s / img. ETA=0:01:06
[06/30 19:59:25] detectron2 INFO: Inference done 25941/26446. 0.1175 s / img. ETA=0:01:00
[06/30 19:59:30] detectron2 INFO: Inference done 25983/26446. 0.1175 s / img. ETA=0:00:55
[06/30 19:59:35] detectron2 INFO: Inference done 26026/26446. 0.1175 s / img. ETA=0:00:50
[06/30 19:59:40] detectron2 INFO: Inference done 26068/26446. 0.1175 s / img. ETA=0:00:45
[06/30 19:59:45] detectron2 INFO: Inference done 26111/26446. 0.1175 s / img. ETA=0:00:40
[06/30 19:59:50] detectron2 INFO: Inference done 26154/26446. 0.1174 s / img. ETA=0:00:35
[06/30 19:59:55] detectron2 INFO: Inference done 26197/26446. 0.1174 s / img. ETA=0:00:30
[06/30 20:00:00] detectron2 INFO: Inference done 26237/26446. 0.1175 s / img. ETA=0:00:25
[06/30 20:00:05] detectron2 INFO: Inference done 26277/26446. 0.1175 s / img. ETA=0:00:20
[06/30 20:00:10] detectron2 INFO: Inference done 26319/26446. 0.1175 s / img. ETA=0:00:15
[06/30 20:00:16] detectron2 INFO: Inference done 26360/26446. 0.1175 s / img. ETA=0:00:10
[06/30 20:00:21] detectron2 INFO: Inference done 26401/26446. 0.1175 s / img. ETA=0:00:05
[06/30 20:00:26] detectron2 INFO: Inference done 26442/26446. 0.1175 s / img. ETA=0:00:00
[06/30 20:00:27] detectron2 INFO: Total inference time: 0:53:11.962254 (0.120720 s / img per device, on 1 devices)
[06/30 20:00:27] detectron2 INFO: Total inference pure compute time: 0:51:46 (0.117480 s / img per device, on 1 devices)
[06/30 20:00:36] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 20:00:36] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 20:00:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 20:00:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[06/30 20:04:45] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 20:04:46] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 20:04:46] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 20:04:46] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 1
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 20:04:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 20:04:46] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 20:04:46] d2.utils.env INFO: Using a generated random seed 46800853
[06/30 20:04:48] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 20:04:48] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 20:04:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 20:04:49] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 20:04:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 20:04:49] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 20:04:51] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 20:04:51] detectron2 INFO: Following metrics will be use for evaluation
[06/30 20:04:51] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 20:04:51] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 20:04:51] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 20:04:51] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 20:04:53] detectron2 INFO: Loading zero shot triplets
[06/30 20:04:53] detectron2 INFO: Start inference on 26446 images
[06/30 20:05:10] detectron2 INFO: Inference done 11/26446. 0.1648 s / img. ETA=1:13:45
[06/30 20:05:15] detectron2 INFO: Inference done 47/26446. 0.1407 s / img. ETA=1:03:09
[06/30 20:05:21] detectron2 INFO: Inference done 81/26446. 0.1429 s / img. ETA=1:04:03
[06/30 20:05:26] detectron2 INFO: Inference done 121/26446. 0.1360 s / img. ETA=1:00:55
[06/30 20:05:31] detectron2 INFO: Inference done 158/26446. 0.1353 s / img. ETA=1:00:32
[06/30 20:05:36] detectron2 INFO: Inference done 200/26446. 0.1318 s / img. ETA=0:58:53
[06/30 20:05:41] detectron2 INFO: Inference done 240/26446. 0.1302 s / img. ETA=0:58:08
[06/30 20:05:46] detectron2 INFO: Inference done 280/26446. 0.1294 s / img. ETA=0:57:41
[06/30 20:05:51] detectron2 INFO: Inference done 319/26446. 0.1291 s / img. ETA=0:57:29
[06/30 20:05:56] detectron2 INFO: Inference done 360/26446. 0.1280 s / img. ETA=0:56:55
[06/30 20:06:01] detectron2 INFO: Inference done 400/26446. 0.1275 s / img. ETA=0:56:38
[06/30 20:06:06] detectron2 INFO: Inference done 440/26446. 0.1271 s / img. ETA=0:56:20
[06/30 20:06:11] detectron2 INFO: Inference done 480/26446. 0.1268 s / img. ETA=0:56:07
[06/30 20:06:16] detectron2 INFO: Inference done 522/26446. 0.1260 s / img. ETA=0:55:41
[06/30 20:06:21] detectron2 INFO: Inference done 563/26446. 0.1256 s / img. ETA=0:55:26
[06/30 20:06:26] detectron2 INFO: Inference done 606/26446. 0.1249 s / img. ETA=0:55:01
[06/30 20:06:31] detectron2 INFO: Inference done 648/26446. 0.1245 s / img. ETA=0:54:46
[06/30 20:06:36] detectron2 INFO: Inference done 689/26446. 0.1243 s / img. ETA=0:54:34
[06/30 20:06:42] detectron2 INFO: Inference done 731/26446. 0.1239 s / img. ETA=0:54:21
[06/30 20:06:47] detectron2 INFO: Inference done 774/26446. 0.1234 s / img. ETA=0:54:02
[06/30 20:06:52] detectron2 INFO: Inference done 816/26446. 0.1231 s / img. ETA=0:53:48
[06/30 20:06:57] detectron2 INFO: Inference done 860/26446. 0.1225 s / img. ETA=0:53:28
[06/30 20:07:02] detectron2 INFO: Inference done 900/26446. 0.1225 s / img. ETA=0:53:23
[06/30 20:07:07] detectron2 INFO: Inference done 944/26446. 0.1221 s / img. ETA=0:53:06
[06/30 20:07:12] detectron2 INFO: Inference done 986/26446. 0.1218 s / img. ETA=0:52:55
[06/30 20:07:17] detectron2 INFO: Inference done 1029/26446. 0.1216 s / img. ETA=0:52:43
[06/30 20:07:22] detectron2 INFO: Inference done 1072/26446. 0.1213 s / img. ETA=0:52:31
[06/30 20:07:27] detectron2 INFO: Inference done 1116/26446. 0.1209 s / img. ETA=0:52:16
[06/30 20:07:32] detectron2 INFO: Inference done 1159/26446. 0.1207 s / img. ETA=0:52:04
[06/30 20:07:37] detectron2 INFO: Inference done 1201/26446. 0.1205 s / img. ETA=0:51:56
[06/30 20:07:42] detectron2 INFO: Inference done 1243/26446. 0.1204 s / img. ETA=0:51:48
[06/30 20:07:47] detectron2 INFO: Inference done 1285/26446. 0.1203 s / img. ETA=0:51:39
[06/30 20:07:52] detectron2 INFO: Inference done 1329/26446. 0.1201 s / img. ETA=0:51:28
[06/30 20:07:57] detectron2 INFO: Inference done 1373/26446. 0.1198 s / img. ETA=0:51:16
[06/30 20:08:02] detectron2 INFO: Inference done 1415/26446. 0.1197 s / img. ETA=0:51:09
[06/30 20:08:07] detectron2 INFO: Inference done 1456/26446. 0.1198 s / img. ETA=0:51:06
[06/30 20:08:13] detectron2 INFO: Inference done 1500/26446. 0.1196 s / img. ETA=0:50:55
[06/30 20:08:18] detectron2 INFO: Inference done 1543/26446. 0.1194 s / img. ETA=0:50:47
[06/30 20:08:23] detectron2 INFO: Inference done 1577/26446. 0.1200 s / img. ETA=0:50:56
[06/30 20:08:28] detectron2 INFO: Inference done 1620/26446. 0.1199 s / img. ETA=0:50:49
[06/30 20:08:33] detectron2 INFO: Inference done 1663/26446. 0.1198 s / img. ETA=0:50:40
[06/30 20:08:38] detectron2 INFO: Inference done 1705/26446. 0.1197 s / img. ETA=0:50:33
[06/30 20:08:43] detectron2 INFO: Inference done 1745/26446. 0.1198 s / img. ETA=0:50:30
[06/30 20:08:48] detectron2 INFO: Inference done 1789/26446. 0.1196 s / img. ETA=0:50:19
[06/30 20:08:53] detectron2 INFO: Inference done 1833/26446. 0.1194 s / img. ETA=0:50:10
[06/30 20:08:58] detectron2 INFO: Inference done 1876/26446. 0.1193 s / img. ETA=0:50:02
[06/30 20:09:03] detectron2 INFO: Inference done 1919/26446. 0.1192 s / img. ETA=0:49:54
[06/30 20:09:08] detectron2 INFO: Inference done 1961/26446. 0.1191 s / img. ETA=0:49:48
[06/30 20:09:13] detectron2 INFO: Inference done 2004/26446. 0.1190 s / img. ETA=0:49:40
[06/30 20:09:18] detectron2 INFO: Inference done 2048/26446. 0.1188 s / img. ETA=0:49:30
[06/30 20:09:23] detectron2 INFO: Inference done 2092/26446. 0.1187 s / img. ETA=0:49:22
[06/30 20:09:28] detectron2 INFO: Inference done 2133/26446. 0.1188 s / img. ETA=0:49:19
[06/30 20:09:34] detectron2 INFO: Inference done 2176/26446. 0.1187 s / img. ETA=0:49:12
[06/30 20:09:39] detectron2 INFO: Inference done 2214/26446. 0.1189 s / img. ETA=0:49:11
[06/30 20:09:44] detectron2 INFO: Inference done 2250/26446. 0.1192 s / img. ETA=0:49:15
[06/30 20:09:49] detectron2 INFO: Inference done 2286/26446. 0.1195 s / img. ETA=0:49:17
[06/30 20:09:54] detectron2 INFO: Inference done 2322/26446. 0.1197 s / img. ETA=0:49:20
[06/30 20:09:59] detectron2 INFO: Inference done 2359/26446. 0.1200 s / img. ETA=0:49:21
[06/30 20:10:04] detectron2 INFO: Inference done 2398/26446. 0.1201 s / img. ETA=0:49:19
[06/30 20:10:09] detectron2 INFO: Inference done 2437/26446. 0.1202 s / img. ETA=0:49:17
[06/30 20:10:14] detectron2 INFO: Inference done 2477/26446. 0.1202 s / img. ETA=0:49:13
[06/30 20:10:19] detectron2 INFO: Inference done 2520/26446. 0.1202 s / img. ETA=0:49:06
[06/30 20:10:24] detectron2 INFO: Inference done 2556/26446. 0.1204 s / img. ETA=0:49:07
[06/30 20:10:29] detectron2 INFO: Inference done 2597/26446. 0.1204 s / img. ETA=0:49:02
[06/30 20:10:34] detectron2 INFO: Inference done 2638/26446. 0.1204 s / img. ETA=0:48:57
[06/30 20:10:39] detectron2 INFO: Inference done 2681/26446. 0.1203 s / img. ETA=0:48:49
[06/30 20:10:44] detectron2 INFO: Inference done 2722/26446. 0.1203 s / img. ETA=0:48:44
[06/30 20:10:50] detectron2 INFO: Inference done 2765/26446. 0.1202 s / img. ETA=0:48:37
[06/30 20:10:55] detectron2 INFO: Inference done 2807/26446. 0.1202 s / img. ETA=0:48:31
[06/30 20:11:00] detectron2 INFO: Inference done 2851/26446. 0.1201 s / img. ETA=0:48:23
[06/30 20:11:05] detectron2 INFO: Inference done 2893/26446. 0.1200 s / img. ETA=0:48:17
[06/30 20:11:10] detectron2 INFO: Inference done 2936/26446. 0.1200 s / img. ETA=0:48:10
[06/30 20:11:15] detectron2 INFO: Inference done 2979/26446. 0.1199 s / img. ETA=0:48:03
[06/30 20:11:20] detectron2 INFO: Inference done 3022/26446. 0.1198 s / img. ETA=0:47:57
[06/30 20:11:25] detectron2 INFO: Inference done 3065/26446. 0.1197 s / img. ETA=0:47:49
[06/30 20:11:30] detectron2 INFO: Inference done 3106/26446. 0.1197 s / img. ETA=0:47:44
[06/30 20:11:35] detectron2 INFO: Inference done 3149/26446. 0.1197 s / img. ETA=0:47:38
[06/30 20:11:40] detectron2 INFO: Inference done 3192/26446. 0.1196 s / img. ETA=0:47:31
[06/30 20:11:45] detectron2 INFO: Inference done 3236/26446. 0.1195 s / img. ETA=0:47:23
[06/30 20:11:50] detectron2 INFO: Inference done 3279/26446. 0.1195 s / img. ETA=0:47:17
[06/30 20:11:55] detectron2 INFO: Inference done 3322/26446. 0.1194 s / img. ETA=0:47:10
[06/30 20:12:01] detectron2 INFO: Inference done 3365/26446. 0.1193 s / img. ETA=0:47:03
[06/30 20:12:06] detectron2 INFO: Inference done 3409/26446. 0.1193 s / img. ETA=0:46:56
[06/30 20:12:11] detectron2 INFO: Inference done 3452/26446. 0.1192 s / img. ETA=0:46:49
[06/30 20:12:16] detectron2 INFO: Inference done 3494/26446. 0.1192 s / img. ETA=0:46:44
[06/30 20:12:21] detectron2 INFO: Inference done 3537/26446. 0.1191 s / img. ETA=0:46:38
[06/30 20:12:26] detectron2 INFO: Inference done 3579/26446. 0.1191 s / img. ETA=0:46:32
[06/30 20:12:31] detectron2 INFO: Inference done 3622/26446. 0.1191 s / img. ETA=0:46:25
[06/30 20:12:36] detectron2 INFO: Inference done 3664/26446. 0.1190 s / img. ETA=0:46:20
[06/30 20:12:41] detectron2 INFO: Inference done 3707/26446. 0.1190 s / img. ETA=0:46:13
[06/30 20:12:46] detectron2 INFO: Inference done 3747/26446. 0.1190 s / img. ETA=0:46:10
[06/30 20:12:51] detectron2 INFO: Inference done 3787/26446. 0.1191 s / img. ETA=0:46:06
[06/30 20:12:56] detectron2 INFO: Inference done 3828/26446. 0.1191 s / img. ETA=0:46:01
[06/30 20:13:01] detectron2 INFO: Inference done 3871/26446. 0.1191 s / img. ETA=0:45:55
[06/30 20:13:06] detectron2 INFO: Inference done 3913/26446. 0.1190 s / img. ETA=0:45:50
[06/30 20:13:12] detectron2 INFO: Inference done 3955/26446. 0.1190 s / img. ETA=0:45:44
[06/30 20:13:17] detectron2 INFO: Inference done 3997/26446. 0.1190 s / img. ETA=0:45:39
[06/30 20:13:22] detectron2 INFO: Inference done 4040/26446. 0.1189 s / img. ETA=0:45:32
[06/30 20:13:27] detectron2 INFO: Inference done 4083/26446. 0.1189 s / img. ETA=0:45:26
[06/30 20:13:32] detectron2 INFO: Inference done 4120/26446. 0.1190 s / img. ETA=0:45:24
[06/30 20:13:37] detectron2 INFO: Inference done 4161/26446. 0.1190 s / img. ETA=0:45:20
[06/30 20:13:42] detectron2 INFO: Inference done 4203/26446. 0.1190 s / img. ETA=0:45:14
[06/30 20:13:47] detectron2 INFO: Inference done 4246/26446. 0.1190 s / img. ETA=0:45:07
[06/30 20:13:52] detectron2 INFO: Inference done 4288/26446. 0.1189 s / img. ETA=0:45:02
[06/30 20:13:57] detectron2 INFO: Inference done 4328/26446. 0.1190 s / img. ETA=0:44:58
[06/30 20:14:02] detectron2 INFO: Inference done 4365/26446. 0.1191 s / img. ETA=0:44:56
[06/30 20:14:07] detectron2 INFO: Inference done 4407/26446. 0.1191 s / img. ETA=0:44:51
[06/30 20:14:12] detectron2 INFO: Inference done 4447/26446. 0.1191 s / img. ETA=0:44:47
[06/30 20:14:17] detectron2 INFO: Inference done 4488/26446. 0.1191 s / img. ETA=0:44:42
[06/30 20:14:22] detectron2 INFO: Inference done 4529/26446. 0.1191 s / img. ETA=0:44:37
[06/30 20:14:27] detectron2 INFO: Inference done 4568/26446. 0.1192 s / img. ETA=0:44:33
[06/30 20:14:32] detectron2 INFO: Inference done 4607/26446. 0.1192 s / img. ETA=0:44:30
[06/30 20:14:37] detectron2 INFO: Inference done 4648/26446. 0.1193 s / img. ETA=0:44:25
[06/30 20:14:42] detectron2 INFO: Inference done 4686/26446. 0.1194 s / img. ETA=0:44:23
[06/30 20:14:48] detectron2 INFO: Inference done 4725/26446. 0.1194 s / img. ETA=0:44:20
[06/30 20:14:53] detectron2 INFO: Inference done 4765/26446. 0.1195 s / img. ETA=0:44:16
[06/30 20:14:58] detectron2 INFO: Inference done 4805/26446. 0.1195 s / img. ETA=0:44:12
[06/30 20:15:03] detectron2 INFO: Inference done 4847/26446. 0.1195 s / img. ETA=0:44:06
[06/30 20:15:08] detectron2 INFO: Inference done 4890/26446. 0.1195 s / img. ETA=0:44:00
[06/30 20:15:13] detectron2 INFO: Inference done 4932/26446. 0.1194 s / img. ETA=0:43:55
[06/30 20:15:18] detectron2 INFO: Inference done 4974/26446. 0.1194 s / img. ETA=0:43:49
[06/30 20:15:23] detectron2 INFO: Inference done 5017/26446. 0.1194 s / img. ETA=0:43:43
[06/30 20:15:28] detectron2 INFO: Inference done 5060/26446. 0.1194 s / img. ETA=0:43:37
[06/30 20:15:33] detectron2 INFO: Inference done 5101/26446. 0.1194 s / img. ETA=0:43:32
[06/30 20:15:38] detectron2 INFO: Inference done 5143/26446. 0.1193 s / img. ETA=0:43:27
[06/30 20:15:43] detectron2 INFO: Inference done 5182/26446. 0.1194 s / img. ETA=0:43:23
[06/30 20:15:49] detectron2 INFO: Inference done 5218/26446. 0.1195 s / img. ETA=0:43:22
[06/30 20:15:54] detectron2 INFO: Inference done 5257/26446. 0.1196 s / img. ETA=0:43:18
[06/30 20:15:59] detectron2 INFO: Inference done 5295/26446. 0.1197 s / img. ETA=0:43:15
[06/30 20:16:04] detectron2 INFO: Inference done 5335/26446. 0.1197 s / img. ETA=0:43:11
[06/30 20:16:09] detectron2 INFO: Inference done 5373/26446. 0.1198 s / img. ETA=0:43:08
[06/30 20:16:14] detectron2 INFO: Inference done 5414/26446. 0.1198 s / img. ETA=0:43:03
[06/30 20:16:19] detectron2 INFO: Inference done 5455/26446. 0.1198 s / img. ETA=0:42:58
[06/30 20:16:24] detectron2 INFO: Inference done 5497/26446. 0.1197 s / img. ETA=0:42:52
[06/30 20:16:29] detectron2 INFO: Inference done 5540/26446. 0.1197 s / img. ETA=0:42:46
[06/30 20:16:34] detectron2 INFO: Inference done 5580/26446. 0.1197 s / img. ETA=0:42:42
[06/30 20:16:39] detectron2 INFO: Inference done 5623/26446. 0.1197 s / img. ETA=0:42:36
[06/30 20:16:44] detectron2 INFO: Inference done 5666/26446. 0.1197 s / img. ETA=0:42:30
[06/30 20:16:49] detectron2 INFO: Inference done 5709/26446. 0.1196 s / img. ETA=0:42:24
[06/30 20:16:54] detectron2 INFO: Inference done 5752/26446. 0.1196 s / img. ETA=0:42:18
[06/30 20:17:00] detectron2 INFO: Inference done 5795/26446. 0.1196 s / img. ETA=0:42:12
[06/30 20:17:05] detectron2 INFO: Inference done 5838/26446. 0.1195 s / img. ETA=0:42:06
[06/30 20:17:10] detectron2 INFO: Inference done 5881/26446. 0.1195 s / img. ETA=0:42:00
[06/30 20:17:15] detectron2 INFO: Inference done 5925/26446. 0.1194 s / img. ETA=0:41:53
[06/30 20:17:20] detectron2 INFO: Inference done 5969/26446. 0.1194 s / img. ETA=0:41:47
[06/30 20:17:25] detectron2 INFO: Inference done 6013/26446. 0.1193 s / img. ETA=0:41:41
[06/30 20:17:30] detectron2 INFO: Inference done 6056/26446. 0.1193 s / img. ETA=0:41:35
[06/30 20:17:35] detectron2 INFO: Inference done 6098/26446. 0.1193 s / img. ETA=0:41:29
[06/30 20:17:40] detectron2 INFO: Inference done 6141/26446. 0.1193 s / img. ETA=0:41:24
[06/30 20:17:45] detectron2 INFO: Inference done 6181/26446. 0.1193 s / img. ETA=0:41:19
[06/30 20:17:50] detectron2 INFO: Inference done 6222/26446. 0.1193 s / img. ETA=0:41:14
[06/30 20:17:55] detectron2 INFO: Inference done 6263/26446. 0.1193 s / img. ETA=0:41:09
[06/30 20:18:00] detectron2 INFO: Inference done 6304/26446. 0.1193 s / img. ETA=0:41:05
[06/30 20:18:05] detectron2 INFO: Inference done 6345/26446. 0.1193 s / img. ETA=0:41:00
[06/30 20:18:10] detectron2 INFO: Inference done 6387/26446. 0.1193 s / img. ETA=0:40:54
[06/30 20:18:16] detectron2 INFO: Inference done 6430/26446. 0.1193 s / img. ETA=0:40:49
[06/30 20:18:21] detectron2 INFO: Inference done 6472/26446. 0.1193 s / img. ETA=0:40:43
[06/30 20:18:26] detectron2 INFO: Inference done 6514/26446. 0.1193 s / img. ETA=0:40:38
[06/30 20:18:31] detectron2 INFO: Inference done 6557/26446. 0.1192 s / img. ETA=0:40:32
[06/30 20:18:36] detectron2 INFO: Inference done 6598/26446. 0.1192 s / img. ETA=0:40:27
[06/30 20:18:41] detectron2 INFO: Inference done 6641/26446. 0.1192 s / img. ETA=0:40:21
[06/30 20:18:46] detectron2 INFO: Inference done 6683/26446. 0.1192 s / img. ETA=0:40:16
[06/30 20:18:51] detectron2 INFO: Inference done 6725/26446. 0.1192 s / img. ETA=0:40:11
[06/30 20:18:56] detectron2 INFO: Inference done 6767/26446. 0.1192 s / img. ETA=0:40:05
[06/30 20:19:01] detectron2 INFO: Inference done 6810/26446. 0.1191 s / img. ETA=0:39:59
[06/30 20:19:06] detectron2 INFO: Inference done 6852/26446. 0.1191 s / img. ETA=0:39:54
[06/30 20:19:11] detectron2 INFO: Inference done 6893/26446. 0.1191 s / img. ETA=0:39:49
[06/30 20:19:16] detectron2 INFO: Inference done 6936/26446. 0.1191 s / img. ETA=0:39:43
[06/30 20:19:21] detectron2 INFO: Inference done 6977/26446. 0.1191 s / img. ETA=0:39:38
[06/30 20:19:26] detectron2 INFO: Inference done 7017/26446. 0.1191 s / img. ETA=0:39:34
[06/30 20:19:31] detectron2 INFO: Inference done 7061/26446. 0.1191 s / img. ETA=0:39:28
[06/30 20:19:36] detectron2 INFO: Inference done 7103/26446. 0.1191 s / img. ETA=0:39:22
[06/30 20:19:42] detectron2 INFO: Inference done 7146/26446. 0.1191 s / img. ETA=0:39:17
[06/30 20:19:47] detectron2 INFO: Inference done 7188/26446. 0.1190 s / img. ETA=0:39:11
[06/30 20:19:52] detectron2 INFO: Inference done 7230/26446. 0.1190 s / img. ETA=0:39:06
[06/30 20:19:57] detectron2 INFO: Inference done 7273/26446. 0.1190 s / img. ETA=0:39:00
[06/30 20:20:02] detectron2 INFO: Inference done 7315/26446. 0.1190 s / img. ETA=0:38:55
[06/30 20:20:07] detectron2 INFO: Inference done 7359/26446. 0.1190 s / img. ETA=0:38:49
[06/30 20:20:12] detectron2 INFO: Inference done 7402/26446. 0.1189 s / img. ETA=0:38:43
[06/30 20:20:17] detectron2 INFO: Inference done 7444/26446. 0.1189 s / img. ETA=0:38:38
[06/30 20:20:23] detectron2 INFO: Inference done 7482/26446. 0.1189 s / img. ETA=0:38:36
[06/30 20:20:28] detectron2 INFO: Inference done 7523/26446. 0.1189 s / img. ETA=0:38:31
[06/30 20:20:33] detectron2 INFO: Inference done 7565/26446. 0.1189 s / img. ETA=0:38:26
[06/30 20:20:38] detectron2 INFO: Inference done 7607/26446. 0.1189 s / img. ETA=0:38:21
[06/30 20:20:43] detectron2 INFO: Inference done 7649/26446. 0.1189 s / img. ETA=0:38:15
[06/30 20:20:48] detectron2 INFO: Inference done 7690/26446. 0.1189 s / img. ETA=0:38:10
[06/30 20:20:53] detectron2 INFO: Inference done 7733/26446. 0.1189 s / img. ETA=0:38:05
[06/30 20:20:58] detectron2 INFO: Inference done 7775/26446. 0.1189 s / img. ETA=0:37:59
[06/30 20:21:03] detectron2 INFO: Inference done 7816/26446. 0.1189 s / img. ETA=0:37:54
[06/30 20:21:08] detectron2 INFO: Inference done 7859/26446. 0.1189 s / img. ETA=0:37:49
[06/30 20:21:13] detectron2 INFO: Inference done 7901/26446. 0.1188 s / img. ETA=0:37:44
[06/30 20:21:19] detectron2 INFO: Inference done 7943/26446. 0.1188 s / img. ETA=0:37:38
[06/30 20:21:24] detectron2 INFO: Inference done 7986/26446. 0.1188 s / img. ETA=0:37:33
[06/30 20:21:29] detectron2 INFO: Inference done 8025/26446. 0.1189 s / img. ETA=0:37:28
[06/30 20:21:34] detectron2 INFO: Inference done 8067/26446. 0.1189 s / img. ETA=0:37:23
[06/30 20:21:39] detectron2 INFO: Inference done 8106/26446. 0.1189 s / img. ETA=0:37:19
[06/30 20:21:44] detectron2 INFO: Inference done 8148/26446. 0.1189 s / img. ETA=0:37:14
[06/30 20:21:49] detectron2 INFO: Inference done 8189/26446. 0.1189 s / img. ETA=0:37:09
[06/30 20:21:54] detectron2 INFO: Inference done 8231/26446. 0.1189 s / img. ETA=0:37:04
[06/30 20:21:59] detectron2 INFO: Inference done 8275/26446. 0.1189 s / img. ETA=0:36:58
[06/30 20:22:04] detectron2 INFO: Inference done 8319/26446. 0.1188 s / img. ETA=0:36:52
[06/30 20:22:09] detectron2 INFO: Inference done 8362/26446. 0.1188 s / img. ETA=0:36:46
[06/30 20:22:14] detectron2 INFO: Inference done 8405/26446. 0.1188 s / img. ETA=0:36:41
[06/30 20:22:19] detectron2 INFO: Inference done 8445/26446. 0.1188 s / img. ETA=0:36:36
[06/30 20:22:25] detectron2 INFO: Inference done 8486/26446. 0.1188 s / img. ETA=0:36:31
[06/30 20:22:30] detectron2 INFO: Inference done 8522/26446. 0.1189 s / img. ETA=0:36:29
[06/30 20:22:35] detectron2 INFO: Inference done 8564/26446. 0.1189 s / img. ETA=0:36:23
[06/30 20:22:40] detectron2 INFO: Inference done 8606/26446. 0.1189 s / img. ETA=0:36:18
[06/30 20:22:45] detectron2 INFO: Inference done 8649/26446. 0.1189 s / img. ETA=0:36:12
[06/30 20:22:50] detectron2 INFO: Inference done 8693/26446. 0.1188 s / img. ETA=0:36:06
[06/30 20:22:55] detectron2 INFO: Inference done 8736/26446. 0.1188 s / img. ETA=0:36:01
[06/30 20:23:00] detectron2 INFO: Inference done 8779/26446. 0.1188 s / img. ETA=0:35:55
[06/30 20:23:05] detectron2 INFO: Inference done 8822/26446. 0.1188 s / img. ETA=0:35:49
[06/30 20:23:10] detectron2 INFO: Inference done 8864/26446. 0.1188 s / img. ETA=0:35:44
[06/30 20:23:15] detectron2 INFO: Inference done 8907/26446. 0.1187 s / img. ETA=0:35:38
[06/30 20:23:20] detectron2 INFO: Inference done 8950/26446. 0.1187 s / img. ETA=0:35:33
[06/30 20:23:25] detectron2 INFO: Inference done 8993/26446. 0.1187 s / img. ETA=0:35:27
[06/30 20:23:30] detectron2 INFO: Inference done 9035/26446. 0.1187 s / img. ETA=0:35:22
[06/30 20:23:35] detectron2 INFO: Inference done 9078/26446. 0.1187 s / img. ETA=0:35:16
[06/30 20:23:40] detectron2 INFO: Inference done 9121/26446. 0.1187 s / img. ETA=0:35:11
[06/30 20:23:45] detectron2 INFO: Inference done 9163/26446. 0.1186 s / img. ETA=0:35:06
[06/30 20:23:51] detectron2 INFO: Inference done 9206/26446. 0.1186 s / img. ETA=0:35:00
[06/30 20:23:56] detectron2 INFO: Inference done 9248/26446. 0.1186 s / img. ETA=0:34:55
[06/30 20:24:01] detectron2 INFO: Inference done 9291/26446. 0.1186 s / img. ETA=0:34:49
[06/30 20:24:06] detectron2 INFO: Inference done 9334/26446. 0.1186 s / img. ETA=0:34:44
[06/30 20:24:11] detectron2 INFO: Inference done 9377/26446. 0.1186 s / img. ETA=0:34:38
[06/30 20:24:16] detectron2 INFO: Inference done 9416/26446. 0.1186 s / img. ETA=0:34:34
[06/30 20:24:21] detectron2 INFO: Inference done 9458/26446. 0.1186 s / img. ETA=0:34:29
[06/30 20:24:26] detectron2 INFO: Inference done 9502/26446. 0.1186 s / img. ETA=0:34:23
[06/30 20:24:31] detectron2 INFO: Inference done 9544/26446. 0.1186 s / img. ETA=0:34:18
[06/30 20:24:36] detectron2 INFO: Inference done 9585/26446. 0.1186 s / img. ETA=0:34:13
[06/30 20:24:41] detectron2 INFO: Inference done 9628/26446. 0.1185 s / img. ETA=0:34:07
[06/30 20:24:46] detectron2 INFO: Inference done 9671/26446. 0.1185 s / img. ETA=0:34:02
[06/30 20:24:51] detectron2 INFO: Inference done 9713/26446. 0.1185 s / img. ETA=0:33:56
[06/30 20:24:56] detectron2 INFO: Inference done 9756/26446. 0.1185 s / img. ETA=0:33:51
[06/30 20:25:01] detectron2 INFO: Inference done 9798/26446. 0.1185 s / img. ETA=0:33:46
[06/30 20:25:06] detectron2 INFO: Inference done 9841/26446. 0.1185 s / img. ETA=0:33:40
[06/30 20:25:12] detectron2 INFO: Inference done 9884/26446. 0.1185 s / img. ETA=0:33:35
[06/30 20:25:17] detectron2 INFO: Inference done 9927/26446. 0.1185 s / img. ETA=0:33:29
[06/30 20:25:22] detectron2 INFO: Inference done 9969/26446. 0.1184 s / img. ETA=0:33:24
[06/30 20:25:27] detectron2 INFO: Inference done 10006/26446. 0.1185 s / img. ETA=0:33:20
[06/30 20:25:32] detectron2 INFO: Inference done 10038/26446. 0.1186 s / img. ETA=0:33:18
[06/30 20:25:37] detectron2 INFO: Inference done 10071/26446. 0.1187 s / img. ETA=0:33:16
[06/30 20:25:42] detectron2 INFO: Inference done 10112/26446. 0.1187 s / img. ETA=0:33:11
[06/30 20:25:47] detectron2 INFO: Inference done 10153/26446. 0.1187 s / img. ETA=0:33:06
[06/30 20:25:52] detectron2 INFO: Inference done 10191/26446. 0.1188 s / img. ETA=0:33:02
[06/30 20:25:57] detectron2 INFO: Inference done 10229/26446. 0.1188 s / img. ETA=0:32:59
[06/30 20:26:02] detectron2 INFO: Inference done 10263/26446. 0.1189 s / img. ETA=0:32:56
[06/30 20:26:07] detectron2 INFO: Inference done 10303/26446. 0.1189 s / img. ETA=0:32:51
[06/30 20:26:12] detectron2 INFO: Inference done 10343/26446. 0.1189 s / img. ETA=0:32:47
[06/30 20:26:17] detectron2 INFO: Inference done 10381/26446. 0.1190 s / img. ETA=0:32:43
[06/30 20:26:23] detectron2 INFO: Inference done 10425/26446. 0.1190 s / img. ETA=0:32:37
[06/30 20:26:28] detectron2 INFO: Inference done 10466/26446. 0.1190 s / img. ETA=0:32:32
[06/30 20:26:33] detectron2 INFO: Inference done 10506/26446. 0.1190 s / img. ETA=0:32:27
[06/30 20:26:38] detectron2 INFO: Inference done 10548/26446. 0.1190 s / img. ETA=0:32:22
[06/30 20:26:43] detectron2 INFO: Inference done 10591/26446. 0.1190 s / img. ETA=0:32:17
[06/30 20:26:48] detectron2 INFO: Inference done 10632/26446. 0.1190 s / img. ETA=0:32:12
[06/30 20:26:53] detectron2 INFO: Inference done 10675/26446. 0.1190 s / img. ETA=0:32:06
[06/30 20:26:58] detectron2 INFO: Inference done 10718/26446. 0.1189 s / img. ETA=0:32:01
[06/30 20:27:03] detectron2 INFO: Inference done 10760/26446. 0.1189 s / img. ETA=0:31:55
[06/30 20:27:08] detectron2 INFO: Inference done 10803/26446. 0.1189 s / img. ETA=0:31:50
[06/30 20:27:13] detectron2 INFO: Inference done 10846/26446. 0.1189 s / img. ETA=0:31:44
[06/30 20:27:18] detectron2 INFO: Inference done 10888/26446. 0.1189 s / img. ETA=0:31:39
[06/30 20:27:23] detectron2 INFO: Inference done 10927/26446. 0.1189 s / img. ETA=0:31:35
[06/30 20:27:28] detectron2 INFO: Inference done 10968/26446. 0.1189 s / img. ETA=0:31:30
[06/30 20:27:33] detectron2 INFO: Inference done 11011/26446. 0.1189 s / img. ETA=0:31:24
[06/30 20:27:38] detectron2 INFO: Inference done 11054/26446. 0.1189 s / img. ETA=0:31:19
[06/30 20:27:44] detectron2 INFO: Inference done 11097/26446. 0.1189 s / img. ETA=0:31:13
[06/30 20:27:49] detectron2 INFO: Inference done 11140/26446. 0.1188 s / img. ETA=0:31:08
[06/30 20:27:54] detectron2 INFO: Inference done 11183/26446. 0.1188 s / img. ETA=0:31:02
[06/30 20:27:59] detectron2 INFO: Inference done 11224/26446. 0.1188 s / img. ETA=0:30:57
[06/30 20:28:04] detectron2 INFO: Inference done 11266/26446. 0.1188 s / img. ETA=0:30:52
[06/30 20:28:09] detectron2 INFO: Inference done 11309/26446. 0.1188 s / img. ETA=0:30:46
[06/30 20:28:14] detectron2 INFO: Inference done 11352/26446. 0.1188 s / img. ETA=0:30:41
[06/30 20:28:19] detectron2 INFO: Inference done 11395/26446. 0.1188 s / img. ETA=0:30:35
[06/30 20:28:24] detectron2 INFO: Inference done 11438/26446. 0.1188 s / img. ETA=0:30:30
[06/30 20:28:29] detectron2 INFO: Inference done 11479/26446. 0.1188 s / img. ETA=0:30:25
[06/30 20:28:34] detectron2 INFO: Inference done 11523/26446. 0.1187 s / img. ETA=0:30:19
[06/30 20:28:39] detectron2 INFO: Inference done 11566/26446. 0.1187 s / img. ETA=0:30:14
[06/30 20:28:44] detectron2 INFO: Inference done 11608/26446. 0.1187 s / img. ETA=0:30:09
[06/30 20:28:49] detectron2 INFO: Inference done 11651/26446. 0.1187 s / img. ETA=0:30:03
[06/30 20:28:54] detectron2 INFO: Inference done 11693/26446. 0.1187 s / img. ETA=0:29:58
[06/30 20:28:59] detectron2 INFO: Inference done 11737/26446. 0.1187 s / img. ETA=0:29:52
[06/30 20:29:04] detectron2 INFO: Inference done 11780/26446. 0.1187 s / img. ETA=0:29:47
[06/30 20:29:09] detectron2 INFO: Inference done 11824/26446. 0.1186 s / img. ETA=0:29:41
[06/30 20:29:15] detectron2 INFO: Inference done 11868/26446. 0.1186 s / img. ETA=0:29:35
[06/30 20:29:20] detectron2 INFO: Inference done 11911/26446. 0.1186 s / img. ETA=0:29:30
[06/30 20:29:25] detectron2 INFO: Inference done 11955/26446. 0.1186 s / img. ETA=0:29:24
[06/30 20:29:30] detectron2 INFO: Inference done 11998/26446. 0.1186 s / img. ETA=0:29:19
[06/30 20:29:35] detectron2 INFO: Inference done 12042/26446. 0.1185 s / img. ETA=0:29:13
[06/30 20:29:40] detectron2 INFO: Inference done 12086/26446. 0.1185 s / img. ETA=0:29:07
[06/30 20:29:45] detectron2 INFO: Inference done 12129/26446. 0.1185 s / img. ETA=0:29:02
[06/30 20:29:50] detectron2 INFO: Inference done 12172/26446. 0.1185 s / img. ETA=0:28:56
[06/30 20:29:55] detectron2 INFO: Inference done 12216/26446. 0.1185 s / img. ETA=0:28:51
[06/30 20:30:00] detectron2 INFO: Inference done 12259/26446. 0.1185 s / img. ETA=0:28:45
[06/30 20:30:05] detectron2 INFO: Inference done 12301/26446. 0.1185 s / img. ETA=0:28:40
[06/30 20:30:10] detectron2 INFO: Inference done 12343/26446. 0.1184 s / img. ETA=0:28:35
[06/30 20:30:15] detectron2 INFO: Inference done 12386/26446. 0.1184 s / img. ETA=0:28:30
[06/30 20:30:20] detectron2 INFO: Inference done 12430/26446. 0.1184 s / img. ETA=0:28:24
[06/30 20:30:25] detectron2 INFO: Inference done 12474/26446. 0.1184 s / img. ETA=0:28:18
[06/30 20:30:30] detectron2 INFO: Inference done 12517/26446. 0.1184 s / img. ETA=0:28:13
[06/30 20:30:35] detectron2 INFO: Inference done 12560/26446. 0.1184 s / img. ETA=0:28:07
[06/30 20:30:41] detectron2 INFO: Inference done 12602/26446. 0.1183 s / img. ETA=0:28:02
[06/30 20:30:46] detectron2 INFO: Inference done 12644/26446. 0.1183 s / img. ETA=0:27:57
[06/30 20:30:51] detectron2 INFO: Inference done 12687/26446. 0.1183 s / img. ETA=0:27:52
[06/30 20:30:56] detectron2 INFO: Inference done 12730/26446. 0.1183 s / img. ETA=0:27:46
[06/30 20:31:01] detectron2 INFO: Inference done 12773/26446. 0.1183 s / img. ETA=0:27:41
[06/30 20:31:06] detectron2 INFO: Inference done 12817/26446. 0.1183 s / img. ETA=0:27:35
[06/30 20:31:11] detectron2 INFO: Inference done 12861/26446. 0.1183 s / img. ETA=0:27:29
[06/30 20:31:16] detectron2 INFO: Inference done 12903/26446. 0.1183 s / img. ETA=0:27:24
[06/30 20:31:21] detectron2 INFO: Inference done 12946/26446. 0.1182 s / img. ETA=0:27:19
[06/30 20:31:26] detectron2 INFO: Inference done 12988/26446. 0.1182 s / img. ETA=0:27:14
[06/30 20:31:31] detectron2 INFO: Inference done 13032/26446. 0.1182 s / img. ETA=0:27:08
[06/30 20:31:36] detectron2 INFO: Inference done 13075/26446. 0.1182 s / img. ETA=0:27:03
[06/30 20:31:41] detectron2 INFO: Inference done 13118/26446. 0.1182 s / img. ETA=0:26:57
[06/30 20:31:46] detectron2 INFO: Inference done 13161/26446. 0.1182 s / img. ETA=0:26:52
[06/30 20:31:51] detectron2 INFO: Inference done 13204/26446. 0.1182 s / img. ETA=0:26:46
[06/30 20:31:56] detectron2 INFO: Inference done 13247/26446. 0.1182 s / img. ETA=0:26:41
[06/30 20:32:01] detectron2 INFO: Inference done 13291/26446. 0.1181 s / img. ETA=0:26:35
[06/30 20:32:06] detectron2 INFO: Inference done 13334/26446. 0.1181 s / img. ETA=0:26:30
[06/30 20:32:11] detectron2 INFO: Inference done 13378/26446. 0.1181 s / img. ETA=0:26:24
[06/30 20:32:17] detectron2 INFO: Inference done 13422/26446. 0.1181 s / img. ETA=0:26:19
[06/30 20:32:22] detectron2 INFO: Inference done 13465/26446. 0.1181 s / img. ETA=0:26:14
[06/30 20:32:27] detectron2 INFO: Inference done 13508/26446. 0.1181 s / img. ETA=0:26:08
[06/30 20:32:32] detectron2 INFO: Inference done 13549/26446. 0.1181 s / img. ETA=0:26:03
[06/30 20:32:37] detectron2 INFO: Inference done 13592/26446. 0.1181 s / img. ETA=0:25:58
[06/30 20:32:42] detectron2 INFO: Inference done 13636/26446. 0.1180 s / img. ETA=0:25:52
[06/30 20:32:47] detectron2 INFO: Inference done 13679/26446. 0.1180 s / img. ETA=0:25:47
[06/30 20:32:52] detectron2 INFO: Inference done 13723/26446. 0.1180 s / img. ETA=0:25:41
[06/30 20:32:57] detectron2 INFO: Inference done 13766/26446. 0.1180 s / img. ETA=0:25:36
[06/30 20:33:02] detectron2 INFO: Inference done 13809/26446. 0.1180 s / img. ETA=0:25:31
[06/30 20:33:07] detectron2 INFO: Inference done 13852/26446. 0.1180 s / img. ETA=0:25:25
[06/30 20:33:12] detectron2 INFO: Inference done 13893/26446. 0.1180 s / img. ETA=0:25:20
[06/30 20:33:17] detectron2 INFO: Inference done 13937/26446. 0.1180 s / img. ETA=0:25:15
[06/30 20:33:22] detectron2 INFO: Inference done 13981/26446. 0.1180 s / img. ETA=0:25:09
[06/30 20:33:27] detectron2 INFO: Inference done 14022/26446. 0.1180 s / img. ETA=0:25:04
[06/30 20:33:32] detectron2 INFO: Inference done 14066/26446. 0.1179 s / img. ETA=0:24:59
[06/30 20:33:38] detectron2 INFO: Inference done 14110/26446. 0.1179 s / img. ETA=0:24:53
[06/30 20:33:43] detectron2 INFO: Inference done 14154/26446. 0.1179 s / img. ETA=0:24:48
[06/30 20:33:48] detectron2 INFO: Inference done 14197/26446. 0.1179 s / img. ETA=0:24:42
[06/30 20:33:53] detectron2 INFO: Inference done 14241/26446. 0.1179 s / img. ETA=0:24:37
[06/30 20:33:58] detectron2 INFO: Inference done 14285/26446. 0.1179 s / img. ETA=0:24:31
[06/30 20:34:03] detectron2 INFO: Inference done 14329/26446. 0.1179 s / img. ETA=0:24:26
[06/30 20:34:08] detectron2 INFO: Inference done 14372/26446. 0.1178 s / img. ETA=0:24:21
[06/30 20:34:13] detectron2 INFO: Inference done 14416/26446. 0.1178 s / img. ETA=0:24:15
[06/30 20:34:18] detectron2 INFO: Inference done 14460/26446. 0.1178 s / img. ETA=0:24:09
[06/30 20:34:23] detectron2 INFO: Inference done 14503/26446. 0.1178 s / img. ETA=0:24:04
[06/30 20:34:28] detectron2 INFO: Inference done 14548/26446. 0.1178 s / img. ETA=0:23:58
[06/30 20:34:33] detectron2 INFO: Inference done 14592/26446. 0.1178 s / img. ETA=0:23:53
[06/30 20:34:38] detectron2 INFO: Inference done 14635/26446. 0.1177 s / img. ETA=0:23:48
[06/30 20:34:43] detectron2 INFO: Inference done 14678/26446. 0.1177 s / img. ETA=0:23:42
[06/30 20:34:49] detectron2 INFO: Inference done 14722/26446. 0.1177 s / img. ETA=0:23:37
[06/30 20:34:54] detectron2 INFO: Inference done 14765/26446. 0.1177 s / img. ETA=0:23:31
[06/30 20:34:59] detectron2 INFO: Inference done 14796/26446. 0.1178 s / img. ETA=0:23:29
[06/30 20:35:04] detectron2 INFO: Inference done 14840/26446. 0.1178 s / img. ETA=0:23:23
[06/30 20:35:09] detectron2 INFO: Inference done 14884/26446. 0.1178 s / img. ETA=0:23:18
[06/30 20:35:14] detectron2 INFO: Inference done 14928/26446. 0.1178 s / img. ETA=0:23:12
[06/30 20:35:19] detectron2 INFO: Inference done 14972/26446. 0.1177 s / img. ETA=0:23:07
[06/30 20:35:24] detectron2 INFO: Inference done 15015/26446. 0.1177 s / img. ETA=0:23:01
[06/30 20:35:29] detectron2 INFO: Inference done 15059/26446. 0.1177 s / img. ETA=0:22:56
[06/30 20:35:34] detectron2 INFO: Inference done 15103/26446. 0.1177 s / img. ETA=0:22:50
[06/30 20:35:39] detectron2 INFO: Inference done 15147/26446. 0.1177 s / img. ETA=0:22:45
[06/30 20:35:44] detectron2 INFO: Inference done 15190/26446. 0.1177 s / img. ETA=0:22:39
[06/30 20:35:49] detectron2 INFO: Inference done 15233/26446. 0.1177 s / img. ETA=0:22:34
[06/30 20:35:54] detectron2 INFO: Inference done 15276/26446. 0.1176 s / img. ETA=0:22:29
[06/30 20:35:59] detectron2 INFO: Inference done 15319/26446. 0.1176 s / img. ETA=0:22:24
[06/30 20:36:04] detectron2 INFO: Inference done 15363/26446. 0.1176 s / img. ETA=0:22:18
[06/30 20:36:09] detectron2 INFO: Inference done 15407/26446. 0.1176 s / img. ETA=0:22:13
[06/30 20:36:15] detectron2 INFO: Inference done 15451/26446. 0.1176 s / img. ETA=0:22:07
[06/30 20:36:20] detectron2 INFO: Inference done 15495/26446. 0.1176 s / img. ETA=0:22:02
[06/30 20:36:25] detectron2 INFO: Inference done 15539/26446. 0.1176 s / img. ETA=0:21:56
[06/30 20:36:30] detectron2 INFO: Inference done 15582/26446. 0.1176 s / img. ETA=0:21:51
[06/30 20:36:35] detectron2 INFO: Inference done 15626/26446. 0.1175 s / img. ETA=0:21:45
[06/30 20:36:40] detectron2 INFO: Inference done 15668/26446. 0.1175 s / img. ETA=0:21:40
[06/30 20:36:45] detectron2 INFO: Inference done 15712/26446. 0.1175 s / img. ETA=0:21:35
[06/30 20:36:50] detectron2 INFO: Inference done 15755/26446. 0.1175 s / img. ETA=0:21:30
[06/30 20:36:55] detectron2 INFO: Inference done 15799/26446. 0.1175 s / img. ETA=0:21:24
[06/30 20:37:00] detectron2 INFO: Inference done 15843/26446. 0.1175 s / img. ETA=0:21:19
[06/30 20:37:05] detectron2 INFO: Inference done 15886/26446. 0.1175 s / img. ETA=0:21:13
[06/30 20:37:10] detectron2 INFO: Inference done 15929/26446. 0.1175 s / img. ETA=0:21:08
[06/30 20:37:15] detectron2 INFO: Inference done 15972/26446. 0.1175 s / img. ETA=0:21:03
[06/30 20:37:20] detectron2 INFO: Inference done 16014/26446. 0.1175 s / img. ETA=0:20:58
[06/30 20:37:25] detectron2 INFO: Inference done 16057/26446. 0.1175 s / img. ETA=0:20:52
[06/30 20:37:30] detectron2 INFO: Inference done 16101/26446. 0.1174 s / img. ETA=0:20:47
[06/30 20:37:36] detectron2 INFO: Inference done 16145/26446. 0.1174 s / img. ETA=0:20:42
[06/30 20:37:41] detectron2 INFO: Inference done 16189/26446. 0.1174 s / img. ETA=0:20:36
[06/30 20:37:46] detectron2 INFO: Inference done 16233/26446. 0.1174 s / img. ETA=0:20:31
[06/30 20:37:51] detectron2 INFO: Inference done 16277/26446. 0.1174 s / img. ETA=0:20:25
[06/30 20:37:56] detectron2 INFO: Inference done 16320/26446. 0.1174 s / img. ETA=0:20:20
[06/30 20:38:01] detectron2 INFO: Inference done 16363/26446. 0.1174 s / img. ETA=0:20:15
[06/30 20:38:06] detectron2 INFO: Inference done 16405/26446. 0.1174 s / img. ETA=0:20:10
[06/30 20:38:11] detectron2 INFO: Inference done 16449/26446. 0.1174 s / img. ETA=0:20:04
[06/30 20:38:16] detectron2 INFO: Inference done 16492/26446. 0.1174 s / img. ETA=0:19:59
[06/30 20:38:21] detectron2 INFO: Inference done 16535/26446. 0.1174 s / img. ETA=0:19:54
[06/30 20:38:26] detectron2 INFO: Inference done 16579/26446. 0.1173 s / img. ETA=0:19:48
[06/30 20:38:31] detectron2 INFO: Inference done 16622/26446. 0.1173 s / img. ETA=0:19:43
[06/30 20:38:36] detectron2 INFO: Inference done 16665/26446. 0.1173 s / img. ETA=0:19:38
[06/30 20:38:41] detectron2 INFO: Inference done 16708/26446. 0.1173 s / img. ETA=0:19:32
[06/30 20:38:46] detectron2 INFO: Inference done 16751/26446. 0.1173 s / img. ETA=0:19:27
[06/30 20:38:52] detectron2 INFO: Inference done 16795/26446. 0.1173 s / img. ETA=0:19:22
[06/30 20:38:57] detectron2 INFO: Inference done 16838/26446. 0.1173 s / img. ETA=0:19:17
[06/30 20:39:02] detectron2 INFO: Inference done 16882/26446. 0.1173 s / img. ETA=0:19:11
[06/30 20:39:07] detectron2 INFO: Inference done 16925/26446. 0.1173 s / img. ETA=0:19:06
[06/30 20:39:12] detectron2 INFO: Inference done 16968/26446. 0.1173 s / img. ETA=0:19:01
[06/30 20:39:17] detectron2 INFO: Inference done 17011/26446. 0.1173 s / img. ETA=0:18:55
[06/30 20:39:22] detectron2 INFO: Inference done 17055/26446. 0.1172 s / img. ETA=0:18:50
[06/30 20:39:27] detectron2 INFO: Inference done 17098/26446. 0.1172 s / img. ETA=0:18:45
[06/30 20:39:32] detectron2 INFO: Inference done 17142/26446. 0.1172 s / img. ETA=0:18:39
[06/30 20:39:37] detectron2 INFO: Inference done 17185/26446. 0.1172 s / img. ETA=0:18:34
[06/30 20:39:42] detectron2 INFO: Inference done 17228/26446. 0.1172 s / img. ETA=0:18:29
[06/30 20:39:47] detectron2 INFO: Inference done 17272/26446. 0.1172 s / img. ETA=0:18:23
[06/30 20:39:52] detectron2 INFO: Inference done 17315/26446. 0.1172 s / img. ETA=0:18:18
[06/30 20:39:57] detectron2 INFO: Inference done 17358/26446. 0.1172 s / img. ETA=0:18:13
[06/30 20:40:02] detectron2 INFO: Inference done 17402/26446. 0.1172 s / img. ETA=0:18:07
[06/30 20:40:07] detectron2 INFO: Inference done 17445/26446. 0.1172 s / img. ETA=0:18:02
[06/30 20:40:12] detectron2 INFO: Inference done 17489/26446. 0.1171 s / img. ETA=0:17:57
[06/30 20:40:17] detectron2 INFO: Inference done 17532/26446. 0.1171 s / img. ETA=0:17:52
[06/30 20:40:22] detectron2 INFO: Inference done 17575/26446. 0.1171 s / img. ETA=0:17:46
[06/30 20:40:27] detectron2 INFO: Inference done 17619/26446. 0.1171 s / img. ETA=0:17:41
[06/30 20:40:33] detectron2 INFO: Inference done 17663/26446. 0.1171 s / img. ETA=0:17:35
[06/30 20:40:38] detectron2 INFO: Inference done 17706/26446. 0.1171 s / img. ETA=0:17:30
[06/30 20:40:43] detectron2 INFO: Inference done 17750/26446. 0.1171 s / img. ETA=0:17:25
[06/30 20:40:48] detectron2 INFO: Inference done 17793/26446. 0.1171 s / img. ETA=0:17:20
[06/30 20:40:53] detectron2 INFO: Inference done 17837/26446. 0.1171 s / img. ETA=0:17:14
[06/30 20:40:58] detectron2 INFO: Inference done 17881/26446. 0.1171 s / img. ETA=0:17:09
[06/30 20:41:03] detectron2 INFO: Inference done 17926/26446. 0.1170 s / img. ETA=0:17:03
[06/30 20:41:08] detectron2 INFO: Inference done 17970/26446. 0.1170 s / img. ETA=0:16:58
[06/30 20:41:13] detectron2 INFO: Inference done 18014/26446. 0.1170 s / img. ETA=0:16:52
[06/30 20:41:18] detectron2 INFO: Inference done 18057/26446. 0.1170 s / img. ETA=0:16:47
[06/30 20:41:23] detectron2 INFO: Inference done 18099/26446. 0.1170 s / img. ETA=0:16:42
[06/30 20:41:28] detectron2 INFO: Inference done 18142/26446. 0.1170 s / img. ETA=0:16:37
[06/30 20:41:33] detectron2 INFO: Inference done 18186/26446. 0.1170 s / img. ETA=0:16:32
[06/30 20:41:38] detectron2 INFO: Inference done 18229/26446. 0.1170 s / img. ETA=0:16:26
[06/30 20:41:43] detectron2 INFO: Inference done 18272/26446. 0.1170 s / img. ETA=0:16:21
[06/30 20:41:48] detectron2 INFO: Inference done 18316/26446. 0.1170 s / img. ETA=0:16:16
[06/30 20:41:53] detectron2 INFO: Inference done 18359/26446. 0.1170 s / img. ETA=0:16:11
[06/30 20:41:58] detectron2 INFO: Inference done 18402/26446. 0.1169 s / img. ETA=0:16:05
[06/30 20:42:03] detectron2 INFO: Inference done 18445/26446. 0.1169 s / img. ETA=0:16:00
[06/30 20:42:09] detectron2 INFO: Inference done 18489/26446. 0.1169 s / img. ETA=0:15:55
[06/30 20:42:14] detectron2 INFO: Inference done 18532/26446. 0.1169 s / img. ETA=0:15:50
[06/30 20:42:19] detectron2 INFO: Inference done 18575/26446. 0.1169 s / img. ETA=0:15:44
[06/30 20:42:24] detectron2 INFO: Inference done 18619/26446. 0.1169 s / img. ETA=0:15:39
[06/30 20:42:29] detectron2 INFO: Inference done 18663/26446. 0.1169 s / img. ETA=0:15:34
[06/30 20:42:34] detectron2 INFO: Inference done 18706/26446. 0.1169 s / img. ETA=0:15:28
[06/30 20:42:39] detectron2 INFO: Inference done 18750/26446. 0.1169 s / img. ETA=0:15:23
[06/30 20:42:44] detectron2 INFO: Inference done 18793/26446. 0.1169 s / img. ETA=0:15:18
[06/30 20:42:49] detectron2 INFO: Inference done 18836/26446. 0.1169 s / img. ETA=0:15:13
[06/30 20:42:54] detectron2 INFO: Inference done 18880/26446. 0.1169 s / img. ETA=0:15:07
[06/30 20:42:59] detectron2 INFO: Inference done 18924/26446. 0.1168 s / img. ETA=0:15:02
[06/30 20:43:04] detectron2 INFO: Inference done 18968/26446. 0.1168 s / img. ETA=0:14:56
[06/30 20:43:09] detectron2 INFO: Inference done 19012/26446. 0.1168 s / img. ETA=0:14:51
[06/30 20:43:14] detectron2 INFO: Inference done 19056/26446. 0.1168 s / img. ETA=0:14:46
[06/30 20:43:19] detectron2 INFO: Inference done 19099/26446. 0.1168 s / img. ETA=0:14:41
[06/30 20:43:24] detectron2 INFO: Inference done 19143/26446. 0.1168 s / img. ETA=0:14:35
[06/30 20:43:29] detectron2 INFO: Inference done 19185/26446. 0.1168 s / img. ETA=0:14:30
[06/30 20:43:34] detectron2 INFO: Inference done 19228/26446. 0.1168 s / img. ETA=0:14:25
[06/30 20:43:40] detectron2 INFO: Inference done 19272/26446. 0.1168 s / img. ETA=0:14:20
[06/30 20:43:45] detectron2 INFO: Inference done 19313/26446. 0.1168 s / img. ETA=0:14:15
[06/30 20:43:50] detectron2 INFO: Inference done 19356/26446. 0.1168 s / img. ETA=0:14:10
[06/30 20:43:55] detectron2 INFO: Inference done 19400/26446. 0.1168 s / img. ETA=0:14:04
[06/30 20:44:00] detectron2 INFO: Inference done 19443/26446. 0.1168 s / img. ETA=0:13:59
[06/30 20:44:05] detectron2 INFO: Inference done 19487/26446. 0.1167 s / img. ETA=0:13:54
[06/30 20:44:10] detectron2 INFO: Inference done 19530/26446. 0.1167 s / img. ETA=0:13:48
[06/30 20:44:15] detectron2 INFO: Inference done 19572/26446. 0.1167 s / img. ETA=0:13:43
[06/30 20:44:20] detectron2 INFO: Inference done 19613/26446. 0.1167 s / img. ETA=0:13:39
[06/30 20:44:25] detectron2 INFO: Inference done 19657/26446. 0.1167 s / img. ETA=0:13:33
[06/30 20:44:30] detectron2 INFO: Inference done 19701/26446. 0.1167 s / img. ETA=0:13:28
[06/30 20:44:35] detectron2 INFO: Inference done 19745/26446. 0.1167 s / img. ETA=0:13:22
[06/30 20:44:40] detectron2 INFO: Inference done 19789/26446. 0.1167 s / img. ETA=0:13:17
[06/30 20:44:45] detectron2 INFO: Inference done 19833/26446. 0.1167 s / img. ETA=0:13:12
[06/30 20:44:50] detectron2 INFO: Inference done 19876/26446. 0.1167 s / img. ETA=0:13:07
[06/30 20:44:55] detectron2 INFO: Inference done 19920/26446. 0.1167 s / img. ETA=0:13:01
[06/30 20:45:00] detectron2 INFO: Inference done 19964/26446. 0.1167 s / img. ETA=0:12:56
[06/30 20:45:05] detectron2 INFO: Inference done 20007/26446. 0.1167 s / img. ETA=0:12:51
[06/30 20:45:10] detectron2 INFO: Inference done 20050/26446. 0.1167 s / img. ETA=0:12:46
[06/30 20:45:15] detectron2 INFO: Inference done 20094/26446. 0.1166 s / img. ETA=0:12:40
[06/30 20:45:20] detectron2 INFO: Inference done 20136/26446. 0.1167 s / img. ETA=0:12:35
[06/30 20:45:26] detectron2 INFO: Inference done 20179/26446. 0.1166 s / img. ETA=0:12:30
[06/30 20:45:31] detectron2 INFO: Inference done 20222/26446. 0.1166 s / img. ETA=0:12:25
[06/30 20:45:36] detectron2 INFO: Inference done 20266/26446. 0.1166 s / img. ETA=0:12:20
[06/30 20:45:41] detectron2 INFO: Inference done 20310/26446. 0.1166 s / img. ETA=0:12:14
[06/30 20:45:46] detectron2 INFO: Inference done 20353/26446. 0.1166 s / img. ETA=0:12:09
[06/30 20:45:51] detectron2 INFO: Inference done 20396/26446. 0.1166 s / img. ETA=0:12:04
[06/30 20:45:56] detectron2 INFO: Inference done 20440/26446. 0.1166 s / img. ETA=0:11:59
[06/30 20:46:01] detectron2 INFO: Inference done 20484/26446. 0.1166 s / img. ETA=0:11:53
[06/30 20:46:06] detectron2 INFO: Inference done 20528/26446. 0.1166 s / img. ETA=0:11:48
[06/30 20:46:11] detectron2 INFO: Inference done 20571/26446. 0.1166 s / img. ETA=0:11:43
[06/30 20:46:16] detectron2 INFO: Inference done 20614/26446. 0.1166 s / img. ETA=0:11:37
[06/30 20:46:21] detectron2 INFO: Inference done 20658/26446. 0.1166 s / img. ETA=0:11:32
[06/30 20:46:26] detectron2 INFO: Inference done 20702/26446. 0.1166 s / img. ETA=0:11:27
[06/30 20:46:31] detectron2 INFO: Inference done 20744/26446. 0.1166 s / img. ETA=0:11:22
[06/30 20:46:36] detectron2 INFO: Inference done 20787/26446. 0.1166 s / img. ETA=0:11:17
[06/30 20:46:41] detectron2 INFO: Inference done 20830/26446. 0.1166 s / img. ETA=0:11:12
[06/30 20:46:47] detectron2 INFO: Inference done 20874/26446. 0.1165 s / img. ETA=0:11:06
[06/30 20:46:52] detectron2 INFO: Inference done 20918/26446. 0.1165 s / img. ETA=0:11:01
[06/30 20:46:57] detectron2 INFO: Inference done 20962/26446. 0.1165 s / img. ETA=0:10:56
[06/30 20:47:02] detectron2 INFO: Inference done 21005/26446. 0.1165 s / img. ETA=0:10:50
[06/30 20:47:07] detectron2 INFO: Inference done 21049/26446. 0.1165 s / img. ETA=0:10:45
[06/30 20:47:12] detectron2 INFO: Inference done 21092/26446. 0.1165 s / img. ETA=0:10:40
[06/30 20:47:17] detectron2 INFO: Inference done 21135/26446. 0.1165 s / img. ETA=0:10:35
[06/30 20:47:22] detectron2 INFO: Inference done 21179/26446. 0.1165 s / img. ETA=0:10:29
[06/30 20:47:27] detectron2 INFO: Inference done 21222/26446. 0.1165 s / img. ETA=0:10:24
[06/30 20:47:32] detectron2 INFO: Inference done 21264/26446. 0.1165 s / img. ETA=0:10:19
[06/30 20:47:37] detectron2 INFO: Inference done 21307/26446. 0.1165 s / img. ETA=0:10:14
[06/30 20:47:42] detectron2 INFO: Inference done 21351/26446. 0.1165 s / img. ETA=0:10:09
[06/30 20:47:47] detectron2 INFO: Inference done 21393/26446. 0.1165 s / img. ETA=0:10:04
[06/30 20:47:52] detectron2 INFO: Inference done 21436/26446. 0.1165 s / img. ETA=0:09:59
[06/30 20:47:57] detectron2 INFO: Inference done 21480/26446. 0.1165 s / img. ETA=0:09:53
[06/30 20:48:02] detectron2 INFO: Inference done 21523/26446. 0.1165 s / img. ETA=0:09:48
[06/30 20:48:07] detectron2 INFO: Inference done 21566/26446. 0.1165 s / img. ETA=0:09:43
[06/30 20:48:12] detectron2 INFO: Inference done 21610/26446. 0.1165 s / img. ETA=0:09:38
[06/30 20:48:18] detectron2 INFO: Inference done 21654/26446. 0.1164 s / img. ETA=0:09:32
[06/30 20:48:23] detectron2 INFO: Inference done 21697/26446. 0.1164 s / img. ETA=0:09:27
[06/30 20:48:28] detectron2 INFO: Inference done 21740/26446. 0.1164 s / img. ETA=0:09:22
[06/30 20:48:33] detectron2 INFO: Inference done 21783/26446. 0.1164 s / img. ETA=0:09:17
[06/30 20:48:38] detectron2 INFO: Inference done 21826/26446. 0.1164 s / img. ETA=0:09:12
[06/30 20:48:43] detectron2 INFO: Inference done 21869/26446. 0.1164 s / img. ETA=0:09:07
[06/30 20:48:48] detectron2 INFO: Inference done 21913/26446. 0.1164 s / img. ETA=0:09:01
[06/30 20:48:53] detectron2 INFO: Inference done 21957/26446. 0.1164 s / img. ETA=0:08:56
[06/30 20:48:58] detectron2 INFO: Inference done 22002/26446. 0.1164 s / img. ETA=0:08:51
[06/30 20:49:03] detectron2 INFO: Inference done 22046/26446. 0.1164 s / img. ETA=0:08:45
[06/30 20:49:08] detectron2 INFO: Inference done 22090/26446. 0.1164 s / img. ETA=0:08:40
[06/30 20:49:13] detectron2 INFO: Inference done 22134/26446. 0.1164 s / img. ETA=0:08:35
[06/30 20:49:18] detectron2 INFO: Inference done 22178/26446. 0.1164 s / img. ETA=0:08:29
[06/30 20:49:23] detectron2 INFO: Inference done 22221/26446. 0.1164 s / img. ETA=0:08:24
[06/30 20:49:28] detectron2 INFO: Inference done 22264/26446. 0.1164 s / img. ETA=0:08:19
[06/30 20:49:33] detectron2 INFO: Inference done 22307/26446. 0.1164 s / img. ETA=0:08:14
[06/30 20:49:39] detectron2 INFO: Inference done 22350/26446. 0.1163 s / img. ETA=0:08:09
[06/30 20:49:44] detectron2 INFO: Inference done 22394/26446. 0.1163 s / img. ETA=0:08:03
[06/30 20:49:49] detectron2 INFO: Inference done 22438/26446. 0.1163 s / img. ETA=0:07:58
[06/30 20:49:54] detectron2 INFO: Inference done 22482/26446. 0.1163 s / img. ETA=0:07:53
[06/30 20:49:59] detectron2 INFO: Inference done 22526/26446. 0.1163 s / img. ETA=0:07:48
[06/30 20:50:04] detectron2 INFO: Inference done 22570/26446. 0.1163 s / img. ETA=0:07:42
[06/30 20:50:09] detectron2 INFO: Inference done 22614/26446. 0.1163 s / img. ETA=0:07:37
[06/30 20:50:14] detectron2 INFO: Inference done 22657/26446. 0.1163 s / img. ETA=0:07:32
[06/30 20:50:19] detectron2 INFO: Inference done 22701/26446. 0.1163 s / img. ETA=0:07:27
[06/30 20:50:24] detectron2 INFO: Inference done 22745/26446. 0.1163 s / img. ETA=0:07:21
[06/30 20:50:29] detectron2 INFO: Inference done 22788/26446. 0.1163 s / img. ETA=0:07:16
[06/30 20:50:34] detectron2 INFO: Inference done 22832/26446. 0.1163 s / img. ETA=0:07:11
[06/30 20:50:39] detectron2 INFO: Inference done 22875/26446. 0.1163 s / img. ETA=0:07:06
[06/30 20:50:44] detectron2 INFO: Inference done 22919/26446. 0.1163 s / img. ETA=0:07:00
[06/30 20:50:49] detectron2 INFO: Inference done 22963/26446. 0.1162 s / img. ETA=0:06:55
[06/30 20:50:54] detectron2 INFO: Inference done 23007/26446. 0.1162 s / img. ETA=0:06:50
[06/30 20:50:59] detectron2 INFO: Inference done 23050/26446. 0.1162 s / img. ETA=0:06:45
[06/30 20:51:04] detectron2 INFO: Inference done 23093/26446. 0.1162 s / img. ETA=0:06:40
[06/30 20:51:10] detectron2 INFO: Inference done 23137/26446. 0.1162 s / img. ETA=0:06:34
[06/30 20:51:15] detectron2 INFO: Inference done 23181/26446. 0.1162 s / img. ETA=0:06:29
[06/30 20:51:20] detectron2 INFO: Inference done 23225/26446. 0.1162 s / img. ETA=0:06:24
[06/30 20:51:25] detectron2 INFO: Inference done 23268/26446. 0.1162 s / img. ETA=0:06:19
[06/30 20:51:30] detectron2 INFO: Inference done 23311/26446. 0.1162 s / img. ETA=0:06:13
[06/30 20:51:35] detectron2 INFO: Inference done 23355/26446. 0.1162 s / img. ETA=0:06:08
[06/30 20:51:40] detectron2 INFO: Inference done 23399/26446. 0.1162 s / img. ETA=0:06:03
[06/30 20:51:45] detectron2 INFO: Inference done 23442/26446. 0.1162 s / img. ETA=0:05:58
[06/30 20:51:50] detectron2 INFO: Inference done 23485/26446. 0.1162 s / img. ETA=0:05:53
[06/30 20:51:55] detectron2 INFO: Inference done 23530/26446. 0.1162 s / img. ETA=0:05:47
[06/30 20:52:00] detectron2 INFO: Inference done 23574/26446. 0.1162 s / img. ETA=0:05:42
[06/30 20:52:05] detectron2 INFO: Inference done 23618/26446. 0.1162 s / img. ETA=0:05:37
[06/30 20:52:10] detectron2 INFO: Inference done 23661/26446. 0.1162 s / img. ETA=0:05:32
[06/30 20:52:16] detectron2 INFO: Inference done 23705/26446. 0.1162 s / img. ETA=0:05:26
[06/30 20:52:21] detectron2 INFO: Inference done 23749/26446. 0.1161 s / img. ETA=0:05:21
[06/30 20:52:26] detectron2 INFO: Inference done 23794/26446. 0.1161 s / img. ETA=0:05:16
[06/30 20:52:31] detectron2 INFO: Inference done 23838/26446. 0.1161 s / img. ETA=0:05:10
[06/30 20:52:36] detectron2 INFO: Inference done 23882/26446. 0.1161 s / img. ETA=0:05:05
[06/30 20:52:41] detectron2 INFO: Inference done 23913/26446. 0.1161 s / img. ETA=0:05:02
[06/30 20:52:46] detectron2 INFO: Inference done 23957/26446. 0.1161 s / img. ETA=0:04:56
[06/30 20:52:51] detectron2 INFO: Inference done 24001/26446. 0.1161 s / img. ETA=0:04:51
[06/30 20:52:56] detectron2 INFO: Inference done 24045/26446. 0.1161 s / img. ETA=0:04:46
[06/30 20:53:01] detectron2 INFO: Inference done 24089/26446. 0.1161 s / img. ETA=0:04:41
[06/30 20:53:06] detectron2 INFO: Inference done 24133/26446. 0.1161 s / img. ETA=0:04:35
[06/30 20:53:11] detectron2 INFO: Inference done 24177/26446. 0.1161 s / img. ETA=0:04:30
[06/30 20:53:16] detectron2 INFO: Inference done 24221/26446. 0.1161 s / img. ETA=0:04:25
[06/30 20:53:21] detectron2 INFO: Inference done 24265/26446. 0.1160 s / img. ETA=0:04:19
[06/30 20:53:26] detectron2 INFO: Inference done 24309/26446. 0.1160 s / img. ETA=0:04:14
[06/30 20:53:31] detectron2 INFO: Inference done 24352/26446. 0.1160 s / img. ETA=0:04:09
[06/30 20:53:37] detectron2 INFO: Inference done 24396/26446. 0.1160 s / img. ETA=0:04:04
[06/30 20:53:42] detectron2 INFO: Inference done 24439/26446. 0.1160 s / img. ETA=0:03:59
[06/30 20:53:47] detectron2 INFO: Inference done 24483/26446. 0.1160 s / img. ETA=0:03:53
[06/30 20:53:52] detectron2 INFO: Inference done 24527/26446. 0.1160 s / img. ETA=0:03:48
[06/30 20:53:57] detectron2 INFO: Inference done 24571/26446. 0.1160 s / img. ETA=0:03:43
[06/30 20:54:02] detectron2 INFO: Inference done 24615/26446. 0.1160 s / img. ETA=0:03:38
[06/30 20:54:07] detectron2 INFO: Inference done 24660/26446. 0.1160 s / img. ETA=0:03:32
[06/30 20:54:12] detectron2 INFO: Inference done 24703/26446. 0.1160 s / img. ETA=0:03:27
[06/30 20:54:17] detectron2 INFO: Inference done 24746/26446. 0.1160 s / img. ETA=0:03:22
[06/30 20:54:22] detectron2 INFO: Inference done 24788/26446. 0.1160 s / img. ETA=0:03:17
[06/30 20:54:27] detectron2 INFO: Inference done 24831/26446. 0.1160 s / img. ETA=0:03:12
[06/30 20:54:32] detectron2 INFO: Inference done 24875/26446. 0.1160 s / img. ETA=0:03:07
[06/30 20:54:37] detectron2 INFO: Inference done 24919/26446. 0.1160 s / img. ETA=0:03:01
[06/30 20:54:42] detectron2 INFO: Inference done 24962/26446. 0.1160 s / img. ETA=0:02:56
[06/30 20:54:47] detectron2 INFO: Inference done 25005/26446. 0.1160 s / img. ETA=0:02:51
[06/30 20:54:52] detectron2 INFO: Inference done 25049/26446. 0.1160 s / img. ETA=0:02:46
[06/30 20:54:57] detectron2 INFO: Inference done 25093/26446. 0.1159 s / img. ETA=0:02:41
[06/30 20:55:02] detectron2 INFO: Inference done 25137/26446. 0.1159 s / img. ETA=0:02:35
[06/30 20:55:08] detectron2 INFO: Inference done 25182/26446. 0.1159 s / img. ETA=0:02:30
[06/30 20:55:13] detectron2 INFO: Inference done 25226/26446. 0.1159 s / img. ETA=0:02:25
[06/30 20:55:18] detectron2 INFO: Inference done 25270/26446. 0.1159 s / img. ETA=0:02:20
[06/30 20:55:23] detectron2 INFO: Inference done 25315/26446. 0.1159 s / img. ETA=0:02:14
[06/30 20:55:28] detectron2 INFO: Inference done 25359/26446. 0.1159 s / img. ETA=0:02:09
[06/30 20:55:33] detectron2 INFO: Inference done 25403/26446. 0.1159 s / img. ETA=0:02:04
[06/30 20:55:38] detectron2 INFO: Inference done 25447/26446. 0.1159 s / img. ETA=0:01:58
[06/30 20:55:43] detectron2 INFO: Inference done 25492/26446. 0.1159 s / img. ETA=0:01:53
[06/30 20:55:48] detectron2 INFO: Inference done 25535/26446. 0.1159 s / img. ETA=0:01:48
[06/30 20:55:53] detectron2 INFO: Inference done 25579/26446. 0.1159 s / img. ETA=0:01:43
[06/30 20:55:58] detectron2 INFO: Inference done 25623/26446. 0.1159 s / img. ETA=0:01:37
[06/30 20:56:03] detectron2 INFO: Inference done 25667/26446. 0.1159 s / img. ETA=0:01:32
[06/30 20:56:08] detectron2 INFO: Inference done 25712/26446. 0.1158 s / img. ETA=0:01:27
[06/30 20:56:13] detectron2 INFO: Inference done 25756/26446. 0.1158 s / img. ETA=0:01:22
[06/30 20:56:18] detectron2 INFO: Inference done 25800/26446. 0.1158 s / img. ETA=0:01:16
[06/30 20:56:23] detectron2 INFO: Inference done 25843/26446. 0.1158 s / img. ETA=0:01:11
[06/30 20:56:29] detectron2 INFO: Inference done 25888/26446. 0.1158 s / img. ETA=0:01:06
[06/30 20:56:34] detectron2 INFO: Inference done 25931/26446. 0.1158 s / img. ETA=0:01:01
[06/30 20:56:39] detectron2 INFO: Inference done 25976/26446. 0.1158 s / img. ETA=0:00:55
[06/30 20:56:44] detectron2 INFO: Inference done 26020/26446. 0.1158 s / img. ETA=0:00:50
[06/30 20:56:49] detectron2 INFO: Inference done 26064/26446. 0.1158 s / img. ETA=0:00:45
[06/30 20:56:54] detectron2 INFO: Inference done 26107/26446. 0.1158 s / img. ETA=0:00:40
[06/30 20:56:59] detectron2 INFO: Inference done 26152/26446. 0.1158 s / img. ETA=0:00:34
[06/30 20:57:04] detectron2 INFO: Inference done 26196/26446. 0.1158 s / img. ETA=0:00:29
[06/30 20:57:09] detectron2 INFO: Inference done 26240/26446. 0.1158 s / img. ETA=0:00:24
[06/30 20:57:14] detectron2 INFO: Inference done 26285/26446. 0.1158 s / img. ETA=0:00:19
[06/30 20:57:19] detectron2 INFO: Inference done 26329/26446. 0.1158 s / img. ETA=0:00:13
[06/30 20:57:25] detectron2 INFO: Inference done 26373/26446. 0.1158 s / img. ETA=0:00:08
[06/30 20:57:30] detectron2 INFO: Inference done 26417/26446. 0.1157 s / img. ETA=0:00:03
[06/30 20:57:34] detectron2 INFO: Total inference time: 0:52:24.627263 (0.118930 s / img per device, on 1 devices)
[06/30 20:57:34] detectron2 INFO: Total inference pure compute time: 0:51:00 (0.115747 s / img per device, on 1 devices)
[06/30 20:57:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 20:57:43] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 20:57:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 20:57:53] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[06/30 21:04:13] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 21:04:16] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 21:04:16] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '20', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 21:04:16] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 40
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 8
VERSION: 2

[06/30 21:04:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 20
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 21:04:16] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 21:04:16] d2.utils.env INFO: Using a generated random seed 16270610
[06/30 21:04:18] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 21:04:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:04:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:04:20] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 21:04:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 21:04:20] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 21:04:21] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 21:04:21] detectron2 INFO: Following metrics will be use for evaluation
[06/30 21:04:21] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 21:04:21] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 21:04:21] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 21:04:21] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 21:04:23] detectron2 INFO: Loading zero shot triplets
[06/30 21:04:23] detectron2 INFO: Start inference on 26446 images
[06/30 21:07:25] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 21:07:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 21:07:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 21:07:27] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 40
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 21:07:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 21:07:27] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 21:07:27] d2.utils.env INFO: Using a generated random seed 27398124
[06/30 21:07:29] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 21:07:29] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:07:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:07:30] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 21:07:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 21:07:30] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 21:07:32] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 21:07:32] detectron2 INFO: Following metrics will be use for evaluation
[06/30 21:07:32] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 21:07:32] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 21:07:32] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 21:07:32] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 21:07:34] detectron2 INFO: Loading zero shot triplets
[06/30 21:07:34] detectron2 INFO: Start inference on 26446 images
[06/30 21:08:40] detectron2 INFO: Inference done 1/26446. 60.2972 s / img. ETA=20 days, 2:17:54
[06/30 21:09:23] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 21:09:24] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 21:09:24] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '20', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 21:09:24] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 40
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 21:09:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 20
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 21:09:25] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 21:09:25] d2.utils.env INFO: Using a generated random seed 25218424
[06/30 21:09:27] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 21:09:27] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:09:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 21:09:28] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 21:09:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 21:09:28] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 21:09:30] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 21:09:30] detectron2 INFO: Following metrics will be use for evaluation
[06/30 21:09:30] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 21:09:30] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 21:09:30] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 21:09:30] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 21:09:32] detectron2 INFO: Loading zero shot triplets
[06/30 21:09:32] detectron2 INFO: Start inference on 26446 images
[06/30 21:09:43] detectron2 INFO: Inference done 11/26446. 0.1639 s / img. ETA=1:13:33
[06/30 21:09:48] detectron2 INFO: Inference done 46/26446. 0.1464 s / img. ETA=1:05:43
[06/30 21:09:53] detectron2 INFO: Inference done 81/26446. 0.1439 s / img. ETA=1:04:30
[06/30 21:09:58] detectron2 INFO: Inference done 121/26446. 0.1365 s / img. ETA=1:01:10
[06/30 21:10:04] detectron2 INFO: Inference done 160/26446. 0.1340 s / img. ETA=0:59:57
[06/30 21:10:09] detectron2 INFO: Inference done 203/26446. 0.1298 s / img. ETA=0:58:03
[06/30 21:10:14] detectron2 INFO: Inference done 244/26446. 0.1281 s / img. ETA=0:57:11
[06/30 21:10:19] detectron2 INFO: Inference done 284/26446. 0.1273 s / img. ETA=0:56:45
[06/30 21:10:24] detectron2 INFO: Inference done 325/26446. 0.1263 s / img. ETA=0:56:14
[06/30 21:10:29] detectron2 INFO: Inference done 368/26446. 0.1250 s / img. ETA=0:55:33
[06/30 21:10:34] detectron2 INFO: Inference done 409/26446. 0.1246 s / img. ETA=0:55:18
[06/30 21:10:39] detectron2 INFO: Inference done 449/26446. 0.1244 s / img. ETA=0:55:08
[06/30 21:10:44] detectron2 INFO: Inference done 490/26446. 0.1241 s / img. ETA=0:54:56
[06/30 21:10:49] detectron2 INFO: Inference done 533/26446. 0.1234 s / img. ETA=0:54:31
[06/30 21:10:54] detectron2 INFO: Inference done 577/26446. 0.1228 s / img. ETA=0:54:09
[06/30 21:10:59] detectron2 INFO: Inference done 620/26446. 0.1222 s / img. ETA=0:53:49
[06/30 21:11:04] detectron2 INFO: Inference done 662/26446. 0.1219 s / img. ETA=0:53:37
[06/30 21:11:09] detectron2 INFO: Inference done 705/26446. 0.1216 s / img. ETA=0:53:22
[06/30 21:11:14] detectron2 INFO: Inference done 749/26446. 0.1209 s / img. ETA=0:53:00
[06/30 21:11:19] detectron2 INFO: Inference done 791/26446. 0.1207 s / img. ETA=0:52:49
[06/30 21:11:24] detectron2 INFO: Inference done 834/26446. 0.1203 s / img. ETA=0:52:35
[06/30 21:11:30] detectron2 INFO: Inference done 878/26446. 0.1200 s / img. ETA=0:52:19
[06/30 21:11:35] detectron2 INFO: Inference done 920/26446. 0.1199 s / img. ETA=0:52:12
[06/30 21:11:40] detectron2 INFO: Inference done 965/26446. 0.1193 s / img. ETA=0:51:53
[06/30 21:11:45] detectron2 INFO: Inference done 1007/26446. 0.1193 s / img. ETA=0:51:48
[06/30 21:11:50] detectron2 INFO: Inference done 1050/26446. 0.1192 s / img. ETA=0:51:38
[06/30 21:11:55] detectron2 INFO: Inference done 1094/26446. 0.1188 s / img. ETA=0:51:24
[06/30 21:12:00] detectron2 INFO: Inference done 1139/26446. 0.1184 s / img. ETA=0:51:08
[06/30 21:12:05] detectron2 INFO: Inference done 1184/26446. 0.1181 s / img. ETA=0:50:54
[06/30 21:12:10] detectron2 INFO: Inference done 1227/26446. 0.1179 s / img. ETA=0:50:45
[06/30 21:12:15] detectron2 INFO: Inference done 1271/26446. 0.1178 s / img. ETA=0:50:36
[06/30 21:12:20] detectron2 INFO: Inference done 1314/26446. 0.1176 s / img. ETA=0:50:27
[06/30 21:12:25] detectron2 INFO: Inference done 1359/26446. 0.1174 s / img. ETA=0:50:16
[06/30 21:12:30] detectron2 INFO: Inference done 1403/26446. 0.1172 s / img. ETA=0:50:05
[06/30 21:12:35] detectron2 INFO: Inference done 1446/26446. 0.1171 s / img. ETA=0:49:59
[06/30 21:12:40] detectron2 INFO: Inference done 1489/26446. 0.1170 s / img. ETA=0:49:51
[06/30 21:12:45] detectron2 INFO: Inference done 1533/26446. 0.1169 s / img. ETA=0:49:43
[06/30 21:12:50] detectron2 INFO: Inference done 1578/26446. 0.1167 s / img. ETA=0:49:33
[06/30 21:12:55] detectron2 INFO: Inference done 1622/26446. 0.1166 s / img. ETA=0:49:25
[06/30 21:13:01] detectron2 INFO: Inference done 1666/26446. 0.1165 s / img. ETA=0:49:17
[06/30 21:13:06] detectron2 INFO: Inference done 1709/26446. 0.1164 s / img. ETA=0:49:10
[06/30 21:13:11] detectron2 INFO: Inference done 1751/26446. 0.1164 s / img. ETA=0:49:05
[06/30 21:13:16] detectron2 INFO: Inference done 1792/26446. 0.1163 s / img. ETA=0:49:13
[06/30 21:13:21] detectron2 INFO: Inference done 1837/26446. 0.1161 s / img. ETA=0:49:03
[06/30 21:13:27] detectron2 INFO: Inference done 1881/26446. 0.1161 s / img. ETA=0:48:55
[06/30 21:13:32] detectron2 INFO: Inference done 1926/26446. 0.1159 s / img. ETA=0:48:46
[06/30 21:13:37] detectron2 INFO: Inference done 1970/26446. 0.1158 s / img. ETA=0:48:39
[06/30 21:13:42] detectron2 INFO: Inference done 2014/26446. 0.1157 s / img. ETA=0:48:31
[06/30 21:13:47] detectron2 INFO: Inference done 2054/26446. 0.1159 s / img. ETA=0:48:30
[06/30 21:13:52] detectron2 INFO: Inference done 2091/26446. 0.1162 s / img. ETA=0:48:33
[06/30 21:13:57] detectron2 INFO: Inference done 2133/26446. 0.1162 s / img. ETA=0:48:29
[06/30 21:14:02] detectron2 INFO: Inference done 2178/26446. 0.1161 s / img. ETA=0:48:21
[06/30 21:14:07] detectron2 INFO: Inference done 2221/26446. 0.1161 s / img. ETA=0:48:14
[06/30 21:14:12] detectron2 INFO: Inference done 2265/26446. 0.1160 s / img. ETA=0:48:07
[06/30 21:14:17] detectron2 INFO: Inference done 2310/26446. 0.1159 s / img. ETA=0:47:58
[06/30 21:14:22] detectron2 INFO: Inference done 2353/26446. 0.1159 s / img. ETA=0:47:52
[06/30 21:14:27] detectron2 INFO: Inference done 2397/26446. 0.1158 s / img. ETA=0:47:45
[06/30 21:14:32] detectron2 INFO: Inference done 2442/26446. 0.1157 s / img. ETA=0:47:36
[06/30 21:14:37] detectron2 INFO: Inference done 2486/26446. 0.1156 s / img. ETA=0:47:29
[06/30 21:14:42] detectron2 INFO: Inference done 2531/26446. 0.1155 s / img. ETA=0:47:20
[06/30 21:14:47] detectron2 INFO: Inference done 2575/26446. 0.1154 s / img. ETA=0:47:14
[06/30 21:14:52] detectron2 INFO: Inference done 2618/26446. 0.1154 s / img. ETA=0:47:08
[06/30 21:14:58] detectron2 INFO: Inference done 2661/26446. 0.1154 s / img. ETA=0:47:02
[06/30 21:15:03] detectron2 INFO: Inference done 2703/26446. 0.1154 s / img. ETA=0:46:58
[06/30 21:15:08] detectron2 INFO: Inference done 2748/26446. 0.1153 s / img. ETA=0:46:50
[06/30 21:15:13] detectron2 INFO: Inference done 2793/26446. 0.1152 s / img. ETA=0:46:43
[06/30 21:15:18] detectron2 INFO: Inference done 2838/26446. 0.1151 s / img. ETA=0:46:35
[06/30 21:15:23] detectron2 INFO: Inference done 2883/26446. 0.1150 s / img. ETA=0:46:28
[06/30 21:15:28] detectron2 INFO: Inference done 2922/26446. 0.1152 s / img. ETA=0:46:27
[06/30 21:15:33] detectron2 INFO: Inference done 2964/26446. 0.1153 s / img. ETA=0:46:23
[06/30 21:15:38] detectron2 INFO: Inference done 3010/26446. 0.1152 s / img. ETA=0:46:15
[06/30 21:15:43] detectron2 INFO: Inference done 3055/26446. 0.1151 s / img. ETA=0:46:08
[06/30 21:15:48] detectron2 INFO: Inference done 3099/26446. 0.1150 s / img. ETA=0:46:01
[06/30 21:15:53] detectron2 INFO: Inference done 3144/26446. 0.1150 s / img. ETA=0:45:54
[06/30 21:15:58] detectron2 INFO: Inference done 3188/26446. 0.1149 s / img. ETA=0:45:48
[06/30 21:16:03] detectron2 INFO: Inference done 3233/26446. 0.1148 s / img. ETA=0:45:41
[06/30 21:16:09] detectron2 INFO: Inference done 3278/26446. 0.1148 s / img. ETA=0:45:34
[06/30 21:16:14] detectron2 INFO: Inference done 3323/26446. 0.1147 s / img. ETA=0:45:26
[06/30 21:16:19] detectron2 INFO: Inference done 3368/26446. 0.1146 s / img. ETA=0:45:19
[06/30 21:16:24] detectron2 INFO: Inference done 3414/26446. 0.1145 s / img. ETA=0:45:12
[06/30 21:16:29] detectron2 INFO: Inference done 3458/26446. 0.1145 s / img. ETA=0:45:06
[06/30 21:16:34] detectron2 INFO: Inference done 3503/26446. 0.1145 s / img. ETA=0:44:59
[06/30 21:16:39] detectron2 INFO: Inference done 3547/26446. 0.1144 s / img. ETA=0:44:53
[06/30 21:16:44] detectron2 INFO: Inference done 3589/26446. 0.1144 s / img. ETA=0:44:49
[06/30 21:16:49] detectron2 INFO: Inference done 3631/26446. 0.1145 s / img. ETA=0:44:45
[06/30 21:16:54] detectron2 INFO: Inference done 3673/26446. 0.1145 s / img. ETA=0:44:40
[06/30 21:16:59] detectron2 INFO: Inference done 3717/26446. 0.1145 s / img. ETA=0:44:34
[06/30 21:17:04] detectron2 INFO: Inference done 3761/26446. 0.1144 s / img. ETA=0:44:28
[06/30 21:17:09] detectron2 INFO: Inference done 3804/26446. 0.1144 s / img. ETA=0:44:23
[06/30 21:17:14] detectron2 INFO: Inference done 3849/26446. 0.1144 s / img. ETA=0:44:17
[06/30 21:17:19] detectron2 INFO: Inference done 3894/26446. 0.1143 s / img. ETA=0:44:10
[06/30 21:17:24] detectron2 INFO: Inference done 3939/26446. 0.1143 s / img. ETA=0:44:04
[06/30 21:17:30] detectron2 INFO: Inference done 3985/26446. 0.1142 s / img. ETA=0:43:56
[06/30 21:17:35] detectron2 INFO: Inference done 4026/26446. 0.1143 s / img. ETA=0:43:53
[06/30 21:17:40] detectron2 INFO: Inference done 4071/26446. 0.1142 s / img. ETA=0:43:46
[06/30 21:17:45] detectron2 INFO: Inference done 4116/26446. 0.1142 s / img. ETA=0:43:40
[06/30 21:17:50] detectron2 INFO: Inference done 4160/26446. 0.1142 s / img. ETA=0:43:34
[06/30 21:17:55] detectron2 INFO: Inference done 4204/26446. 0.1141 s / img. ETA=0:43:29
[06/30 21:18:00] detectron2 INFO: Inference done 4249/26446. 0.1141 s / img. ETA=0:43:23
[06/30 21:18:05] detectron2 INFO: Inference done 4294/26446. 0.1141 s / img. ETA=0:43:16
[06/30 21:18:10] detectron2 INFO: Inference done 4338/26446. 0.1140 s / img. ETA=0:43:10
[06/30 21:18:15] detectron2 INFO: Inference done 4381/26446. 0.1140 s / img. ETA=0:43:05
[06/30 21:18:20] detectron2 INFO: Inference done 4426/26446. 0.1140 s / img. ETA=0:42:59
[06/30 21:18:25] detectron2 INFO: Inference done 4471/26446. 0.1139 s / img. ETA=0:42:53
[06/30 21:18:30] detectron2 INFO: Inference done 4515/26446. 0.1139 s / img. ETA=0:42:47
[06/30 21:18:35] detectron2 INFO: Inference done 4559/26446. 0.1139 s / img. ETA=0:42:42
[06/30 21:18:40] detectron2 INFO: Inference done 4604/26446. 0.1139 s / img. ETA=0:42:35
[06/30 21:18:45] detectron2 INFO: Inference done 4649/26446. 0.1138 s / img. ETA=0:42:29
[06/30 21:18:51] detectron2 INFO: Inference done 4695/26446. 0.1138 s / img. ETA=0:42:22
[06/30 21:18:56] detectron2 INFO: Inference done 4739/26446. 0.1137 s / img. ETA=0:42:17
[06/30 21:19:01] detectron2 INFO: Inference done 4784/26446. 0.1137 s / img. ETA=0:42:10
[06/30 21:19:06] detectron2 INFO: Inference done 4828/26446. 0.1137 s / img. ETA=0:42:05
[06/30 21:19:11] detectron2 INFO: Inference done 4873/26446. 0.1137 s / img. ETA=0:41:59
[06/30 21:19:16] detectron2 INFO: Inference done 4917/26446. 0.1136 s / img. ETA=0:41:53
[06/30 21:19:21] detectron2 INFO: Inference done 4962/26446. 0.1136 s / img. ETA=0:41:47
[06/30 21:19:26] detectron2 INFO: Inference done 5007/26446. 0.1136 s / img. ETA=0:41:41
[06/30 21:19:31] detectron2 INFO: Inference done 5050/26446. 0.1136 s / img. ETA=0:41:37
[06/30 21:19:36] detectron2 INFO: Inference done 5094/26446. 0.1136 s / img. ETA=0:41:31
[06/30 21:19:41] detectron2 INFO: Inference done 5135/26446. 0.1136 s / img. ETA=0:41:28
[06/30 21:19:46] detectron2 INFO: Inference done 5179/26446. 0.1136 s / img. ETA=0:41:22
[06/30 21:19:51] detectron2 INFO: Inference done 5225/26446. 0.1136 s / img. ETA=0:41:15
[06/30 21:19:56] detectron2 INFO: Inference done 5271/26446. 0.1135 s / img. ETA=0:41:09
[06/30 21:20:01] detectron2 INFO: Inference done 5315/26446. 0.1135 s / img. ETA=0:41:03
[06/30 21:20:07] detectron2 INFO: Inference done 5360/26446. 0.1135 s / img. ETA=0:40:57
[06/30 21:20:12] detectron2 INFO: Inference done 5405/26446. 0.1134 s / img. ETA=0:40:52
[06/30 21:20:17] detectron2 INFO: Inference done 5450/26446. 0.1134 s / img. ETA=0:40:46
[06/30 21:20:22] detectron2 INFO: Inference done 5496/26446. 0.1133 s / img. ETA=0:40:39
[06/30 21:20:27] detectron2 INFO: Inference done 5540/26446. 0.1133 s / img. ETA=0:40:34
[06/30 21:20:32] detectron2 INFO: Inference done 5584/26446. 0.1133 s / img. ETA=0:40:28
[06/30 21:20:37] detectron2 INFO: Inference done 5630/26446. 0.1132 s / img. ETA=0:40:21
[06/30 21:20:42] detectron2 INFO: Inference done 5675/26446. 0.1132 s / img. ETA=0:40:15
[06/30 21:20:47] detectron2 INFO: Inference done 5719/26446. 0.1132 s / img. ETA=0:40:10
[06/30 21:20:52] detectron2 INFO: Inference done 5765/26446. 0.1132 s / img. ETA=0:40:04
[06/30 21:20:57] detectron2 INFO: Inference done 5811/26446. 0.1131 s / img. ETA=0:39:57
[06/30 21:21:02] detectron2 INFO: Inference done 5856/26446. 0.1131 s / img. ETA=0:39:51
[06/30 21:21:07] detectron2 INFO: Inference done 5901/26446. 0.1130 s / img. ETA=0:39:45
[06/30 21:21:12] detectron2 INFO: Inference done 5947/26446. 0.1130 s / img. ETA=0:39:39
[06/30 21:21:17] detectron2 INFO: Inference done 5991/26446. 0.1130 s / img. ETA=0:39:34
[06/30 21:21:22] detectron2 INFO: Inference done 6036/26446. 0.1130 s / img. ETA=0:39:28
[06/30 21:21:27] detectron2 INFO: Inference done 6082/26446. 0.1129 s / img. ETA=0:39:22
[06/30 21:21:32] detectron2 INFO: Inference done 6127/26446. 0.1129 s / img. ETA=0:39:16
[06/30 21:21:37] detectron2 INFO: Inference done 6172/26446. 0.1129 s / img. ETA=0:39:11
[06/30 21:21:43] detectron2 INFO: Inference done 6216/26446. 0.1129 s / img. ETA=0:39:06
[06/30 21:21:48] detectron2 INFO: Inference done 6257/26446. 0.1129 s / img. ETA=0:39:02
[06/30 21:21:53] detectron2 INFO: Inference done 6298/26446. 0.1130 s / img. ETA=0:38:58
[06/30 21:21:58] detectron2 INFO: Inference done 6342/26446. 0.1130 s / img. ETA=0:38:53
[06/30 21:22:03] detectron2 INFO: Inference done 6387/26446. 0.1130 s / img. ETA=0:38:47
[06/30 21:22:08] detectron2 INFO: Inference done 6428/26446. 0.1130 s / img. ETA=0:38:43
[06/30 21:22:13] detectron2 INFO: Inference done 6472/26446. 0.1130 s / img. ETA=0:38:38
[06/30 21:22:18] detectron2 INFO: Inference done 6517/26446. 0.1130 s / img. ETA=0:38:32
[06/30 21:22:23] detectron2 INFO: Inference done 6562/26446. 0.1129 s / img. ETA=0:38:26
[06/30 21:22:28] detectron2 INFO: Inference done 6606/26446. 0.1129 s / img. ETA=0:38:21
[06/30 21:22:33] detectron2 INFO: Inference done 6651/26446. 0.1129 s / img. ETA=0:38:16
[06/30 21:22:38] detectron2 INFO: Inference done 6696/26446. 0.1129 s / img. ETA=0:38:10
[06/30 21:22:43] detectron2 INFO: Inference done 6740/26446. 0.1129 s / img. ETA=0:38:05
[06/30 21:22:48] detectron2 INFO: Inference done 6785/26446. 0.1129 s / img. ETA=0:37:59
[06/30 21:22:53] detectron2 INFO: Inference done 6830/26446. 0.1128 s / img. ETA=0:37:53
[06/30 21:22:58] detectron2 INFO: Inference done 6873/26446. 0.1129 s / img. ETA=0:37:48
[06/30 21:23:04] detectron2 INFO: Inference done 6918/26446. 0.1128 s / img. ETA=0:37:43
[06/30 21:23:09] detectron2 INFO: Inference done 6962/26446. 0.1128 s / img. ETA=0:37:38
[06/30 21:23:14] detectron2 INFO: Inference done 7007/26446. 0.1128 s / img. ETA=0:37:32
[06/30 21:23:19] detectron2 INFO: Inference done 7052/26446. 0.1128 s / img. ETA=0:37:26
[06/30 21:23:24] detectron2 INFO: Inference done 7098/26446. 0.1128 s / img. ETA=0:37:20
[06/30 21:23:29] detectron2 INFO: Inference done 7143/26446. 0.1127 s / img. ETA=0:37:15
[06/30 21:23:34] detectron2 INFO: Inference done 7189/26446. 0.1127 s / img. ETA=0:37:09
[06/30 21:23:39] detectron2 INFO: Inference done 7233/26446. 0.1127 s / img. ETA=0:37:03
[06/30 21:23:44] detectron2 INFO: Inference done 7278/26446. 0.1127 s / img. ETA=0:36:58
[06/30 21:23:49] detectron2 INFO: Inference done 7322/26446. 0.1127 s / img. ETA=0:36:53
[06/30 21:23:54] detectron2 INFO: Inference done 7367/26446. 0.1127 s / img. ETA=0:36:47
[06/30 21:23:59] detectron2 INFO: Inference done 7412/26446. 0.1126 s / img. ETA=0:36:41
[06/30 21:24:04] detectron2 INFO: Inference done 7458/26446. 0.1126 s / img. ETA=0:36:35
[06/30 21:24:09] detectron2 INFO: Inference done 7503/26446. 0.1126 s / img. ETA=0:36:30
[06/30 21:24:14] detectron2 INFO: Inference done 7547/26446. 0.1126 s / img. ETA=0:36:25
[06/30 21:24:19] detectron2 INFO: Inference done 7588/26446. 0.1126 s / img. ETA=0:36:21
[06/30 21:24:24] detectron2 INFO: Inference done 7631/26446. 0.1126 s / img. ETA=0:36:16
[06/30 21:24:30] detectron2 INFO: Inference done 7675/26446. 0.1126 s / img. ETA=0:36:11
[06/30 21:24:35] detectron2 INFO: Inference done 7714/26446. 0.1128 s / img. ETA=0:36:09
[06/30 21:24:40] detectron2 INFO: Inference done 7759/26446. 0.1128 s / img. ETA=0:36:04
[06/30 21:24:45] detectron2 INFO: Inference done 7804/26446. 0.1127 s / img. ETA=0:35:58
[06/30 21:24:50] detectron2 INFO: Inference done 7849/26446. 0.1127 s / img. ETA=0:35:53
[06/30 21:24:56] detectron2 INFO: Inference done 7893/26446. 0.1127 s / img. ETA=0:35:47
[06/30 21:25:01] detectron2 INFO: Inference done 7938/26446. 0.1127 s / img. ETA=0:35:42
[06/30 21:25:06] detectron2 INFO: Inference done 7983/26446. 0.1127 s / img. ETA=0:35:36
[06/30 21:25:11] detectron2 INFO: Inference done 8027/26446. 0.1127 s / img. ETA=0:35:31
[06/30 21:25:16] detectron2 INFO: Inference done 8071/26446. 0.1127 s / img. ETA=0:35:26
[06/30 21:25:21] detectron2 INFO: Inference done 8113/26446. 0.1127 s / img. ETA=0:35:22
[06/30 21:25:26] detectron2 INFO: Inference done 8155/26446. 0.1127 s / img. ETA=0:35:17
[06/30 21:25:31] detectron2 INFO: Inference done 8200/26446. 0.1127 s / img. ETA=0:35:12
[06/30 21:25:36] detectron2 INFO: Inference done 8245/26446. 0.1127 s / img. ETA=0:35:06
[06/30 21:25:41] detectron2 INFO: Inference done 8290/26446. 0.1127 s / img. ETA=0:35:01
[06/30 21:25:46] detectron2 INFO: Inference done 8333/26446. 0.1127 s / img. ETA=0:34:56
[06/30 21:25:51] detectron2 INFO: Inference done 8378/26446. 0.1127 s / img. ETA=0:34:50
[06/30 21:25:56] detectron2 INFO: Inference done 8422/26446. 0.1127 s / img. ETA=0:34:45
[06/30 21:26:01] detectron2 INFO: Inference done 8466/26446. 0.1127 s / img. ETA=0:34:40
[06/30 21:26:06] detectron2 INFO: Inference done 8510/26446. 0.1126 s / img. ETA=0:34:35
[06/30 21:26:11] detectron2 INFO: Inference done 8554/26446. 0.1126 s / img. ETA=0:34:29
[06/30 21:26:16] detectron2 INFO: Inference done 8596/26446. 0.1127 s / img. ETA=0:34:25
[06/30 21:26:21] detectron2 INFO: Inference done 8639/26446. 0.1127 s / img. ETA=0:34:20
[06/30 21:26:27] detectron2 INFO: Inference done 8681/26446. 0.1127 s / img. ETA=0:34:16
[06/30 21:26:32] detectron2 INFO: Inference done 8723/26446. 0.1127 s / img. ETA=0:34:11
[06/30 21:26:37] detectron2 INFO: Inference done 8766/26446. 0.1127 s / img. ETA=0:34:06
[06/30 21:26:42] detectron2 INFO: Inference done 8807/26446. 0.1128 s / img. ETA=0:34:02
[06/30 21:26:47] detectron2 INFO: Inference done 8850/26446. 0.1128 s / img. ETA=0:33:58
[06/30 21:26:52] detectron2 INFO: Inference done 8892/26446. 0.1128 s / img. ETA=0:33:53
[06/30 21:26:57] detectron2 INFO: Inference done 8935/26446. 0.1128 s / img. ETA=0:33:48
[06/30 21:27:02] detectron2 INFO: Inference done 8976/26446. 0.1128 s / img. ETA=0:33:44
[06/30 21:27:07] detectron2 INFO: Inference done 9019/26446. 0.1129 s / img. ETA=0:33:39
[06/30 21:27:12] detectron2 INFO: Inference done 9061/26446. 0.1129 s / img. ETA=0:33:35
[06/30 21:27:17] detectron2 INFO: Inference done 9104/26446. 0.1129 s / img. ETA=0:33:30
[06/30 21:27:22] detectron2 INFO: Inference done 9146/26446. 0.1129 s / img. ETA=0:33:25
[06/30 21:27:27] detectron2 INFO: Inference done 9188/26446. 0.1129 s / img. ETA=0:33:21
[06/30 21:27:32] detectron2 INFO: Inference done 9229/26446. 0.1130 s / img. ETA=0:33:17
[06/30 21:27:37] detectron2 INFO: Inference done 9271/26446. 0.1130 s / img. ETA=0:33:12
[06/30 21:27:42] detectron2 INFO: Inference done 9313/26446. 0.1130 s / img. ETA=0:33:08
[06/30 21:27:47] detectron2 INFO: Inference done 9355/26446. 0.1130 s / img. ETA=0:33:03
[06/30 21:27:52] detectron2 INFO: Inference done 9397/26446. 0.1130 s / img. ETA=0:32:58
[06/30 21:27:58] detectron2 INFO: Inference done 9438/26446. 0.1131 s / img. ETA=0:32:54
[06/30 21:28:03] detectron2 INFO: Inference done 9481/26446. 0.1131 s / img. ETA=0:32:49
[06/30 21:28:08] detectron2 INFO: Inference done 9524/26446. 0.1131 s / img. ETA=0:32:45
[06/30 21:28:13] detectron2 INFO: Inference done 9567/26446. 0.1131 s / img. ETA=0:32:40
[06/30 21:28:18] detectron2 INFO: Inference done 9609/26446. 0.1131 s / img. ETA=0:32:35
[06/30 21:28:23] detectron2 INFO: Inference done 9651/26446. 0.1131 s / img. ETA=0:32:31
[06/30 21:28:28] detectron2 INFO: Inference done 9694/26446. 0.1131 s / img. ETA=0:32:26
[06/30 21:28:33] detectron2 INFO: Inference done 9736/26446. 0.1131 s / img. ETA=0:32:21
[06/30 21:28:38] detectron2 INFO: Inference done 9779/26446. 0.1131 s / img. ETA=0:32:16
[06/30 21:28:43] detectron2 INFO: Inference done 9822/26446. 0.1132 s / img. ETA=0:32:11
[06/30 21:28:48] detectron2 INFO: Inference done 9865/26446. 0.1132 s / img. ETA=0:32:06
[06/30 21:28:53] detectron2 INFO: Inference done 9907/26446. 0.1132 s / img. ETA=0:32:02
[06/30 21:28:58] detectron2 INFO: Inference done 9950/26446. 0.1132 s / img. ETA=0:31:57
[06/30 21:29:03] detectron2 INFO: Inference done 9993/26446. 0.1132 s / img. ETA=0:31:52
[06/30 21:29:08] detectron2 INFO: Inference done 10035/26446. 0.1132 s / img. ETA=0:31:47
[06/30 21:29:13] detectron2 INFO: Inference done 10077/26446. 0.1132 s / img. ETA=0:31:43
[06/30 21:29:19] detectron2 INFO: Inference done 10120/26446. 0.1132 s / img. ETA=0:31:38
[06/30 21:29:24] detectron2 INFO: Inference done 10162/26446. 0.1132 s / img. ETA=0:31:33
[06/30 21:29:29] detectron2 INFO: Inference done 10204/26446. 0.1133 s / img. ETA=0:31:29
[06/30 21:29:34] detectron2 INFO: Inference done 10247/26446. 0.1133 s / img. ETA=0:31:24
[06/30 21:29:39] detectron2 INFO: Inference done 10290/26446. 0.1133 s / img. ETA=0:31:19
[06/30 21:29:44] detectron2 INFO: Inference done 10333/26446. 0.1133 s / img. ETA=0:31:14
[06/30 21:29:49] detectron2 INFO: Inference done 10376/26446. 0.1133 s / img. ETA=0:31:09
[06/30 21:29:54] detectron2 INFO: Inference done 10420/26446. 0.1133 s / img. ETA=0:31:04
[06/30 21:29:59] detectron2 INFO: Inference done 10463/26446. 0.1133 s / img. ETA=0:30:59
[06/30 21:30:04] detectron2 INFO: Inference done 10504/26446. 0.1133 s / img. ETA=0:30:55
[06/30 21:30:09] detectron2 INFO: Inference done 10546/26446. 0.1134 s / img. ETA=0:30:50
[06/30 21:30:14] detectron2 INFO: Inference done 10589/26446. 0.1134 s / img. ETA=0:30:45
[06/30 21:30:20] detectron2 INFO: Inference done 10632/26446. 0.1134 s / img. ETA=0:30:41
[06/30 21:30:25] detectron2 INFO: Inference done 10675/26446. 0.1134 s / img. ETA=0:30:36
[06/30 21:30:30] detectron2 INFO: Inference done 10718/26446. 0.1134 s / img. ETA=0:30:31
[06/30 21:30:35] detectron2 INFO: Inference done 10761/26446. 0.1134 s / img. ETA=0:30:26
[06/30 21:30:40] detectron2 INFO: Inference done 10804/26446. 0.1134 s / img. ETA=0:30:21
[06/30 21:30:45] detectron2 INFO: Inference done 10846/26446. 0.1134 s / img. ETA=0:30:16
[06/30 21:30:50] detectron2 INFO: Inference done 10889/26446. 0.1134 s / img. ETA=0:30:11
[06/30 21:30:55] detectron2 INFO: Inference done 10931/26446. 0.1134 s / img. ETA=0:30:07
[06/30 21:31:00] detectron2 INFO: Inference done 10974/26446. 0.1134 s / img. ETA=0:30:02
[06/30 21:31:05] detectron2 INFO: Inference done 11017/26446. 0.1134 s / img. ETA=0:29:57
[06/30 21:31:10] detectron2 INFO: Inference done 11060/26446. 0.1134 s / img. ETA=0:29:52
[06/30 21:31:15] detectron2 INFO: Inference done 11102/26446. 0.1134 s / img. ETA=0:29:47
[06/30 21:31:20] detectron2 INFO: Inference done 11145/26446. 0.1134 s / img. ETA=0:29:42
[06/30 21:31:25] detectron2 INFO: Inference done 11188/26446. 0.1135 s / img. ETA=0:29:37
[06/30 21:31:30] detectron2 INFO: Inference done 11231/26446. 0.1135 s / img. ETA=0:29:32
[06/30 21:31:35] detectron2 INFO: Inference done 11274/26446. 0.1135 s / img. ETA=0:29:27
[06/30 21:31:40] detectron2 INFO: Inference done 11317/26446. 0.1135 s / img. ETA=0:29:22
[06/30 21:31:45] detectron2 INFO: Inference done 11360/26446. 0.1135 s / img. ETA=0:29:17
[06/30 21:31:51] detectron2 INFO: Inference done 11402/26446. 0.1135 s / img. ETA=0:29:13
[06/30 21:31:56] detectron2 INFO: Inference done 11445/26446. 0.1135 s / img. ETA=0:29:08
[06/30 21:32:01] detectron2 INFO: Inference done 11488/26446. 0.1135 s / img. ETA=0:29:03
[06/30 21:32:06] detectron2 INFO: Inference done 11531/26446. 0.1135 s / img. ETA=0:28:58
[06/30 21:32:11] detectron2 INFO: Inference done 11574/26446. 0.1135 s / img. ETA=0:28:53
[06/30 21:32:16] detectron2 INFO: Inference done 11616/26446. 0.1135 s / img. ETA=0:28:48
[06/30 21:32:21] detectron2 INFO: Inference done 11659/26446. 0.1135 s / img. ETA=0:28:43
[06/30 21:32:26] detectron2 INFO: Inference done 11701/26446. 0.1135 s / img. ETA=0:28:39
[06/30 21:32:31] detectron2 INFO: Inference done 11742/26446. 0.1136 s / img. ETA=0:28:34
[06/30 21:32:36] detectron2 INFO: Inference done 11784/26446. 0.1136 s / img. ETA=0:28:30
[06/30 21:32:41] detectron2 INFO: Inference done 11827/26446. 0.1136 s / img. ETA=0:28:25
[06/30 21:32:46] detectron2 INFO: Inference done 11870/26446. 0.1136 s / img. ETA=0:28:20
[06/30 21:32:51] detectron2 INFO: Inference done 11912/26446. 0.1136 s / img. ETA=0:28:15
[06/30 21:32:56] detectron2 INFO: Inference done 11955/26446. 0.1136 s / img. ETA=0:28:10
[06/30 21:33:01] detectron2 INFO: Inference done 11997/26446. 0.1136 s / img. ETA=0:28:05
[06/30 21:33:06] detectron2 INFO: Inference done 12040/26446. 0.1136 s / img. ETA=0:28:00
[06/30 21:33:11] detectron2 INFO: Inference done 12083/26446. 0.1136 s / img. ETA=0:27:55
[06/30 21:33:16] detectron2 INFO: Inference done 12125/26446. 0.1136 s / img. ETA=0:27:50
[06/30 21:33:21] detectron2 INFO: Inference done 12168/26446. 0.1136 s / img. ETA=0:27:45
[06/30 21:33:27] detectron2 INFO: Inference done 12211/26446. 0.1136 s / img. ETA=0:27:41
[06/30 21:33:32] detectron2 INFO: Inference done 12254/26446. 0.1136 s / img. ETA=0:27:36
[06/30 21:33:37] detectron2 INFO: Inference done 12297/26446. 0.1136 s / img. ETA=0:27:31
[06/30 21:33:42] detectron2 INFO: Inference done 12340/26446. 0.1136 s / img. ETA=0:27:26
[06/30 21:33:47] detectron2 INFO: Inference done 12383/26446. 0.1136 s / img. ETA=0:27:21
[06/30 21:33:52] detectron2 INFO: Inference done 12425/26446. 0.1136 s / img. ETA=0:27:16
[06/30 21:33:57] detectron2 INFO: Inference done 12468/26446. 0.1137 s / img. ETA=0:27:11
[06/30 21:34:02] detectron2 INFO: Inference done 12511/26446. 0.1137 s / img. ETA=0:27:06
[06/30 21:34:07] detectron2 INFO: Inference done 12554/26446. 0.1137 s / img. ETA=0:27:01
[06/30 21:34:12] detectron2 INFO: Inference done 12596/26446. 0.1137 s / img. ETA=0:26:56
[06/30 21:34:17] detectron2 INFO: Inference done 12639/26446. 0.1137 s / img. ETA=0:26:51
[06/30 21:34:22] detectron2 INFO: Inference done 12682/26446. 0.1137 s / img. ETA=0:26:46
[06/30 21:34:27] detectron2 INFO: Inference done 12725/26446. 0.1137 s / img. ETA=0:26:41
[06/30 21:34:32] detectron2 INFO: Inference done 12768/26446. 0.1137 s / img. ETA=0:26:36
[06/30 21:34:37] detectron2 INFO: Inference done 12811/26446. 0.1137 s / img. ETA=0:26:31
[06/30 21:34:42] detectron2 INFO: Inference done 12854/26446. 0.1137 s / img. ETA=0:26:26
[06/30 21:34:47] detectron2 INFO: Inference done 12897/26446. 0.1137 s / img. ETA=0:26:21
[06/30 21:34:53] detectron2 INFO: Inference done 12939/26446. 0.1137 s / img. ETA=0:26:17
[06/30 21:34:58] detectron2 INFO: Inference done 12981/26446. 0.1137 s / img. ETA=0:26:12
[06/30 21:35:03] detectron2 INFO: Inference done 13024/26446. 0.1137 s / img. ETA=0:26:07
[06/30 21:35:08] detectron2 INFO: Inference done 13067/26446. 0.1137 s / img. ETA=0:26:02
[06/30 21:35:13] detectron2 INFO: Inference done 13110/26446. 0.1137 s / img. ETA=0:25:57
[06/30 21:35:18] detectron2 INFO: Inference done 13152/26446. 0.1137 s / img. ETA=0:25:52
[06/30 21:35:23] detectron2 INFO: Inference done 13195/26446. 0.1137 s / img. ETA=0:25:47
[06/30 21:35:28] detectron2 INFO: Inference done 13237/26446. 0.1138 s / img. ETA=0:25:42
[06/30 21:35:33] detectron2 INFO: Inference done 13279/26446. 0.1138 s / img. ETA=0:25:38
[06/30 21:35:38] detectron2 INFO: Inference done 13322/26446. 0.1138 s / img. ETA=0:25:33
[06/30 21:35:43] detectron2 INFO: Inference done 13365/26446. 0.1138 s / img. ETA=0:25:28
[06/30 21:35:48] detectron2 INFO: Inference done 13408/26446. 0.1138 s / img. ETA=0:25:23
[06/30 21:35:53] detectron2 INFO: Inference done 13450/26446. 0.1138 s / img. ETA=0:25:18
[06/30 21:35:58] detectron2 INFO: Inference done 13492/26446. 0.1138 s / img. ETA=0:25:13
[06/30 21:36:04] detectron2 INFO: Inference done 13535/26446. 0.1138 s / img. ETA=0:25:08
[06/30 21:36:09] detectron2 INFO: Inference done 13578/26446. 0.1138 s / img. ETA=0:25:03
[06/30 21:36:14] detectron2 INFO: Inference done 13621/26446. 0.1138 s / img. ETA=0:24:58
[06/30 21:36:19] detectron2 INFO: Inference done 13664/26446. 0.1138 s / img. ETA=0:24:53
[06/30 21:36:24] detectron2 INFO: Inference done 13707/26446. 0.1138 s / img. ETA=0:24:48
[06/30 21:36:29] detectron2 INFO: Inference done 13749/26446. 0.1138 s / img. ETA=0:24:44
[06/30 21:36:34] detectron2 INFO: Inference done 13791/26446. 0.1138 s / img. ETA=0:24:39
[06/30 21:36:39] detectron2 INFO: Inference done 13833/26446. 0.1138 s / img. ETA=0:24:34
[06/30 21:36:44] detectron2 INFO: Inference done 13876/26446. 0.1139 s / img. ETA=0:24:29
[06/30 21:36:49] detectron2 INFO: Inference done 13919/26446. 0.1139 s / img. ETA=0:24:24
[06/30 21:36:54] detectron2 INFO: Inference done 13962/26446. 0.1139 s / img. ETA=0:24:19
[06/30 21:36:59] detectron2 INFO: Inference done 14005/26446. 0.1139 s / img. ETA=0:24:14
[06/30 21:37:04] detectron2 INFO: Inference done 14048/26446. 0.1139 s / img. ETA=0:24:09
[06/30 21:37:09] detectron2 INFO: Inference done 14091/26446. 0.1139 s / img. ETA=0:24:04
[06/30 21:37:14] detectron2 INFO: Inference done 14134/26446. 0.1139 s / img. ETA=0:23:59
[06/30 21:37:19] detectron2 INFO: Inference done 14177/26446. 0.1139 s / img. ETA=0:23:54
[06/30 21:37:24] detectron2 INFO: Inference done 14220/26446. 0.1139 s / img. ETA=0:23:49
[06/30 21:37:30] detectron2 INFO: Inference done 14263/26446. 0.1139 s / img. ETA=0:23:44
[06/30 21:37:35] detectron2 INFO: Inference done 14306/26446. 0.1139 s / img. ETA=0:23:39
[06/30 21:37:40] detectron2 INFO: Inference done 14349/26446. 0.1139 s / img. ETA=0:23:34
[06/30 21:37:45] detectron2 INFO: Inference done 14392/26446. 0.1139 s / img. ETA=0:23:29
[06/30 21:37:50] detectron2 INFO: Inference done 14435/26446. 0.1139 s / img. ETA=0:23:24
[06/30 21:37:55] detectron2 INFO: Inference done 14478/26446. 0.1139 s / img. ETA=0:23:19
[06/30 21:38:00] detectron2 INFO: Inference done 14521/26446. 0.1139 s / img. ETA=0:23:14
[06/30 21:38:05] detectron2 INFO: Inference done 14564/26446. 0.1139 s / img. ETA=0:23:09
[06/30 21:38:10] detectron2 INFO: Inference done 14607/26446. 0.1139 s / img. ETA=0:23:04
[06/30 21:38:15] detectron2 INFO: Inference done 14650/26446. 0.1139 s / img. ETA=0:22:59
[06/30 21:38:20] detectron2 INFO: Inference done 14693/26446. 0.1139 s / img. ETA=0:22:54
[06/30 21:38:25] detectron2 INFO: Inference done 14736/26446. 0.1139 s / img. ETA=0:22:49
[06/30 21:38:30] detectron2 INFO: Inference done 14779/26446. 0.1139 s / img. ETA=0:22:44
[06/30 21:38:35] detectron2 INFO: Inference done 14821/26446. 0.1139 s / img. ETA=0:22:39
[06/30 21:38:40] detectron2 INFO: Inference done 14864/26446. 0.1139 s / img. ETA=0:22:34
[06/30 21:38:45] detectron2 INFO: Inference done 14907/26446. 0.1139 s / img. ETA=0:22:29
[06/30 21:38:51] detectron2 INFO: Inference done 14947/26446. 0.1139 s / img. ETA=0:22:25
[06/30 21:38:56] detectron2 INFO: Inference done 14989/26446. 0.1139 s / img. ETA=0:22:20
[06/30 21:39:01] detectron2 INFO: Inference done 15031/26446. 0.1140 s / img. ETA=0:22:15
[06/30 21:39:07] detectron2 INFO: Inference done 15073/26446. 0.1140 s / img. ETA=0:22:12
[06/30 21:39:12] detectron2 INFO: Inference done 15115/26446. 0.1140 s / img. ETA=0:22:07
[06/30 21:39:17] detectron2 INFO: Inference done 15158/26446. 0.1140 s / img. ETA=0:22:02
[06/30 21:39:22] detectron2 INFO: Inference done 15201/26446. 0.1140 s / img. ETA=0:21:57
[06/30 21:39:27] detectron2 INFO: Inference done 15244/26446. 0.1140 s / img. ETA=0:21:52
[06/30 21:39:32] detectron2 INFO: Inference done 15287/26446. 0.1140 s / img. ETA=0:21:47
[06/30 21:39:37] detectron2 INFO: Inference done 15330/26446. 0.1140 s / img. ETA=0:21:42
[06/30 21:39:42] detectron2 INFO: Inference done 15372/26446. 0.1140 s / img. ETA=0:21:37
[06/30 21:39:47] detectron2 INFO: Inference done 15415/26446. 0.1140 s / img. ETA=0:21:32
[06/30 21:39:53] detectron2 INFO: Inference done 15458/26446. 0.1140 s / img. ETA=0:21:27
[06/30 21:39:58] detectron2 INFO: Inference done 15501/26446. 0.1140 s / img. ETA=0:21:22
[06/30 21:40:03] detectron2 INFO: Inference done 15544/26446. 0.1140 s / img. ETA=0:21:17
[06/30 21:40:08] detectron2 INFO: Inference done 15586/26446. 0.1140 s / img. ETA=0:21:12
[06/30 21:40:13] detectron2 INFO: Inference done 15629/26446. 0.1140 s / img. ETA=0:21:07
[06/30 21:40:18] detectron2 INFO: Inference done 15671/26446. 0.1140 s / img. ETA=0:21:02
[06/30 21:40:23] detectron2 INFO: Inference done 15714/26446. 0.1140 s / img. ETA=0:20:57
[06/30 21:40:28] detectron2 INFO: Inference done 15757/26446. 0.1140 s / img. ETA=0:20:52
[06/30 21:40:33] detectron2 INFO: Inference done 15800/26446. 0.1140 s / img. ETA=0:20:47
[06/30 21:40:38] detectron2 INFO: Inference done 15844/26446. 0.1140 s / img. ETA=0:20:42
[06/30 21:40:43] detectron2 INFO: Inference done 15886/26446. 0.1140 s / img. ETA=0:20:37
[06/30 21:40:48] detectron2 INFO: Inference done 15928/26446. 0.1140 s / img. ETA=0:20:32
[06/30 21:40:53] detectron2 INFO: Inference done 15971/26446. 0.1140 s / img. ETA=0:20:27
[06/30 21:40:58] detectron2 INFO: Inference done 16014/26446. 0.1140 s / img. ETA=0:20:22
[06/30 21:41:03] detectron2 INFO: Inference done 16057/26446. 0.1140 s / img. ETA=0:20:17
[06/30 21:41:08] detectron2 INFO: Inference done 16101/26446. 0.1140 s / img. ETA=0:20:12
[06/30 21:41:13] detectron2 INFO: Inference done 16144/26446. 0.1140 s / img. ETA=0:20:07
[06/30 21:41:18] detectron2 INFO: Inference done 16186/26446. 0.1140 s / img. ETA=0:20:02
[06/30 21:41:23] detectron2 INFO: Inference done 16228/26446. 0.1140 s / img. ETA=0:19:57
[06/30 21:41:28] detectron2 INFO: Inference done 16271/26446. 0.1140 s / img. ETA=0:19:52
[06/30 21:41:33] detectron2 INFO: Inference done 16314/26446. 0.1140 s / img. ETA=0:19:47
[06/30 21:41:39] detectron2 INFO: Inference done 16357/26446. 0.1140 s / img. ETA=0:19:42
[06/30 21:41:44] detectron2 INFO: Inference done 16399/26446. 0.1140 s / img. ETA=0:19:37
[06/30 21:41:49] detectron2 INFO: Inference done 16442/26446. 0.1140 s / img. ETA=0:19:32
[06/30 21:41:54] detectron2 INFO: Inference done 16483/26446. 0.1141 s / img. ETA=0:19:27
[06/30 21:41:59] detectron2 INFO: Inference done 16524/26446. 0.1141 s / img. ETA=0:19:23
[06/30 21:42:04] detectron2 INFO: Inference done 16566/26446. 0.1141 s / img. ETA=0:19:18
[06/30 21:42:09] detectron2 INFO: Inference done 16609/26446. 0.1141 s / img. ETA=0:19:13
[06/30 21:42:14] detectron2 INFO: Inference done 16651/26446. 0.1141 s / img. ETA=0:19:08
[06/30 21:42:19] detectron2 INFO: Inference done 16690/26446. 0.1141 s / img. ETA=0:19:04
[06/30 21:42:24] detectron2 INFO: Inference done 16730/26446. 0.1141 s / img. ETA=0:18:59
[06/30 21:42:29] detectron2 INFO: Inference done 16772/26446. 0.1141 s / img. ETA=0:18:54
[06/30 21:42:34] detectron2 INFO: Inference done 16815/26446. 0.1141 s / img. ETA=0:18:49
[06/30 21:42:39] detectron2 INFO: Inference done 16858/26446. 0.1141 s / img. ETA=0:18:44
[06/30 21:42:44] detectron2 INFO: Inference done 16901/26446. 0.1141 s / img. ETA=0:18:39
[06/30 21:42:49] detectron2 INFO: Inference done 16943/26446. 0.1142 s / img. ETA=0:18:34
[06/30 21:42:54] detectron2 INFO: Inference done 16985/26446. 0.1142 s / img. ETA=0:18:29
[06/30 21:42:59] detectron2 INFO: Inference done 17028/26446. 0.1142 s / img. ETA=0:18:24
[06/30 21:43:04] detectron2 INFO: Inference done 17070/26446. 0.1142 s / img. ETA=0:18:20
[06/30 21:43:09] detectron2 INFO: Inference done 17112/26446. 0.1142 s / img. ETA=0:18:15
[06/30 21:43:15] detectron2 INFO: Inference done 17155/26446. 0.1142 s / img. ETA=0:18:10
[06/30 21:43:20] detectron2 INFO: Inference done 17197/26446. 0.1142 s / img. ETA=0:18:05
[06/30 21:43:25] detectron2 INFO: Inference done 17240/26446. 0.1142 s / img. ETA=0:18:00
[06/30 21:43:30] detectron2 INFO: Inference done 17283/26446. 0.1142 s / img. ETA=0:17:55
[06/30 21:43:35] detectron2 INFO: Inference done 17326/26446. 0.1142 s / img. ETA=0:17:50
[06/30 21:43:40] detectron2 INFO: Inference done 17368/26446. 0.1142 s / img. ETA=0:17:45
[06/30 21:43:45] detectron2 INFO: Inference done 17411/26446. 0.1142 s / img. ETA=0:17:40
[06/30 21:43:50] detectron2 INFO: Inference done 17454/26446. 0.1142 s / img. ETA=0:17:35
[06/30 21:43:55] detectron2 INFO: Inference done 17497/26446. 0.1142 s / img. ETA=0:17:30
[06/30 21:44:00] detectron2 INFO: Inference done 17541/26446. 0.1142 s / img. ETA=0:17:24
[06/30 21:44:05] detectron2 INFO: Inference done 17584/26446. 0.1142 s / img. ETA=0:17:19
[06/30 21:44:10] detectron2 INFO: Inference done 17627/26446. 0.1142 s / img. ETA=0:17:14
[06/30 21:44:15] detectron2 INFO: Inference done 17669/26446. 0.1142 s / img. ETA=0:17:09
[06/30 21:44:20] detectron2 INFO: Inference done 17709/26446. 0.1142 s / img. ETA=0:17:05
[06/30 21:44:25] detectron2 INFO: Inference done 17752/26446. 0.1142 s / img. ETA=0:17:00
[06/30 21:44:30] detectron2 INFO: Inference done 17795/26446. 0.1142 s / img. ETA=0:16:55
[06/30 21:44:36] detectron2 INFO: Inference done 17838/26446. 0.1142 s / img. ETA=0:16:50
[06/30 21:44:41] detectron2 INFO: Inference done 17881/26446. 0.1142 s / img. ETA=0:16:45
[06/30 21:44:46] detectron2 INFO: Inference done 17924/26446. 0.1142 s / img. ETA=0:16:40
[06/30 21:44:51] detectron2 INFO: Inference done 17967/26446. 0.1142 s / img. ETA=0:16:35
[06/30 21:44:56] detectron2 INFO: Inference done 18010/26446. 0.1142 s / img. ETA=0:16:30
[06/30 21:45:01] detectron2 INFO: Inference done 18053/26446. 0.1142 s / img. ETA=0:16:25
[06/30 21:45:06] detectron2 INFO: Inference done 18096/26446. 0.1142 s / img. ETA=0:16:20
[06/30 21:45:11] detectron2 INFO: Inference done 18138/26446. 0.1142 s / img. ETA=0:16:15
[06/30 21:45:16] detectron2 INFO: Inference done 18181/26446. 0.1142 s / img. ETA=0:16:10
[06/30 21:45:21] detectron2 INFO: Inference done 18223/26446. 0.1143 s / img. ETA=0:16:05
[06/30 21:45:26] detectron2 INFO: Inference done 18266/26446. 0.1143 s / img. ETA=0:16:00
[06/30 21:45:31] detectron2 INFO: Inference done 18309/26446. 0.1143 s / img. ETA=0:15:55
[06/30 21:45:36] detectron2 INFO: Inference done 18352/26446. 0.1143 s / img. ETA=0:15:50
[06/30 21:45:41] detectron2 INFO: Inference done 18395/26446. 0.1143 s / img. ETA=0:15:45
[06/30 21:45:46] detectron2 INFO: Inference done 18437/26446. 0.1143 s / img. ETA=0:15:40
[06/30 21:45:52] detectron2 INFO: Inference done 18480/26446. 0.1143 s / img. ETA=0:15:35
[06/30 21:45:57] detectron2 INFO: Inference done 18523/26446. 0.1143 s / img. ETA=0:15:30
[06/30 21:46:02] detectron2 INFO: Inference done 18566/26446. 0.1143 s / img. ETA=0:15:25
[06/30 21:46:07] detectron2 INFO: Inference done 18609/26446. 0.1143 s / img. ETA=0:15:20
[06/30 21:46:12] detectron2 INFO: Inference done 18652/26446. 0.1143 s / img. ETA=0:15:15
[06/30 21:46:17] detectron2 INFO: Inference done 18695/26446. 0.1143 s / img. ETA=0:15:10
[06/30 21:46:22] detectron2 INFO: Inference done 18738/26446. 0.1143 s / img. ETA=0:15:05
[06/30 21:46:27] detectron2 INFO: Inference done 18781/26446. 0.1143 s / img. ETA=0:14:59
[06/30 21:46:32] detectron2 INFO: Inference done 18824/26446. 0.1143 s / img. ETA=0:14:54
[06/30 21:46:37] detectron2 INFO: Inference done 18867/26446. 0.1143 s / img. ETA=0:14:49
[06/30 21:46:42] detectron2 INFO: Inference done 18910/26446. 0.1143 s / img. ETA=0:14:44
[06/30 21:46:47] detectron2 INFO: Inference done 18951/26446. 0.1143 s / img. ETA=0:14:40
[06/30 21:46:52] detectron2 INFO: Inference done 18994/26446. 0.1143 s / img. ETA=0:14:35
[06/30 21:46:57] detectron2 INFO: Inference done 19037/26446. 0.1143 s / img. ETA=0:14:30
[06/30 21:47:02] detectron2 INFO: Inference done 19079/26446. 0.1143 s / img. ETA=0:14:25
[06/30 21:47:07] detectron2 INFO: Inference done 19121/26446. 0.1143 s / img. ETA=0:14:20
[06/30 21:47:12] detectron2 INFO: Inference done 19163/26446. 0.1143 s / img. ETA=0:14:15
[06/30 21:47:17] detectron2 INFO: Inference done 19206/26446. 0.1143 s / img. ETA=0:14:10
[06/30 21:47:22] detectron2 INFO: Inference done 19248/26446. 0.1143 s / img. ETA=0:14:05
[06/30 21:47:28] detectron2 INFO: Inference done 19291/26446. 0.1143 s / img. ETA=0:14:00
[06/30 21:47:33] detectron2 INFO: Inference done 19332/26446. 0.1143 s / img. ETA=0:13:55
[06/30 21:47:38] detectron2 INFO: Inference done 19374/26446. 0.1143 s / img. ETA=0:13:50
[06/30 21:47:43] detectron2 INFO: Inference done 19416/26446. 0.1143 s / img. ETA=0:13:45
[06/30 21:47:48] detectron2 INFO: Inference done 19459/26446. 0.1143 s / img. ETA=0:13:40
[06/30 21:47:53] detectron2 INFO: Inference done 19502/26446. 0.1143 s / img. ETA=0:13:35
[06/30 21:47:58] detectron2 INFO: Inference done 19545/26446. 0.1143 s / img. ETA=0:13:30
[06/30 21:48:03] detectron2 INFO: Inference done 19587/26446. 0.1143 s / img. ETA=0:13:25
[06/30 21:48:08] detectron2 INFO: Inference done 19630/26446. 0.1143 s / img. ETA=0:13:20
[06/30 21:48:13] detectron2 INFO: Inference done 19673/26446. 0.1143 s / img. ETA=0:13:15
[06/30 21:48:18] detectron2 INFO: Inference done 19715/26446. 0.1143 s / img. ETA=0:13:10
[06/30 21:48:23] detectron2 INFO: Inference done 19758/26446. 0.1143 s / img. ETA=0:13:05
[06/30 21:48:28] detectron2 INFO: Inference done 19801/26446. 0.1143 s / img. ETA=0:13:00
[06/30 21:48:33] detectron2 INFO: Inference done 19844/26446. 0.1143 s / img. ETA=0:12:55
[06/30 21:48:38] detectron2 INFO: Inference done 19886/26446. 0.1144 s / img. ETA=0:12:50
[06/30 21:48:43] detectron2 INFO: Inference done 19929/26446. 0.1144 s / img. ETA=0:12:45
[06/30 21:48:48] detectron2 INFO: Inference done 19972/26446. 0.1144 s / img. ETA=0:12:40
[06/30 21:48:53] detectron2 INFO: Inference done 20015/26446. 0.1144 s / img. ETA=0:12:35
[06/30 21:48:58] detectron2 INFO: Inference done 20058/26446. 0.1144 s / img. ETA=0:12:30
[06/30 21:49:03] detectron2 INFO: Inference done 20101/26446. 0.1144 s / img. ETA=0:12:25
[06/30 21:49:08] detectron2 INFO: Inference done 20143/26446. 0.1144 s / img. ETA=0:12:20
[06/30 21:49:14] detectron2 INFO: Inference done 20187/26446. 0.1144 s / img. ETA=0:12:15
[06/30 21:49:19] detectron2 INFO: Inference done 20230/26446. 0.1144 s / img. ETA=0:12:10
[06/30 21:49:24] detectron2 INFO: Inference done 20273/26446. 0.1144 s / img. ETA=0:12:05
[06/30 21:49:29] detectron2 INFO: Inference done 20316/26446. 0.1144 s / img. ETA=0:12:00
[06/30 21:49:34] detectron2 INFO: Inference done 20359/26446. 0.1144 s / img. ETA=0:11:55
[06/30 21:49:39] detectron2 INFO: Inference done 20402/26446. 0.1144 s / img. ETA=0:11:50
[06/30 21:49:44] detectron2 INFO: Inference done 20444/26446. 0.1144 s / img. ETA=0:11:45
[06/30 21:49:49] detectron2 INFO: Inference done 20487/26446. 0.1144 s / img. ETA=0:11:40
[06/30 21:49:54] detectron2 INFO: Inference done 20529/26446. 0.1144 s / img. ETA=0:11:35
[06/30 21:49:59] detectron2 INFO: Inference done 20571/26446. 0.1144 s / img. ETA=0:11:30
[06/30 21:50:04] detectron2 INFO: Inference done 20615/26446. 0.1144 s / img. ETA=0:11:25
[06/30 21:50:09] detectron2 INFO: Inference done 20658/26446. 0.1144 s / img. ETA=0:11:20
[06/30 21:50:14] detectron2 INFO: Inference done 20701/26446. 0.1144 s / img. ETA=0:11:15
[06/30 21:50:19] detectron2 INFO: Inference done 20743/26446. 0.1144 s / img. ETA=0:11:10
[06/30 21:50:24] detectron2 INFO: Inference done 20785/26446. 0.1144 s / img. ETA=0:11:05
[06/30 21:50:29] detectron2 INFO: Inference done 20828/26446. 0.1144 s / img. ETA=0:11:00
[06/30 21:50:34] detectron2 INFO: Inference done 20871/26446. 0.1144 s / img. ETA=0:10:55
[06/30 21:50:39] detectron2 INFO: Inference done 20914/26446. 0.1144 s / img. ETA=0:10:50
[06/30 21:50:44] detectron2 INFO: Inference done 20957/26446. 0.1144 s / img. ETA=0:10:45
[06/30 21:50:49] detectron2 INFO: Inference done 20999/26446. 0.1144 s / img. ETA=0:10:40
[06/30 21:50:55] detectron2 INFO: Inference done 21043/26446. 0.1144 s / img. ETA=0:10:34
[06/30 21:51:00] detectron2 INFO: Inference done 21086/26446. 0.1144 s / img. ETA=0:10:29
[06/30 21:51:05] detectron2 INFO: Inference done 21128/26446. 0.1144 s / img. ETA=0:10:24
[06/30 21:51:10] detectron2 INFO: Inference done 21171/26446. 0.1144 s / img. ETA=0:10:19
[06/30 21:51:15] detectron2 INFO: Inference done 21214/26446. 0.1144 s / img. ETA=0:10:14
[06/30 21:51:20] detectron2 INFO: Inference done 21256/26446. 0.1144 s / img. ETA=0:10:09
[06/30 21:51:25] detectron2 INFO: Inference done 21299/26446. 0.1144 s / img. ETA=0:10:04
[06/30 21:51:30] detectron2 INFO: Inference done 21342/26446. 0.1144 s / img. ETA=0:09:59
[06/30 21:51:35] detectron2 INFO: Inference done 21385/26446. 0.1144 s / img. ETA=0:09:54
[06/30 21:51:40] detectron2 INFO: Inference done 21427/26446. 0.1144 s / img. ETA=0:09:49
[06/30 21:51:45] detectron2 INFO: Inference done 21470/26446. 0.1144 s / img. ETA=0:09:44
[06/30 21:51:50] detectron2 INFO: Inference done 21511/26446. 0.1144 s / img. ETA=0:09:40
[06/30 21:51:55] detectron2 INFO: Inference done 21554/26446. 0.1144 s / img. ETA=0:09:35
[06/30 21:52:00] detectron2 INFO: Inference done 21597/26446. 0.1144 s / img. ETA=0:09:29
[06/30 21:52:05] detectron2 INFO: Inference done 21640/26446. 0.1144 s / img. ETA=0:09:24
[06/30 21:52:10] detectron2 INFO: Inference done 21682/26446. 0.1144 s / img. ETA=0:09:19
[06/30 21:52:15] detectron2 INFO: Inference done 21725/26446. 0.1144 s / img. ETA=0:09:14
[06/30 21:52:20] detectron2 INFO: Inference done 21767/26446. 0.1144 s / img. ETA=0:09:10
[06/30 21:52:26] detectron2 INFO: Inference done 21809/26446. 0.1144 s / img. ETA=0:09:05
[06/30 21:52:31] detectron2 INFO: Inference done 21852/26446. 0.1144 s / img. ETA=0:09:00
[06/30 21:52:36] detectron2 INFO: Inference done 21895/26446. 0.1144 s / img. ETA=0:08:55
[06/30 21:52:41] detectron2 INFO: Inference done 21938/26446. 0.1144 s / img. ETA=0:08:49
[06/30 21:52:46] detectron2 INFO: Inference done 21981/26446. 0.1144 s / img. ETA=0:08:44
[06/30 21:52:51] detectron2 INFO: Inference done 22024/26446. 0.1144 s / img. ETA=0:08:39
[06/30 21:52:56] detectron2 INFO: Inference done 22067/26446. 0.1144 s / img. ETA=0:08:34
[06/30 21:53:01] detectron2 INFO: Inference done 22110/26446. 0.1144 s / img. ETA=0:08:29
[06/30 21:53:06] detectron2 INFO: Inference done 22153/26446. 0.1144 s / img. ETA=0:08:24
[06/30 21:53:11] detectron2 INFO: Inference done 22196/26446. 0.1144 s / img. ETA=0:08:19
[06/30 21:53:16] detectron2 INFO: Inference done 22239/26446. 0.1144 s / img. ETA=0:08:14
[06/30 21:53:21] detectron2 INFO: Inference done 22282/26446. 0.1144 s / img. ETA=0:08:09
[06/30 21:53:26] detectron2 INFO: Inference done 22325/26446. 0.1144 s / img. ETA=0:08:04
[06/30 21:53:31] detectron2 INFO: Inference done 22368/26446. 0.1144 s / img. ETA=0:07:59
[06/30 21:53:36] detectron2 INFO: Inference done 22411/26446. 0.1144 s / img. ETA=0:07:54
[06/30 21:53:41] detectron2 INFO: Inference done 22453/26446. 0.1144 s / img. ETA=0:07:49
[06/30 21:53:46] detectron2 INFO: Inference done 22496/26446. 0.1144 s / img. ETA=0:07:44
[06/30 21:53:52] detectron2 INFO: Inference done 22539/26446. 0.1144 s / img. ETA=0:07:39
[06/30 21:53:57] detectron2 INFO: Inference done 22583/26446. 0.1144 s / img. ETA=0:07:34
[06/30 21:54:02] detectron2 INFO: Inference done 22626/26446. 0.1144 s / img. ETA=0:07:29
[06/30 21:54:07] detectron2 INFO: Inference done 22669/26446. 0.1144 s / img. ETA=0:07:24
[06/30 21:54:12] detectron2 INFO: Inference done 22712/26446. 0.1144 s / img. ETA=0:07:18
[06/30 21:54:17] detectron2 INFO: Inference done 22755/26446. 0.1144 s / img. ETA=0:07:13
[06/30 21:54:22] detectron2 INFO: Inference done 22798/26446. 0.1144 s / img. ETA=0:07:08
[06/30 21:54:27] detectron2 INFO: Inference done 22841/26446. 0.1144 s / img. ETA=0:07:03
[06/30 21:54:32] detectron2 INFO: Inference done 22884/26446. 0.1144 s / img. ETA=0:06:58
[06/30 21:54:37] detectron2 INFO: Inference done 22927/26446. 0.1144 s / img. ETA=0:06:53
[06/30 21:54:42] detectron2 INFO: Inference done 22969/26446. 0.1144 s / img. ETA=0:06:48
[06/30 21:54:47] detectron2 INFO: Inference done 23012/26446. 0.1144 s / img. ETA=0:06:43
[06/30 21:54:52] detectron2 INFO: Inference done 23055/26446. 0.1144 s / img. ETA=0:06:38
[06/30 21:54:57] detectron2 INFO: Inference done 23098/26446. 0.1144 s / img. ETA=0:06:33
[06/30 21:55:02] detectron2 INFO: Inference done 23141/26446. 0.1144 s / img. ETA=0:06:28
[06/30 21:55:07] detectron2 INFO: Inference done 23184/26446. 0.1144 s / img. ETA=0:06:23
[06/30 21:55:12] detectron2 INFO: Inference done 23226/26446. 0.1144 s / img. ETA=0:06:18
[06/30 21:55:17] detectron2 INFO: Inference done 23269/26446. 0.1144 s / img. ETA=0:06:13
[06/30 21:55:23] detectron2 INFO: Inference done 23312/26446. 0.1144 s / img. ETA=0:06:08
[06/30 21:55:28] detectron2 INFO: Inference done 23355/26446. 0.1144 s / img. ETA=0:06:03
[06/30 21:55:33] detectron2 INFO: Inference done 23398/26446. 0.1144 s / img. ETA=0:05:58
[06/30 21:55:38] detectron2 INFO: Inference done 23440/26446. 0.1144 s / img. ETA=0:05:53
[06/30 21:55:43] detectron2 INFO: Inference done 23483/26446. 0.1144 s / img. ETA=0:05:48
[06/30 21:55:48] detectron2 INFO: Inference done 23525/26446. 0.1145 s / img. ETA=0:05:43
[06/30 21:55:53] detectron2 INFO: Inference done 23568/26446. 0.1145 s / img. ETA=0:05:38
[06/30 21:55:58] detectron2 INFO: Inference done 23611/26446. 0.1145 s / img. ETA=0:05:33
[06/30 21:56:03] detectron2 INFO: Inference done 23654/26446. 0.1145 s / img. ETA=0:05:28
[06/30 21:56:08] detectron2 INFO: Inference done 23697/26446. 0.1145 s / img. ETA=0:05:23
[06/30 21:56:13] detectron2 INFO: Inference done 23740/26446. 0.1145 s / img. ETA=0:05:18
[06/30 21:56:18] detectron2 INFO: Inference done 23783/26446. 0.1145 s / img. ETA=0:05:13
[06/30 21:56:23] detectron2 INFO: Inference done 23826/26446. 0.1145 s / img. ETA=0:05:08
[06/30 21:56:28] detectron2 INFO: Inference done 23869/26446. 0.1145 s / img. ETA=0:05:03
[06/30 21:56:33] detectron2 INFO: Inference done 23912/26446. 0.1145 s / img. ETA=0:04:57
[06/30 21:56:39] detectron2 INFO: Inference done 23955/26446. 0.1145 s / img. ETA=0:04:52
[06/30 21:56:44] detectron2 INFO: Inference done 23998/26446. 0.1145 s / img. ETA=0:04:47
[06/30 21:56:49] detectron2 INFO: Inference done 24040/26446. 0.1145 s / img. ETA=0:04:42
[06/30 21:56:54] detectron2 INFO: Inference done 24082/26446. 0.1145 s / img. ETA=0:04:37
[06/30 21:56:59] detectron2 INFO: Inference done 24125/26446. 0.1145 s / img. ETA=0:04:32
[06/30 21:57:04] detectron2 INFO: Inference done 24168/26446. 0.1145 s / img. ETA=0:04:27
[06/30 21:57:09] detectron2 INFO: Inference done 24200/26446. 0.1145 s / img. ETA=0:04:24
[06/30 21:57:14] detectron2 INFO: Inference done 24242/26446. 0.1145 s / img. ETA=0:04:19
[06/30 21:57:19] detectron2 INFO: Inference done 24285/26446. 0.1145 s / img. ETA=0:04:14
[06/30 21:57:25] detectron2 INFO: Inference done 24328/26446. 0.1145 s / img. ETA=0:04:09
[06/30 21:57:30] detectron2 INFO: Inference done 24371/26446. 0.1145 s / img. ETA=0:04:04
[06/30 21:57:35] detectron2 INFO: Inference done 24414/26446. 0.1145 s / img. ETA=0:03:59
[06/30 21:57:40] detectron2 INFO: Inference done 24457/26446. 0.1145 s / img. ETA=0:03:54
[06/30 21:57:45] detectron2 INFO: Inference done 24500/26446. 0.1145 s / img. ETA=0:03:48
[06/30 21:57:50] detectron2 INFO: Inference done 24543/26446. 0.1145 s / img. ETA=0:03:43
[06/30 21:57:55] detectron2 INFO: Inference done 24586/26446. 0.1145 s / img. ETA=0:03:38
[06/30 21:58:00] detectron2 INFO: Inference done 24629/26446. 0.1145 s / img. ETA=0:03:33
[06/30 21:58:05] detectron2 INFO: Inference done 24672/26446. 0.1145 s / img. ETA=0:03:28
[06/30 21:58:10] detectron2 INFO: Inference done 24712/26446. 0.1145 s / img. ETA=0:03:24
[06/30 21:58:15] detectron2 INFO: Inference done 24755/26446. 0.1145 s / img. ETA=0:03:19
[06/30 21:58:20] detectron2 INFO: Inference done 24798/26446. 0.1145 s / img. ETA=0:03:13
[06/30 21:58:25] detectron2 INFO: Inference done 24841/26446. 0.1145 s / img. ETA=0:03:08
[06/30 21:58:30] detectron2 INFO: Inference done 24883/26446. 0.1145 s / img. ETA=0:03:03
[06/30 21:58:35] detectron2 INFO: Inference done 24926/26446. 0.1145 s / img. ETA=0:02:58
[06/30 21:58:40] detectron2 INFO: Inference done 24968/26446. 0.1145 s / img. ETA=0:02:53
[06/30 21:58:45] detectron2 INFO: Inference done 25010/26446. 0.1145 s / img. ETA=0:02:49
[06/30 21:58:50] detectron2 INFO: Inference done 25051/26446. 0.1145 s / img. ETA=0:02:44
[06/30 21:58:55] detectron2 INFO: Inference done 25093/26446. 0.1145 s / img. ETA=0:02:39
[06/30 21:59:00] detectron2 INFO: Inference done 25135/26446. 0.1145 s / img. ETA=0:02:34
[06/30 21:59:05] detectron2 INFO: Inference done 25177/26446. 0.1145 s / img. ETA=0:02:29
[06/30 21:59:10] detectron2 INFO: Inference done 25220/26446. 0.1145 s / img. ETA=0:02:24
[06/30 21:59:15] detectron2 INFO: Inference done 25263/26446. 0.1145 s / img. ETA=0:02:19
[06/30 21:59:20] detectron2 INFO: Inference done 25305/26446. 0.1145 s / img. ETA=0:02:14
[06/30 21:59:26] detectron2 INFO: Inference done 25348/26446. 0.1145 s / img. ETA=0:02:09
[06/30 21:59:31] detectron2 INFO: Inference done 25391/26446. 0.1145 s / img. ETA=0:02:04
[06/30 21:59:36] detectron2 INFO: Inference done 25433/26446. 0.1145 s / img. ETA=0:01:59
[06/30 21:59:41] detectron2 INFO: Inference done 25476/26446. 0.1145 s / img. ETA=0:01:54
[06/30 21:59:46] detectron2 INFO: Inference done 25518/26446. 0.1145 s / img. ETA=0:01:49
[06/30 21:59:51] detectron2 INFO: Inference done 25561/26446. 0.1145 s / img. ETA=0:01:44
[06/30 21:59:56] detectron2 INFO: Inference done 25604/26446. 0.1145 s / img. ETA=0:01:39
[06/30 22:00:01] detectron2 INFO: Inference done 25647/26446. 0.1145 s / img. ETA=0:01:34
[06/30 22:00:06] detectron2 INFO: Inference done 25689/26446. 0.1145 s / img. ETA=0:01:29
[06/30 22:00:11] detectron2 INFO: Inference done 25731/26446. 0.1145 s / img. ETA=0:01:24
[06/30 22:00:16] detectron2 INFO: Inference done 25773/26446. 0.1145 s / img. ETA=0:01:19
[06/30 22:00:21] detectron2 INFO: Inference done 25814/26446. 0.1145 s / img. ETA=0:01:14
[06/30 22:00:26] detectron2 INFO: Inference done 25856/26446. 0.1146 s / img. ETA=0:01:09
[06/30 22:00:31] detectron2 INFO: Inference done 25899/26446. 0.1146 s / img. ETA=0:01:04
[06/30 22:00:36] detectron2 INFO: Inference done 25942/26446. 0.1146 s / img. ETA=0:00:59
[06/30 22:00:41] detectron2 INFO: Inference done 25984/26446. 0.1146 s / img. ETA=0:00:54
[06/30 22:00:46] detectron2 INFO: Inference done 26026/26446. 0.1146 s / img. ETA=0:00:49
[06/30 22:00:52] detectron2 INFO: Inference done 26068/26446. 0.1146 s / img. ETA=0:00:44
[06/30 22:00:57] detectron2 INFO: Inference done 26111/26446. 0.1146 s / img. ETA=0:00:39
[06/30 22:01:02] detectron2 INFO: Inference done 26154/26446. 0.1146 s / img. ETA=0:00:34
[06/30 22:01:07] detectron2 INFO: Inference done 26197/26446. 0.1146 s / img. ETA=0:00:29
[06/30 22:01:12] detectron2 INFO: Inference done 26239/26446. 0.1146 s / img. ETA=0:00:24
[06/30 22:01:17] detectron2 INFO: Inference done 26282/26446. 0.1146 s / img. ETA=0:00:19
[06/30 22:01:22] detectron2 INFO: Inference done 26325/26446. 0.1146 s / img. ETA=0:00:14
[06/30 22:01:27] detectron2 INFO: Inference done 26366/26446. 0.1146 s / img. ETA=0:00:09
[06/30 22:01:32] detectron2 INFO: Inference done 26409/26446. 0.1146 s / img. ETA=0:00:04
[06/30 22:01:38] detectron2 INFO: Total inference time: 0:51:55.306652 (0.117821 s / img per device, on 1 devices)
[06/30 22:01:38] detectron2 INFO: Total inference pure compute time: 0:50:29 (0.114591 s / img per device, on 1 devices)
[06/30 22:01:46] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 22:01:46] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 22:01:53] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 22:01:58] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[06/30 22:08:07] detectron2 INFO: Rank of current process: 0. World size: 1
[06/30 22:08:09] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
Compiler                         MSVC 193933523
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.17.2 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------
PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.8.1  (built against CUDA 12.0)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.8.1, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/30 22:08:09] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '20', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[06/30 22:08:09] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 40
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[06/30 22:08:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 20
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[06/30 22:08:09] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[06/30 22:08:09] d2.utils.env INFO: Using a generated random seed 9892032
[06/30 22:08:12] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0-5): 6 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0-5): 6 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0-5): 6 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0-5): 6 x Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0-4): 5 x MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0-4): 5 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0-4): 5 x Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[06/30 22:08:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 22:08:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[06/30 22:08:13] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[06/30 22:08:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/30 22:08:13] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[06/30 22:08:15] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[06/30 22:08:15] detectron2 INFO: Following metrics will be use for evaluation
[06/30 22:08:15] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[06/30 22:08:15] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[06/30 22:08:15] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[06/30 22:08:15] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[06/30 22:08:17] detectron2 INFO: Loading zero shot triplets
[06/30 22:08:17] detectron2 INFO: Start inference on 26446 images
[06/30 22:08:29] detectron2 INFO: Inference done 1/26446. 6.6810 s / img. ETA=3 days, 16:58:49
[06/30 22:08:34] detectron2 INFO: Inference done 34/26446. 0.1433 s / img. ETA=1:04:18
[06/30 22:08:39] detectron2 INFO: Inference done 69/26446. 0.1424 s / img. ETA=1:03:49
[06/30 22:08:44] detectron2 INFO: Inference done 107/26446. 0.1379 s / img. ETA=1:01:44
[06/30 22:08:49] detectron2 INFO: Inference done 147/26446. 0.1340 s / img. ETA=0:59:58
[06/30 22:08:54] detectron2 INFO: Inference done 188/26446. 0.1311 s / img. ETA=0:58:36
[06/30 22:08:59] detectron2 INFO: Inference done 230/26446. 0.1284 s / img. ETA=0:57:19
[06/30 22:09:04] detectron2 INFO: Inference done 270/26446. 0.1280 s / img. ETA=0:57:05
[06/30 22:09:10] detectron2 INFO: Inference done 310/26446. 0.1276 s / img. ETA=0:56:48
[06/30 22:09:15] detectron2 INFO: Inference done 353/26446. 0.1259 s / img. ETA=0:56:01
[06/30 22:09:20] detectron2 INFO: Inference done 393/26446. 0.1256 s / img. ETA=0:55:48
[06/30 22:09:25] detectron2 INFO: Inference done 434/26446. 0.1251 s / img. ETA=0:55:29
[06/30 22:09:30] detectron2 INFO: Inference done 474/26446. 0.1249 s / img. ETA=0:55:19
[06/30 22:09:35] detectron2 INFO: Inference done 517/26446. 0.1241 s / img. ETA=0:54:52
[06/30 22:09:40] detectron2 INFO: Inference done 558/26446. 0.1238 s / img. ETA=0:54:40
[06/30 22:09:45] detectron2 INFO: Inference done 601/26446. 0.1233 s / img. ETA=0:54:19
[06/30 22:09:50] detectron2 INFO: Inference done 642/26446. 0.1230 s / img. ETA=0:54:09
[06/30 22:09:55] detectron2 INFO: Inference done 684/26446. 0.1226 s / img. ETA=0:53:53
[06/30 22:10:00] detectron2 INFO: Inference done 727/26446. 0.1222 s / img. ETA=0:53:36
[06/30 22:10:05] detectron2 INFO: Inference done 771/26446. 0.1216 s / img. ETA=0:53:15
[06/30 22:10:10] detectron2 INFO: Inference done 814/26446. 0.1213 s / img. ETA=0:53:02
[06/30 22:10:15] detectron2 INFO: Inference done 858/26446. 0.1207 s / img. ETA=0:52:43
[06/30 22:10:20] detectron2 INFO: Inference done 900/26446. 0.1206 s / img. ETA=0:52:34
[06/30 22:10:25] detectron2 INFO: Inference done 945/26446. 0.1201 s / img. ETA=0:52:16
[06/30 22:10:30] detectron2 INFO: Inference done 988/26446. 0.1199 s / img. ETA=0:52:04
[06/30 22:10:36] detectron2 INFO: Inference done 1031/26446. 0.1197 s / img. ETA=0:51:54
[06/30 22:10:41] detectron2 INFO: Inference done 1075/26446. 0.1193 s / img. ETA=0:51:40
[06/30 22:10:46] detectron2 INFO: Inference done 1120/26446. 0.1190 s / img. ETA=0:51:26
[06/30 22:10:51] detectron2 INFO: Inference done 1164/26446. 0.1187 s / img. ETA=0:51:14
[06/30 22:10:56] detectron2 INFO: Inference done 1207/26446. 0.1186 s / img. ETA=0:51:05
[06/30 22:11:01] detectron2 INFO: Inference done 1250/26446. 0.1184 s / img. ETA=0:50:56
[06/30 22:11:06] detectron2 INFO: Inference done 1293/26446. 0.1183 s / img. ETA=0:50:49
[06/30 22:11:11] detectron2 INFO: Inference done 1337/26446. 0.1181 s / img. ETA=0:50:39
[06/30 22:11:16] detectron2 INFO: Inference done 1382/26446. 0.1179 s / img. ETA=0:50:26
[06/30 22:11:21] detectron2 INFO: Inference done 1424/26446. 0.1179 s / img. ETA=0:50:21
[06/30 22:11:26] detectron2 INFO: Inference done 1466/26446. 0.1179 s / img. ETA=0:50:16
[06/30 22:11:31] detectron2 INFO: Inference done 1509/26446. 0.1178 s / img. ETA=0:50:09
[06/30 22:11:36] detectron2 INFO: Inference done 1553/26446. 0.1177 s / img. ETA=0:50:00
[06/30 22:11:41] detectron2 INFO: Inference done 1595/26446. 0.1176 s / img. ETA=0:49:54
[06/30 22:11:46] detectron2 INFO: Inference done 1639/26446. 0.1175 s / img. ETA=0:49:46
[06/30 22:11:52] detectron2 INFO: Inference done 1678/26446. 0.1177 s / img. ETA=0:49:47
[06/30 22:11:57] detectron2 INFO: Inference done 1720/26446. 0.1177 s / img. ETA=0:49:41
[06/30 22:12:02] detectron2 INFO: Inference done 1762/26446. 0.1177 s / img. ETA=0:49:36
[06/30 22:12:07] detectron2 INFO: Inference done 1798/26446. 0.1175 s / img. ETA=0:49:42
[06/30 22:12:12] detectron2 INFO: Inference done 1843/26446. 0.1173 s / img. ETA=0:49:32
[06/30 22:12:17] detectron2 INFO: Inference done 1887/26446. 0.1172 s / img. ETA=0:49:22
[06/30 22:12:22] detectron2 INFO: Inference done 1931/26446. 0.1170 s / img. ETA=0:49:14
[06/30 22:12:27] detectron2 INFO: Inference done 1974/26446. 0.1170 s / img. ETA=0:49:07
[06/30 22:12:32] detectron2 INFO: Inference done 2018/26446. 0.1169 s / img. ETA=0:49:00
[06/30 22:12:37] detectron2 INFO: Inference done 2062/26446. 0.1168 s / img. ETA=0:48:51
[06/30 22:12:42] detectron2 INFO: Inference done 2106/26446. 0.1167 s / img. ETA=0:48:43
[06/30 22:12:47] detectron2 INFO: Inference done 2149/26446. 0.1167 s / img. ETA=0:48:37
[06/30 22:12:52] detectron2 INFO: Inference done 2190/26446. 0.1167 s / img. ETA=0:48:33
[06/30 22:12:57] detectron2 INFO: Inference done 2234/26446. 0.1166 s / img. ETA=0:48:26
[06/30 22:13:02] detectron2 INFO: Inference done 2277/26446. 0.1166 s / img. ETA=0:48:20
[06/30 22:13:08] detectron2 INFO: Inference done 2322/26446. 0.1165 s / img. ETA=0:48:12
[06/30 22:13:13] detectron2 INFO: Inference done 2366/26446. 0.1164 s / img. ETA=0:48:04
[06/30 22:13:18] detectron2 INFO: Inference done 2409/26446. 0.1164 s / img. ETA=0:47:59
[06/30 22:13:23] detectron2 INFO: Inference done 2453/26446. 0.1163 s / img. ETA=0:47:51
[06/30 22:13:28] detectron2 INFO: Inference done 2498/26446. 0.1162 s / img. ETA=0:47:43
[06/30 22:13:33] detectron2 INFO: Inference done 2543/26446. 0.1161 s / img. ETA=0:47:34
[06/30 22:13:38] detectron2 INFO: Inference done 2587/26446. 0.1160 s / img. ETA=0:47:28
[06/30 22:13:43] detectron2 INFO: Inference done 2629/26446. 0.1161 s / img. ETA=0:47:23
[06/30 22:13:48] detectron2 INFO: Inference done 2671/26446. 0.1161 s / img. ETA=0:47:18
[06/30 22:13:53] detectron2 INFO: Inference done 2712/26446. 0.1161 s / img. ETA=0:47:15
[06/30 22:13:58] detectron2 INFO: Inference done 2757/26446. 0.1160 s / img. ETA=0:47:06
[06/30 22:14:03] detectron2 INFO: Inference done 2801/26446. 0.1160 s / img. ETA=0:47:00
[06/30 22:14:08] detectron2 INFO: Inference done 2845/26446. 0.1159 s / img. ETA=0:46:53
[06/30 22:14:13] detectron2 INFO: Inference done 2889/26446. 0.1158 s / img. ETA=0:46:46
[06/30 22:14:18] detectron2 INFO: Inference done 2933/26446. 0.1158 s / img. ETA=0:46:39
[06/30 22:14:23] detectron2 INFO: Inference done 2976/26446. 0.1158 s / img. ETA=0:46:33
[06/30 22:14:29] detectron2 INFO: Inference done 3021/26446. 0.1157 s / img. ETA=0:46:26
[06/30 22:14:34] detectron2 INFO: Inference done 3064/26446. 0.1157 s / img. ETA=0:46:21
[06/30 22:14:39] detectron2 INFO: Inference done 3108/26446. 0.1156 s / img. ETA=0:46:14
[06/30 22:14:44] detectron2 INFO: Inference done 3152/26446. 0.1156 s / img. ETA=0:46:08
[06/30 22:14:49] detectron2 INFO: Inference done 3196/26446. 0.1155 s / img. ETA=0:46:01
[06/30 22:14:54] detectron2 INFO: Inference done 3240/26446. 0.1155 s / img. ETA=0:45:55
[06/30 22:14:59] detectron2 INFO: Inference done 3284/26446. 0.1154 s / img. ETA=0:45:49
[06/30 22:15:04] detectron2 INFO: Inference done 3329/26446. 0.1154 s / img. ETA=0:45:42
[06/30 22:15:09] detectron2 INFO: Inference done 3374/26446. 0.1153 s / img. ETA=0:45:35
[06/30 22:15:14] detectron2 INFO: Inference done 3418/26446. 0.1153 s / img. ETA=0:45:29
[06/30 22:15:19] detectron2 INFO: Inference done 3462/26446. 0.1152 s / img. ETA=0:45:22
[06/30 22:15:24] detectron2 INFO: Inference done 3507/26446. 0.1152 s / img. ETA=0:45:16
[06/30 22:15:30] detectron2 INFO: Inference done 3551/26446. 0.1151 s / img. ETA=0:45:09
[06/30 22:15:35] detectron2 INFO: Inference done 3594/26446. 0.1151 s / img. ETA=0:45:04
[06/30 22:15:40] detectron2 INFO: Inference done 3638/26446. 0.1151 s / img. ETA=0:44:58
[06/30 22:15:45] detectron2 INFO: Inference done 3678/26446. 0.1152 s / img. ETA=0:44:55
[06/30 22:15:50] detectron2 INFO: Inference done 3720/26446. 0.1152 s / img. ETA=0:44:51
[06/30 22:15:55] detectron2 INFO: Inference done 3764/26446. 0.1152 s / img. ETA=0:44:45
[06/30 22:16:00] detectron2 INFO: Inference done 3805/26446. 0.1152 s / img. ETA=0:44:41
[06/30 22:16:05] detectron2 INFO: Inference done 3845/26446. 0.1153 s / img. ETA=0:44:38
[06/30 22:16:10] detectron2 INFO: Inference done 3889/26446. 0.1153 s / img. ETA=0:44:32
[06/30 22:16:15] detectron2 INFO: Inference done 3933/26446. 0.1153 s / img. ETA=0:44:26
[06/30 22:16:20] detectron2 INFO: Inference done 3978/26446. 0.1152 s / img. ETA=0:44:20
[06/30 22:16:25] detectron2 INFO: Inference done 4022/26446. 0.1152 s / img. ETA=0:44:14
[06/30 22:16:30] detectron2 INFO: Inference done 4067/26446. 0.1151 s / img. ETA=0:44:07
[06/30 22:16:35] detectron2 INFO: Inference done 4111/26446. 0.1151 s / img. ETA=0:44:01
[06/30 22:16:41] detectron2 INFO: Inference done 4154/26446. 0.1151 s / img. ETA=0:43:56
[06/30 22:16:46] detectron2 INFO: Inference done 4197/26446. 0.1151 s / img. ETA=0:43:51
[06/30 22:16:51] detectron2 INFO: Inference done 4241/26446. 0.1151 s / img. ETA=0:43:45
[06/30 22:16:56] detectron2 INFO: Inference done 4282/26446. 0.1151 s / img. ETA=0:43:42
[06/30 22:17:01] detectron2 INFO: Inference done 4325/26446. 0.1151 s / img. ETA=0:43:36
[06/30 22:17:06] detectron2 INFO: Inference done 4367/26446. 0.1151 s / img. ETA=0:43:32
[06/30 22:17:11] detectron2 INFO: Inference done 4411/26446. 0.1151 s / img. ETA=0:43:26
[06/30 22:17:16] detectron2 INFO: Inference done 4454/26446. 0.1151 s / img. ETA=0:43:20
[06/30 22:17:21] detectron2 INFO: Inference done 4497/26446. 0.1151 s / img. ETA=0:43:15
[06/30 22:17:26] detectron2 INFO: Inference done 4541/26446. 0.1150 s / img. ETA=0:43:09
[06/30 22:17:31] detectron2 INFO: Inference done 4584/26446. 0.1150 s / img. ETA=0:43:04
[06/30 22:17:36] detectron2 INFO: Inference done 4627/26446. 0.1150 s / img. ETA=0:42:58
[06/30 22:17:41] detectron2 INFO: Inference done 4670/26446. 0.1150 s / img. ETA=0:42:53
[06/30 22:17:46] detectron2 INFO: Inference done 4715/26446. 0.1150 s / img. ETA=0:42:47
[06/30 22:17:51] detectron2 INFO: Inference done 4759/26446. 0.1150 s / img. ETA=0:42:41
[06/30 22:17:56] detectron2 INFO: Inference done 4803/26446. 0.1149 s / img. ETA=0:42:35
[06/30 22:18:01] detectron2 INFO: Inference done 4845/26446. 0.1149 s / img. ETA=0:42:30
[06/30 22:18:06] detectron2 INFO: Inference done 4889/26446. 0.1149 s / img. ETA=0:42:24
[06/30 22:18:11] detectron2 INFO: Inference done 4932/26446. 0.1149 s / img. ETA=0:42:19
[06/30 22:18:16] detectron2 INFO: Inference done 4975/26446. 0.1149 s / img. ETA=0:42:14
[06/30 22:18:21] detectron2 INFO: Inference done 5019/26446. 0.1148 s / img. ETA=0:42:08
[06/30 22:18:26] detectron2 INFO: Inference done 5063/26446. 0.1148 s / img. ETA=0:42:02
[06/30 22:18:32] detectron2 INFO: Inference done 5107/26446. 0.1148 s / img. ETA=0:41:56
[06/30 22:18:37] detectron2 INFO: Inference done 5151/26446. 0.1148 s / img. ETA=0:41:50
[06/30 22:18:42] detectron2 INFO: Inference done 5195/26446. 0.1147 s / img. ETA=0:41:45
[06/30 22:18:47] detectron2 INFO: Inference done 5238/26446. 0.1147 s / img. ETA=0:41:39
[06/30 22:18:52] detectron2 INFO: Inference done 5282/26446. 0.1147 s / img. ETA=0:41:34
[06/30 22:18:57] detectron2 INFO: Inference done 5322/26446. 0.1148 s / img. ETA=0:41:30
[06/30 22:19:02] detectron2 INFO: Inference done 5367/26446. 0.1147 s / img. ETA=0:41:24
[06/30 22:19:07] detectron2 INFO: Inference done 5412/26446. 0.1147 s / img. ETA=0:41:18
[06/30 22:19:12] detectron2 INFO: Inference done 5456/26446. 0.1147 s / img. ETA=0:41:12
[06/30 22:19:17] detectron2 INFO: Inference done 5500/26446. 0.1146 s / img. ETA=0:41:06
[06/30 22:19:22] detectron2 INFO: Inference done 5544/26446. 0.1146 s / img. ETA=0:41:01
[06/30 22:19:27] detectron2 INFO: Inference done 5588/26446. 0.1146 s / img. ETA=0:40:55
[06/30 22:19:32] detectron2 INFO: Inference done 5633/26446. 0.1145 s / img. ETA=0:40:49
[06/30 22:19:37] detectron2 INFO: Inference done 5678/26446. 0.1145 s / img. ETA=0:40:43
[06/30 22:19:42] detectron2 INFO: Inference done 5722/26446. 0.1145 s / img. ETA=0:40:37
[06/30 22:19:47] detectron2 INFO: Inference done 5766/26446. 0.1145 s / img. ETA=0:40:31
[06/30 22:19:52] detectron2 INFO: Inference done 5810/26446. 0.1144 s / img. ETA=0:40:25
[06/30 22:19:57] detectron2 INFO: Inference done 5853/26446. 0.1144 s / img. ETA=0:40:20
[06/30 22:20:02] detectron2 INFO: Inference done 5898/26446. 0.1144 s / img. ETA=0:40:15
[06/30 22:20:07] detectron2 INFO: Inference done 5942/26446. 0.1144 s / img. ETA=0:40:09
[06/30 22:20:12] detectron2 INFO: Inference done 5986/26446. 0.1144 s / img. ETA=0:40:03
[06/30 22:20:17] detectron2 INFO: Inference done 6031/26446. 0.1143 s / img. ETA=0:39:57
[06/30 22:20:23] detectron2 INFO: Inference done 6074/26446. 0.1143 s / img. ETA=0:39:52
[06/30 22:20:28] detectron2 INFO: Inference done 6119/26446. 0.1143 s / img. ETA=0:39:46
[06/30 22:20:33] detectron2 INFO: Inference done 6164/26446. 0.1143 s / img. ETA=0:39:40
[06/30 22:20:38] detectron2 INFO: Inference done 6206/26446. 0.1143 s / img. ETA=0:39:36
[06/30 22:20:43] detectron2 INFO: Inference done 6249/26446. 0.1143 s / img. ETA=0:39:31
[06/30 22:20:48] detectron2 INFO: Inference done 6292/26446. 0.1143 s / img. ETA=0:39:26
[06/30 22:20:53] detectron2 INFO: Inference done 6335/26446. 0.1143 s / img. ETA=0:39:20
[06/30 22:20:58] detectron2 INFO: Inference done 6379/26446. 0.1143 s / img. ETA=0:39:15
[06/30 22:21:03] detectron2 INFO: Inference done 6423/26446. 0.1143 s / img. ETA=0:39:10
[06/30 22:21:08] detectron2 INFO: Inference done 6467/26446. 0.1142 s / img. ETA=0:39:04
[06/30 22:21:13] detectron2 INFO: Inference done 6512/26446. 0.1142 s / img. ETA=0:38:58
[06/30 22:21:18] detectron2 INFO: Inference done 6556/26446. 0.1142 s / img. ETA=0:38:53
[06/30 22:21:23] detectron2 INFO: Inference done 6599/26446. 0.1142 s / img. ETA=0:38:48
[06/30 22:21:28] detectron2 INFO: Inference done 6643/26446. 0.1142 s / img. ETA=0:38:42
[06/30 22:21:33] detectron2 INFO: Inference done 6687/26446. 0.1142 s / img. ETA=0:38:37
[06/30 22:21:38] detectron2 INFO: Inference done 6731/26446. 0.1142 s / img. ETA=0:38:31
[06/30 22:21:44] detectron2 INFO: Inference done 6775/26446. 0.1141 s / img. ETA=0:38:26
[06/30 22:21:49] detectron2 INFO: Inference done 6819/26446. 0.1141 s / img. ETA=0:38:20
[06/30 22:21:54] detectron2 INFO: Inference done 6862/26446. 0.1141 s / img. ETA=0:38:15
[06/30 22:21:59] detectron2 INFO: Inference done 6906/26446. 0.1141 s / img. ETA=0:38:10
[06/30 22:22:04] detectron2 INFO: Inference done 6949/26446. 0.1141 s / img. ETA=0:38:05
[06/30 22:22:09] detectron2 INFO: Inference done 6992/26446. 0.1141 s / img. ETA=0:38:00
[06/30 22:22:14] detectron2 INFO: Inference done 7037/26446. 0.1141 s / img. ETA=0:37:54
[06/30 22:22:19] detectron2 INFO: Inference done 7081/26446. 0.1141 s / img. ETA=0:37:48
[06/30 22:22:24] detectron2 INFO: Inference done 7125/26446. 0.1141 s / img. ETA=0:37:43
[06/30 22:22:29] detectron2 INFO: Inference done 7170/26446. 0.1140 s / img. ETA=0:37:37
[06/30 22:22:34] detectron2 INFO: Inference done 7214/26446. 0.1140 s / img. ETA=0:37:32
[06/30 22:22:39] detectron2 INFO: Inference done 7258/26446. 0.1140 s / img. ETA=0:37:26
[06/30 22:22:44] detectron2 INFO: Inference done 7302/26446. 0.1140 s / img. ETA=0:37:21
[06/30 22:22:49] detectron2 INFO: Inference done 7346/26446. 0.1140 s / img. ETA=0:37:16
[06/30 22:22:54] detectron2 INFO: Inference done 7390/26446. 0.1140 s / img. ETA=0:37:10
[06/30 22:22:59] detectron2 INFO: Inference done 7435/26446. 0.1140 s / img. ETA=0:37:05
[06/30 22:23:05] detectron2 INFO: Inference done 7480/26446. 0.1139 s / img. ETA=0:36:59
[06/30 22:23:10] detectron2 INFO: Inference done 7525/26446. 0.1139 s / img. ETA=0:36:53
[06/30 22:23:15] detectron2 INFO: Inference done 7569/26446. 0.1139 s / img. ETA=0:36:48
[06/30 22:23:20] detectron2 INFO: Inference done 7613/26446. 0.1139 s / img. ETA=0:36:42
[06/30 22:23:25] detectron2 INFO: Inference done 7657/26446. 0.1139 s / img. ETA=0:36:37
[06/30 22:23:30] detectron2 INFO: Inference done 7701/26446. 0.1139 s / img. ETA=0:36:32
[06/30 22:23:35] detectron2 INFO: Inference done 7734/26446. 0.1140 s / img. ETA=0:36:30
[06/30 22:23:40] detectron2 INFO: Inference done 7778/26446. 0.1140 s / img. ETA=0:36:25
[06/30 22:23:45] detectron2 INFO: Inference done 7822/26446. 0.1140 s / img. ETA=0:36:20
[06/30 22:23:50] detectron2 INFO: Inference done 7866/26446. 0.1140 s / img. ETA=0:36:15
[06/30 22:23:55] detectron2 INFO: Inference done 7910/26446. 0.1140 s / img. ETA=0:36:09
[06/30 22:24:00] detectron2 INFO: Inference done 7955/26446. 0.1140 s / img. ETA=0:36:03
[06/30 22:24:05] detectron2 INFO: Inference done 7999/26446. 0.1139 s / img. ETA=0:35:58
[06/30 22:24:10] detectron2 INFO: Inference done 8043/26446. 0.1139 s / img. ETA=0:35:53
[06/30 22:24:15] detectron2 INFO: Inference done 8085/26446. 0.1139 s / img. ETA=0:35:48
[06/30 22:24:20] detectron2 INFO: Inference done 8126/26446. 0.1140 s / img. ETA=0:35:44
[06/30 22:24:25] detectron2 INFO: Inference done 8171/26446. 0.1140 s / img. ETA=0:35:38
[06/30 22:24:30] detectron2 INFO: Inference done 8215/26446. 0.1139 s / img. ETA=0:35:33
[06/30 22:24:36] detectron2 INFO: Inference done 8259/26446. 0.1139 s / img. ETA=0:35:28
[06/30 22:24:41] detectron2 INFO: Inference done 8302/26446. 0.1139 s / img. ETA=0:35:22
[06/30 22:24:46] detectron2 INFO: Inference done 8347/26446. 0.1139 s / img. ETA=0:35:17
[06/30 22:24:51] detectron2 INFO: Inference done 8391/26446. 0.1139 s / img. ETA=0:35:11
[06/30 22:24:56] detectron2 INFO: Inference done 8434/26446. 0.1139 s / img. ETA=0:35:06
[06/30 22:25:01] detectron2 INFO: Inference done 8478/26446. 0.1139 s / img. ETA=0:35:01
[06/30 22:25:06] detectron2 INFO: Inference done 8522/26446. 0.1139 s / img. ETA=0:34:56
[06/30 22:25:11] detectron2 INFO: Inference done 8567/26446. 0.1139 s / img. ETA=0:34:50
[06/30 22:25:16] detectron2 INFO: Inference done 8611/26446. 0.1138 s / img. ETA=0:34:45
[06/30 22:25:21] detectron2 INFO: Inference done 8655/26446. 0.1138 s / img. ETA=0:34:39
[06/30 22:25:26] detectron2 INFO: Inference done 8699/26446. 0.1138 s / img. ETA=0:34:34
[06/30 22:25:31] detectron2 INFO: Inference done 8743/26446. 0.1138 s / img. ETA=0:34:29
[06/30 22:25:36] detectron2 INFO: Inference done 8788/26446. 0.1138 s / img. ETA=0:34:23
[06/30 22:25:41] detectron2 INFO: Inference done 8833/26446. 0.1138 s / img. ETA=0:34:17
[06/30 22:25:46] detectron2 INFO: Inference done 8877/26446. 0.1138 s / img. ETA=0:34:12
[06/30 22:25:51] detectron2 INFO: Inference done 8921/26446. 0.1138 s / img. ETA=0:34:07
[06/30 22:25:56] detectron2 INFO: Inference done 8966/26446. 0.1137 s / img. ETA=0:34:01
[06/30 22:26:02] detectron2 INFO: Inference done 9010/26446. 0.1137 s / img. ETA=0:33:56
[06/30 22:26:07] detectron2 INFO: Inference done 9055/26446. 0.1137 s / img. ETA=0:33:50
[06/30 22:26:12] detectron2 INFO: Inference done 9100/26446. 0.1137 s / img. ETA=0:33:45
[06/30 22:26:17] detectron2 INFO: Inference done 9145/26446. 0.1137 s / img. ETA=0:33:39
[06/30 22:26:22] detectron2 INFO: Inference done 9190/26446. 0.1137 s / img. ETA=0:33:34
[06/30 22:26:27] detectron2 INFO: Inference done 9233/26446. 0.1137 s / img. ETA=0:33:29
[06/30 22:26:32] detectron2 INFO: Inference done 9277/26446. 0.1137 s / img. ETA=0:33:23
[06/30 22:26:37] detectron2 INFO: Inference done 9321/26446. 0.1136 s / img. ETA=0:33:18
[06/30 22:26:42] detectron2 INFO: Inference done 9366/26446. 0.1136 s / img. ETA=0:33:12
[06/30 22:26:47] detectron2 INFO: Inference done 9410/26446. 0.1136 s / img. ETA=0:33:07
[06/30 22:26:52] detectron2 INFO: Inference done 9454/26446. 0.1136 s / img. ETA=0:33:02
[06/30 22:26:57] detectron2 INFO: Inference done 9497/26446. 0.1136 s / img. ETA=0:32:57
[06/30 22:27:02] detectron2 INFO: Inference done 9538/26446. 0.1136 s / img. ETA=0:32:52
[06/30 22:27:07] detectron2 INFO: Inference done 9580/26446. 0.1136 s / img. ETA=0:32:48
[06/30 22:27:12] detectron2 INFO: Inference done 9622/26446. 0.1137 s / img. ETA=0:32:43
[06/30 22:27:17] detectron2 INFO: Inference done 9664/26446. 0.1137 s / img. ETA=0:32:38
[06/30 22:27:22] detectron2 INFO: Inference done 9706/26446. 0.1137 s / img. ETA=0:32:34
[06/30 22:27:27] detectron2 INFO: Inference done 9748/26446. 0.1137 s / img. ETA=0:32:29
[06/30 22:27:32] detectron2 INFO: Inference done 9790/26446. 0.1137 s / img. ETA=0:32:25
[06/30 22:27:38] detectron2 INFO: Inference done 9831/26446. 0.1138 s / img. ETA=0:32:20
[06/30 22:27:43] detectron2 INFO: Inference done 9872/26446. 0.1138 s / img. ETA=0:32:16
[06/30 22:27:48] detectron2 INFO: Inference done 9915/26446. 0.1138 s / img. ETA=0:32:11
[06/30 22:27:53] detectron2 INFO: Inference done 9957/26446. 0.1138 s / img. ETA=0:32:06
[06/30 22:27:58] detectron2 INFO: Inference done 9999/26446. 0.1138 s / img. ETA=0:32:02
[06/30 22:28:03] detectron2 INFO: Inference done 10043/26446. 0.1138 s / img. ETA=0:31:57
[06/30 22:28:08] detectron2 INFO: Inference done 10087/26446. 0.1138 s / img. ETA=0:31:51
[06/30 22:28:13] detectron2 INFO: Inference done 10130/26446. 0.1138 s / img. ETA=0:31:46
[06/30 22:28:18] detectron2 INFO: Inference done 10175/26446. 0.1138 s / img. ETA=0:31:41
[06/30 22:28:23] detectron2 INFO: Inference done 10218/26446. 0.1138 s / img. ETA=0:31:36
[06/30 22:28:28] detectron2 INFO: Inference done 10262/26446. 0.1138 s / img. ETA=0:31:30
[06/30 22:28:33] detectron2 INFO: Inference done 10306/26446. 0.1138 s / img. ETA=0:31:25
[06/30 22:28:38] detectron2 INFO: Inference done 10351/26446. 0.1138 s / img. ETA=0:31:20
[06/30 22:28:43] detectron2 INFO: Inference done 10395/26446. 0.1138 s / img. ETA=0:31:14
[06/30 22:28:49] detectron2 INFO: Inference done 10438/26446. 0.1138 s / img. ETA=0:31:09
[06/30 22:28:54] detectron2 INFO: Inference done 10481/26446. 0.1138 s / img. ETA=0:31:05
[06/30 22:28:59] detectron2 INFO: Inference done 10524/26446. 0.1138 s / img. ETA=0:30:59
[06/30 22:29:04] detectron2 INFO: Inference done 10568/26446. 0.1138 s / img. ETA=0:30:54
[06/30 22:29:09] detectron2 INFO: Inference done 10613/26446. 0.1137 s / img. ETA=0:30:49
[06/30 22:29:14] detectron2 INFO: Inference done 10657/26446. 0.1137 s / img. ETA=0:30:43
[06/30 22:29:19] detectron2 INFO: Inference done 10702/26446. 0.1137 s / img. ETA=0:30:38
[06/30 22:29:24] detectron2 INFO: Inference done 10745/26446. 0.1137 s / img. ETA=0:30:33
[06/30 22:29:29] detectron2 INFO: Inference done 10790/26446. 0.1137 s / img. ETA=0:30:27
[06/30 22:29:34] detectron2 INFO: Inference done 10835/26446. 0.1137 s / img. ETA=0:30:22
[06/30 22:29:39] detectron2 INFO: Inference done 10880/26446. 0.1137 s / img. ETA=0:30:16
[06/30 22:29:44] detectron2 INFO: Inference done 10923/26446. 0.1137 s / img. ETA=0:30:11
[06/30 22:29:49] detectron2 INFO: Inference done 10967/26446. 0.1137 s / img. ETA=0:30:06
[06/30 22:29:54] detectron2 INFO: Inference done 11011/26446. 0.1137 s / img. ETA=0:30:01
[06/30 22:29:59] detectron2 INFO: Inference done 11055/26446. 0.1136 s / img. ETA=0:29:55
[06/30 22:30:04] detectron2 INFO: Inference done 11099/26446. 0.1136 s / img. ETA=0:29:50
[06/30 22:30:09] detectron2 INFO: Inference done 11141/26446. 0.1136 s / img. ETA=0:29:45
[06/30 22:30:14] detectron2 INFO: Inference done 11185/26446. 0.1136 s / img. ETA=0:29:40
[06/30 22:30:19] detectron2 INFO: Inference done 11229/26446. 0.1136 s / img. ETA=0:29:35
[06/30 22:30:24] detectron2 INFO: Inference done 11273/26446. 0.1136 s / img. ETA=0:29:30
[06/30 22:30:29] detectron2 INFO: Inference done 11316/26446. 0.1136 s / img. ETA=0:29:25
[06/30 22:30:34] detectron2 INFO: Inference done 11360/26446. 0.1136 s / img. ETA=0:29:19
[06/30 22:30:40] detectron2 INFO: Inference done 11403/26446. 0.1136 s / img. ETA=0:29:14
[06/30 22:30:45] detectron2 INFO: Inference done 11447/26446. 0.1136 s / img. ETA=0:29:09
[06/30 22:30:50] detectron2 INFO: Inference done 11491/26446. 0.1136 s / img. ETA=0:29:04
[06/30 22:30:55] detectron2 INFO: Inference done 11536/26446. 0.1136 s / img. ETA=0:28:59
[06/30 22:31:00] detectron2 INFO: Inference done 11580/26446. 0.1136 s / img. ETA=0:28:53
[06/30 22:31:05] detectron2 INFO: Inference done 11625/26446. 0.1136 s / img. ETA=0:28:48
[06/30 22:31:10] detectron2 INFO: Inference done 11668/26446. 0.1136 s / img. ETA=0:28:43
[06/30 22:31:15] detectron2 INFO: Inference done 11700/26446. 0.1137 s / img. ETA=0:28:41
[06/30 22:31:20] detectron2 INFO: Inference done 11742/26446. 0.1137 s / img. ETA=0:28:36
[06/30 22:31:25] detectron2 INFO: Inference done 11784/26446. 0.1137 s / img. ETA=0:28:32
[06/30 22:31:30] detectron2 INFO: Inference done 11825/26446. 0.1138 s / img. ETA=0:28:27
[06/30 22:31:35] detectron2 INFO: Inference done 11866/26446. 0.1138 s / img. ETA=0:28:23
[06/30 22:31:40] detectron2 INFO: Inference done 11908/26446. 0.1138 s / img. ETA=0:28:18
[06/30 22:31:45] detectron2 INFO: Inference done 11949/26446. 0.1138 s / img. ETA=0:28:13
[06/30 22:31:50] detectron2 INFO: Inference done 11990/26446. 0.1138 s / img. ETA=0:28:09
[06/30 22:31:56] detectron2 INFO: Inference done 12028/26446. 0.1139 s / img. ETA=0:28:05
[06/30 22:32:01] detectron2 INFO: Inference done 12070/26446. 0.1139 s / img. ETA=0:28:00
[06/30 22:32:06] detectron2 INFO: Inference done 12113/26446. 0.1139 s / img. ETA=0:27:56
[06/30 22:32:11] detectron2 INFO: Inference done 12158/26446. 0.1139 s / img. ETA=0:27:50
[06/30 22:32:16] detectron2 INFO: Inference done 12203/26446. 0.1139 s / img. ETA=0:27:45
[06/30 22:32:21] detectron2 INFO: Inference done 12247/26446. 0.1139 s / img. ETA=0:27:39
[06/30 22:32:26] detectron2 INFO: Inference done 12291/26446. 0.1138 s / img. ETA=0:27:34
[06/30 22:32:31] detectron2 INFO: Inference done 12334/26446. 0.1138 s / img. ETA=0:27:29
[06/30 22:32:36] detectron2 INFO: Inference done 12377/26446. 0.1138 s / img. ETA=0:27:24
[06/30 22:32:41] detectron2 INFO: Inference done 12421/26446. 0.1138 s / img. ETA=0:27:19
[06/30 22:32:46] detectron2 INFO: Inference done 12465/26446. 0.1138 s / img. ETA=0:27:13
[06/30 22:32:51] detectron2 INFO: Inference done 12510/26446. 0.1138 s / img. ETA=0:27:08
[06/30 22:32:56] detectron2 INFO: Inference done 12555/26446. 0.1138 s / img. ETA=0:27:02
[06/30 22:33:01] detectron2 INFO: Inference done 12599/26446. 0.1138 s / img. ETA=0:26:57
[06/30 22:33:06] detectron2 INFO: Inference done 12643/26446. 0.1138 s / img. ETA=0:26:52
[06/30 22:33:11] detectron2 INFO: Inference done 12688/26446. 0.1138 s / img. ETA=0:26:47
[06/30 22:33:16] detectron2 INFO: Inference done 12732/26446. 0.1138 s / img. ETA=0:26:41
[06/30 22:33:21] detectron2 INFO: Inference done 12776/26446. 0.1137 s / img. ETA=0:26:36
[06/30 22:33:26] detectron2 INFO: Inference done 12820/26446. 0.1137 s / img. ETA=0:26:31
[06/30 22:33:31] detectron2 INFO: Inference done 12865/26446. 0.1137 s / img. ETA=0:26:25
[06/30 22:33:36] detectron2 INFO: Inference done 12909/26446. 0.1137 s / img. ETA=0:26:20
[06/30 22:33:41] detectron2 INFO: Inference done 12953/26446. 0.1137 s / img. ETA=0:26:15
[06/30 22:33:47] detectron2 INFO: Inference done 12996/26446. 0.1137 s / img. ETA=0:26:10
[06/30 22:33:52] detectron2 INFO: Inference done 13040/26446. 0.1137 s / img. ETA=0:26:05
[06/30 22:33:57] detectron2 INFO: Inference done 13083/26446. 0.1137 s / img. ETA=0:26:00
[06/30 22:34:02] detectron2 INFO: Inference done 13124/26446. 0.1137 s / img. ETA=0:25:55
[06/30 22:34:07] detectron2 INFO: Inference done 13169/26446. 0.1137 s / img. ETA=0:25:50
[06/30 22:34:12] detectron2 INFO: Inference done 13213/26446. 0.1137 s / img. ETA=0:25:44
[06/30 22:34:17] detectron2 INFO: Inference done 13256/26446. 0.1137 s / img. ETA=0:25:39
[06/30 22:34:22] detectron2 INFO: Inference done 13299/26446. 0.1137 s / img. ETA=0:25:34
[06/30 22:34:27] detectron2 INFO: Inference done 13343/26446. 0.1137 s / img. ETA=0:25:29
[06/30 22:34:32] detectron2 INFO: Inference done 13388/26446. 0.1137 s / img. ETA=0:25:24
[06/30 22:34:37] detectron2 INFO: Inference done 13432/26446. 0.1137 s / img. ETA=0:25:19
[06/30 22:34:42] detectron2 INFO: Inference done 13476/26446. 0.1137 s / img. ETA=0:25:13
[06/30 22:34:47] detectron2 INFO: Inference done 13520/26446. 0.1137 s / img. ETA=0:25:08
[06/30 22:34:52] detectron2 INFO: Inference done 13563/26446. 0.1137 s / img. ETA=0:25:03
[06/30 22:34:57] detectron2 INFO: Inference done 13607/26446. 0.1137 s / img. ETA=0:24:58
[06/30 22:35:02] detectron2 INFO: Inference done 13651/26446. 0.1137 s / img. ETA=0:24:53
[06/30 22:35:07] detectron2 INFO: Inference done 13695/26446. 0.1137 s / img. ETA=0:24:48
[06/30 22:35:12] detectron2 INFO: Inference done 13740/26446. 0.1137 s / img. ETA=0:24:42
[06/30 22:35:18] detectron2 INFO: Inference done 13785/26446. 0.1136 s / img. ETA=0:24:37
[06/30 22:35:23] detectron2 INFO: Inference done 13828/26446. 0.1136 s / img. ETA=0:24:32
[06/30 22:35:28] detectron2 INFO: Inference done 13873/26446. 0.1136 s / img. ETA=0:24:26
[06/30 22:35:33] detectron2 INFO: Inference done 13917/26446. 0.1136 s / img. ETA=0:24:21
[06/30 22:35:38] detectron2 INFO: Inference done 13962/26446. 0.1136 s / img. ETA=0:24:16
[06/30 22:35:43] detectron2 INFO: Inference done 14006/26446. 0.1136 s / img. ETA=0:24:11
[06/30 22:35:48] detectron2 INFO: Inference done 14050/26446. 0.1136 s / img. ETA=0:24:05
[06/30 22:35:53] detectron2 INFO: Inference done 14095/26446. 0.1136 s / img. ETA=0:24:00
[06/30 22:35:58] detectron2 INFO: Inference done 14139/26446. 0.1136 s / img. ETA=0:23:55
[06/30 22:36:03] detectron2 INFO: Inference done 14183/26446. 0.1136 s / img. ETA=0:23:50
[06/30 22:36:08] detectron2 INFO: Inference done 14227/26446. 0.1136 s / img. ETA=0:23:44
[06/30 22:36:13] detectron2 INFO: Inference done 14272/26446. 0.1136 s / img. ETA=0:23:39
[06/30 22:36:18] detectron2 INFO: Inference done 14317/26446. 0.1136 s / img. ETA=0:23:34
[06/30 22:36:24] detectron2 INFO: Inference done 14362/26446. 0.1136 s / img. ETA=0:23:28
[06/30 22:36:29] detectron2 INFO: Inference done 14406/26446. 0.1136 s / img. ETA=0:23:23
[06/30 22:36:34] detectron2 INFO: Inference done 14451/26446. 0.1135 s / img. ETA=0:23:18
[06/30 22:36:39] detectron2 INFO: Inference done 14496/26446. 0.1135 s / img. ETA=0:23:12
[06/30 22:36:44] detectron2 INFO: Inference done 14541/26446. 0.1135 s / img. ETA=0:23:07
[06/30 22:36:49] detectron2 INFO: Inference done 14585/26446. 0.1135 s / img. ETA=0:23:02
[06/30 22:36:54] detectron2 INFO: Inference done 14629/26446. 0.1135 s / img. ETA=0:22:57
[06/30 22:36:59] detectron2 INFO: Inference done 14673/26446. 0.1135 s / img. ETA=0:22:51
[06/30 22:37:04] detectron2 INFO: Inference done 14717/26446. 0.1135 s / img. ETA=0:22:46
[06/30 22:37:09] detectron2 INFO: Inference done 14762/26446. 0.1135 s / img. ETA=0:22:41
[06/30 22:37:14] detectron2 INFO: Inference done 14806/26446. 0.1135 s / img. ETA=0:22:36
[06/30 22:37:19] detectron2 INFO: Inference done 14851/26446. 0.1135 s / img. ETA=0:22:30
[06/30 22:37:24] detectron2 INFO: Inference done 14895/26446. 0.1135 s / img. ETA=0:22:25
[06/30 22:37:29] detectron2 INFO: Inference done 14939/26446. 0.1135 s / img. ETA=0:22:20
[06/30 22:37:34] detectron2 INFO: Inference done 14984/26446. 0.1135 s / img. ETA=0:22:15
[06/30 22:37:39] detectron2 INFO: Inference done 15028/26446. 0.1134 s / img. ETA=0:22:09
[06/30 22:37:44] detectron2 INFO: Inference done 15072/26446. 0.1134 s / img. ETA=0:22:04
[06/30 22:37:50] detectron2 INFO: Inference done 15103/26446. 0.1134 s / img. ETA=0:22:02
[06/30 22:37:55] detectron2 INFO: Inference done 15146/26446. 0.1134 s / img. ETA=0:21:57
[06/30 22:38:00] detectron2 INFO: Inference done 15190/26446. 0.1134 s / img. ETA=0:21:51
[06/30 22:38:05] detectron2 INFO: Inference done 15235/26446. 0.1134 s / img. ETA=0:21:46
[06/30 22:38:10] detectron2 INFO: Inference done 15280/26446. 0.1134 s / img. ETA=0:21:41
[06/30 22:38:15] detectron2 INFO: Inference done 15326/26446. 0.1134 s / img. ETA=0:21:35
[06/30 22:38:20] detectron2 INFO: Inference done 15369/26446. 0.1134 s / img. ETA=0:21:30
[06/30 22:38:25] detectron2 INFO: Inference done 15413/26446. 0.1134 s / img. ETA=0:21:25
[06/30 22:38:30] detectron2 INFO: Inference done 15457/26446. 0.1134 s / img. ETA=0:21:20
[06/30 22:38:35] detectron2 INFO: Inference done 15501/26446. 0.1134 s / img. ETA=0:21:15
[06/30 22:38:40] detectron2 INFO: Inference done 15545/26446. 0.1134 s / img. ETA=0:21:09
[06/30 22:38:45] detectron2 INFO: Inference done 15589/26446. 0.1134 s / img. ETA=0:21:04
[06/30 22:38:50] detectron2 INFO: Inference done 15634/26446. 0.1134 s / img. ETA=0:20:59
[06/30 22:38:55] detectron2 INFO: Inference done 15678/26446. 0.1134 s / img. ETA=0:20:54
[06/30 22:39:00] detectron2 INFO: Inference done 15722/26446. 0.1133 s / img. ETA=0:20:48
[06/30 22:39:05] detectron2 INFO: Inference done 15766/26446. 0.1133 s / img. ETA=0:20:43
[06/30 22:39:10] detectron2 INFO: Inference done 15810/26446. 0.1133 s / img. ETA=0:20:38
[06/30 22:39:15] detectron2 INFO: Inference done 15854/26446. 0.1133 s / img. ETA=0:20:33
[06/30 22:39:20] detectron2 INFO: Inference done 15899/26446. 0.1133 s / img. ETA=0:20:27
[06/30 22:39:25] detectron2 INFO: Inference done 15943/26446. 0.1133 s / img. ETA=0:20:22
[06/30 22:39:30] detectron2 INFO: Inference done 15987/26446. 0.1133 s / img. ETA=0:20:17
[06/30 22:39:35] detectron2 INFO: Inference done 16031/26446. 0.1133 s / img. ETA=0:20:12
[06/30 22:39:40] detectron2 INFO: Inference done 16076/26446. 0.1133 s / img. ETA=0:20:07
[06/30 22:39:45] detectron2 INFO: Inference done 16120/26446. 0.1133 s / img. ETA=0:20:01
[06/30 22:39:50] detectron2 INFO: Inference done 16164/26446. 0.1133 s / img. ETA=0:19:56
[06/30 22:39:55] detectron2 INFO: Inference done 16208/26446. 0.1133 s / img. ETA=0:19:51
[06/30 22:40:01] detectron2 INFO: Inference done 16252/26446. 0.1133 s / img. ETA=0:19:46
[06/30 22:40:06] detectron2 INFO: Inference done 16297/26446. 0.1133 s / img. ETA=0:19:40
[06/30 22:40:11] detectron2 INFO: Inference done 16341/26446. 0.1133 s / img. ETA=0:19:35
[06/30 22:40:16] detectron2 INFO: Inference done 16385/26446. 0.1132 s / img. ETA=0:19:30
[06/30 22:40:21] detectron2 INFO: Inference done 16429/26446. 0.1132 s / img. ETA=0:19:25
[06/30 22:40:26] detectron2 INFO: Inference done 16473/26446. 0.1132 s / img. ETA=0:19:20
[06/30 22:40:31] detectron2 INFO: Inference done 16517/26446. 0.1132 s / img. ETA=0:19:15
[06/30 22:40:36] detectron2 INFO: Inference done 16561/26446. 0.1132 s / img. ETA=0:19:09
[06/30 22:40:41] detectron2 INFO: Inference done 16605/26446. 0.1132 s / img. ETA=0:19:04
[06/30 22:40:46] detectron2 INFO: Inference done 16650/26446. 0.1132 s / img. ETA=0:18:59
[06/30 22:40:51] detectron2 INFO: Inference done 16693/26446. 0.1132 s / img. ETA=0:18:54
[06/30 22:40:56] detectron2 INFO: Inference done 16737/26446. 0.1132 s / img. ETA=0:18:49
[06/30 22:41:01] detectron2 INFO: Inference done 16782/26446. 0.1132 s / img. ETA=0:18:43
[06/30 22:41:06] detectron2 INFO: Inference done 16827/26446. 0.1132 s / img. ETA=0:18:38
[06/30 22:41:11] detectron2 INFO: Inference done 16871/26446. 0.1132 s / img. ETA=0:18:33
[06/30 22:41:16] detectron2 INFO: Inference done 16916/26446. 0.1132 s / img. ETA=0:18:28
[06/30 22:41:21] detectron2 INFO: Inference done 16961/26446. 0.1132 s / img. ETA=0:18:22
[06/30 22:41:26] detectron2 INFO: Inference done 17005/26446. 0.1132 s / img. ETA=0:18:17
[06/30 22:41:31] detectron2 INFO: Inference done 17049/26446. 0.1132 s / img. ETA=0:18:12
[06/30 22:41:36] detectron2 INFO: Inference done 17093/26446. 0.1132 s / img. ETA=0:18:07
[06/30 22:41:41] detectron2 INFO: Inference done 17137/26446. 0.1132 s / img. ETA=0:18:02
[06/30 22:41:47] detectron2 INFO: Inference done 17181/26446. 0.1132 s / img. ETA=0:17:57
[06/30 22:41:52] detectron2 INFO: Inference done 17226/26446. 0.1131 s / img. ETA=0:17:51
[06/30 22:41:57] detectron2 INFO: Inference done 17270/26446. 0.1131 s / img. ETA=0:17:46
[06/30 22:42:02] detectron2 INFO: Inference done 17314/26446. 0.1131 s / img. ETA=0:17:41
[06/30 22:42:07] detectron2 INFO: Inference done 17358/26446. 0.1131 s / img. ETA=0:17:36
[06/30 22:42:12] detectron2 INFO: Inference done 17401/26446. 0.1131 s / img. ETA=0:17:31
[06/30 22:42:17] detectron2 INFO: Inference done 17445/26446. 0.1131 s / img. ETA=0:17:26
[06/30 22:42:22] detectron2 INFO: Inference done 17490/26446. 0.1131 s / img. ETA=0:17:20
[06/30 22:42:27] detectron2 INFO: Inference done 17534/26446. 0.1131 s / img. ETA=0:17:15
[06/30 22:42:32] detectron2 INFO: Inference done 17579/26446. 0.1131 s / img. ETA=0:17:10
[06/30 22:42:37] detectron2 INFO: Inference done 17623/26446. 0.1131 s / img. ETA=0:17:05
[06/30 22:42:42] detectron2 INFO: Inference done 17668/26446. 0.1131 s / img. ETA=0:16:59
[06/30 22:42:47] detectron2 INFO: Inference done 17711/26446. 0.1131 s / img. ETA=0:16:55
[06/30 22:42:52] detectron2 INFO: Inference done 17755/26446. 0.1131 s / img. ETA=0:16:49
[06/30 22:42:57] detectron2 INFO: Inference done 17799/26446. 0.1131 s / img. ETA=0:16:44
[06/30 22:43:03] detectron2 INFO: Inference done 17844/26446. 0.1131 s / img. ETA=0:16:39
[06/30 22:43:08] detectron2 INFO: Inference done 17888/26446. 0.1131 s / img. ETA=0:16:34
[06/30 22:43:13] detectron2 INFO: Inference done 17933/26446. 0.1131 s / img. ETA=0:16:29
[06/30 22:43:18] detectron2 INFO: Inference done 17978/26446. 0.1131 s / img. ETA=0:16:23
[06/30 22:43:23] detectron2 INFO: Inference done 18021/26446. 0.1131 s / img. ETA=0:16:18
[06/30 22:43:28] detectron2 INFO: Inference done 18066/26446. 0.1131 s / img. ETA=0:16:13
[06/30 22:43:33] detectron2 INFO: Inference done 18110/26446. 0.1131 s / img. ETA=0:16:08
[06/30 22:43:38] detectron2 INFO: Inference done 18155/26446. 0.1131 s / img. ETA=0:16:02
[06/30 22:43:43] detectron2 INFO: Inference done 18199/26446. 0.1131 s / img. ETA=0:15:57
[06/30 22:43:48] detectron2 INFO: Inference done 18242/26446. 0.1131 s / img. ETA=0:15:52
[06/30 22:43:53] detectron2 INFO: Inference done 18286/26446. 0.1131 s / img. ETA=0:15:47
[06/30 22:43:58] detectron2 INFO: Inference done 18331/26446. 0.1131 s / img. ETA=0:15:42
[06/30 22:44:03] detectron2 INFO: Inference done 18375/26446. 0.1131 s / img. ETA=0:15:37
[06/30 22:44:08] detectron2 INFO: Inference done 18420/26446. 0.1130 s / img. ETA=0:15:32
[06/30 22:44:13] detectron2 INFO: Inference done 18464/26446. 0.1130 s / img. ETA=0:15:26
[06/30 22:44:18] detectron2 INFO: Inference done 18506/26446. 0.1130 s / img. ETA=0:15:22
[06/30 22:44:23] detectron2 INFO: Inference done 18550/26446. 0.1130 s / img. ETA=0:15:16
[06/30 22:44:28] detectron2 INFO: Inference done 18594/26446. 0.1130 s / img. ETA=0:15:11
[06/30 22:44:33] detectron2 INFO: Inference done 18638/26446. 0.1130 s / img. ETA=0:15:06
[06/30 22:44:39] detectron2 INFO: Inference done 18683/26446. 0.1130 s / img. ETA=0:15:01
[06/30 22:44:44] detectron2 INFO: Inference done 18728/26446. 0.1130 s / img. ETA=0:14:56
[06/30 22:44:49] detectron2 INFO: Inference done 18772/26446. 0.1130 s / img. ETA=0:14:50
[06/30 22:44:54] detectron2 INFO: Inference done 18816/26446. 0.1130 s / img. ETA=0:14:45
[06/30 22:44:59] detectron2 INFO: Inference done 18861/26446. 0.1130 s / img. ETA=0:14:40
[06/30 22:45:04] detectron2 INFO: Inference done 18906/26446. 0.1130 s / img. ETA=0:14:35
[06/30 22:45:09] detectron2 INFO: Inference done 18951/26446. 0.1130 s / img. ETA=0:14:29
[06/30 22:45:14] detectron2 INFO: Inference done 18996/26446. 0.1130 s / img. ETA=0:14:24
[06/30 22:45:19] detectron2 INFO: Inference done 19041/26446. 0.1130 s / img. ETA=0:14:19
[06/30 22:45:24] detectron2 INFO: Inference done 19085/26446. 0.1130 s / img. ETA=0:14:14
[06/30 22:45:29] detectron2 INFO: Inference done 19129/26446. 0.1130 s / img. ETA=0:14:09
[06/30 22:45:34] detectron2 INFO: Inference done 19173/26446. 0.1130 s / img. ETA=0:14:03
[06/30 22:45:39] detectron2 INFO: Inference done 19218/26446. 0.1130 s / img. ETA=0:13:58
[06/30 22:45:44] detectron2 INFO: Inference done 19261/26446. 0.1130 s / img. ETA=0:13:53
[06/30 22:45:49] detectron2 INFO: Inference done 19305/26446. 0.1130 s / img. ETA=0:13:48
[06/30 22:45:54] detectron2 INFO: Inference done 19349/26446. 0.1130 s / img. ETA=0:13:43
[06/30 22:45:59] detectron2 INFO: Inference done 19394/26446. 0.1129 s / img. ETA=0:13:38
[06/30 22:46:04] detectron2 INFO: Inference done 19437/26446. 0.1130 s / img. ETA=0:13:33
[06/30 22:46:09] detectron2 INFO: Inference done 19482/26446. 0.1129 s / img. ETA=0:13:27
[06/30 22:46:15] detectron2 INFO: Inference done 19527/26446. 0.1129 s / img. ETA=0:13:22
[06/30 22:46:20] detectron2 INFO: Inference done 19571/26446. 0.1129 s / img. ETA=0:13:17
[06/30 22:46:25] detectron2 INFO: Inference done 19615/26446. 0.1129 s / img. ETA=0:13:12
[06/30 22:46:30] detectron2 INFO: Inference done 19659/26446. 0.1129 s / img. ETA=0:13:07
[06/30 22:46:35] detectron2 INFO: Inference done 19703/26446. 0.1129 s / img. ETA=0:13:02
[06/30 22:46:40] detectron2 INFO: Inference done 19747/26446. 0.1129 s / img. ETA=0:12:57
[06/30 22:46:45] detectron2 INFO: Inference done 19791/26446. 0.1129 s / img. ETA=0:12:51
[06/30 22:46:50] detectron2 INFO: Inference done 19836/26446. 0.1129 s / img. ETA=0:12:46
[06/30 22:46:55] detectron2 INFO: Inference done 19881/26446. 0.1129 s / img. ETA=0:12:41
[06/30 22:47:00] detectron2 INFO: Inference done 19925/26446. 0.1129 s / img. ETA=0:12:36
[06/30 22:47:05] detectron2 INFO: Inference done 19970/26446. 0.1129 s / img. ETA=0:12:30
[06/30 22:47:10] detectron2 INFO: Inference done 20013/26446. 0.1129 s / img. ETA=0:12:25
[06/30 22:47:15] detectron2 INFO: Inference done 20057/26446. 0.1129 s / img. ETA=0:12:20
[06/30 22:47:20] detectron2 INFO: Inference done 20101/26446. 0.1129 s / img. ETA=0:12:15
[06/30 22:47:25] detectron2 INFO: Inference done 20145/26446. 0.1129 s / img. ETA=0:12:10
[06/30 22:47:30] detectron2 INFO: Inference done 20190/26446. 0.1129 s / img. ETA=0:12:05
[06/30 22:47:35] detectron2 INFO: Inference done 20231/26446. 0.1129 s / img. ETA=0:12:00
[06/30 22:47:40] detectron2 INFO: Inference done 20275/26446. 0.1129 s / img. ETA=0:11:55
[06/30 22:47:45] detectron2 INFO: Inference done 20319/26446. 0.1129 s / img. ETA=0:11:50
[06/30 22:47:50] detectron2 INFO: Inference done 20364/26446. 0.1129 s / img. ETA=0:11:45
[06/30 22:47:55] detectron2 INFO: Inference done 20409/26446. 0.1129 s / img. ETA=0:11:39
[06/30 22:48:00] detectron2 INFO: Inference done 20452/26446. 0.1129 s / img. ETA=0:11:34
[06/30 22:48:05] detectron2 INFO: Inference done 20496/26446. 0.1129 s / img. ETA=0:11:29
[06/30 22:48:11] detectron2 INFO: Inference done 20540/26446. 0.1129 s / img. ETA=0:11:24
[06/30 22:48:16] detectron2 INFO: Inference done 20584/26446. 0.1129 s / img. ETA=0:11:19
[06/30 22:48:21] detectron2 INFO: Inference done 20629/26446. 0.1129 s / img. ETA=0:11:14
[06/30 22:48:26] detectron2 INFO: Inference done 20673/26446. 0.1129 s / img. ETA=0:11:09
[06/30 22:48:31] detectron2 INFO: Inference done 20717/26446. 0.1128 s / img. ETA=0:11:04
[06/30 22:48:36] detectron2 INFO: Inference done 20761/26446. 0.1128 s / img. ETA=0:10:58
[06/30 22:48:41] detectron2 INFO: Inference done 20805/26446. 0.1128 s / img. ETA=0:10:53
[06/30 22:48:46] detectron2 INFO: Inference done 20849/26446. 0.1128 s / img. ETA=0:10:48
[06/30 22:48:51] detectron2 INFO: Inference done 20893/26446. 0.1128 s / img. ETA=0:10:43
[06/30 22:48:56] detectron2 INFO: Inference done 20938/26446. 0.1128 s / img. ETA=0:10:38
[06/30 22:49:01] detectron2 INFO: Inference done 20982/26446. 0.1128 s / img. ETA=0:10:33
[06/30 22:49:06] detectron2 INFO: Inference done 21027/26446. 0.1128 s / img. ETA=0:10:27
[06/30 22:49:11] detectron2 INFO: Inference done 21071/26446. 0.1128 s / img. ETA=0:10:22
[06/30 22:49:16] detectron2 INFO: Inference done 21116/26446. 0.1128 s / img. ETA=0:10:17
[06/30 22:49:21] detectron2 INFO: Inference done 21160/26446. 0.1128 s / img. ETA=0:10:12
[06/30 22:49:26] detectron2 INFO: Inference done 21204/26446. 0.1128 s / img. ETA=0:10:07
[06/30 22:49:31] detectron2 INFO: Inference done 21248/26446. 0.1128 s / img. ETA=0:10:02
[06/30 22:49:36] detectron2 INFO: Inference done 21293/26446. 0.1128 s / img. ETA=0:09:57
[06/30 22:49:41] detectron2 INFO: Inference done 21338/26446. 0.1128 s / img. ETA=0:09:51
[06/30 22:49:46] detectron2 INFO: Inference done 21382/26446. 0.1128 s / img. ETA=0:09:46
[06/30 22:49:52] detectron2 INFO: Inference done 21426/26446. 0.1128 s / img. ETA=0:09:41
[06/30 22:49:57] detectron2 INFO: Inference done 21471/26446. 0.1128 s / img. ETA=0:09:36
[06/30 22:50:02] detectron2 INFO: Inference done 21515/26446. 0.1128 s / img. ETA=0:09:31
[06/30 22:50:07] detectron2 INFO: Inference done 21559/26446. 0.1128 s / img. ETA=0:09:26
[06/30 22:50:12] detectron2 INFO: Inference done 21604/26446. 0.1128 s / img. ETA=0:09:20
[06/30 22:50:17] detectron2 INFO: Inference done 21647/26446. 0.1128 s / img. ETA=0:09:15
[06/30 22:50:22] detectron2 INFO: Inference done 21691/26446. 0.1128 s / img. ETA=0:09:10
[06/30 22:50:27] detectron2 INFO: Inference done 21735/26446. 0.1128 s / img. ETA=0:09:05
[06/30 22:50:32] detectron2 INFO: Inference done 21781/26446. 0.1128 s / img. ETA=0:09:00
[06/30 22:50:37] detectron2 INFO: Inference done 21823/26446. 0.1128 s / img. ETA=0:08:55
[06/30 22:50:42] detectron2 INFO: Inference done 21868/26446. 0.1128 s / img. ETA=0:08:50
[06/30 22:50:47] detectron2 INFO: Inference done 21912/26446. 0.1128 s / img. ETA=0:08:45
[06/30 22:50:52] detectron2 INFO: Inference done 21957/26446. 0.1128 s / img. ETA=0:08:39
[06/30 22:50:57] detectron2 INFO: Inference done 22002/26446. 0.1127 s / img. ETA=0:08:34
[06/30 22:51:02] detectron2 INFO: Inference done 22047/26446. 0.1127 s / img. ETA=0:08:29
[06/30 22:51:07] detectron2 INFO: Inference done 22091/26446. 0.1127 s / img. ETA=0:08:24
[06/30 22:51:12] detectron2 INFO: Inference done 22135/26446. 0.1127 s / img. ETA=0:08:19
[06/30 22:51:17] detectron2 INFO: Inference done 22178/26446. 0.1127 s / img. ETA=0:08:14
[06/30 22:51:22] detectron2 INFO: Inference done 22223/26446. 0.1127 s / img. ETA=0:08:08
[06/30 22:51:27] detectron2 INFO: Inference done 22267/26446. 0.1127 s / img. ETA=0:08:03
[06/30 22:51:32] detectron2 INFO: Inference done 22311/26446. 0.1127 s / img. ETA=0:07:58
[06/30 22:51:37] detectron2 INFO: Inference done 22355/26446. 0.1127 s / img. ETA=0:07:53
[06/30 22:51:43] detectron2 INFO: Inference done 22399/26446. 0.1127 s / img. ETA=0:07:48
[06/30 22:51:48] detectron2 INFO: Inference done 22443/26446. 0.1127 s / img. ETA=0:07:43
[06/30 22:51:53] detectron2 INFO: Inference done 22487/26446. 0.1127 s / img. ETA=0:07:38
[06/30 22:51:58] detectron2 INFO: Inference done 22529/26446. 0.1127 s / img. ETA=0:07:33
[06/30 22:52:03] detectron2 INFO: Inference done 22574/26446. 0.1127 s / img. ETA=0:07:28
[06/30 22:52:08] detectron2 INFO: Inference done 22618/26446. 0.1127 s / img. ETA=0:07:23
[06/30 22:52:13] detectron2 INFO: Inference done 22663/26446. 0.1127 s / img. ETA=0:07:17
[06/30 22:52:18] detectron2 INFO: Inference done 22708/26446. 0.1127 s / img. ETA=0:07:12
[06/30 22:52:23] detectron2 INFO: Inference done 22752/26446. 0.1127 s / img. ETA=0:07:07
[06/30 22:52:28] detectron2 INFO: Inference done 22795/26446. 0.1127 s / img. ETA=0:07:02
[06/30 22:52:33] detectron2 INFO: Inference done 22839/26446. 0.1127 s / img. ETA=0:06:57
[06/30 22:52:38] detectron2 INFO: Inference done 22884/26446. 0.1127 s / img. ETA=0:06:52
[06/30 22:52:43] detectron2 INFO: Inference done 22929/26446. 0.1127 s / img. ETA=0:06:47
[06/30 22:52:48] detectron2 INFO: Inference done 22974/26446. 0.1127 s / img. ETA=0:06:41
[06/30 22:52:53] detectron2 INFO: Inference done 23019/26446. 0.1127 s / img. ETA=0:06:36
[06/30 22:52:58] detectron2 INFO: Inference done 23063/26446. 0.1127 s / img. ETA=0:06:31
[06/30 22:53:04] detectron2 INFO: Inference done 23107/26446. 0.1127 s / img. ETA=0:06:26
[06/30 22:53:09] detectron2 INFO: Inference done 23152/26446. 0.1127 s / img. ETA=0:06:21
[06/30 22:53:14] detectron2 INFO: Inference done 23197/26446. 0.1127 s / img. ETA=0:06:15
[06/30 22:53:19] detectron2 INFO: Inference done 23241/26446. 0.1127 s / img. ETA=0:06:10
[06/30 22:53:24] detectron2 INFO: Inference done 23285/26446. 0.1127 s / img. ETA=0:06:05
[06/30 22:53:29] detectron2 INFO: Inference done 23329/26446. 0.1127 s / img. ETA=0:06:00
[06/30 22:53:34] detectron2 INFO: Inference done 23374/26446. 0.1127 s / img. ETA=0:05:55
[06/30 22:53:39] detectron2 INFO: Inference done 23419/26446. 0.1127 s / img. ETA=0:05:50
[06/30 22:53:44] detectron2 INFO: Inference done 23463/26446. 0.1127 s / img. ETA=0:05:45
[06/30 22:53:49] detectron2 INFO: Inference done 23508/26446. 0.1127 s / img. ETA=0:05:39
[06/30 22:53:54] detectron2 INFO: Inference done 23553/26446. 0.1127 s / img. ETA=0:05:34
[06/30 22:53:59] detectron2 INFO: Inference done 23597/26446. 0.1127 s / img. ETA=0:05:29
[06/30 22:54:04] detectron2 INFO: Inference done 23641/26446. 0.1126 s / img. ETA=0:05:24
[06/30 22:54:09] detectron2 INFO: Inference done 23686/26446. 0.1126 s / img. ETA=0:05:19
[06/30 22:54:15] detectron2 INFO: Inference done 23731/26446. 0.1126 s / img. ETA=0:05:14
[06/30 22:54:20] detectron2 INFO: Inference done 23776/26446. 0.1126 s / img. ETA=0:05:08
[06/30 22:54:25] detectron2 INFO: Inference done 23822/26446. 0.1126 s / img. ETA=0:05:03
[06/30 22:54:30] detectron2 INFO: Inference done 23867/26446. 0.1126 s / img. ETA=0:04:58
[06/30 22:54:35] detectron2 INFO: Inference done 23911/26446. 0.1126 s / img. ETA=0:04:53
[06/30 22:54:40] detectron2 INFO: Inference done 23955/26446. 0.1126 s / img. ETA=0:04:48
[06/30 22:54:45] detectron2 INFO: Inference done 23998/26446. 0.1126 s / img. ETA=0:04:43
[06/30 22:54:50] detectron2 INFO: Inference done 24042/26446. 0.1126 s / img. ETA=0:04:38
[06/30 22:54:55] detectron2 INFO: Inference done 24086/26446. 0.1126 s / img. ETA=0:04:32
[06/30 22:55:00] detectron2 INFO: Inference done 24131/26446. 0.1126 s / img. ETA=0:04:27
[06/30 22:55:05] detectron2 INFO: Inference done 24174/26446. 0.1126 s / img. ETA=0:04:22
[06/30 22:55:10] detectron2 INFO: Inference done 24204/26446. 0.1126 s / img. ETA=0:04:19
[06/30 22:55:15] detectron2 INFO: Inference done 24249/26446. 0.1126 s / img. ETA=0:04:14
[06/30 22:55:20] detectron2 INFO: Inference done 24294/26446. 0.1126 s / img. ETA=0:04:09
[06/30 22:55:25] detectron2 INFO: Inference done 24338/26446. 0.1126 s / img. ETA=0:04:03
[06/30 22:55:31] detectron2 INFO: Inference done 24383/26446. 0.1126 s / img. ETA=0:03:58
[06/30 22:55:36] detectron2 INFO: Inference done 24427/26446. 0.1126 s / img. ETA=0:03:53
[06/30 22:55:41] detectron2 INFO: Inference done 24471/26446. 0.1126 s / img. ETA=0:03:48
[06/30 22:55:46] detectron2 INFO: Inference done 24515/26446. 0.1126 s / img. ETA=0:03:43
[06/30 22:55:51] detectron2 INFO: Inference done 24560/26446. 0.1126 s / img. ETA=0:03:38
[06/30 22:55:56] detectron2 INFO: Inference done 24605/26446. 0.1126 s / img. ETA=0:03:32
[06/30 22:56:01] detectron2 INFO: Inference done 24649/26446. 0.1126 s / img. ETA=0:03:27
[06/30 22:56:06] detectron2 INFO: Inference done 24694/26446. 0.1126 s / img. ETA=0:03:22
[06/30 22:56:11] detectron2 INFO: Inference done 24738/26446. 0.1126 s / img. ETA=0:03:17
[06/30 22:56:16] detectron2 INFO: Inference done 24783/26446. 0.1126 s / img. ETA=0:03:12
[06/30 22:56:21] detectron2 INFO: Inference done 24828/26446. 0.1126 s / img. ETA=0:03:07
[06/30 22:56:26] detectron2 INFO: Inference done 24873/26446. 0.1126 s / img. ETA=0:03:01
[06/30 22:56:31] detectron2 INFO: Inference done 24917/26446. 0.1126 s / img. ETA=0:02:56
[06/30 22:56:36] detectron2 INFO: Inference done 24961/26446. 0.1126 s / img. ETA=0:02:51
[06/30 22:56:41] detectron2 INFO: Inference done 25004/26446. 0.1126 s / img. ETA=0:02:46
[06/30 22:56:46] detectron2 INFO: Inference done 25047/26446. 0.1126 s / img. ETA=0:02:41
[06/30 22:56:51] detectron2 INFO: Inference done 25091/26446. 0.1126 s / img. ETA=0:02:36
[06/30 22:56:56] detectron2 INFO: Inference done 25134/26446. 0.1126 s / img. ETA=0:02:31
[06/30 22:57:01] detectron2 INFO: Inference done 25178/26446. 0.1126 s / img. ETA=0:02:26
[06/30 22:57:07] detectron2 INFO: Inference done 25222/26446. 0.1126 s / img. ETA=0:02:21
[06/30 22:57:12] detectron2 INFO: Inference done 25267/26446. 0.1126 s / img. ETA=0:02:16
[06/30 22:57:17] detectron2 INFO: Inference done 25310/26446. 0.1126 s / img. ETA=0:02:11
[06/30 22:57:22] detectron2 INFO: Inference done 25354/26446. 0.1126 s / img. ETA=0:02:06
[06/30 22:57:27] detectron2 INFO: Inference done 25398/26446. 0.1126 s / img. ETA=0:02:01
[06/30 22:57:32] detectron2 INFO: Inference done 25442/26446. 0.1126 s / img. ETA=0:01:56
[06/30 22:57:37] detectron2 INFO: Inference done 25486/26446. 0.1126 s / img. ETA=0:01:51
[06/30 22:57:42] detectron2 INFO: Inference done 25531/26446. 0.1125 s / img. ETA=0:01:45
[06/30 22:57:47] detectron2 INFO: Inference done 25575/26446. 0.1125 s / img. ETA=0:01:40
[06/30 22:57:52] detectron2 INFO: Inference done 25619/26446. 0.1125 s / img. ETA=0:01:35
[06/30 22:57:57] detectron2 INFO: Inference done 25663/26446. 0.1125 s / img. ETA=0:01:30
[06/30 22:58:02] detectron2 INFO: Inference done 25708/26446. 0.1125 s / img. ETA=0:01:25
[06/30 22:58:07] detectron2 INFO: Inference done 25751/26446. 0.1125 s / img. ETA=0:01:20
[06/30 22:58:12] detectron2 INFO: Inference done 25793/26446. 0.1126 s / img. ETA=0:01:15
[06/30 22:58:17] detectron2 INFO: Inference done 25835/26446. 0.1126 s / img. ETA=0:01:10
[06/30 22:58:22] detectron2 INFO: Inference done 25877/26446. 0.1126 s / img. ETA=0:01:05
[06/30 22:58:28] detectron2 INFO: Inference done 25921/26446. 0.1126 s / img. ETA=0:01:00
[06/30 22:58:33] detectron2 INFO: Inference done 25965/26446. 0.1126 s / img. ETA=0:00:55
[06/30 22:58:38] detectron2 INFO: Inference done 26010/26446. 0.1126 s / img. ETA=0:00:50
[06/30 22:58:43] detectron2 INFO: Inference done 26053/26446. 0.1126 s / img. ETA=0:00:45
[06/30 22:58:48] detectron2 INFO: Inference done 26097/26446. 0.1126 s / img. ETA=0:00:40
[06/30 22:58:53] detectron2 INFO: Inference done 26142/26446. 0.1126 s / img. ETA=0:00:35
[06/30 22:58:58] detectron2 INFO: Inference done 26187/26446. 0.1126 s / img. ETA=0:00:29
[06/30 22:59:03] detectron2 INFO: Inference done 26231/26446. 0.1126 s / img. ETA=0:00:24
[06/30 22:59:08] detectron2 INFO: Inference done 26276/26446. 0.1125 s / img. ETA=0:00:19
[06/30 22:59:13] detectron2 INFO: Inference done 26320/26446. 0.1125 s / img. ETA=0:00:14
[06/30 22:59:18] detectron2 INFO: Inference done 26366/26446. 0.1125 s / img. ETA=0:00:09
[06/30 22:59:23] detectron2 INFO: Inference done 26410/26446. 0.1125 s / img. ETA=0:00:04
[06/30 22:59:29] detectron2 INFO: Total inference time: 0:50:58.912345 (0.115688 s / img per device, on 1 devices)
[06/30 22:59:29] detectron2 INFO: Total inference pure compute time: 0:49:35 (0.112539 s / img per device, on 1 devices)
[06/30 22:59:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[06/30 22:59:37] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[06/30 22:59:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[06/30 22:59:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[07/01 08:18:48] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 08:18:49] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 08:18:49] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '20', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 08:18:49] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 40
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 08:18:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 20
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 08:18:49] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 08:18:49] d2.utils.env INFO: Using a generated random seed 49875000
[07/01 08:18:52] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 08:18:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 08:18:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 08:18:54] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 08:18:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 08:18:54] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 08:18:55] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 08:18:55] detectron2 INFO: Following metrics will be use for evaluation
[07/01 08:18:55] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 08:18:55] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 08:18:55] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 08:18:55] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 08:18:55] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 08:18:57] detectron2 INFO: Loading zero shot triplets
[07/01 08:18:57] detectron2 INFO: Start inference on 26446 images
[07/01 08:19:07] detectron2 INFO: Inference done 1/26446. 5.9832 s / img. ETA=2 days, 23:45:46
[07/01 08:19:12] detectron2 INFO: Inference done 32/26446. 0.1585 s / img. ETA=1:10:48
[07/01 08:19:17] detectron2 INFO: Inference done 64/26446. 0.1581 s / img. ETA=1:10:31
[07/01 08:19:22] detectron2 INFO: Inference done 96/26446. 0.1574 s / img. ETA=1:10:06
[07/01 08:19:27] detectron2 INFO: Inference done 128/26446. 0.1569 s / img. ETA=1:09:50
[07/01 08:19:33] detectron2 INFO: Inference done 161/26446. 0.1562 s / img. ETA=1:09:24
[07/01 08:19:38] detectron2 INFO: Inference done 194/26446. 0.1558 s / img. ETA=1:09:09
[07/01 08:19:43] detectron2 INFO: Inference done 225/26446. 0.1562 s / img. ETA=1:09:16
[07/01 08:19:48] detectron2 INFO: Inference done 256/26446. 0.1567 s / img. ETA=1:09:24
[07/01 08:19:53] detectron2 INFO: Inference done 288/26446. 0.1569 s / img. ETA=1:09:24
[07/01 08:19:58] detectron2 INFO: Inference done 318/26446. 0.1578 s / img. ETA=1:09:42
[07/01 08:20:03] detectron2 INFO: Inference done 349/26446. 0.1579 s / img. ETA=1:09:41
[07/01 08:20:08] detectron2 INFO: Inference done 381/26446. 0.1579 s / img. ETA=1:09:34
[07/01 08:20:13] detectron2 INFO: Inference done 411/26446. 0.1584 s / img. ETA=1:09:45
[07/01 08:20:18] detectron2 INFO: Inference done 442/26446. 0.1585 s / img. ETA=1:09:42
[07/01 08:20:23] detectron2 INFO: Inference done 474/26446. 0.1585 s / img. ETA=1:09:37
[07/01 08:20:28] detectron2 INFO: Inference done 506/26446. 0.1585 s / img. ETA=1:09:32
[07/01 08:20:33] detectron2 INFO: Inference done 537/26446. 0.1586 s / img. ETA=1:09:29
[07/01 08:20:39] detectron2 INFO: Inference done 569/26446. 0.1585 s / img. ETA=1:09:21
[07/01 08:20:44] detectron2 INFO: Inference done 601/26446. 0.1584 s / img. ETA=1:09:15
[07/01 08:20:49] detectron2 INFO: Inference done 633/26446. 0.1583 s / img. ETA=1:09:06
[07/01 08:20:54] detectron2 INFO: Inference done 665/26446. 0.1582 s / img. ETA=1:08:59
[07/01 08:20:59] detectron2 INFO: Inference done 697/26446. 0.1580 s / img. ETA=1:08:49
[07/01 08:21:04] detectron2 INFO: Inference done 725/26446. 0.1588 s / img. ETA=1:09:05
[07/01 08:21:09] detectron2 INFO: Inference done 756/26446. 0.1589 s / img. ETA=1:09:00
[07/01 08:21:14] detectron2 INFO: Inference done 788/26446. 0.1588 s / img. ETA=1:08:54
[07/01 08:21:19] detectron2 INFO: Inference done 820/26446. 0.1588 s / img. ETA=1:08:48
[07/01 08:21:24] detectron2 INFO: Inference done 851/26446. 0.1589 s / img. ETA=1:08:46
[07/01 08:21:29] detectron2 INFO: Inference done 883/26446. 0.1588 s / img. ETA=1:08:40
[07/01 08:21:34] detectron2 INFO: Inference done 914/26446. 0.1589 s / img. ETA=1:08:36
[07/01 08:21:40] detectron2 INFO: Inference done 946/26446. 0.1588 s / img. ETA=1:08:30
[07/01 08:21:45] detectron2 INFO: Inference done 978/26446. 0.1589 s / img. ETA=1:08:25
[07/01 08:21:50] detectron2 INFO: Inference done 1010/26446. 0.1588 s / img. ETA=1:08:19
[07/01 08:21:55] detectron2 INFO: Inference done 1042/26446. 0.1588 s / img. ETA=1:08:12
[07/01 08:22:00] detectron2 INFO: Inference done 1074/26446. 0.1587 s / img. ETA=1:08:04
[07/01 08:22:05] detectron2 INFO: Inference done 1106/26446. 0.1586 s / img. ETA=1:07:57
[07/01 08:22:10] detectron2 INFO: Inference done 1138/26446. 0.1586 s / img. ETA=1:07:52
[07/01 08:22:15] detectron2 INFO: Inference done 1170/26446. 0.1586 s / img. ETA=1:07:47
[07/01 08:22:20] detectron2 INFO: Inference done 1201/26446. 0.1586 s / img. ETA=1:07:42
[07/01 08:22:26] detectron2 INFO: Inference done 1233/26446. 0.1586 s / img. ETA=1:07:37
[07/01 08:22:31] detectron2 INFO: Inference done 1264/26446. 0.1587 s / img. ETA=1:07:33
[07/01 08:22:36] detectron2 INFO: Inference done 1295/26446. 0.1587 s / img. ETA=1:07:30
[07/01 08:22:41] detectron2 INFO: Inference done 1327/26446. 0.1587 s / img. ETA=1:07:24
[07/01 08:22:46] detectron2 INFO: Inference done 1359/26446. 0.1587 s / img. ETA=1:07:19
[07/01 08:22:51] detectron2 INFO: Inference done 1391/26446. 0.1587 s / img. ETA=1:07:14
[07/01 08:22:56] detectron2 INFO: Inference done 1422/26446. 0.1587 s / img. ETA=1:07:10
[07/01 08:23:01] detectron2 INFO: Inference done 1454/26446. 0.1587 s / img. ETA=1:07:04
[07/01 08:23:06] detectron2 INFO: Inference done 1486/26446. 0.1586 s / img. ETA=1:06:57
[07/01 08:23:11] detectron2 INFO: Inference done 1518/26446. 0.1586 s / img. ETA=1:06:52
[07/01 08:23:16] detectron2 INFO: Inference done 1550/26446. 0.1586 s / img. ETA=1:06:45
[07/01 08:23:22] detectron2 INFO: Inference done 1582/26446. 0.1585 s / img. ETA=1:06:39
[07/01 08:23:27] detectron2 INFO: Inference done 1614/26446. 0.1585 s / img. ETA=1:06:34
[07/01 08:23:32] detectron2 INFO: Inference done 1645/26446. 0.1586 s / img. ETA=1:06:30
[07/01 08:23:37] detectron2 INFO: Inference done 1677/26446. 0.1585 s / img. ETA=1:06:24
[07/01 08:23:42] detectron2 INFO: Inference done 1709/26446. 0.1585 s / img. ETA=1:06:18
[07/01 08:23:47] detectron2 INFO: Inference done 1740/26446. 0.1586 s / img. ETA=1:06:14
[07/01 08:23:52] detectron2 INFO: Inference done 1772/26446. 0.1585 s / img. ETA=1:06:08
[07/01 08:23:57] detectron2 INFO: Inference done 1804/26446. 0.1585 s / img. ETA=1:06:03
[07/01 08:24:02] detectron2 INFO: Inference done 1835/26446. 0.1585 s / img. ETA=1:05:58
[07/01 08:24:07] detectron2 INFO: Inference done 1867/26446. 0.1585 s / img. ETA=1:05:53
[07/01 08:24:12] detectron2 INFO: Inference done 1898/26446. 0.1586 s / img. ETA=1:05:49
[07/01 08:24:17] detectron2 INFO: Inference done 1929/26446. 0.1586 s / img. ETA=1:05:44
[07/01 08:24:23] detectron2 INFO: Inference done 1961/26446. 0.1586 s / img. ETA=1:05:39
[07/01 08:24:28] detectron2 INFO: Inference done 1986/26446. 0.1591 s / img. ETA=1:05:47
[07/01 08:24:33] detectron2 INFO: Inference done 2018/26446. 0.1591 s / img. ETA=1:05:42
[07/01 08:24:38] detectron2 INFO: Inference done 2050/26446. 0.1590 s / img. ETA=1:05:36
[07/01 08:24:43] detectron2 INFO: Inference done 2081/26446. 0.1591 s / img. ETA=1:05:33
[07/01 08:24:48] detectron2 INFO: Inference done 2111/26446. 0.1592 s / img. ETA=1:05:30
[07/01 08:24:53] detectron2 INFO: Inference done 2142/26446. 0.1592 s / img. ETA=1:05:25
[07/01 08:24:58] detectron2 INFO: Inference done 2174/26446. 0.1592 s / img. ETA=1:05:20
[07/01 08:25:03] detectron2 INFO: Inference done 2205/26446. 0.1592 s / img. ETA=1:05:15
[07/01 08:25:08] detectron2 INFO: Inference done 2236/26446. 0.1592 s / img. ETA=1:05:10
[07/01 08:25:13] detectron2 INFO: Inference done 2268/26446. 0.1592 s / img. ETA=1:05:05
[07/01 08:25:18] detectron2 INFO: Inference done 2299/26446. 0.1592 s / img. ETA=1:05:00
[07/01 08:25:24] detectron2 INFO: Inference done 2330/26446. 0.1592 s / img. ETA=1:04:56
[07/01 08:25:29] detectron2 INFO: Inference done 2362/26446. 0.1592 s / img. ETA=1:04:50
[07/01 08:25:34] detectron2 INFO: Inference done 2393/26446. 0.1592 s / img. ETA=1:04:45
[07/01 08:25:39] detectron2 INFO: Inference done 2423/26446. 0.1593 s / img. ETA=1:04:42
[07/01 08:25:44] detectron2 INFO: Inference done 2455/26446. 0.1593 s / img. ETA=1:04:36
[07/01 08:25:49] detectron2 INFO: Inference done 2486/26446. 0.1593 s / img. ETA=1:04:32
[07/01 08:25:54] detectron2 INFO: Inference done 2518/26446. 0.1593 s / img. ETA=1:04:26
[07/01 08:25:59] detectron2 INFO: Inference done 2550/26446. 0.1592 s / img. ETA=1:04:20
[07/01 08:26:04] detectron2 INFO: Inference done 2582/26446. 0.1592 s / img. ETA=1:04:14
[07/01 08:26:09] detectron2 INFO: Inference done 2613/26446. 0.1592 s / img. ETA=1:04:10
[07/01 08:26:14] detectron2 INFO: Inference done 2645/26446. 0.1592 s / img. ETA=1:04:04
[07/01 08:26:19] detectron2 INFO: Inference done 2677/26446. 0.1592 s / img. ETA=1:03:59
[07/01 08:26:25] detectron2 INFO: Inference done 2709/26446. 0.1592 s / img. ETA=1:03:53
[07/01 08:26:30] detectron2 INFO: Inference done 2741/26446. 0.1592 s / img. ETA=1:03:48
[07/01 08:26:35] detectron2 INFO: Inference done 2772/26446. 0.1592 s / img. ETA=1:03:43
[07/01 08:26:40] detectron2 INFO: Inference done 2804/26446. 0.1591 s / img. ETA=1:03:37
[07/01 08:26:45] detectron2 INFO: Inference done 2836/26446. 0.1591 s / img. ETA=1:03:32
[07/01 08:26:50] detectron2 INFO: Inference done 2868/26446. 0.1591 s / img. ETA=1:03:26
[07/01 08:26:55] detectron2 INFO: Inference done 2899/26446. 0.1591 s / img. ETA=1:03:21
[07/01 08:27:00] detectron2 INFO: Inference done 2930/26446. 0.1591 s / img. ETA=1:03:16
[07/01 08:27:05] detectron2 INFO: Inference done 2960/26446. 0.1592 s / img. ETA=1:03:13
[07/01 08:27:10] detectron2 INFO: Inference done 2990/26446. 0.1593 s / img. ETA=1:03:10
[07/01 08:27:15] detectron2 INFO: Inference done 3021/26446. 0.1593 s / img. ETA=1:03:06
[07/01 08:27:20] detectron2 INFO: Inference done 3052/26446. 0.1593 s / img. ETA=1:03:01
[07/01 08:27:26] detectron2 INFO: Inference done 3083/26446. 0.1594 s / img. ETA=1:02:57
[07/01 08:27:31] detectron2 INFO: Inference done 3114/26446. 0.1594 s / img. ETA=1:02:53
[07/01 08:27:36] detectron2 INFO: Inference done 3143/26446. 0.1595 s / img. ETA=1:02:51
[07/01 08:27:41] detectron2 INFO: Inference done 3175/26446. 0.1595 s / img. ETA=1:02:45
[07/01 08:27:46] detectron2 INFO: Inference done 3207/26446. 0.1595 s / img. ETA=1:02:40
[07/01 08:27:51] detectron2 INFO: Inference done 3239/26446. 0.1595 s / img. ETA=1:02:34
[07/01 08:27:56] detectron2 INFO: Inference done 3271/26446. 0.1594 s / img. ETA=1:02:28
[07/01 08:28:01] detectron2 INFO: Inference done 3303/26446. 0.1594 s / img. ETA=1:02:22
[07/01 08:28:06] detectron2 INFO: Inference done 3336/26446. 0.1593 s / img. ETA=1:02:16
[07/01 08:28:11] detectron2 INFO: Inference done 3367/26446. 0.1594 s / img. ETA=1:02:11
[07/01 08:28:17] detectron2 INFO: Inference done 3398/26446. 0.1594 s / img. ETA=1:02:06
[07/01 08:28:22] detectron2 INFO: Inference done 3430/26446. 0.1593 s / img. ETA=1:02:00
[07/01 08:28:27] detectron2 INFO: Inference done 3462/26446. 0.1593 s / img. ETA=1:01:54
[07/01 08:28:32] detectron2 INFO: Inference done 3493/26446. 0.1593 s / img. ETA=1:01:49
[07/01 08:28:37] detectron2 INFO: Inference done 3524/26446. 0.1593 s / img. ETA=1:01:44
[07/01 08:28:42] detectron2 INFO: Inference done 3555/26446. 0.1593 s / img. ETA=1:01:39
[07/01 08:28:47] detectron2 INFO: Inference done 3587/26446. 0.1593 s / img. ETA=1:01:34
[07/01 08:28:52] detectron2 INFO: Inference done 3617/26446. 0.1593 s / img. ETA=1:01:30
[07/01 08:28:57] detectron2 INFO: Inference done 3648/26446. 0.1594 s / img. ETA=1:01:26
[07/01 08:29:02] detectron2 INFO: Inference done 3680/26446. 0.1594 s / img. ETA=1:01:20
[07/01 08:29:07] detectron2 INFO: Inference done 3712/26446. 0.1593 s / img. ETA=1:01:15
[07/01 08:29:12] detectron2 INFO: Inference done 3743/26446. 0.1593 s / img. ETA=1:01:10
[07/01 08:29:17] detectron2 INFO: Inference done 3774/26446. 0.1594 s / img. ETA=1:01:05
[07/01 08:29:22] detectron2 INFO: Inference done 3805/26446. 0.1594 s / img. ETA=1:01:01
[07/01 08:29:27] detectron2 INFO: Inference done 3835/26446. 0.1595 s / img. ETA=1:00:57
[07/01 08:29:33] detectron2 INFO: Inference done 3867/26446. 0.1594 s / img. ETA=1:00:52
[07/01 08:29:38] detectron2 INFO: Inference done 3899/26446. 0.1594 s / img. ETA=1:00:46
[07/01 08:29:43] detectron2 INFO: Inference done 3930/26446. 0.1594 s / img. ETA=1:00:41
[07/01 08:29:48] detectron2 INFO: Inference done 3961/26446. 0.1594 s / img. ETA=1:00:37
[07/01 08:29:53] detectron2 INFO: Inference done 3993/26446. 0.1594 s / img. ETA=1:00:31
[07/01 08:29:58] detectron2 INFO: Inference done 4025/26446. 0.1594 s / img. ETA=1:00:26
[07/01 08:30:03] detectron2 INFO: Inference done 4056/26446. 0.1594 s / img. ETA=1:00:22
[07/01 08:30:08] detectron2 INFO: Inference done 4087/26446. 0.1594 s / img. ETA=1:00:16
[07/01 08:30:13] detectron2 INFO: Inference done 4119/26446. 0.1594 s / img. ETA=1:00:11
[07/01 08:30:18] detectron2 INFO: Inference done 4150/26446. 0.1594 s / img. ETA=1:00:06
[07/01 08:30:24] detectron2 INFO: Inference done 4182/26446. 0.1594 s / img. ETA=1:00:01
[07/01 08:30:29] detectron2 INFO: Inference done 4213/26446. 0.1594 s / img. ETA=0:59:56
[07/01 08:30:34] detectron2 INFO: Inference done 4245/26446. 0.1594 s / img. ETA=0:59:51
[07/01 08:30:39] detectron2 INFO: Inference done 4276/26446. 0.1594 s / img. ETA=0:59:46
[07/01 08:30:44] detectron2 INFO: Inference done 4307/26446. 0.1594 s / img. ETA=0:59:41
[07/01 08:30:49] detectron2 INFO: Inference done 4338/26446. 0.1594 s / img. ETA=0:59:36
[07/01 08:30:54] detectron2 INFO: Inference done 4370/26446. 0.1594 s / img. ETA=0:59:31
[07/01 08:30:59] detectron2 INFO: Inference done 4401/26446. 0.1594 s / img. ETA=0:59:25
[07/01 08:31:04] detectron2 INFO: Inference done 4432/26446. 0.1594 s / img. ETA=0:59:20
[07/01 08:31:09] detectron2 INFO: Inference done 4464/26446. 0.1594 s / img. ETA=0:59:15
[07/01 08:31:14] detectron2 INFO: Inference done 4496/26446. 0.1594 s / img. ETA=0:59:10
[07/01 08:31:19] detectron2 INFO: Inference done 4527/26446. 0.1594 s / img. ETA=0:59:05
[07/01 08:31:24] detectron2 INFO: Inference done 4558/26446. 0.1594 s / img. ETA=0:59:00
[07/01 08:31:30] detectron2 INFO: Inference done 4590/26446. 0.1594 s / img. ETA=0:58:55
[07/01 08:31:35] detectron2 INFO: Inference done 4622/26446. 0.1594 s / img. ETA=0:58:49
[07/01 08:31:40] detectron2 INFO: Inference done 4653/26446. 0.1594 s / img. ETA=0:58:44
[07/01 08:31:45] detectron2 INFO: Inference done 4684/26446. 0.1594 s / img. ETA=0:58:39
[07/01 08:31:50] detectron2 INFO: Inference done 4715/26446. 0.1594 s / img. ETA=0:58:35
[07/01 08:31:55] detectron2 INFO: Inference done 4746/26446. 0.1595 s / img. ETA=0:58:30
[07/01 08:32:00] detectron2 INFO: Inference done 4778/26446. 0.1595 s / img. ETA=0:58:25
[07/01 08:32:05] detectron2 INFO: Inference done 4810/26446. 0.1595 s / img. ETA=0:58:20
[07/01 08:32:10] detectron2 INFO: Inference done 4841/26446. 0.1595 s / img. ETA=0:58:15
[07/01 08:32:15] detectron2 INFO: Inference done 4872/26446. 0.1595 s / img. ETA=0:58:10
[07/01 08:32:20] detectron2 INFO: Inference done 4903/26446. 0.1595 s / img. ETA=0:58:05
[07/01 08:32:26] detectron2 INFO: Inference done 4935/26446. 0.1595 s / img. ETA=0:58:00
[07/01 08:32:31] detectron2 INFO: Inference done 4967/26446. 0.1595 s / img. ETA=0:57:54
[07/01 08:32:36] detectron2 INFO: Inference done 4998/26446. 0.1595 s / img. ETA=0:57:50
[07/01 08:32:41] detectron2 INFO: Inference done 5030/26446. 0.1595 s / img. ETA=0:57:44
[07/01 08:32:46] detectron2 INFO: Inference done 5061/26446. 0.1595 s / img. ETA=0:57:39
[07/01 08:32:51] detectron2 INFO: Inference done 5093/26446. 0.1595 s / img. ETA=0:57:34
[07/01 08:32:56] detectron2 INFO: Inference done 5125/26446. 0.1594 s / img. ETA=0:57:28
[07/01 08:33:01] detectron2 INFO: Inference done 5157/26446. 0.1594 s / img. ETA=0:57:23
[07/01 08:33:06] detectron2 INFO: Inference done 5189/26446. 0.1594 s / img. ETA=0:57:18
[07/01 08:33:11] detectron2 INFO: Inference done 5221/26446. 0.1594 s / img. ETA=0:57:12
[07/01 08:33:17] detectron2 INFO: Inference done 5253/26446. 0.1594 s / img. ETA=0:57:07
[07/01 08:33:22] detectron2 INFO: Inference done 5284/26446. 0.1594 s / img. ETA=0:57:02
[07/01 08:33:27] detectron2 INFO: Inference done 5315/26446. 0.1594 s / img. ETA=0:56:57
[07/01 08:33:32] detectron2 INFO: Inference done 5347/26446. 0.1594 s / img. ETA=0:56:52
[07/01 08:33:37] detectron2 INFO: Inference done 5379/26446. 0.1594 s / img. ETA=0:56:47
[07/01 08:33:42] detectron2 INFO: Inference done 5411/26446. 0.1594 s / img. ETA=0:56:41
[07/01 08:33:47] detectron2 INFO: Inference done 5442/26446. 0.1594 s / img. ETA=0:56:37
[07/01 08:33:52] detectron2 INFO: Inference done 5474/26446. 0.1594 s / img. ETA=0:56:31
[07/01 08:33:57] detectron2 INFO: Inference done 5505/26446. 0.1594 s / img. ETA=0:56:26
[07/01 08:34:03] detectron2 INFO: Inference done 5537/26446. 0.1594 s / img. ETA=0:56:21
[07/01 08:34:08] detectron2 INFO: Inference done 5568/26446. 0.1594 s / img. ETA=0:56:16
[07/01 08:34:13] detectron2 INFO: Inference done 5600/26446. 0.1594 s / img. ETA=0:56:11
[07/01 08:34:18] detectron2 INFO: Inference done 5632/26446. 0.1594 s / img. ETA=0:56:05
[07/01 08:34:23] detectron2 INFO: Inference done 5664/26446. 0.1594 s / img. ETA=0:56:00
[07/01 08:34:28] detectron2 INFO: Inference done 5695/26446. 0.1594 s / img. ETA=0:55:55
[07/01 08:34:33] detectron2 INFO: Inference done 5726/26446. 0.1594 s / img. ETA=0:55:50
[07/01 08:34:38] detectron2 INFO: Inference done 5758/26446. 0.1594 s / img. ETA=0:55:44
[07/01 08:34:43] detectron2 INFO: Inference done 5790/26446. 0.1594 s / img. ETA=0:55:39
[07/01 08:34:48] detectron2 INFO: Inference done 5822/26446. 0.1594 s / img. ETA=0:55:34
[07/01 08:34:53] detectron2 INFO: Inference done 5854/26446. 0.1593 s / img. ETA=0:55:28
[07/01 08:34:58] detectron2 INFO: Inference done 5885/26446. 0.1593 s / img. ETA=0:55:23
[07/01 08:35:04] detectron2 INFO: Inference done 5917/26446. 0.1593 s / img. ETA=0:55:18
[07/01 08:35:09] detectron2 INFO: Inference done 5949/26446. 0.1593 s / img. ETA=0:55:12
[07/01 08:35:14] detectron2 INFO: Inference done 5980/26446. 0.1593 s / img. ETA=0:55:07
[07/01 08:35:19] detectron2 INFO: Inference done 6012/26446. 0.1593 s / img. ETA=0:55:02
[07/01 08:35:24] detectron2 INFO: Inference done 6043/26446. 0.1593 s / img. ETA=0:54:57
[07/01 08:35:29] detectron2 INFO: Inference done 6075/26446. 0.1593 s / img. ETA=0:54:52
[07/01 08:35:34] detectron2 INFO: Inference done 6107/26446. 0.1593 s / img. ETA=0:54:46
[07/01 08:35:39] detectron2 INFO: Inference done 6139/26446. 0.1593 s / img. ETA=0:54:41
[07/01 08:35:44] detectron2 INFO: Inference done 6170/26446. 0.1593 s / img. ETA=0:54:36
[07/01 08:35:49] detectron2 INFO: Inference done 6201/26446. 0.1593 s / img. ETA=0:54:31
[07/01 08:35:54] detectron2 INFO: Inference done 6233/26446. 0.1593 s / img. ETA=0:54:25
[07/01 08:35:59] detectron2 INFO: Inference done 6264/26446. 0.1593 s / img. ETA=0:54:21
[07/01 08:36:04] detectron2 INFO: Inference done 6295/26446. 0.1593 s / img. ETA=0:54:16
[07/01 08:36:09] detectron2 INFO: Inference done 6326/26446. 0.1593 s / img. ETA=0:54:11
[07/01 08:36:14] detectron2 INFO: Inference done 6357/26446. 0.1593 s / img. ETA=0:54:06
[07/01 08:36:20] detectron2 INFO: Inference done 6389/26446. 0.1593 s / img. ETA=0:54:01
[07/01 08:36:25] detectron2 INFO: Inference done 6421/26446. 0.1593 s / img. ETA=0:53:55
[07/01 08:36:30] detectron2 INFO: Inference done 6452/26446. 0.1593 s / img. ETA=0:53:50
[07/01 08:36:35] detectron2 INFO: Inference done 6484/26446. 0.1593 s / img. ETA=0:53:45
[07/01 08:36:40] detectron2 INFO: Inference done 6516/26446. 0.1593 s / img. ETA=0:53:40
[07/01 08:36:45] detectron2 INFO: Inference done 6547/26446. 0.1593 s / img. ETA=0:53:35
[07/01 08:36:50] detectron2 INFO: Inference done 6578/26446. 0.1593 s / img. ETA=0:53:30
[07/01 08:36:55] detectron2 INFO: Inference done 6610/26446. 0.1593 s / img. ETA=0:53:25
[07/01 08:37:00] detectron2 INFO: Inference done 6641/26446. 0.1593 s / img. ETA=0:53:20
[07/01 08:37:05] detectron2 INFO: Inference done 6672/26446. 0.1593 s / img. ETA=0:53:15
[07/01 08:37:10] detectron2 INFO: Inference done 6704/26446. 0.1593 s / img. ETA=0:53:09
[07/01 08:37:15] detectron2 INFO: Inference done 6735/26446. 0.1593 s / img. ETA=0:53:05
[07/01 08:37:21] detectron2 INFO: Inference done 6767/26446. 0.1593 s / img. ETA=0:52:59
[07/01 08:37:26] detectron2 INFO: Inference done 6799/26446. 0.1593 s / img. ETA=0:52:54
[07/01 08:37:31] detectron2 INFO: Inference done 6831/26446. 0.1592 s / img. ETA=0:52:48
[07/01 08:37:36] detectron2 INFO: Inference done 6862/26446. 0.1592 s / img. ETA=0:52:43
[07/01 08:37:41] detectron2 INFO: Inference done 6894/26446. 0.1592 s / img. ETA=0:52:38
[07/01 08:37:46] detectron2 INFO: Inference done 6925/26446. 0.1592 s / img. ETA=0:52:33
[07/01 08:37:51] detectron2 INFO: Inference done 6957/26446. 0.1592 s / img. ETA=0:52:28
[07/01 08:37:56] detectron2 INFO: Inference done 6989/26446. 0.1592 s / img. ETA=0:52:23
[07/01 08:38:01] detectron2 INFO: Inference done 7021/26446. 0.1592 s / img. ETA=0:52:17
[07/01 08:38:06] detectron2 INFO: Inference done 7053/26446. 0.1592 s / img. ETA=0:52:12
[07/01 08:38:11] detectron2 INFO: Inference done 7084/26446. 0.1592 s / img. ETA=0:52:07
[07/01 08:38:16] detectron2 INFO: Inference done 7115/26446. 0.1592 s / img. ETA=0:52:02
[07/01 08:38:21] detectron2 INFO: Inference done 7146/26446. 0.1592 s / img. ETA=0:51:57
[07/01 08:38:27] detectron2 INFO: Inference done 7178/26446. 0.1592 s / img. ETA=0:51:52
[07/01 08:38:32] detectron2 INFO: Inference done 7209/26446. 0.1592 s / img. ETA=0:51:47
[07/01 08:38:37] detectron2 INFO: Inference done 7241/26446. 0.1592 s / img. ETA=0:51:42
[07/01 08:38:42] detectron2 INFO: Inference done 7272/26446. 0.1592 s / img. ETA=0:51:37
[07/01 08:38:47] detectron2 INFO: Inference done 7304/26446. 0.1592 s / img. ETA=0:51:32
[07/01 08:38:52] detectron2 INFO: Inference done 7335/26446. 0.1593 s / img. ETA=0:51:27
[07/01 08:38:57] detectron2 INFO: Inference done 7366/26446. 0.1593 s / img. ETA=0:51:22
[07/01 08:39:02] detectron2 INFO: Inference done 7398/26446. 0.1593 s / img. ETA=0:51:17
[07/01 08:39:08] detectron2 INFO: Inference done 7430/26446. 0.1592 s / img. ETA=0:51:12
[07/01 08:39:13] detectron2 INFO: Inference done 7461/26446. 0.1593 s / img. ETA=0:51:07
[07/01 08:39:18] detectron2 INFO: Inference done 7493/26446. 0.1592 s / img. ETA=0:51:01
[07/01 08:39:23] detectron2 INFO: Inference done 7524/26446. 0.1593 s / img. ETA=0:50:57
[07/01 08:39:28] detectron2 INFO: Inference done 7556/26446. 0.1592 s / img. ETA=0:50:51
[07/01 08:39:33] detectron2 INFO: Inference done 7588/26446. 0.1592 s / img. ETA=0:50:46
[07/01 08:39:38] detectron2 INFO: Inference done 7620/26446. 0.1592 s / img. ETA=0:50:41
[07/01 08:39:43] detectron2 INFO: Inference done 7653/26446. 0.1592 s / img. ETA=0:50:35
[07/01 08:39:48] detectron2 INFO: Inference done 7685/26446. 0.1592 s / img. ETA=0:50:30
[07/01 08:39:53] detectron2 INFO: Inference done 7717/26446. 0.1592 s / img. ETA=0:50:24
[07/01 08:39:59] detectron2 INFO: Inference done 7748/26446. 0.1592 s / img. ETA=0:50:20
[07/01 08:40:04] detectron2 INFO: Inference done 7780/26446. 0.1592 s / img. ETA=0:50:14
[07/01 08:40:09] detectron2 INFO: Inference done 7811/26446. 0.1592 s / img. ETA=0:50:09
[07/01 08:40:14] detectron2 INFO: Inference done 7842/26446. 0.1592 s / img. ETA=0:50:04
[07/01 08:40:19] detectron2 INFO: Inference done 7873/26446. 0.1592 s / img. ETA=0:49:59
[07/01 08:40:24] detectron2 INFO: Inference done 7905/26446. 0.1592 s / img. ETA=0:49:54
[07/01 08:40:29] detectron2 INFO: Inference done 7936/26446. 0.1592 s / img. ETA=0:49:49
[07/01 08:40:34] detectron2 INFO: Inference done 7968/26446. 0.1592 s / img. ETA=0:49:44
[07/01 08:40:39] detectron2 INFO: Inference done 8000/26446. 0.1592 s / img. ETA=0:49:39
[07/01 08:40:44] detectron2 INFO: Inference done 8032/26446. 0.1592 s / img. ETA=0:49:33
[07/01 08:40:49] detectron2 INFO: Inference done 8064/26446. 0.1592 s / img. ETA=0:49:28
[07/01 08:40:55] detectron2 INFO: Inference done 8095/26446. 0.1592 s / img. ETA=0:49:23
[07/01 08:41:00] detectron2 INFO: Inference done 8127/26446. 0.1592 s / img. ETA=0:49:18
[07/01 08:41:05] detectron2 INFO: Inference done 8159/26446. 0.1592 s / img. ETA=0:49:13
[07/01 08:41:10] detectron2 INFO: Inference done 8191/26446. 0.1592 s / img. ETA=0:49:08
[07/01 08:41:15] detectron2 INFO: Inference done 8215/26446. 0.1593 s / img. ETA=0:49:07
[07/01 08:41:20] detectron2 INFO: Inference done 8247/26446. 0.1593 s / img. ETA=0:49:01
[07/01 08:41:25] detectron2 INFO: Inference done 8279/26446. 0.1593 s / img. ETA=0:48:56
[07/01 08:41:30] detectron2 INFO: Inference done 8310/26446. 0.1593 s / img. ETA=0:48:51
[07/01 08:41:35] detectron2 INFO: Inference done 8341/26446. 0.1593 s / img. ETA=0:48:46
[07/01 08:41:41] detectron2 INFO: Inference done 8373/26446. 0.1593 s / img. ETA=0:48:41
[07/01 08:41:46] detectron2 INFO: Inference done 8405/26446. 0.1593 s / img. ETA=0:48:35
[07/01 08:41:51] detectron2 INFO: Inference done 8437/26446. 0.1593 s / img. ETA=0:48:30
[07/01 08:41:56] detectron2 INFO: Inference done 8468/26446. 0.1593 s / img. ETA=0:48:25
[07/01 08:42:01] detectron2 INFO: Inference done 8500/26446. 0.1593 s / img. ETA=0:48:20
[07/01 08:42:06] detectron2 INFO: Inference done 8530/26446. 0.1593 s / img. ETA=0:48:16
[07/01 08:42:11] detectron2 INFO: Inference done 8562/26446. 0.1593 s / img. ETA=0:48:10
[07/01 08:42:16] detectron2 INFO: Inference done 8594/26446. 0.1593 s / img. ETA=0:48:05
[07/01 08:42:21] detectron2 INFO: Inference done 8625/26446. 0.1593 s / img. ETA=0:48:00
[07/01 08:42:26] detectron2 INFO: Inference done 8657/26446. 0.1593 s / img. ETA=0:47:55
[07/01 08:42:31] detectron2 INFO: Inference done 8689/26446. 0.1593 s / img. ETA=0:47:49
[07/01 08:42:36] detectron2 INFO: Inference done 8720/26446. 0.1593 s / img. ETA=0:47:44
[07/01 08:42:42] detectron2 INFO: Inference done 8751/26446. 0.1593 s / img. ETA=0:47:40
[07/01 08:42:47] detectron2 INFO: Inference done 8783/26446. 0.1593 s / img. ETA=0:47:34
[07/01 08:42:52] detectron2 INFO: Inference done 8815/26446. 0.1593 s / img. ETA=0:47:29
[07/01 08:42:57] detectron2 INFO: Inference done 8847/26446. 0.1593 s / img. ETA=0:47:24
[07/01 08:43:02] detectron2 INFO: Inference done 8878/26446. 0.1593 s / img. ETA=0:47:19
[07/01 08:43:07] detectron2 INFO: Inference done 8909/26446. 0.1593 s / img. ETA=0:47:14
[07/01 08:43:12] detectron2 INFO: Inference done 8941/26446. 0.1593 s / img. ETA=0:47:09
[07/01 08:43:17] detectron2 INFO: Inference done 8973/26446. 0.1593 s / img. ETA=0:47:04
[07/01 08:43:23] detectron2 INFO: Inference done 9005/26446. 0.1593 s / img. ETA=0:46:58
[07/01 08:43:28] detectron2 INFO: Inference done 9036/26446. 0.1593 s / img. ETA=0:46:53
[07/01 08:43:33] detectron2 INFO: Inference done 9068/26446. 0.1593 s / img. ETA=0:46:48
[07/01 08:43:38] detectron2 INFO: Inference done 9100/26446. 0.1593 s / img. ETA=0:46:43
[07/01 08:43:43] detectron2 INFO: Inference done 9131/26446. 0.1593 s / img. ETA=0:46:38
[07/01 08:43:48] detectron2 INFO: Inference done 9163/26446. 0.1593 s / img. ETA=0:46:33
[07/01 08:43:53] detectron2 INFO: Inference done 9194/26446. 0.1593 s / img. ETA=0:46:28
[07/01 08:43:58] detectron2 INFO: Inference done 9225/26446. 0.1593 s / img. ETA=0:46:23
[07/01 08:44:03] detectron2 INFO: Inference done 9257/26446. 0.1593 s / img. ETA=0:46:18
[07/01 08:44:08] detectron2 INFO: Inference done 9288/26446. 0.1593 s / img. ETA=0:46:13
[07/01 08:44:13] detectron2 INFO: Inference done 9320/26446. 0.1593 s / img. ETA=0:46:07
[07/01 08:44:18] detectron2 INFO: Inference done 9350/26446. 0.1593 s / img. ETA=0:46:03
[07/01 08:44:23] detectron2 INFO: Inference done 9380/26446. 0.1593 s / img. ETA=0:45:58
[07/01 08:44:28] detectron2 INFO: Inference done 9411/26446. 0.1593 s / img. ETA=0:45:53
[07/01 08:44:33] detectron2 INFO: Inference done 9442/26446. 0.1593 s / img. ETA=0:45:48
[07/01 08:44:38] detectron2 INFO: Inference done 9473/26446. 0.1593 s / img. ETA=0:45:43
[07/01 08:44:44] detectron2 INFO: Inference done 9505/26446. 0.1593 s / img. ETA=0:45:38
[07/01 08:44:49] detectron2 INFO: Inference done 9537/26446. 0.1593 s / img. ETA=0:45:33
[07/01 08:44:54] detectron2 INFO: Inference done 9568/26446. 0.1593 s / img. ETA=0:45:28
[07/01 08:44:59] detectron2 INFO: Inference done 9599/26446. 0.1593 s / img. ETA=0:45:23
[07/01 08:45:04] detectron2 INFO: Inference done 9630/26446. 0.1593 s / img. ETA=0:45:18
[07/01 08:45:09] detectron2 INFO: Inference done 9661/26446. 0.1593 s / img. ETA=0:45:13
[07/01 08:45:14] detectron2 INFO: Inference done 9692/26446. 0.1593 s / img. ETA=0:45:08
[07/01 08:45:19] detectron2 INFO: Inference done 9723/26446. 0.1593 s / img. ETA=0:45:03
[07/01 08:45:24] detectron2 INFO: Inference done 9754/26446. 0.1593 s / img. ETA=0:44:58
[07/01 08:45:29] detectron2 INFO: Inference done 9785/26446. 0.1594 s / img. ETA=0:44:53
[07/01 08:45:34] detectron2 INFO: Inference done 9816/26446. 0.1594 s / img. ETA=0:44:48
[07/01 08:45:39] detectron2 INFO: Inference done 9848/26446. 0.1594 s / img. ETA=0:44:43
[07/01 08:45:44] detectron2 INFO: Inference done 9879/26446. 0.1594 s / img. ETA=0:44:38
[07/01 08:45:49] detectron2 INFO: Inference done 9911/26446. 0.1594 s / img. ETA=0:44:33
[07/01 08:45:54] detectron2 INFO: Inference done 9942/26446. 0.1594 s / img. ETA=0:44:28
[07/01 08:46:00] detectron2 INFO: Inference done 9974/26446. 0.1594 s / img. ETA=0:44:23
[07/01 08:46:05] detectron2 INFO: Inference done 10005/26446. 0.1594 s / img. ETA=0:44:18
[07/01 08:46:10] detectron2 INFO: Inference done 10037/26446. 0.1594 s / img. ETA=0:44:12
[07/01 08:46:15] detectron2 INFO: Inference done 10068/26446. 0.1594 s / img. ETA=0:44:07
[07/01 08:46:20] detectron2 INFO: Inference done 10099/26446. 0.1594 s / img. ETA=0:44:02
[07/01 08:46:25] detectron2 INFO: Inference done 10131/26446. 0.1594 s / img. ETA=0:43:57
[07/01 08:46:30] detectron2 INFO: Inference done 10162/26446. 0.1594 s / img. ETA=0:43:52
[07/01 08:46:35] detectron2 INFO: Inference done 10194/26446. 0.1594 s / img. ETA=0:43:47
[07/01 08:46:40] detectron2 INFO: Inference done 10224/26446. 0.1594 s / img. ETA=0:43:42
[07/01 08:46:45] detectron2 INFO: Inference done 10256/26446. 0.1594 s / img. ETA=0:43:37
[07/01 08:46:50] detectron2 INFO: Inference done 10287/26446. 0.1594 s / img. ETA=0:43:32
[07/01 08:46:55] detectron2 INFO: Inference done 10319/26446. 0.1594 s / img. ETA=0:43:27
[07/01 08:47:01] detectron2 INFO: Inference done 10351/26446. 0.1594 s / img. ETA=0:43:22
[07/01 08:47:06] detectron2 INFO: Inference done 10382/26446. 0.1594 s / img. ETA=0:43:17
[07/01 08:47:11] detectron2 INFO: Inference done 10413/26446. 0.1594 s / img. ETA=0:43:12
[07/01 08:47:16] detectron2 INFO: Inference done 10445/26446. 0.1594 s / img. ETA=0:43:07
[07/01 08:47:21] detectron2 INFO: Inference done 10475/26446. 0.1594 s / img. ETA=0:43:02
[07/01 08:47:26] detectron2 INFO: Inference done 10506/26446. 0.1594 s / img. ETA=0:42:57
[07/01 08:47:31] detectron2 INFO: Inference done 10537/26446. 0.1594 s / img. ETA=0:42:52
[07/01 08:47:36] detectron2 INFO: Inference done 10569/26446. 0.1594 s / img. ETA=0:42:47
[07/01 08:47:41] detectron2 INFO: Inference done 10601/26446. 0.1594 s / img. ETA=0:42:42
[07/01 08:47:46] detectron2 INFO: Inference done 10632/26446. 0.1594 s / img. ETA=0:42:37
[07/01 08:47:51] detectron2 INFO: Inference done 10663/26446. 0.1594 s / img. ETA=0:42:32
[07/01 08:47:57] detectron2 INFO: Inference done 10695/26446. 0.1594 s / img. ETA=0:42:27
[07/01 08:48:02] detectron2 INFO: Inference done 10726/26446. 0.1594 s / img. ETA=0:42:22
[07/01 08:48:07] detectron2 INFO: Inference done 10758/26446. 0.1594 s / img. ETA=0:42:16
[07/01 08:48:12] detectron2 INFO: Inference done 10790/26446. 0.1594 s / img. ETA=0:42:11
[07/01 08:48:17] detectron2 INFO: Inference done 10821/26446. 0.1594 s / img. ETA=0:42:06
[07/01 08:48:22] detectron2 INFO: Inference done 10853/26446. 0.1594 s / img. ETA=0:42:01
[07/01 08:48:27] detectron2 INFO: Inference done 10885/26446. 0.1594 s / img. ETA=0:41:56
[07/01 08:48:32] detectron2 INFO: Inference done 10916/26446. 0.1594 s / img. ETA=0:41:51
[07/01 08:48:37] detectron2 INFO: Inference done 10947/26446. 0.1594 s / img. ETA=0:41:46
[07/01 08:48:42] detectron2 INFO: Inference done 10978/26446. 0.1594 s / img. ETA=0:41:41
[07/01 08:48:47] detectron2 INFO: Inference done 11009/26446. 0.1594 s / img. ETA=0:41:36
[07/01 08:48:52] detectron2 INFO: Inference done 11041/26446. 0.1594 s / img. ETA=0:41:30
[07/01 08:48:58] detectron2 INFO: Inference done 11073/26446. 0.1594 s / img. ETA=0:41:25
[07/01 08:49:03] detectron2 INFO: Inference done 11105/26446. 0.1594 s / img. ETA=0:41:20
[07/01 08:49:08] detectron2 INFO: Inference done 11136/26446. 0.1594 s / img. ETA=0:41:15
[07/01 08:49:13] detectron2 INFO: Inference done 11167/26446. 0.1594 s / img. ETA=0:41:10
[07/01 08:49:18] detectron2 INFO: Inference done 11198/26446. 0.1594 s / img. ETA=0:41:05
[07/01 08:49:23] detectron2 INFO: Inference done 11230/26446. 0.1594 s / img. ETA=0:41:00
[07/01 08:49:28] detectron2 INFO: Inference done 11260/26446. 0.1594 s / img. ETA=0:40:55
[07/01 08:49:33] detectron2 INFO: Inference done 11292/26446. 0.1594 s / img. ETA=0:40:50
[07/01 08:49:38] detectron2 INFO: Inference done 11323/26446. 0.1594 s / img. ETA=0:40:45
[07/01 08:49:43] detectron2 INFO: Inference done 11355/26446. 0.1594 s / img. ETA=0:40:40
[07/01 08:49:49] detectron2 INFO: Inference done 11387/26446. 0.1594 s / img. ETA=0:40:35
[07/01 08:49:54] detectron2 INFO: Inference done 11419/26446. 0.1594 s / img. ETA=0:40:30
[07/01 08:49:59] detectron2 INFO: Inference done 11450/26446. 0.1594 s / img. ETA=0:40:25
[07/01 08:50:04] detectron2 INFO: Inference done 11481/26446. 0.1594 s / img. ETA=0:40:20
[07/01 08:50:09] detectron2 INFO: Inference done 11513/26446. 0.1594 s / img. ETA=0:40:14
[07/01 08:50:14] detectron2 INFO: Inference done 11545/26446. 0.1594 s / img. ETA=0:40:09
[07/01 08:50:19] detectron2 INFO: Inference done 11576/26446. 0.1594 s / img. ETA=0:40:04
[07/01 08:50:24] detectron2 INFO: Inference done 11607/26446. 0.1594 s / img. ETA=0:39:59
[07/01 08:50:29] detectron2 INFO: Inference done 11638/26446. 0.1594 s / img. ETA=0:39:54
[07/01 08:50:34] detectron2 INFO: Inference done 11669/26446. 0.1594 s / img. ETA=0:39:49
[07/01 08:50:39] detectron2 INFO: Inference done 11701/26446. 0.1594 s / img. ETA=0:39:44
[07/01 08:50:44] detectron2 INFO: Inference done 11732/26446. 0.1594 s / img. ETA=0:39:39
[07/01 08:50:50] detectron2 INFO: Inference done 11763/26446. 0.1594 s / img. ETA=0:39:34
[07/01 08:50:55] detectron2 INFO: Inference done 11794/26446. 0.1594 s / img. ETA=0:39:29
[07/01 08:51:00] detectron2 INFO: Inference done 11826/26446. 0.1594 s / img. ETA=0:39:24
[07/01 08:51:05] detectron2 INFO: Inference done 11858/26446. 0.1594 s / img. ETA=0:39:19
[07/01 08:51:10] detectron2 INFO: Inference done 11889/26446. 0.1594 s / img. ETA=0:39:14
[07/01 08:51:15] detectron2 INFO: Inference done 11920/26446. 0.1594 s / img. ETA=0:39:09
[07/01 08:51:20] detectron2 INFO: Inference done 11952/26446. 0.1594 s / img. ETA=0:39:03
[07/01 08:51:25] detectron2 INFO: Inference done 11984/26446. 0.1594 s / img. ETA=0:38:58
[07/01 08:51:30] detectron2 INFO: Inference done 12015/26446. 0.1594 s / img. ETA=0:38:53
[07/01 08:51:35] detectron2 INFO: Inference done 12047/26446. 0.1594 s / img. ETA=0:38:48
[07/01 08:51:40] detectron2 INFO: Inference done 12077/26446. 0.1594 s / img. ETA=0:38:44
[07/01 08:51:46] detectron2 INFO: Inference done 12107/26446. 0.1594 s / img. ETA=0:38:39
[07/01 08:51:51] detectron2 INFO: Inference done 12138/26446. 0.1595 s / img. ETA=0:38:34
[07/01 08:51:56] detectron2 INFO: Inference done 12169/26446. 0.1595 s / img. ETA=0:38:29
[07/01 08:52:01] detectron2 INFO: Inference done 12200/26446. 0.1595 s / img. ETA=0:38:24
[07/01 08:52:06] detectron2 INFO: Inference done 12232/26446. 0.1595 s / img. ETA=0:38:19
[07/01 08:52:11] detectron2 INFO: Inference done 12264/26446. 0.1594 s / img. ETA=0:38:14
[07/01 08:52:16] detectron2 INFO: Inference done 12293/26446. 0.1595 s / img. ETA=0:38:09
[07/01 08:52:21] detectron2 INFO: Inference done 12316/26446. 0.1596 s / img. ETA=0:38:07
[07/01 08:52:26] detectron2 INFO: Inference done 12344/26446. 0.1596 s / img. ETA=0:38:03
[07/01 08:52:31] detectron2 INFO: Inference done 12375/26446. 0.1596 s / img. ETA=0:37:58
[07/01 08:52:36] detectron2 INFO: Inference done 12406/26446. 0.1596 s / img. ETA=0:37:53
[07/01 08:52:41] detectron2 INFO: Inference done 12436/26446. 0.1597 s / img. ETA=0:37:49
[07/01 08:52:47] detectron2 INFO: Inference done 12467/26446. 0.1597 s / img. ETA=0:37:44
[07/01 08:52:52] detectron2 INFO: Inference done 12498/26446. 0.1597 s / img. ETA=0:37:39
[07/01 08:52:57] detectron2 INFO: Inference done 12529/26446. 0.1597 s / img. ETA=0:37:34
[07/01 08:53:02] detectron2 INFO: Inference done 12560/26446. 0.1597 s / img. ETA=0:37:29
[07/01 08:53:07] detectron2 INFO: Inference done 12591/26446. 0.1597 s / img. ETA=0:37:24
[07/01 08:53:12] detectron2 INFO: Inference done 12622/26446. 0.1597 s / img. ETA=0:37:19
[07/01 08:53:17] detectron2 INFO: Inference done 12654/26446. 0.1597 s / img. ETA=0:37:14
[07/01 08:53:22] detectron2 INFO: Inference done 12685/26446. 0.1597 s / img. ETA=0:37:09
[07/01 08:53:27] detectron2 INFO: Inference done 12716/26446. 0.1597 s / img. ETA=0:37:04
[07/01 08:53:32] detectron2 INFO: Inference done 12747/26446. 0.1597 s / img. ETA=0:36:59
[07/01 08:53:37] detectron2 INFO: Inference done 12778/26446. 0.1597 s / img. ETA=0:36:54
[07/01 08:53:42] detectron2 INFO: Inference done 12809/26446. 0.1597 s / img. ETA=0:36:49
[07/01 08:53:47] detectron2 INFO: Inference done 12840/26446. 0.1597 s / img. ETA=0:36:44
[07/01 08:53:52] detectron2 INFO: Inference done 12871/26446. 0.1597 s / img. ETA=0:36:39
[07/01 08:53:58] detectron2 INFO: Inference done 12902/26446. 0.1597 s / img. ETA=0:36:34
[07/01 08:54:03] detectron2 INFO: Inference done 12933/26446. 0.1597 s / img. ETA=0:36:29
[07/01 08:54:08] detectron2 INFO: Inference done 12964/26446. 0.1597 s / img. ETA=0:36:24
[07/01 08:54:13] detectron2 INFO: Inference done 12996/26446. 0.1597 s / img. ETA=0:36:19
[07/01 08:54:18] detectron2 INFO: Inference done 13027/26446. 0.1597 s / img. ETA=0:36:14
[07/01 08:54:23] detectron2 INFO: Inference done 13058/26446. 0.1597 s / img. ETA=0:36:09
[07/01 08:54:28] detectron2 INFO: Inference done 13089/26446. 0.1597 s / img. ETA=0:36:04
[07/01 08:54:33] detectron2 INFO: Inference done 13120/26446. 0.1597 s / img. ETA=0:35:59
[07/01 08:54:38] detectron2 INFO: Inference done 13151/26446. 0.1597 s / img. ETA=0:35:54
[07/01 08:54:43] detectron2 INFO: Inference done 13184/26446. 0.1597 s / img. ETA=0:35:48
[07/01 08:54:48] detectron2 INFO: Inference done 13215/26446. 0.1597 s / img. ETA=0:35:43
[07/01 08:54:53] detectron2 INFO: Inference done 13247/26446. 0.1597 s / img. ETA=0:35:38
[07/01 08:54:58] detectron2 INFO: Inference done 13279/26446. 0.1597 s / img. ETA=0:35:33
[07/01 08:55:03] detectron2 INFO: Inference done 13310/26446. 0.1597 s / img. ETA=0:35:28
[07/01 08:55:08] detectron2 INFO: Inference done 13341/26446. 0.1597 s / img. ETA=0:35:23
[07/01 08:55:13] detectron2 INFO: Inference done 13372/26446. 0.1597 s / img. ETA=0:35:17
[07/01 08:55:19] detectron2 INFO: Inference done 13402/26446. 0.1597 s / img. ETA=0:35:13
[07/01 08:55:24] detectron2 INFO: Inference done 13433/26446. 0.1597 s / img. ETA=0:35:08
[07/01 08:55:29] detectron2 INFO: Inference done 13465/26446. 0.1597 s / img. ETA=0:35:03
[07/01 08:55:34] detectron2 INFO: Inference done 13497/26446. 0.1597 s / img. ETA=0:34:57
[07/01 08:55:39] detectron2 INFO: Inference done 13529/26446. 0.1597 s / img. ETA=0:34:52
[07/01 08:55:44] detectron2 INFO: Inference done 13561/26446. 0.1597 s / img. ETA=0:34:47
[07/01 08:55:49] detectron2 INFO: Inference done 13592/26446. 0.1597 s / img. ETA=0:34:42
[07/01 08:55:54] detectron2 INFO: Inference done 13623/26446. 0.1597 s / img. ETA=0:34:37
[07/01 08:55:59] detectron2 INFO: Inference done 13654/26446. 0.1597 s / img. ETA=0:34:32
[07/01 08:56:04] detectron2 INFO: Inference done 13686/26446. 0.1597 s / img. ETA=0:34:27
[07/01 08:56:09] detectron2 INFO: Inference done 13717/26446. 0.1597 s / img. ETA=0:34:22
[07/01 08:56:15] detectron2 INFO: Inference done 13749/26446. 0.1597 s / img. ETA=0:34:16
[07/01 08:56:20] detectron2 INFO: Inference done 13780/26446. 0.1597 s / img. ETA=0:34:11
[07/01 08:56:25] detectron2 INFO: Inference done 13811/26446. 0.1597 s / img. ETA=0:34:07
[07/01 08:56:30] detectron2 INFO: Inference done 13842/26446. 0.1597 s / img. ETA=0:34:02
[07/01 08:56:35] detectron2 INFO: Inference done 13874/26446. 0.1597 s / img. ETA=0:33:56
[07/01 08:56:40] detectron2 INFO: Inference done 13905/26446. 0.1597 s / img. ETA=0:33:51
[07/01 08:56:45] detectron2 INFO: Inference done 13937/26446. 0.1597 s / img. ETA=0:33:46
[07/01 08:56:50] detectron2 INFO: Inference done 13968/26446. 0.1597 s / img. ETA=0:33:41
[07/01 08:56:55] detectron2 INFO: Inference done 13999/26446. 0.1597 s / img. ETA=0:33:36
[07/01 08:57:00] detectron2 INFO: Inference done 14030/26446. 0.1597 s / img. ETA=0:33:31
[07/01 08:57:05] detectron2 INFO: Inference done 14061/26446. 0.1597 s / img. ETA=0:33:26
[07/01 08:57:10] detectron2 INFO: Inference done 14092/26446. 0.1597 s / img. ETA=0:33:21
[07/01 08:57:15] detectron2 INFO: Inference done 14123/26446. 0.1597 s / img. ETA=0:33:16
[07/01 08:57:20] detectron2 INFO: Inference done 14154/26446. 0.1597 s / img. ETA=0:33:11
[07/01 08:57:26] detectron2 INFO: Inference done 14186/26446. 0.1597 s / img. ETA=0:33:06
[07/01 08:57:31] detectron2 INFO: Inference done 14216/26446. 0.1597 s / img. ETA=0:33:01
[07/01 08:57:36] detectron2 INFO: Inference done 14248/26446. 0.1597 s / img. ETA=0:32:56
[07/01 08:57:41] detectron2 INFO: Inference done 14279/26446. 0.1597 s / img. ETA=0:32:51
[07/01 08:57:46] detectron2 INFO: Inference done 14310/26446. 0.1597 s / img. ETA=0:32:46
[07/01 08:57:51] detectron2 INFO: Inference done 14341/26446. 0.1597 s / img. ETA=0:32:41
[07/01 08:57:56] detectron2 INFO: Inference done 14373/26446. 0.1597 s / img. ETA=0:32:36
[07/01 08:58:01] detectron2 INFO: Inference done 14404/26446. 0.1597 s / img. ETA=0:32:31
[07/01 08:58:06] detectron2 INFO: Inference done 14436/26446. 0.1597 s / img. ETA=0:32:25
[07/01 08:58:11] detectron2 INFO: Inference done 14468/26446. 0.1597 s / img. ETA=0:32:20
[07/01 08:58:16] detectron2 INFO: Inference done 14500/26446. 0.1597 s / img. ETA=0:32:15
[07/01 08:58:21] detectron2 INFO: Inference done 14531/26446. 0.1597 s / img. ETA=0:32:10
[07/01 08:58:27] detectron2 INFO: Inference done 14563/26446. 0.1597 s / img. ETA=0:32:05
[07/01 08:58:32] detectron2 INFO: Inference done 14595/26446. 0.1597 s / img. ETA=0:32:00
[07/01 08:58:37] detectron2 INFO: Inference done 14626/26446. 0.1597 s / img. ETA=0:31:55
[07/01 08:58:42] detectron2 INFO: Inference done 14657/26446. 0.1597 s / img. ETA=0:31:50
[07/01 08:58:47] detectron2 INFO: Inference done 14688/26446. 0.1597 s / img. ETA=0:31:45
[07/01 08:58:52] detectron2 INFO: Inference done 14719/26446. 0.1597 s / img. ETA=0:31:40
[07/01 08:58:57] detectron2 INFO: Inference done 14750/26446. 0.1597 s / img. ETA=0:31:34
[07/01 08:59:02] detectron2 INFO: Inference done 14781/26446. 0.1597 s / img. ETA=0:31:30
[07/01 08:59:07] detectron2 INFO: Inference done 14813/26446. 0.1597 s / img. ETA=0:31:24
[07/01 08:59:12] detectron2 INFO: Inference done 14845/26446. 0.1597 s / img. ETA=0:31:19
[07/01 08:59:17] detectron2 INFO: Inference done 14877/26446. 0.1597 s / img. ETA=0:31:14
[07/01 08:59:23] detectron2 INFO: Inference done 14909/26446. 0.1597 s / img. ETA=0:31:09
[07/01 08:59:28] detectron2 INFO: Inference done 14941/26446. 0.1597 s / img. ETA=0:31:03
[07/01 08:59:33] detectron2 INFO: Inference done 14972/26446. 0.1597 s / img. ETA=0:30:58
[07/01 08:59:38] detectron2 INFO: Inference done 15003/26446. 0.1597 s / img. ETA=0:30:53
[07/01 08:59:43] detectron2 INFO: Inference done 15034/26446. 0.1597 s / img. ETA=0:30:48
[07/01 08:59:48] detectron2 INFO: Inference done 15066/26446. 0.1597 s / img. ETA=0:30:43
[07/01 08:59:53] detectron2 INFO: Inference done 15097/26446. 0.1597 s / img. ETA=0:30:38
[07/01 08:59:58] detectron2 INFO: Inference done 15129/26446. 0.1597 s / img. ETA=0:30:33
[07/01 09:00:03] detectron2 INFO: Inference done 15159/26446. 0.1597 s / img. ETA=0:30:28
[07/01 09:00:08] detectron2 INFO: Inference done 15191/26446. 0.1597 s / img. ETA=0:30:23
[07/01 09:00:14] detectron2 INFO: Inference done 15223/26446. 0.1597 s / img. ETA=0:30:18
[07/01 09:00:19] detectron2 INFO: Inference done 15254/26446. 0.1597 s / img. ETA=0:30:13
[07/01 09:00:24] detectron2 INFO: Inference done 15285/26446. 0.1597 s / img. ETA=0:30:08
[07/01 09:00:29] detectron2 INFO: Inference done 15316/26446. 0.1597 s / img. ETA=0:30:03
[07/01 09:00:34] detectron2 INFO: Inference done 15347/26446. 0.1597 s / img. ETA=0:29:58
[07/01 09:00:39] detectron2 INFO: Inference done 15378/26446. 0.1597 s / img. ETA=0:29:53
[07/01 09:00:44] detectron2 INFO: Inference done 15409/26446. 0.1597 s / img. ETA=0:29:48
[07/01 09:00:49] detectron2 INFO: Inference done 15440/26446. 0.1597 s / img. ETA=0:29:43
[07/01 09:00:54] detectron2 INFO: Inference done 15471/26446. 0.1597 s / img. ETA=0:29:38
[07/01 09:00:59] detectron2 INFO: Inference done 15503/26446. 0.1597 s / img. ETA=0:29:33
[07/01 09:01:04] detectron2 INFO: Inference done 15534/26446. 0.1597 s / img. ETA=0:29:28
[07/01 09:01:09] detectron2 INFO: Inference done 15565/26446. 0.1597 s / img. ETA=0:29:23
[07/01 09:01:14] detectron2 INFO: Inference done 15597/26446. 0.1597 s / img. ETA=0:29:17
[07/01 09:01:20] detectron2 INFO: Inference done 15628/26446. 0.1597 s / img. ETA=0:29:12
[07/01 09:01:25] detectron2 INFO: Inference done 15660/26446. 0.1597 s / img. ETA=0:29:07
[07/01 09:01:30] detectron2 INFO: Inference done 15691/26446. 0.1597 s / img. ETA=0:29:02
[07/01 09:01:35] detectron2 INFO: Inference done 15722/26446. 0.1597 s / img. ETA=0:28:57
[07/01 09:01:40] detectron2 INFO: Inference done 15753/26446. 0.1597 s / img. ETA=0:28:52
[07/01 09:01:45] detectron2 INFO: Inference done 15784/26446. 0.1597 s / img. ETA=0:28:47
[07/01 09:01:50] detectron2 INFO: Inference done 15815/26446. 0.1597 s / img. ETA=0:28:42
[07/01 09:01:55] detectron2 INFO: Inference done 15846/26446. 0.1597 s / img. ETA=0:28:37
[07/01 09:02:00] detectron2 INFO: Inference done 15877/26446. 0.1597 s / img. ETA=0:28:32
[07/01 09:02:06] detectron2 INFO: Inference done 15905/26446. 0.1598 s / img. ETA=0:28:29
[07/01 09:02:11] detectron2 INFO: Inference done 15937/26446. 0.1598 s / img. ETA=0:28:24
[07/01 09:02:16] detectron2 INFO: Inference done 15968/26446. 0.1598 s / img. ETA=0:28:18
[07/01 09:02:21] detectron2 INFO: Inference done 15999/26446. 0.1598 s / img. ETA=0:28:13
[07/01 09:02:26] detectron2 INFO: Inference done 16030/26446. 0.1598 s / img. ETA=0:28:08
[07/01 09:02:31] detectron2 INFO: Inference done 16061/26446. 0.1598 s / img. ETA=0:28:03
[07/01 09:02:37] detectron2 INFO: Inference done 16093/26446. 0.1598 s / img. ETA=0:27:58
[07/01 09:02:42] detectron2 INFO: Inference done 16124/26446. 0.1598 s / img. ETA=0:27:53
[07/01 09:02:47] detectron2 INFO: Inference done 16155/26446. 0.1598 s / img. ETA=0:27:48
[07/01 09:02:52] detectron2 INFO: Inference done 16187/26446. 0.1598 s / img. ETA=0:27:43
[07/01 09:02:57] detectron2 INFO: Inference done 16218/26446. 0.1598 s / img. ETA=0:27:38
[07/01 09:03:02] detectron2 INFO: Inference done 16249/26446. 0.1598 s / img. ETA=0:27:33
[07/01 09:03:07] detectron2 INFO: Inference done 16280/26446. 0.1598 s / img. ETA=0:27:28
[07/01 09:03:12] detectron2 INFO: Inference done 16312/26446. 0.1598 s / img. ETA=0:27:23
[07/01 09:03:17] detectron2 INFO: Inference done 16343/26446. 0.1598 s / img. ETA=0:27:18
[07/01 09:03:22] detectron2 INFO: Inference done 16374/26446. 0.1598 s / img. ETA=0:27:13
[07/01 09:03:27] detectron2 INFO: Inference done 16406/26446. 0.1598 s / img. ETA=0:27:07
[07/01 09:03:32] detectron2 INFO: Inference done 16437/26446. 0.1598 s / img. ETA=0:27:02
[07/01 09:03:37] detectron2 INFO: Inference done 16468/26446. 0.1598 s / img. ETA=0:26:57
[07/01 09:03:43] detectron2 INFO: Inference done 16499/26446. 0.1598 s / img. ETA=0:26:52
[07/01 09:03:48] detectron2 INFO: Inference done 16530/26446. 0.1598 s / img. ETA=0:26:47
[07/01 09:03:53] detectron2 INFO: Inference done 16562/26446. 0.1598 s / img. ETA=0:26:42
[07/01 09:03:58] detectron2 INFO: Inference done 16594/26446. 0.1598 s / img. ETA=0:26:37
[07/01 09:04:03] detectron2 INFO: Inference done 16625/26446. 0.1598 s / img. ETA=0:26:32
[07/01 09:04:08] detectron2 INFO: Inference done 16656/26446. 0.1598 s / img. ETA=0:26:27
[07/01 09:04:13] detectron2 INFO: Inference done 16688/26446. 0.1598 s / img. ETA=0:26:22
[07/01 09:04:18] detectron2 INFO: Inference done 16719/26446. 0.1598 s / img. ETA=0:26:17
[07/01 09:04:23] detectron2 INFO: Inference done 16751/26446. 0.1598 s / img. ETA=0:26:11
[07/01 09:04:28] detectron2 INFO: Inference done 16783/26446. 0.1598 s / img. ETA=0:26:06
[07/01 09:04:33] detectron2 INFO: Inference done 16814/26446. 0.1598 s / img. ETA=0:26:01
[07/01 09:04:38] detectron2 INFO: Inference done 16845/26446. 0.1598 s / img. ETA=0:25:56
[07/01 09:04:43] detectron2 INFO: Inference done 16876/26446. 0.1598 s / img. ETA=0:25:51
[07/01 09:04:48] detectron2 INFO: Inference done 16908/26446. 0.1598 s / img. ETA=0:25:46
[07/01 09:04:54] detectron2 INFO: Inference done 16940/26446. 0.1598 s / img. ETA=0:25:41
[07/01 09:04:59] detectron2 INFO: Inference done 16970/26446. 0.1598 s / img. ETA=0:25:36
[07/01 09:05:04] detectron2 INFO: Inference done 17001/26446. 0.1598 s / img. ETA=0:25:31
[07/01 09:05:09] detectron2 INFO: Inference done 17032/26446. 0.1598 s / img. ETA=0:25:26
[07/01 09:05:14] detectron2 INFO: Inference done 17063/26446. 0.1598 s / img. ETA=0:25:21
[07/01 09:05:19] detectron2 INFO: Inference done 17094/26446. 0.1598 s / img. ETA=0:25:16
[07/01 09:05:24] detectron2 INFO: Inference done 17126/26446. 0.1598 s / img. ETA=0:25:11
[07/01 09:05:29] detectron2 INFO: Inference done 17158/26446. 0.1598 s / img. ETA=0:25:05
[07/01 09:05:34] detectron2 INFO: Inference done 17190/26446. 0.1598 s / img. ETA=0:25:00
[07/01 09:05:39] detectron2 INFO: Inference done 17221/26446. 0.1598 s / img. ETA=0:24:55
[07/01 09:05:45] detectron2 INFO: Inference done 17253/26446. 0.1598 s / img. ETA=0:24:50
[07/01 09:05:50] detectron2 INFO: Inference done 17283/26446. 0.1598 s / img. ETA=0:24:45
[07/01 09:05:55] detectron2 INFO: Inference done 17312/26446. 0.1598 s / img. ETA=0:24:41
[07/01 09:06:00] detectron2 INFO: Inference done 17342/26446. 0.1598 s / img. ETA=0:24:36
[07/01 09:06:05] detectron2 INFO: Inference done 17373/26446. 0.1598 s / img. ETA=0:24:31
[07/01 09:06:10] detectron2 INFO: Inference done 17404/26446. 0.1599 s / img. ETA=0:24:26
[07/01 09:06:15] detectron2 INFO: Inference done 17434/26446. 0.1599 s / img. ETA=0:24:21
[07/01 09:06:20] detectron2 INFO: Inference done 17466/26446. 0.1599 s / img. ETA=0:24:16
[07/01 09:06:25] detectron2 INFO: Inference done 17498/26446. 0.1598 s / img. ETA=0:24:11
[07/01 09:06:30] detectron2 INFO: Inference done 17529/26446. 0.1598 s / img. ETA=0:24:06
[07/01 09:06:35] detectron2 INFO: Inference done 17560/26446. 0.1598 s / img. ETA=0:24:01
[07/01 09:06:40] detectron2 INFO: Inference done 17590/26446. 0.1599 s / img. ETA=0:23:56
[07/01 09:06:45] detectron2 INFO: Inference done 17620/26446. 0.1599 s / img. ETA=0:23:51
[07/01 09:06:50] detectron2 INFO: Inference done 17651/26446. 0.1599 s / img. ETA=0:23:46
[07/01 09:06:55] detectron2 INFO: Inference done 17682/26446. 0.1599 s / img. ETA=0:23:41
[07/01 09:07:00] detectron2 INFO: Inference done 17714/26446. 0.1599 s / img. ETA=0:23:36
[07/01 09:07:05] detectron2 INFO: Inference done 17746/26446. 0.1599 s / img. ETA=0:23:31
[07/01 09:07:10] detectron2 INFO: Inference done 17776/26446. 0.1599 s / img. ETA=0:23:26
[07/01 09:07:16] detectron2 INFO: Inference done 17808/26446. 0.1599 s / img. ETA=0:23:21
[07/01 09:07:21] detectron2 INFO: Inference done 17839/26446. 0.1599 s / img. ETA=0:23:16
[07/01 09:07:26] detectron2 INFO: Inference done 17871/26446. 0.1599 s / img. ETA=0:23:10
[07/01 09:07:31] detectron2 INFO: Inference done 17902/26446. 0.1599 s / img. ETA=0:23:05
[07/01 09:07:36] detectron2 INFO: Inference done 17934/26446. 0.1599 s / img. ETA=0:23:00
[07/01 09:07:41] detectron2 INFO: Inference done 17965/26446. 0.1599 s / img. ETA=0:22:55
[07/01 09:07:46] detectron2 INFO: Inference done 17997/26446. 0.1599 s / img. ETA=0:22:50
[07/01 09:07:51] detectron2 INFO: Inference done 18029/26446. 0.1599 s / img. ETA=0:22:45
[07/01 09:07:56] detectron2 INFO: Inference done 18060/26446. 0.1599 s / img. ETA=0:22:40
[07/01 09:08:01] detectron2 INFO: Inference done 18092/26446. 0.1598 s / img. ETA=0:22:34
[07/01 09:08:06] detectron2 INFO: Inference done 18124/26446. 0.1598 s / img. ETA=0:22:29
[07/01 09:08:11] detectron2 INFO: Inference done 18155/26446. 0.1598 s / img. ETA=0:22:24
[07/01 09:08:17] detectron2 INFO: Inference done 18186/26446. 0.1598 s / img. ETA=0:22:19
[07/01 09:08:22] detectron2 INFO: Inference done 18218/26446. 0.1598 s / img. ETA=0:22:14
[07/01 09:08:27] detectron2 INFO: Inference done 18250/26446. 0.1598 s / img. ETA=0:22:09
[07/01 09:08:32] detectron2 INFO: Inference done 18281/26446. 0.1598 s / img. ETA=0:22:04
[07/01 09:08:37] detectron2 INFO: Inference done 18312/26446. 0.1598 s / img. ETA=0:21:59
[07/01 09:08:42] detectron2 INFO: Inference done 18342/26446. 0.1598 s / img. ETA=0:21:54
[07/01 09:08:47] detectron2 INFO: Inference done 18373/26446. 0.1599 s / img. ETA=0:21:49
[07/01 09:08:52] detectron2 INFO: Inference done 18404/26446. 0.1599 s / img. ETA=0:21:44
[07/01 09:08:57] detectron2 INFO: Inference done 18434/26446. 0.1599 s / img. ETA=0:21:39
[07/01 09:09:02] detectron2 INFO: Inference done 18464/26446. 0.1599 s / img. ETA=0:21:34
[07/01 09:09:07] detectron2 INFO: Inference done 18494/26446. 0.1599 s / img. ETA=0:21:29
[07/01 09:09:12] detectron2 INFO: Inference done 18524/26446. 0.1599 s / img. ETA=0:21:25
[07/01 09:09:17] detectron2 INFO: Inference done 18554/26446. 0.1599 s / img. ETA=0:21:20
[07/01 09:09:23] detectron2 INFO: Inference done 18584/26446. 0.1599 s / img. ETA=0:21:15
[07/01 09:09:28] detectron2 INFO: Inference done 18615/26446. 0.1599 s / img. ETA=0:21:10
[07/01 09:09:33] detectron2 INFO: Inference done 18645/26446. 0.1599 s / img. ETA=0:21:05
[07/01 09:09:38] detectron2 INFO: Inference done 18676/26446. 0.1599 s / img. ETA=0:21:00
[07/01 09:09:43] detectron2 INFO: Inference done 18708/26446. 0.1599 s / img. ETA=0:20:55
[07/01 09:09:48] detectron2 INFO: Inference done 18739/26446. 0.1599 s / img. ETA=0:20:50
[07/01 09:09:53] detectron2 INFO: Inference done 18769/26446. 0.1600 s / img. ETA=0:20:45
[07/01 10:04:34] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 10:04:35] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 10:04:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '20', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 10:04:35] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 10:04:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 20
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 10:04:35] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 10:04:35] d2.utils.env INFO: Using a generated random seed 35982634
[07/01 10:04:39] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 10:04:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:04:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:04:41] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 10:04:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 10:04:41] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 10:04:43] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 10:04:43] detectron2 INFO: Following metrics will be use for evaluation
[07/01 10:04:43] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 10:04:43] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 10:04:43] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 10:04:43] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 10:04:43] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 10:04:45] detectron2 INFO: Loading zero shot triplets
[07/01 10:04:45] detectron2 INFO: Start inference on 26446 images
[07/01 10:04:55] detectron2 INFO: Inference done 11/26446. 0.1607 s / img. ETA=1:11:46
[07/01 10:05:00] detectron2 INFO: Inference done 41/26446. 0.1632 s / img. ETA=1:13:11
[07/01 10:05:39] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 10:05:40] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 10:05:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 10:05:40] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 10:05:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 10:05:40] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 10:05:40] d2.utils.env INFO: Using a generated random seed 40674312
[07/01 10:05:43] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 10:05:43] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:05:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:05:44] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 10:05:44] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 10:05:44] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 10:05:46] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 10:05:46] detectron2 INFO: Following metrics will be use for evaluation
[07/01 10:05:46] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 10:05:46] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 10:05:46] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 10:05:46] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 10:05:46] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 10:05:48] detectron2 INFO: Loading zero shot triplets
[07/01 10:05:48] detectron2 INFO: Start inference on 26446 images
[07/01 10:05:58] detectron2 INFO: Inference done 11/26446. 0.1717 s / img. ETA=1:16:32
[07/01 10:06:03] detectron2 INFO: Inference done 42/26446. 0.1654 s / img. ETA=1:13:44
[07/01 10:06:08] detectron2 INFO: Inference done 74/26446. 0.1617 s / img. ETA=1:12:02
[07/01 10:06:13] detectron2 INFO: Inference done 106/26446. 0.1598 s / img. ETA=1:11:09
[07/01 10:06:18] detectron2 INFO: Inference done 137/26446. 0.1603 s / img. ETA=1:11:17
[07/01 10:06:23] detectron2 INFO: Inference done 169/26446. 0.1598 s / img. ETA=1:10:58
[07/01 10:06:28] detectron2 INFO: Inference done 201/26446. 0.1594 s / img. ETA=1:10:44
[07/01 10:06:33] detectron2 INFO: Inference done 233/26446. 0.1592 s / img. ETA=1:10:32
[07/01 10:06:38] detectron2 INFO: Inference done 265/26446. 0.1590 s / img. ETA=1:10:23
[07/01 10:06:44] detectron2 INFO: Inference done 297/26446. 0.1588 s / img. ETA=1:10:12
[07/01 10:06:49] detectron2 INFO: Inference done 328/26446. 0.1589 s / img. ETA=1:10:09
[07/01 10:06:54] detectron2 INFO: Inference done 358/26446. 0.1594 s / img. ETA=1:10:17
[07/01 10:06:59] detectron2 INFO: Inference done 389/26446. 0.1594 s / img. ETA=1:10:13
[07/01 10:07:04] detectron2 INFO: Inference done 421/26446. 0.1594 s / img. ETA=1:10:07
[07/01 10:07:09] detectron2 INFO: Inference done 453/26446. 0.1592 s / img. ETA=1:09:57
[07/01 10:07:14] detectron2 INFO: Inference done 484/26446. 0.1592 s / img. ETA=1:09:52
[07/01 10:07:19] detectron2 INFO: Inference done 515/26446. 0.1594 s / img. ETA=1:09:54
[07/01 10:07:24] detectron2 INFO: Inference done 546/26446. 0.1596 s / img. ETA=1:09:52
[07/01 10:07:29] detectron2 INFO: Inference done 577/26446. 0.1598 s / img. ETA=1:09:53
[07/01 10:07:34] detectron2 INFO: Inference done 609/26446. 0.1597 s / img. ETA=1:09:46
[07/01 10:07:39] detectron2 INFO: Inference done 640/26446. 0.1597 s / img. ETA=1:09:41
[07/01 10:07:45] detectron2 INFO: Inference done 672/26446. 0.1596 s / img. ETA=1:09:32
[07/01 10:07:50] detectron2 INFO: Inference done 703/26446. 0.1596 s / img. ETA=1:09:28
[07/01 10:07:55] detectron2 INFO: Inference done 734/26446. 0.1597 s / img. ETA=1:09:27
[07/01 10:08:00] detectron2 INFO: Inference done 766/26446. 0.1595 s / img. ETA=1:09:16
[07/01 10:08:05] detectron2 INFO: Inference done 798/26446. 0.1594 s / img. ETA=1:09:09
[07/01 10:08:10] detectron2 INFO: Inference done 829/26446. 0.1594 s / img. ETA=1:09:03
[07/01 10:08:15] detectron2 INFO: Inference done 860/26446. 0.1595 s / img. ETA=1:09:01
[07/01 10:08:20] detectron2 INFO: Inference done 891/26446. 0.1596 s / img. ETA=1:08:57
[07/01 10:08:25] detectron2 INFO: Inference done 922/26446. 0.1597 s / img. ETA=1:08:55
[07/01 10:08:30] detectron2 INFO: Inference done 952/26446. 0.1599 s / img. ETA=1:08:55
[07/01 10:09:09] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 10:09:10] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 10:09:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 10:09:10] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 10:09:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 10:09:10] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 10:09:10] d2.utils.env INFO: Using a generated random seed 10274679
[07/01 10:09:12] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 10:09:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:09:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 10:09:14] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 10:09:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 10:09:14] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 10:09:15] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 10:09:15] detectron2 INFO: Following metrics will be use for evaluation
[07/01 10:09:15] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 10:09:15] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 10:09:15] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 10:09:15] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 10:09:15] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 10:09:17] detectron2 INFO: Loading zero shot triplets
[07/01 10:09:17] detectron2 INFO: Start inference on 26446 images
[07/01 10:09:26] detectron2 INFO: Inference done 11/26446. 0.1579 s / img. ETA=1:10:28
[07/01 10:09:31] detectron2 INFO: Inference done 43/26446. 0.1573 s / img. ETA=1:10:13
[07/01 10:09:36] detectron2 INFO: Inference done 75/26446. 0.1573 s / img. ETA=1:10:09
[07/01 10:09:41] detectron2 INFO: Inference done 107/26446. 0.1566 s / img. ETA=1:09:44
[07/01 10:09:46] detectron2 INFO: Inference done 140/26446. 0.1556 s / img. ETA=1:09:13
[07/01 10:09:51] detectron2 INFO: Inference done 172/26446. 0.1556 s / img. ETA=1:09:07
[07/01 10:09:56] detectron2 INFO: Inference done 204/26446. 0.1560 s / img. ETA=1:09:13
[07/01 10:10:01] detectron2 INFO: Inference done 236/26446. 0.1558 s / img. ETA=1:09:02
[07/01 10:10:06] detectron2 INFO: Inference done 269/26446. 0.1555 s / img. ETA=1:08:49
[07/01 10:10:12] detectron2 INFO: Inference done 301/26446. 0.1556 s / img. ETA=1:08:47
[07/01 10:10:17] detectron2 INFO: Inference done 332/26446. 0.1561 s / img. ETA=1:08:55
[07/01 10:10:22] detectron2 INFO: Inference done 364/26446. 0.1562 s / img. ETA=1:08:53
[07/01 10:10:27] detectron2 INFO: Inference done 396/26446. 0.1564 s / img. ETA=1:08:53
[07/01 10:10:32] detectron2 INFO: Inference done 428/26446. 0.1563 s / img. ETA=1:08:46
[07/01 10:10:37] detectron2 INFO: Inference done 460/26446. 0.1563 s / img. ETA=1:08:40
[07/01 10:10:42] detectron2 INFO: Inference done 492/26446. 0.1563 s / img. ETA=1:08:35
[07/01 10:10:47] detectron2 INFO: Inference done 524/26446. 0.1563 s / img. ETA=1:08:30
[07/01 10:10:52] detectron2 INFO: Inference done 556/26446. 0.1563 s / img. ETA=1:08:27
[07/01 10:10:57] detectron2 INFO: Inference done 589/26446. 0.1562 s / img. ETA=1:08:18
[07/01 10:11:02] detectron2 INFO: Inference done 620/26446. 0.1564 s / img. ETA=1:08:19
[07/01 10:11:07] detectron2 INFO: Inference done 652/26446. 0.1564 s / img. ETA=1:08:13
[07/01 10:11:13] detectron2 INFO: Inference done 684/26446. 0.1565 s / img. ETA=1:08:11
[07/01 10:11:18] detectron2 INFO: Inference done 715/26446. 0.1566 s / img. ETA=1:08:09
[07/01 10:11:23] detectron2 INFO: Inference done 747/26446. 0.1566 s / img. ETA=1:08:02
[07/01 10:11:28] detectron2 INFO: Inference done 779/26446. 0.1565 s / img. ETA=1:07:55
[07/01 10:11:33] detectron2 INFO: Inference done 811/26446. 0.1565 s / img. ETA=1:07:51
[07/01 10:11:38] detectron2 INFO: Inference done 843/26446. 0.1565 s / img. ETA=1:07:46
[07/01 10:11:43] detectron2 INFO: Inference done 875/26446. 0.1565 s / img. ETA=1:07:40
[07/01 10:11:48] detectron2 INFO: Inference done 906/26446. 0.1566 s / img. ETA=1:07:37
[07/01 10:11:53] detectron2 INFO: Inference done 938/26446. 0.1566 s / img. ETA=1:07:32
[07/01 10:11:58] detectron2 INFO: Inference done 970/26446. 0.1566 s / img. ETA=1:07:26
[07/01 10:12:03] detectron2 INFO: Inference done 1002/26446. 0.1566 s / img. ETA=1:07:22
[07/01 10:12:08] detectron2 INFO: Inference done 1033/26446. 0.1567 s / img. ETA=1:07:21
[07/01 10:12:13] detectron2 INFO: Inference done 1065/26446. 0.1567 s / img. ETA=1:07:16
[07/01 10:12:18] detectron2 INFO: Inference done 1097/26446. 0.1567 s / img. ETA=1:07:09
[07/01 10:12:23] detectron2 INFO: Inference done 1129/26446. 0.1567 s / img. ETA=1:07:04
[07/01 10:12:29] detectron2 INFO: Inference done 1161/26446. 0.1566 s / img. ETA=1:06:58
[07/01 10:12:34] detectron2 INFO: Inference done 1192/26446. 0.1567 s / img. ETA=1:06:55
[07/01 10:12:39] detectron2 INFO: Inference done 1224/26446. 0.1567 s / img. ETA=1:06:51
[07/01 10:12:44] detectron2 INFO: Inference done 1255/26446. 0.1568 s / img. ETA=1:06:48
[07/01 10:12:49] detectron2 INFO: Inference done 1287/26446. 0.1569 s / img. ETA=1:06:44
[07/01 10:12:54] detectron2 INFO: Inference done 1319/26446. 0.1568 s / img. ETA=1:06:38
[07/01 10:12:59] detectron2 INFO: Inference done 1351/26446. 0.1568 s / img. ETA=1:06:34
[07/01 10:13:04] detectron2 INFO: Inference done 1383/26446. 0.1569 s / img. ETA=1:06:29
[07/01 10:13:09] detectron2 INFO: Inference done 1413/26446. 0.1571 s / img. ETA=1:06:29
[07/01 10:13:14] detectron2 INFO: Inference done 1445/26446. 0.1571 s / img. ETA=1:06:24
[07/01 10:13:19] detectron2 INFO: Inference done 1477/26446. 0.1570 s / img. ETA=1:06:18
[07/01 10:13:24] detectron2 INFO: Inference done 1509/26446. 0.1571 s / img. ETA=1:06:14
[07/01 10:13:30] detectron2 INFO: Inference done 1541/26446. 0.1570 s / img. ETA=1:06:08
[07/01 10:13:35] detectron2 INFO: Inference done 1573/26446. 0.1570 s / img. ETA=1:06:03
[07/01 10:13:40] detectron2 INFO: Inference done 1605/26446. 0.1570 s / img. ETA=1:05:57
[07/01 10:13:45] detectron2 INFO: Inference done 1637/26446. 0.1570 s / img. ETA=1:05:52
[07/01 10:13:50] detectron2 INFO: Inference done 1669/26446. 0.1570 s / img. ETA=1:05:48
[07/01 10:13:55] detectron2 INFO: Inference done 1701/26446. 0.1570 s / img. ETA=1:05:42
[07/01 10:14:00] detectron2 INFO: Inference done 1733/26446. 0.1571 s / img. ETA=1:05:38
[07/01 10:14:05] detectron2 INFO: Inference done 1764/26446. 0.1571 s / img. ETA=1:05:35
[07/01 10:14:10] detectron2 INFO: Inference done 1795/26446. 0.1572 s / img. ETA=1:05:31
[07/01 10:14:15] detectron2 INFO: Inference done 1827/26446. 0.1571 s / img. ETA=1:05:25
[07/01 10:14:20] detectron2 INFO: Inference done 1858/26446. 0.1572 s / img. ETA=1:05:21
[07/01 10:14:25] detectron2 INFO: Inference done 1890/26446. 0.1572 s / img. ETA=1:05:17
[07/01 10:14:31] detectron2 INFO: Inference done 1921/26446. 0.1573 s / img. ETA=1:05:13
[07/01 10:14:36] detectron2 INFO: Inference done 1953/26446. 0.1573 s / img. ETA=1:05:08
[07/01 10:14:41] detectron2 INFO: Inference done 1979/26446. 0.1578 s / img. ETA=1:05:17
[07/01 10:14:46] detectron2 INFO: Inference done 2011/26446. 0.1578 s / img. ETA=1:05:12
[07/01 10:14:51] detectron2 INFO: Inference done 2043/26446. 0.1578 s / img. ETA=1:05:07
[07/01 10:14:56] detectron2 INFO: Inference done 2075/26446. 0.1578 s / img. ETA=1:05:02
[07/01 10:15:01] detectron2 INFO: Inference done 2106/26446. 0.1579 s / img. ETA=1:04:58
[07/01 10:15:06] detectron2 INFO: Inference done 2137/26446. 0.1579 s / img. ETA=1:04:54
[07/01 10:15:11] detectron2 INFO: Inference done 2169/26446. 0.1579 s / img. ETA=1:04:48
[07/01 10:15:16] detectron2 INFO: Inference done 2200/26446. 0.1579 s / img. ETA=1:04:44
[07/01 10:15:22] detectron2 INFO: Inference done 2232/26446. 0.1579 s / img. ETA=1:04:38
[07/01 10:15:27] detectron2 INFO: Inference done 2263/26446. 0.1579 s / img. ETA=1:04:34
[07/01 10:15:32] detectron2 INFO: Inference done 2295/26446. 0.1579 s / img. ETA=1:04:29
[07/01 10:15:37] detectron2 INFO: Inference done 2326/26446. 0.1580 s / img. ETA=1:04:25
[07/01 10:15:42] detectron2 INFO: Inference done 2358/26446. 0.1580 s / img. ETA=1:04:20
[07/01 10:15:47] detectron2 INFO: Inference done 2389/26446. 0.1580 s / img. ETA=1:04:16
[07/01 10:15:52] detectron2 INFO: Inference done 2421/26446. 0.1580 s / img. ETA=1:04:11
[07/01 10:15:57] detectron2 INFO: Inference done 2452/26446. 0.1580 s / img. ETA=1:04:06
[07/01 10:16:02] detectron2 INFO: Inference done 2483/26446. 0.1580 s / img. ETA=1:04:02
[07/01 10:16:07] detectron2 INFO: Inference done 2515/26446. 0.1580 s / img. ETA=1:03:56
[07/01 10:16:12] detectron2 INFO: Inference done 2547/26446. 0.1580 s / img. ETA=1:03:50
[07/01 10:16:17] detectron2 INFO: Inference done 2578/26446. 0.1580 s / img. ETA=1:03:47
[07/01 10:16:22] detectron2 INFO: Inference done 2610/26446. 0.1580 s / img. ETA=1:03:41
[07/01 10:16:27] detectron2 INFO: Inference done 2642/26446. 0.1580 s / img. ETA=1:03:35
[07/01 10:16:33] detectron2 INFO: Inference done 2673/26446. 0.1580 s / img. ETA=1:03:31
[07/01 10:16:38] detectron2 INFO: Inference done 2704/26446. 0.1580 s / img. ETA=1:03:27
[07/01 10:16:43] detectron2 INFO: Inference done 2736/26446. 0.1580 s / img. ETA=1:03:21
[07/01 10:16:48] detectron2 INFO: Inference done 2767/26446. 0.1581 s / img. ETA=1:03:17
[07/01 10:16:53] detectron2 INFO: Inference done 2798/26446. 0.1581 s / img. ETA=1:03:13
[07/01 10:16:58] detectron2 INFO: Inference done 2830/26446. 0.1581 s / img. ETA=1:03:08
[07/01 10:17:03] detectron2 INFO: Inference done 2861/26446. 0.1581 s / img. ETA=1:03:03
[07/01 10:17:08] detectron2 INFO: Inference done 2892/26446. 0.1581 s / img. ETA=1:02:59
[07/01 10:17:13] detectron2 INFO: Inference done 2923/26446. 0.1582 s / img. ETA=1:02:54
[07/01 10:17:18] detectron2 INFO: Inference done 2954/26446. 0.1582 s / img. ETA=1:02:50
[07/01 10:17:23] detectron2 INFO: Inference done 2986/26446. 0.1582 s / img. ETA=1:02:44
[07/01 10:17:28] detectron2 INFO: Inference done 3017/26446. 0.1582 s / img. ETA=1:02:39
[07/01 10:17:33] detectron2 INFO: Inference done 3049/26446. 0.1581 s / img. ETA=1:02:34
[07/01 10:17:38] detectron2 INFO: Inference done 3080/26446. 0.1582 s / img. ETA=1:02:29
[07/01 10:17:43] detectron2 INFO: Inference done 3112/26446. 0.1582 s / img. ETA=1:02:24
[07/01 10:17:48] detectron2 INFO: Inference done 3144/26446. 0.1582 s / img. ETA=1:02:19
[07/01 10:17:53] detectron2 INFO: Inference done 3175/26446. 0.1582 s / img. ETA=1:02:14
[07/01 10:17:59] detectron2 INFO: Inference done 3207/26446. 0.1582 s / img. ETA=1:02:09
[07/01 10:18:04] detectron2 INFO: Inference done 3238/26446. 0.1582 s / img. ETA=1:02:04
[07/01 10:18:09] detectron2 INFO: Inference done 3270/26446. 0.1582 s / img. ETA=1:01:58
[07/01 10:18:14] detectron2 INFO: Inference done 3302/26446. 0.1581 s / img. ETA=1:01:53
[07/01 10:18:19] detectron2 INFO: Inference done 3334/26446. 0.1581 s / img. ETA=1:01:47
[07/01 10:18:24] detectron2 INFO: Inference done 3366/26446. 0.1581 s / img. ETA=1:01:42
[07/01 10:18:29] detectron2 INFO: Inference done 3398/26446. 0.1581 s / img. ETA=1:01:37
[07/01 10:18:34] detectron2 INFO: Inference done 3430/26446. 0.1581 s / img. ETA=1:01:32
[07/01 10:18:39] detectron2 INFO: Inference done 3462/26446. 0.1581 s / img. ETA=1:01:27
[07/01 10:18:44] detectron2 INFO: Inference done 3493/26446. 0.1581 s / img. ETA=1:01:22
[07/01 10:18:49] detectron2 INFO: Inference done 3525/26446. 0.1581 s / img. ETA=1:01:16
[07/01 10:18:55] detectron2 INFO: Inference done 3556/26446. 0.1581 s / img. ETA=1:01:12
[07/01 10:19:00] detectron2 INFO: Inference done 3588/26446. 0.1581 s / img. ETA=1:01:07
[07/01 10:19:05] detectron2 INFO: Inference done 3620/26446. 0.1581 s / img. ETA=1:01:01
[07/01 10:19:10] detectron2 INFO: Inference done 3651/26446. 0.1581 s / img. ETA=1:00:57
[07/01 10:19:15] detectron2 INFO: Inference done 3683/26446. 0.1581 s / img. ETA=1:00:51
[07/01 10:19:20] detectron2 INFO: Inference done 3714/26446. 0.1581 s / img. ETA=1:00:47
[07/01 10:19:25] detectron2 INFO: Inference done 3745/26446. 0.1581 s / img. ETA=1:00:42
[07/01 10:19:30] detectron2 INFO: Inference done 3776/26446. 0.1581 s / img. ETA=1:00:37
[07/01 10:19:35] detectron2 INFO: Inference done 3808/26446. 0.1581 s / img. ETA=1:00:31
[07/01 10:19:40] detectron2 INFO: Inference done 3839/26446. 0.1581 s / img. ETA=1:00:26
[07/01 10:19:45] detectron2 INFO: Inference done 3870/26446. 0.1582 s / img. ETA=1:00:22
[07/01 10:19:50] detectron2 INFO: Inference done 3901/26446. 0.1582 s / img. ETA=1:00:18
[07/01 10:19:55] detectron2 INFO: Inference done 3931/26446. 0.1582 s / img. ETA=1:00:14
[07/01 10:20:00] detectron2 INFO: Inference done 3959/26446. 0.1584 s / img. ETA=1:00:13
[07/01 10:20:05] detectron2 INFO: Inference done 3989/26446. 0.1584 s / img. ETA=1:00:09
[07/01 10:20:10] detectron2 INFO: Inference done 4021/26446. 0.1584 s / img. ETA=1:00:04
[07/01 10:20:15] detectron2 INFO: Inference done 4052/26446. 0.1584 s / img. ETA=0:59:59
[07/01 10:20:20] detectron2 INFO: Inference done 4083/26446. 0.1584 s / img. ETA=0:59:54
[07/01 10:20:25] detectron2 INFO: Inference done 4114/26446. 0.1584 s / img. ETA=0:59:50
[07/01 10:20:30] detectron2 INFO: Inference done 4145/26446. 0.1585 s / img. ETA=0:59:45
[07/01 10:20:35] detectron2 INFO: Inference done 4176/26446. 0.1585 s / img. ETA=0:59:40
[07/01 10:20:40] detectron2 INFO: Inference done 4207/26446. 0.1585 s / img. ETA=0:59:36
[07/01 10:20:45] detectron2 INFO: Inference done 4238/26446. 0.1585 s / img. ETA=0:59:31
[07/01 10:20:51] detectron2 INFO: Inference done 4269/26446. 0.1585 s / img. ETA=0:59:26
[07/01 10:20:56] detectron2 INFO: Inference done 4301/26446. 0.1585 s / img. ETA=0:59:21
[07/01 10:21:01] detectron2 INFO: Inference done 4332/26446. 0.1585 s / img. ETA=0:59:16
[07/01 10:21:06] detectron2 INFO: Inference done 4363/26446. 0.1585 s / img. ETA=0:59:11
[07/01 10:21:11] detectron2 INFO: Inference done 4395/26446. 0.1585 s / img. ETA=0:59:06
[07/01 10:21:16] detectron2 INFO: Inference done 4426/26446. 0.1585 s / img. ETA=0:59:02
[07/01 10:21:21] detectron2 INFO: Inference done 4458/26446. 0.1585 s / img. ETA=0:58:56
[07/01 10:21:26] detectron2 INFO: Inference done 4489/26446. 0.1585 s / img. ETA=0:58:52
[07/01 10:21:31] detectron2 INFO: Inference done 4520/26446. 0.1586 s / img. ETA=0:58:47
[07/01 10:21:36] detectron2 INFO: Inference done 4551/26446. 0.1586 s / img. ETA=0:58:42
[07/01 10:21:41] detectron2 INFO: Inference done 4583/26446. 0.1586 s / img. ETA=0:58:37
[07/01 10:21:46] detectron2 INFO: Inference done 4614/26446. 0.1586 s / img. ETA=0:58:32
[07/01 10:21:51] detectron2 INFO: Inference done 4645/26446. 0.1586 s / img. ETA=0:58:27
[07/01 10:21:57] detectron2 INFO: Inference done 4676/26446. 0.1586 s / img. ETA=0:58:23
[07/01 10:22:02] detectron2 INFO: Inference done 4707/26446. 0.1586 s / img. ETA=0:58:18
[07/01 10:22:07] detectron2 INFO: Inference done 4738/26446. 0.1586 s / img. ETA=0:58:14
[07/01 10:22:12] detectron2 INFO: Inference done 4769/26446. 0.1587 s / img. ETA=0:58:09
[07/01 10:22:17] detectron2 INFO: Inference done 4800/26446. 0.1587 s / img. ETA=0:58:04
[07/01 10:22:22] detectron2 INFO: Inference done 4832/26446. 0.1587 s / img. ETA=0:57:59
[07/01 10:22:27] detectron2 INFO: Inference done 4863/26446. 0.1587 s / img. ETA=0:57:55
[07/01 10:22:32] detectron2 INFO: Inference done 4895/26446. 0.1587 s / img. ETA=0:57:49
[07/01 10:22:37] detectron2 INFO: Inference done 4927/26446. 0.1587 s / img. ETA=0:57:44
[07/01 10:22:42] detectron2 INFO: Inference done 4959/26446. 0.1587 s / img. ETA=0:57:39
[07/01 10:22:47] detectron2 INFO: Inference done 4991/26446. 0.1587 s / img. ETA=0:57:34
[07/01 10:22:53] detectron2 INFO: Inference done 5023/26446. 0.1587 s / img. ETA=0:57:28
[07/01 10:22:58] detectron2 INFO: Inference done 5054/26446. 0.1587 s / img. ETA=0:57:23
[07/01 10:23:03] detectron2 INFO: Inference done 5086/26446. 0.1587 s / img. ETA=0:57:18
[07/01 10:23:08] detectron2 INFO: Inference done 5117/26446. 0.1587 s / img. ETA=0:57:13
[07/01 10:23:13] detectron2 INFO: Inference done 5148/26446. 0.1587 s / img. ETA=0:57:09
[07/01 10:23:18] detectron2 INFO: Inference done 5180/26446. 0.1587 s / img. ETA=0:57:04
[07/01 10:23:23] detectron2 INFO: Inference done 5212/26446. 0.1587 s / img. ETA=0:56:58
[07/01 10:23:28] detectron2 INFO: Inference done 5244/26446. 0.1587 s / img. ETA=0:56:53
[07/01 10:23:33] detectron2 INFO: Inference done 5275/26446. 0.1587 s / img. ETA=0:56:48
[07/01 10:23:38] detectron2 INFO: Inference done 5307/26446. 0.1587 s / img. ETA=0:56:42
[07/01 10:23:43] detectron2 INFO: Inference done 5338/26446. 0.1587 s / img. ETA=0:56:38
[07/01 10:23:48] detectron2 INFO: Inference done 5369/26446. 0.1587 s / img. ETA=0:56:33
[07/01 10:23:53] detectron2 INFO: Inference done 5400/26446. 0.1587 s / img. ETA=0:56:28
[07/01 10:23:59] detectron2 INFO: Inference done 5432/26446. 0.1587 s / img. ETA=0:56:23
[07/01 10:24:04] detectron2 INFO: Inference done 5463/26446. 0.1587 s / img. ETA=0:56:18
[07/01 10:24:09] detectron2 INFO: Inference done 5495/26446. 0.1587 s / img. ETA=0:56:13
[07/01 10:24:14] detectron2 INFO: Inference done 5526/26446. 0.1587 s / img. ETA=0:56:08
[07/01 10:24:19] detectron2 INFO: Inference done 5557/26446. 0.1587 s / img. ETA=0:56:03
[07/01 10:24:24] detectron2 INFO: Inference done 5588/26446. 0.1587 s / img. ETA=0:55:59
[07/01 10:24:29] detectron2 INFO: Inference done 5620/26446. 0.1587 s / img. ETA=0:55:53
[07/01 10:24:34] detectron2 INFO: Inference done 5651/26446. 0.1587 s / img. ETA=0:55:48
[07/01 10:24:39] detectron2 INFO: Inference done 5683/26446. 0.1587 s / img. ETA=0:55:43
[07/01 10:24:44] detectron2 INFO: Inference done 5714/26446. 0.1587 s / img. ETA=0:55:39
[07/01 10:24:49] detectron2 INFO: Inference done 5745/26446. 0.1587 s / img. ETA=0:55:34
[07/01 10:24:54] detectron2 INFO: Inference done 5776/26446. 0.1588 s / img. ETA=0:55:29
[07/01 10:25:00] detectron2 INFO: Inference done 5808/26446. 0.1588 s / img. ETA=0:55:24
[07/01 10:25:05] detectron2 INFO: Inference done 5839/26446. 0.1588 s / img. ETA=0:55:19
[07/01 10:25:10] detectron2 INFO: Inference done 5871/26446. 0.1587 s / img. ETA=0:55:13
[07/01 10:25:15] detectron2 INFO: Inference done 5903/26446. 0.1587 s / img. ETA=0:55:08
[07/01 10:25:20] detectron2 INFO: Inference done 5935/26446. 0.1587 s / img. ETA=0:55:03
[07/01 10:25:25] detectron2 INFO: Inference done 5967/26446. 0.1587 s / img. ETA=0:54:58
[07/01 10:25:30] detectron2 INFO: Inference done 5998/26446. 0.1587 s / img. ETA=0:54:53
[07/01 10:25:35] detectron2 INFO: Inference done 6029/26446. 0.1587 s / img. ETA=0:54:48
[07/01 10:25:40] detectron2 INFO: Inference done 6060/26446. 0.1587 s / img. ETA=0:54:43
[07/01 10:25:45] detectron2 INFO: Inference done 6092/26446. 0.1587 s / img. ETA=0:54:37
[07/01 10:25:50] detectron2 INFO: Inference done 6123/26446. 0.1587 s / img. ETA=0:54:32
[07/01 10:25:55] detectron2 INFO: Inference done 6155/26446. 0.1587 s / img. ETA=0:54:27
[07/01 10:26:00] detectron2 INFO: Inference done 6186/26446. 0.1587 s / img. ETA=0:54:22
[07/01 10:26:05] detectron2 INFO: Inference done 6217/26446. 0.1587 s / img. ETA=0:54:18
[07/01 10:26:10] detectron2 INFO: Inference done 6249/26446. 0.1587 s / img. ETA=0:54:13
[07/01 10:26:16] detectron2 INFO: Inference done 6280/26446. 0.1587 s / img. ETA=0:54:08
[07/01 10:26:21] detectron2 INFO: Inference done 6311/26446. 0.1587 s / img. ETA=0:54:03
[07/01 10:26:26] detectron2 INFO: Inference done 6343/26446. 0.1587 s / img. ETA=0:53:58
[07/01 10:26:31] detectron2 INFO: Inference done 6374/26446. 0.1588 s / img. ETA=0:53:53
[07/01 10:26:36] detectron2 INFO: Inference done 6405/26446. 0.1588 s / img. ETA=0:53:48
[07/01 10:26:41] detectron2 INFO: Inference done 6436/26446. 0.1588 s / img. ETA=0:53:43
[07/01 10:26:46] detectron2 INFO: Inference done 6468/26446. 0.1588 s / img. ETA=0:53:38
[07/01 10:26:51] detectron2 INFO: Inference done 6500/26446. 0.1588 s / img. ETA=0:53:33
[07/01 10:26:56] detectron2 INFO: Inference done 6532/26446. 0.1588 s / img. ETA=0:53:27
[07/01 10:27:01] detectron2 INFO: Inference done 6563/26446. 0.1588 s / img. ETA=0:53:22
[07/01 10:27:06] detectron2 INFO: Inference done 6594/26446. 0.1588 s / img. ETA=0:53:18
[07/01 10:27:11] detectron2 INFO: Inference done 6625/26446. 0.1588 s / img. ETA=0:53:13
[07/01 10:27:16] detectron2 INFO: Inference done 6657/26446. 0.1588 s / img. ETA=0:53:08
[07/01 10:27:22] detectron2 INFO: Inference done 6689/26446. 0.1588 s / img. ETA=0:53:03
[07/01 10:27:27] detectron2 INFO: Inference done 6720/26446. 0.1588 s / img. ETA=0:52:58
[07/01 10:27:32] detectron2 INFO: Inference done 6751/26446. 0.1588 s / img. ETA=0:52:53
[07/01 10:27:37] detectron2 INFO: Inference done 6783/26446. 0.1588 s / img. ETA=0:52:48
[07/01 10:27:42] detectron2 INFO: Inference done 6815/26446. 0.1588 s / img. ETA=0:52:42
[07/01 10:27:47] detectron2 INFO: Inference done 6846/26446. 0.1588 s / img. ETA=0:52:38
[07/01 10:27:52] detectron2 INFO: Inference done 6877/26446. 0.1588 s / img. ETA=0:52:33
[07/01 10:27:57] detectron2 INFO: Inference done 6908/26446. 0.1588 s / img. ETA=0:52:28
[07/01 10:28:02] detectron2 INFO: Inference done 6940/26446. 0.1588 s / img. ETA=0:52:23
[07/01 10:28:07] detectron2 INFO: Inference done 6972/26446. 0.1588 s / img. ETA=0:52:18
[07/01 10:28:13] detectron2 INFO: Inference done 7003/26446. 0.1588 s / img. ETA=0:52:13
[07/01 10:28:18] detectron2 INFO: Inference done 7034/26446. 0.1588 s / img. ETA=0:52:08
[07/01 10:28:23] detectron2 INFO: Inference done 7065/26446. 0.1588 s / img. ETA=0:52:03
[07/01 10:28:28] detectron2 INFO: Inference done 7097/26446. 0.1588 s / img. ETA=0:51:58
[07/01 10:28:33] detectron2 INFO: Inference done 7128/26446. 0.1589 s / img. ETA=0:51:53
[07/01 10:28:38] detectron2 INFO: Inference done 7159/26446. 0.1589 s / img. ETA=0:51:49
[07/01 10:28:43] detectron2 INFO: Inference done 7191/26446. 0.1589 s / img. ETA=0:51:43
[07/01 10:28:48] detectron2 INFO: Inference done 7222/26446. 0.1589 s / img. ETA=0:51:38
[07/01 10:28:53] detectron2 INFO: Inference done 7253/26446. 0.1589 s / img. ETA=0:51:34
[07/01 10:28:58] detectron2 INFO: Inference done 7284/26446. 0.1589 s / img. ETA=0:51:29
[07/01 10:29:03] detectron2 INFO: Inference done 7315/26446. 0.1589 s / img. ETA=0:51:24
[07/01 10:29:09] detectron2 INFO: Inference done 7345/26446. 0.1589 s / img. ETA=0:51:20
[07/01 10:29:14] detectron2 INFO: Inference done 7375/26446. 0.1590 s / img. ETA=0:51:16
[07/01 10:29:19] detectron2 INFO: Inference done 7405/26446. 0.1590 s / img. ETA=0:51:12
[07/01 10:29:24] detectron2 INFO: Inference done 7435/26446. 0.1590 s / img. ETA=0:51:07
[07/01 10:29:29] detectron2 INFO: Inference done 7465/26446. 0.1591 s / img. ETA=0:51:03
[07/01 10:29:34] detectron2 INFO: Inference done 7496/26446. 0.1591 s / img. ETA=0:50:58
[07/01 10:29:39] detectron2 INFO: Inference done 7526/26446. 0.1591 s / img. ETA=0:50:54
[07/01 10:29:44] detectron2 INFO: Inference done 7555/26446. 0.1592 s / img. ETA=0:50:50
[07/01 10:29:49] detectron2 INFO: Inference done 7585/26446. 0.1592 s / img. ETA=0:50:46
[07/01 10:29:54] detectron2 INFO: Inference done 7615/26446. 0.1592 s / img. ETA=0:50:42
[07/01 10:29:59] detectron2 INFO: Inference done 7646/26446. 0.1592 s / img. ETA=0:50:37
[07/01 10:30:04] detectron2 INFO: Inference done 7677/26446. 0.1592 s / img. ETA=0:50:32
[07/01 10:30:10] detectron2 INFO: Inference done 7708/26446. 0.1593 s / img. ETA=0:50:27
[07/01 10:30:15] detectron2 INFO: Inference done 7739/26446. 0.1593 s / img. ETA=0:50:23
[07/01 10:30:20] detectron2 INFO: Inference done 7770/26446. 0.1593 s / img. ETA=0:50:18
[07/01 10:30:25] detectron2 INFO: Inference done 7802/26446. 0.1593 s / img. ETA=0:50:13
[07/01 10:30:30] detectron2 INFO: Inference done 7833/26446. 0.1593 s / img. ETA=0:50:08
[07/01 10:30:35] detectron2 INFO: Inference done 7864/26446. 0.1593 s / img. ETA=0:50:03
[07/01 10:30:40] detectron2 INFO: Inference done 7895/26446. 0.1593 s / img. ETA=0:49:58
[07/01 10:30:45] detectron2 INFO: Inference done 7927/26446. 0.1593 s / img. ETA=0:49:53
[07/01 10:30:50] detectron2 INFO: Inference done 7959/26446. 0.1593 s / img. ETA=0:49:47
[07/01 10:30:55] detectron2 INFO: Inference done 7990/26446. 0.1593 s / img. ETA=0:49:42
[07/01 10:31:00] detectron2 INFO: Inference done 8021/26446. 0.1593 s / img. ETA=0:49:38
[07/01 10:31:06] detectron2 INFO: Inference done 8053/26446. 0.1593 s / img. ETA=0:49:32
[07/01 10:31:11] detectron2 INFO: Inference done 8084/26446. 0.1593 s / img. ETA=0:49:27
[07/01 10:31:16] detectron2 INFO: Inference done 8115/26446. 0.1593 s / img. ETA=0:49:23
[07/01 10:31:21] detectron2 INFO: Inference done 8147/26446. 0.1593 s / img. ETA=0:49:17
[07/01 10:31:26] detectron2 INFO: Inference done 8178/26446. 0.1593 s / img. ETA=0:49:12
[07/01 10:31:31] detectron2 INFO: Inference done 8202/26446. 0.1594 s / img. ETA=0:49:11
[07/01 10:31:36] detectron2 INFO: Inference done 8233/26446. 0.1594 s / img. ETA=0:49:06
[07/01 10:31:41] detectron2 INFO: Inference done 8264/26446. 0.1594 s / img. ETA=0:49:01
[07/01 10:31:46] detectron2 INFO: Inference done 8294/26446. 0.1595 s / img. ETA=0:48:57
[07/01 10:31:51] detectron2 INFO: Inference done 8325/26446. 0.1595 s / img. ETA=0:48:52
[07/01 10:31:56] detectron2 INFO: Inference done 8356/26446. 0.1595 s / img. ETA=0:48:47
[07/01 10:32:01] detectron2 INFO: Inference done 8387/26446. 0.1595 s / img. ETA=0:48:42
[07/01 10:32:06] detectron2 INFO: Inference done 8418/26446. 0.1595 s / img. ETA=0:48:37
[07/01 10:32:12] detectron2 INFO: Inference done 8449/26446. 0.1595 s / img. ETA=0:48:32
[07/01 10:32:17] detectron2 INFO: Inference done 8480/26446. 0.1595 s / img. ETA=0:48:28
[07/01 10:32:22] detectron2 INFO: Inference done 8511/26446. 0.1595 s / img. ETA=0:48:23
[07/01 10:32:27] detectron2 INFO: Inference done 8543/26446. 0.1595 s / img. ETA=0:48:17
[07/01 10:32:32] detectron2 INFO: Inference done 8575/26446. 0.1595 s / img. ETA=0:48:12
[07/01 10:32:37] detectron2 INFO: Inference done 8607/26446. 0.1595 s / img. ETA=0:48:07
[07/01 10:32:42] detectron2 INFO: Inference done 8638/26446. 0.1595 s / img. ETA=0:48:02
[07/01 10:32:47] detectron2 INFO: Inference done 8670/26446. 0.1595 s / img. ETA=0:47:56
[07/01 10:32:52] detectron2 INFO: Inference done 8701/26446. 0.1595 s / img. ETA=0:47:52
[07/01 10:32:57] detectron2 INFO: Inference done 8733/26446. 0.1595 s / img. ETA=0:47:46
[07/01 10:33:03] detectron2 INFO: Inference done 8764/26446. 0.1595 s / img. ETA=0:47:42
[07/01 10:33:08] detectron2 INFO: Inference done 8796/26446. 0.1595 s / img. ETA=0:47:36
[07/01 10:33:13] detectron2 INFO: Inference done 8828/26446. 0.1595 s / img. ETA=0:47:31
[07/01 10:33:18] detectron2 INFO: Inference done 8859/26446. 0.1595 s / img. ETA=0:47:26
[07/01 10:33:23] detectron2 INFO: Inference done 8890/26446. 0.1595 s / img. ETA=0:47:21
[07/01 10:33:28] detectron2 INFO: Inference done 8921/26446. 0.1595 s / img. ETA=0:47:16
[07/01 10:33:33] detectron2 INFO: Inference done 8952/26446. 0.1595 s / img. ETA=0:47:11
[07/01 10:33:38] detectron2 INFO: Inference done 8983/26446. 0.1595 s / img. ETA=0:47:06
[07/01 10:33:43] detectron2 INFO: Inference done 9014/26446. 0.1595 s / img. ETA=0:47:01
[07/01 10:33:48] detectron2 INFO: Inference done 9045/26446. 0.1595 s / img. ETA=0:46:56
[07/01 10:33:53] detectron2 INFO: Inference done 9076/26446. 0.1595 s / img. ETA=0:46:52
[07/01 10:33:58] detectron2 INFO: Inference done 9108/26446. 0.1595 s / img. ETA=0:46:46
[07/01 10:34:03] detectron2 INFO: Inference done 9139/26446. 0.1595 s / img. ETA=0:46:41
[07/01 10:34:08] detectron2 INFO: Inference done 9170/26446. 0.1595 s / img. ETA=0:46:36
[07/01 10:34:13] detectron2 INFO: Inference done 9201/26446. 0.1595 s / img. ETA=0:46:31
[07/01 10:34:19] detectron2 INFO: Inference done 9232/26446. 0.1595 s / img. ETA=0:46:26
[07/01 10:34:24] detectron2 INFO: Inference done 9263/26446. 0.1595 s / img. ETA=0:46:21
[07/01 10:34:29] detectron2 INFO: Inference done 9294/26446. 0.1595 s / img. ETA=0:46:16
[07/01 10:34:34] detectron2 INFO: Inference done 9325/26446. 0.1595 s / img. ETA=0:46:11
[07/01 10:34:39] detectron2 INFO: Inference done 9357/26446. 0.1595 s / img. ETA=0:46:06
[07/01 10:34:44] detectron2 INFO: Inference done 9388/26446. 0.1595 s / img. ETA=0:46:01
[07/01 10:34:49] detectron2 INFO: Inference done 9419/26446. 0.1596 s / img. ETA=0:45:56
[07/01 10:34:54] detectron2 INFO: Inference done 9450/26446. 0.1596 s / img. ETA=0:45:51
[07/01 10:34:59] detectron2 INFO: Inference done 9482/26446. 0.1596 s / img. ETA=0:45:46
[07/01 10:35:04] detectron2 INFO: Inference done 9513/26446. 0.1596 s / img. ETA=0:45:41
[07/01 10:35:09] detectron2 INFO: Inference done 9544/26446. 0.1596 s / img. ETA=0:45:36
[07/01 10:35:14] detectron2 INFO: Inference done 9574/26446. 0.1596 s / img. ETA=0:45:32
[07/01 10:35:19] detectron2 INFO: Inference done 9602/26446. 0.1596 s / img. ETA=0:45:28
[07/01 10:35:25] detectron2 INFO: Inference done 9633/26446. 0.1597 s / img. ETA=0:45:23
[07/01 10:35:30] detectron2 INFO: Inference done 9665/26446. 0.1596 s / img. ETA=0:45:18
[07/01 10:35:35] detectron2 INFO: Inference done 9696/26446. 0.1597 s / img. ETA=0:45:13
[07/01 10:35:40] detectron2 INFO: Inference done 9727/26446. 0.1597 s / img. ETA=0:45:08
[07/01 10:35:45] detectron2 INFO: Inference done 9758/26446. 0.1597 s / img. ETA=0:45:03
[07/01 10:35:50] detectron2 INFO: Inference done 9789/26446. 0.1597 s / img. ETA=0:44:58
[07/01 10:35:55] detectron2 INFO: Inference done 9820/26446. 0.1597 s / img. ETA=0:44:53
[07/01 10:36:00] detectron2 INFO: Inference done 9851/26446. 0.1597 s / img. ETA=0:44:48
[07/01 10:36:05] detectron2 INFO: Inference done 9882/26446. 0.1597 s / img. ETA=0:44:43
[07/01 10:36:10] detectron2 INFO: Inference done 9913/26446. 0.1597 s / img. ETA=0:44:38
[07/01 10:36:15] detectron2 INFO: Inference done 9944/26446. 0.1597 s / img. ETA=0:44:34
[07/01 10:36:20] detectron2 INFO: Inference done 9975/26446. 0.1597 s / img. ETA=0:44:28
[07/01 10:36:25] detectron2 INFO: Inference done 10006/26446. 0.1597 s / img. ETA=0:44:23
[07/01 10:36:31] detectron2 INFO: Inference done 10038/26446. 0.1597 s / img. ETA=0:44:18
[07/01 10:36:36] detectron2 INFO: Inference done 10070/26446. 0.1597 s / img. ETA=0:44:13
[07/01 10:36:41] detectron2 INFO: Inference done 10101/26446. 0.1597 s / img. ETA=0:44:08
[07/01 10:36:46] detectron2 INFO: Inference done 10133/26446. 0.1597 s / img. ETA=0:44:03
[07/01 10:36:51] detectron2 INFO: Inference done 10164/26446. 0.1597 s / img. ETA=0:43:58
[07/01 10:36:56] detectron2 INFO: Inference done 10195/26446. 0.1597 s / img. ETA=0:43:53
[07/01 10:37:01] detectron2 INFO: Inference done 10227/26446. 0.1597 s / img. ETA=0:43:48
[07/01 10:37:06] detectron2 INFO: Inference done 10259/26446. 0.1597 s / img. ETA=0:43:42
[07/01 10:37:11] detectron2 INFO: Inference done 10291/26446. 0.1597 s / img. ETA=0:43:37
[07/01 10:37:16] detectron2 INFO: Inference done 10322/26446. 0.1597 s / img. ETA=0:43:32
[07/01 10:37:21] detectron2 INFO: Inference done 10353/26446. 0.1597 s / img. ETA=0:43:27
[07/01 10:37:26] detectron2 INFO: Inference done 10384/26446. 0.1597 s / img. ETA=0:43:22
[07/01 10:37:32] detectron2 INFO: Inference done 10415/26446. 0.1597 s / img. ETA=0:43:17
[07/01 10:37:37] detectron2 INFO: Inference done 10446/26446. 0.1597 s / img. ETA=0:43:12
[07/01 10:37:42] detectron2 INFO: Inference done 10476/26446. 0.1597 s / img. ETA=0:43:07
[07/01 10:37:47] detectron2 INFO: Inference done 10507/26446. 0.1597 s / img. ETA=0:43:03
[07/01 10:37:52] detectron2 INFO: Inference done 10538/26446. 0.1597 s / img. ETA=0:42:58
[07/01 10:37:57] detectron2 INFO: Inference done 10569/26446. 0.1597 s / img. ETA=0:42:53
[07/01 10:38:02] detectron2 INFO: Inference done 10600/26446. 0.1597 s / img. ETA=0:42:48
[07/01 10:38:07] detectron2 INFO: Inference done 10631/26446. 0.1597 s / img. ETA=0:42:43
[07/01 10:38:12] detectron2 INFO: Inference done 10663/26446. 0.1597 s / img. ETA=0:42:37
[07/01 10:38:17] detectron2 INFO: Inference done 10693/26446. 0.1597 s / img. ETA=0:42:33
[07/01 10:38:22] detectron2 INFO: Inference done 10724/26446. 0.1597 s / img. ETA=0:42:28
[07/01 10:38:27] detectron2 INFO: Inference done 10755/26446. 0.1598 s / img. ETA=0:42:23
[07/01 10:38:32] detectron2 INFO: Inference done 10786/26446. 0.1598 s / img. ETA=0:42:18
[07/01 10:38:38] detectron2 INFO: Inference done 10817/26446. 0.1598 s / img. ETA=0:42:13
[07/01 10:38:43] detectron2 INFO: Inference done 10848/26446. 0.1598 s / img. ETA=0:42:08
[07/01 10:38:48] detectron2 INFO: Inference done 10879/26446. 0.1598 s / img. ETA=0:42:03
[07/01 10:38:53] detectron2 INFO: Inference done 10910/26446. 0.1598 s / img. ETA=0:41:58
[07/01 10:38:58] detectron2 INFO: Inference done 10940/26446. 0.1598 s / img. ETA=0:41:54
[07/01 10:39:03] detectron2 INFO: Inference done 10970/26446. 0.1598 s / img. ETA=0:41:49
[07/01 10:39:08] detectron2 INFO: Inference done 11000/26446. 0.1598 s / img. ETA=0:41:44
[07/01 10:39:13] detectron2 INFO: Inference done 11030/26446. 0.1598 s / img. ETA=0:41:40
[07/01 10:39:18] detectron2 INFO: Inference done 11061/26446. 0.1598 s / img. ETA=0:41:35
[07/01 10:39:23] detectron2 INFO: Inference done 11092/26446. 0.1598 s / img. ETA=0:41:30
[07/01 10:39:28] detectron2 INFO: Inference done 11122/26446. 0.1599 s / img. ETA=0:41:25
[07/01 10:39:33] detectron2 INFO: Inference done 11153/26446. 0.1599 s / img. ETA=0:41:20
[07/01 10:39:38] detectron2 INFO: Inference done 11184/26446. 0.1599 s / img. ETA=0:41:15
[07/01 10:39:43] detectron2 INFO: Inference done 11214/26446. 0.1599 s / img. ETA=0:41:11
[07/01 10:39:48] detectron2 INFO: Inference done 11245/26446. 0.1599 s / img. ETA=0:41:06
[07/01 10:39:54] detectron2 INFO: Inference done 11276/26446. 0.1599 s / img. ETA=0:41:01
[07/01 10:39:59] detectron2 INFO: Inference done 11306/26446. 0.1599 s / img. ETA=0:40:56
[07/01 10:40:04] detectron2 INFO: Inference done 11337/26446. 0.1599 s / img. ETA=0:40:51
[07/01 10:40:09] detectron2 INFO: Inference done 11368/26446. 0.1599 s / img. ETA=0:40:46
[07/01 10:40:14] detectron2 INFO: Inference done 11399/26446. 0.1599 s / img. ETA=0:40:41
[07/01 10:40:19] detectron2 INFO: Inference done 11430/26446. 0.1599 s / img. ETA=0:40:36
[07/01 10:40:24] detectron2 INFO: Inference done 11461/26446. 0.1599 s / img. ETA=0:40:31
[07/01 10:40:29] detectron2 INFO: Inference done 11491/26446. 0.1599 s / img. ETA=0:40:27
[07/01 10:40:34] detectron2 INFO: Inference done 11523/26446. 0.1599 s / img. ETA=0:40:21
[07/01 10:40:39] detectron2 INFO: Inference done 11553/26446. 0.1599 s / img. ETA=0:40:17
[07/01 10:40:44] detectron2 INFO: Inference done 11584/26446. 0.1600 s / img. ETA=0:40:12
[07/01 10:40:49] detectron2 INFO: Inference done 11614/26446. 0.1600 s / img. ETA=0:40:07
[07/01 10:40:54] detectron2 INFO: Inference done 11645/26446. 0.1600 s / img. ETA=0:40:02
[07/01 10:40:59] detectron2 INFO: Inference done 11675/26446. 0.1600 s / img. ETA=0:39:57
[07/01 10:41:04] detectron2 INFO: Inference done 11706/26446. 0.1600 s / img. ETA=0:39:52
[07/01 10:41:09] detectron2 INFO: Inference done 11737/26446. 0.1600 s / img. ETA=0:39:47
[07/01 10:41:15] detectron2 INFO: Inference done 11769/26446. 0.1600 s / img. ETA=0:39:42
[07/01 10:41:20] detectron2 INFO: Inference done 11800/26446. 0.1600 s / img. ETA=0:39:37
[07/01 10:41:25] detectron2 INFO: Inference done 11831/26446. 0.1600 s / img. ETA=0:39:32
[07/01 10:41:30] detectron2 INFO: Inference done 11862/26446. 0.1600 s / img. ETA=0:39:27
[07/01 10:41:35] detectron2 INFO: Inference done 11893/26446. 0.1600 s / img. ETA=0:39:22
[07/01 10:41:40] detectron2 INFO: Inference done 11925/26446. 0.1600 s / img. ETA=0:39:17
[07/01 10:41:45] detectron2 INFO: Inference done 11956/26446. 0.1600 s / img. ETA=0:39:12
[07/01 10:41:50] detectron2 INFO: Inference done 11987/26446. 0.1600 s / img. ETA=0:39:07
[07/01 10:41:55] detectron2 INFO: Inference done 12018/26446. 0.1600 s / img. ETA=0:39:02
[07/01 10:42:00] detectron2 INFO: Inference done 12050/26446. 0.1600 s / img. ETA=0:38:57
[07/01 10:42:05] detectron2 INFO: Inference done 12080/26446. 0.1600 s / img. ETA=0:38:52
[07/01 10:42:10] detectron2 INFO: Inference done 12111/26446. 0.1600 s / img. ETA=0:38:47
[07/01 10:42:15] detectron2 INFO: Inference done 12142/26446. 0.1600 s / img. ETA=0:38:42
[07/01 10:42:20] detectron2 INFO: Inference done 12173/26446. 0.1600 s / img. ETA=0:38:37
[07/01 10:42:26] detectron2 INFO: Inference done 12204/26446. 0.1600 s / img. ETA=0:38:32
[07/01 10:42:31] detectron2 INFO: Inference done 12235/26446. 0.1600 s / img. ETA=0:38:27
[07/01 10:42:36] detectron2 INFO: Inference done 12266/26446. 0.1600 s / img. ETA=0:38:22
[07/01 10:42:41] detectron2 INFO: Inference done 12296/26446. 0.1600 s / img. ETA=0:38:17
[07/01 10:42:46] detectron2 INFO: Inference done 12327/26446. 0.1600 s / img. ETA=0:38:12
[07/01 10:42:51] detectron2 INFO: Inference done 12358/26446. 0.1600 s / img. ETA=0:38:07
[07/01 10:42:56] detectron2 INFO: Inference done 12389/26446. 0.1600 s / img. ETA=0:38:02
[07/01 10:43:01] detectron2 INFO: Inference done 12420/26446. 0.1600 s / img. ETA=0:37:57
[07/01 10:43:06] detectron2 INFO: Inference done 12451/26446. 0.1600 s / img. ETA=0:37:52
[07/01 10:43:11] detectron2 INFO: Inference done 12482/26446. 0.1600 s / img. ETA=0:37:47
[07/01 10:43:16] detectron2 INFO: Inference done 12513/26446. 0.1600 s / img. ETA=0:37:42
[07/01 10:43:21] detectron2 INFO: Inference done 12544/26446. 0.1600 s / img. ETA=0:37:37
[07/01 10:43:26] detectron2 INFO: Inference done 12575/26446. 0.1600 s / img. ETA=0:37:32
[07/01 10:43:31] detectron2 INFO: Inference done 12607/26446. 0.1600 s / img. ETA=0:37:27
[07/01 10:43:36] detectron2 INFO: Inference done 12639/26446. 0.1600 s / img. ETA=0:37:22
[07/01 10:43:41] detectron2 INFO: Inference done 12670/26446. 0.1600 s / img. ETA=0:37:17
[07/01 10:43:47] detectron2 INFO: Inference done 12702/26446. 0.1600 s / img. ETA=0:37:11
[07/01 10:43:52] detectron2 INFO: Inference done 12733/26446. 0.1600 s / img. ETA=0:37:06
[07/01 10:43:57] detectron2 INFO: Inference done 12764/26446. 0.1600 s / img. ETA=0:37:01
[07/01 10:44:02] detectron2 INFO: Inference done 12796/26446. 0.1600 s / img. ETA=0:36:56
[07/01 10:44:07] detectron2 INFO: Inference done 12827/26446. 0.1600 s / img. ETA=0:36:51
[07/01 10:44:12] detectron2 INFO: Inference done 12858/26446. 0.1600 s / img. ETA=0:36:46
[07/01 10:44:17] detectron2 INFO: Inference done 12889/26446. 0.1600 s / img. ETA=0:36:41
[07/01 10:44:22] detectron2 INFO: Inference done 12921/26446. 0.1600 s / img. ETA=0:36:36
[07/01 10:44:27] detectron2 INFO: Inference done 12952/26446. 0.1600 s / img. ETA=0:36:31
[07/01 10:44:33] detectron2 INFO: Inference done 12984/26446. 0.1600 s / img. ETA=0:36:26
[07/01 10:44:38] detectron2 INFO: Inference done 13015/26446. 0.1600 s / img. ETA=0:36:21
[07/01 10:44:43] detectron2 INFO: Inference done 13046/26446. 0.1600 s / img. ETA=0:36:16
[07/01 10:44:48] detectron2 INFO: Inference done 13077/26446. 0.1600 s / img. ETA=0:36:11
[07/01 10:44:53] detectron2 INFO: Inference done 13108/26446. 0.1600 s / img. ETA=0:36:06
[07/01 10:44:58] detectron2 INFO: Inference done 13140/26446. 0.1600 s / img. ETA=0:36:01
[07/01 10:45:03] detectron2 INFO: Inference done 13172/26446. 0.1600 s / img. ETA=0:35:55
[07/01 10:45:08] detectron2 INFO: Inference done 13204/26446. 0.1600 s / img. ETA=0:35:50
[07/01 10:45:13] detectron2 INFO: Inference done 13235/26446. 0.1600 s / img. ETA=0:35:45
[07/01 10:45:18] detectron2 INFO: Inference done 13265/26446. 0.1601 s / img. ETA=0:35:40
[07/01 10:45:23] detectron2 INFO: Inference done 13296/26446. 0.1601 s / img. ETA=0:35:35
[07/01 10:45:29] detectron2 INFO: Inference done 13327/26446. 0.1601 s / img. ETA=0:35:30
[07/01 10:45:34] detectron2 INFO: Inference done 13358/26446. 0.1601 s / img. ETA=0:35:25
[07/01 10:45:39] detectron2 INFO: Inference done 13389/26446. 0.1601 s / img. ETA=0:35:20
[07/01 10:45:44] detectron2 INFO: Inference done 13420/26446. 0.1601 s / img. ETA=0:35:15
[07/01 10:45:49] detectron2 INFO: Inference done 13451/26446. 0.1601 s / img. ETA=0:35:10
[07/01 10:45:54] detectron2 INFO: Inference done 13482/26446. 0.1601 s / img. ETA=0:35:05
[07/01 10:45:59] detectron2 INFO: Inference done 13513/26446. 0.1601 s / img. ETA=0:35:00
[07/01 10:46:04] detectron2 INFO: Inference done 13545/26446. 0.1601 s / img. ETA=0:34:55
[07/01 10:46:09] detectron2 INFO: Inference done 13576/26446. 0.1601 s / img. ETA=0:34:50
[07/01 10:46:14] detectron2 INFO: Inference done 13607/26446. 0.1601 s / img. ETA=0:34:45
[07/01 10:46:19] detectron2 INFO: Inference done 13638/26446. 0.1601 s / img. ETA=0:34:40
[07/01 10:46:24] detectron2 INFO: Inference done 13669/26446. 0.1601 s / img. ETA=0:34:35
[07/01 10:46:29] detectron2 INFO: Inference done 13700/26446. 0.1601 s / img. ETA=0:34:30
[07/01 10:46:35] detectron2 INFO: Inference done 13731/26446. 0.1601 s / img. ETA=0:34:25
[07/01 10:46:40] detectron2 INFO: Inference done 13762/26446. 0.1601 s / img. ETA=0:34:20
[07/01 10:46:45] detectron2 INFO: Inference done 13794/26446. 0.1601 s / img. ETA=0:34:15
[07/01 10:46:50] detectron2 INFO: Inference done 13824/26446. 0.1601 s / img. ETA=0:34:10
[07/01 10:46:55] detectron2 INFO: Inference done 13854/26446. 0.1601 s / img. ETA=0:34:05
[07/01 10:47:00] detectron2 INFO: Inference done 13883/26446. 0.1601 s / img. ETA=0:34:01
[07/01 10:47:05] detectron2 INFO: Inference done 13913/26446. 0.1601 s / img. ETA=0:33:56
[07/01 10:47:10] detectron2 INFO: Inference done 13943/26446. 0.1602 s / img. ETA=0:33:51
[07/01 10:47:15] detectron2 INFO: Inference done 13974/26446. 0.1602 s / img. ETA=0:33:46
[07/01 10:47:20] detectron2 INFO: Inference done 14005/26446. 0.1602 s / img. ETA=0:33:41
[07/01 10:47:25] detectron2 INFO: Inference done 14036/26446. 0.1602 s / img. ETA=0:33:36
[07/01 10:47:30] detectron2 INFO: Inference done 14068/26446. 0.1601 s / img. ETA=0:33:31
[07/01 10:47:35] detectron2 INFO: Inference done 14099/26446. 0.1601 s / img. ETA=0:33:26
[07/01 10:47:40] detectron2 INFO: Inference done 14130/26446. 0.1601 s / img. ETA=0:33:21
[07/01 10:47:45] detectron2 INFO: Inference done 14161/26446. 0.1602 s / img. ETA=0:33:16
[07/01 10:47:50] detectron2 INFO: Inference done 14192/26446. 0.1602 s / img. ETA=0:33:11
[07/01 10:47:56] detectron2 INFO: Inference done 14223/26446. 0.1602 s / img. ETA=0:33:06
[07/01 10:48:01] detectron2 INFO: Inference done 14254/26446. 0.1602 s / img. ETA=0:33:01
[07/01 10:48:06] detectron2 INFO: Inference done 14286/26446. 0.1602 s / img. ETA=0:32:56
[07/01 10:48:11] detectron2 INFO: Inference done 14317/26446. 0.1602 s / img. ETA=0:32:51
[07/01 10:48:16] detectron2 INFO: Inference done 14348/26446. 0.1602 s / img. ETA=0:32:46
[07/01 10:48:21] detectron2 INFO: Inference done 14380/26446. 0.1602 s / img. ETA=0:32:41
[07/01 10:48:26] detectron2 INFO: Inference done 14411/26446. 0.1602 s / img. ETA=0:32:36
[07/01 10:48:31] detectron2 INFO: Inference done 14442/26446. 0.1602 s / img. ETA=0:32:31
[07/01 10:48:36] detectron2 INFO: Inference done 14474/26446. 0.1602 s / img. ETA=0:32:25
[07/01 10:48:42] detectron2 INFO: Inference done 14506/26446. 0.1602 s / img. ETA=0:32:20
[07/01 10:48:47] detectron2 INFO: Inference done 14538/26446. 0.1601 s / img. ETA=0:32:15
[07/01 10:48:52] detectron2 INFO: Inference done 14569/26446. 0.1602 s / img. ETA=0:32:10
[07/01 10:48:57] detectron2 INFO: Inference done 14600/26446. 0.1602 s / img. ETA=0:32:05
[07/01 10:49:02] detectron2 INFO: Inference done 14631/26446. 0.1602 s / img. ETA=0:32:00
[07/01 10:49:07] detectron2 INFO: Inference done 14662/26446. 0.1602 s / img. ETA=0:31:55
[07/01 10:49:12] detectron2 INFO: Inference done 14693/26446. 0.1602 s / img. ETA=0:31:50
[07/01 10:49:17] detectron2 INFO: Inference done 14725/26446. 0.1601 s / img. ETA=0:31:44
[07/01 10:49:22] detectron2 INFO: Inference done 14756/26446. 0.1602 s / img. ETA=0:31:39
[07/01 10:49:27] detectron2 INFO: Inference done 14787/26446. 0.1602 s / img. ETA=0:31:34
[07/01 10:49:32] detectron2 INFO: Inference done 14818/26446. 0.1602 s / img. ETA=0:31:29
[07/01 10:49:37] detectron2 INFO: Inference done 14850/26446. 0.1602 s / img. ETA=0:31:24
[07/01 10:49:42] detectron2 INFO: Inference done 14881/26446. 0.1602 s / img. ETA=0:31:19
[07/01 10:49:48] detectron2 INFO: Inference done 14913/26446. 0.1601 s / img. ETA=0:31:14
[07/01 10:49:53] detectron2 INFO: Inference done 14944/26446. 0.1602 s / img. ETA=0:31:09
[07/01 10:49:58] detectron2 INFO: Inference done 14975/26446. 0.1602 s / img. ETA=0:31:04
[07/01 10:50:03] detectron2 INFO: Inference done 15006/26446. 0.1602 s / img. ETA=0:30:59
[07/01 10:50:08] detectron2 INFO: Inference done 15037/26446. 0.1602 s / img. ETA=0:30:54
[07/01 10:50:13] detectron2 INFO: Inference done 15068/26446. 0.1602 s / img. ETA=0:30:49
[07/01 10:50:18] detectron2 INFO: Inference done 15099/26446. 0.1602 s / img. ETA=0:30:44
[07/01 10:50:23] detectron2 INFO: Inference done 15130/26446. 0.1602 s / img. ETA=0:30:39
[07/01 10:50:28] detectron2 INFO: Inference done 15161/26446. 0.1602 s / img. ETA=0:30:34
[07/01 10:50:33] detectron2 INFO: Inference done 15192/26446. 0.1602 s / img. ETA=0:30:29
[07/01 10:50:38] detectron2 INFO: Inference done 15223/26446. 0.1602 s / img. ETA=0:30:24
[07/01 10:50:43] detectron2 INFO: Inference done 15255/26446. 0.1602 s / img. ETA=0:30:18
[07/01 10:50:49] detectron2 INFO: Inference done 15286/26446. 0.1602 s / img. ETA=0:30:13
[07/01 10:50:54] detectron2 INFO: Inference done 15317/26446. 0.1602 s / img. ETA=0:30:08
[07/01 10:50:59] detectron2 INFO: Inference done 15348/26446. 0.1602 s / img. ETA=0:30:03
[07/01 10:51:04] detectron2 INFO: Inference done 15379/26446. 0.1602 s / img. ETA=0:29:58
[07/01 10:51:09] detectron2 INFO: Inference done 15410/26446. 0.1602 s / img. ETA=0:29:53
[07/01 10:51:14] detectron2 INFO: Inference done 15441/26446. 0.1602 s / img. ETA=0:29:48
[07/01 10:51:19] detectron2 INFO: Inference done 15472/26446. 0.1602 s / img. ETA=0:29:43
[07/01 10:51:24] detectron2 INFO: Inference done 15503/26446. 0.1602 s / img. ETA=0:29:38
[07/01 10:51:29] detectron2 INFO: Inference done 15534/26446. 0.1602 s / img. ETA=0:29:33
[07/01 10:51:34] detectron2 INFO: Inference done 15565/26446. 0.1602 s / img. ETA=0:29:28
[07/01 10:51:39] detectron2 INFO: Inference done 15596/26446. 0.1602 s / img. ETA=0:29:23
[07/01 10:51:44] detectron2 INFO: Inference done 15627/26446. 0.1602 s / img. ETA=0:29:18
[07/01 10:51:49] detectron2 INFO: Inference done 15658/26446. 0.1602 s / img. ETA=0:29:13
[07/01 10:51:54] detectron2 INFO: Inference done 15689/26446. 0.1602 s / img. ETA=0:29:08
[07/01 10:51:59] detectron2 INFO: Inference done 15720/26446. 0.1602 s / img. ETA=0:29:03
[07/01 10:52:04] detectron2 INFO: Inference done 15751/26446. 0.1602 s / img. ETA=0:28:58
[07/01 10:52:09] detectron2 INFO: Inference done 15783/26446. 0.1602 s / img. ETA=0:28:53
[07/01 10:52:15] detectron2 INFO: Inference done 15814/26446. 0.1602 s / img. ETA=0:28:48
[07/01 10:52:20] detectron2 INFO: Inference done 15844/26446. 0.1602 s / img. ETA=0:28:43
[07/01 10:52:25] detectron2 INFO: Inference done 15875/26446. 0.1602 s / img. ETA=0:28:38
[07/01 10:52:30] detectron2 INFO: Inference done 15904/26446. 0.1602 s / img. ETA=0:28:33
[07/01 10:52:35] detectron2 INFO: Inference done 15925/26446. 0.1602 s / img. ETA=0:28:31
[07/01 10:52:40] detectron2 INFO: Inference done 15955/26446. 0.1602 s / img. ETA=0:28:26
[07/01 10:52:45] detectron2 INFO: Inference done 15985/26446. 0.1603 s / img. ETA=0:28:22
[07/01 10:52:50] detectron2 INFO: Inference done 16015/26446. 0.1603 s / img. ETA=0:28:17
[07/01 10:52:55] detectron2 INFO: Inference done 16045/26446. 0.1603 s / img. ETA=0:28:12
[07/01 10:53:00] detectron2 INFO: Inference done 16076/26446. 0.1603 s / img. ETA=0:28:07
[07/01 10:53:05] detectron2 INFO: Inference done 16107/26446. 0.1603 s / img. ETA=0:28:02
[07/01 10:53:11] detectron2 INFO: Inference done 16137/26446. 0.1603 s / img. ETA=0:27:57
[07/01 10:53:16] detectron2 INFO: Inference done 16168/26446. 0.1603 s / img. ETA=0:27:52
[07/01 10:53:21] detectron2 INFO: Inference done 16198/26446. 0.1603 s / img. ETA=0:27:48
[07/01 10:53:26] detectron2 INFO: Inference done 16228/26446. 0.1603 s / img. ETA=0:27:43
[07/01 10:53:31] detectron2 INFO: Inference done 16258/26446. 0.1603 s / img. ETA=0:27:38
[07/01 10:53:36] detectron2 INFO: Inference done 16289/26446. 0.1604 s / img. ETA=0:27:33
[07/01 10:53:41] detectron2 INFO: Inference done 16320/26446. 0.1604 s / img. ETA=0:27:28
[07/01 10:53:46] detectron2 INFO: Inference done 16350/26446. 0.1604 s / img. ETA=0:27:23
[07/01 10:53:51] detectron2 INFO: Inference done 16380/26446. 0.1604 s / img. ETA=0:27:19
[07/01 10:53:56] detectron2 INFO: Inference done 16410/26446. 0.1604 s / img. ETA=0:27:14
[07/01 10:54:01] detectron2 INFO: Inference done 16440/26446. 0.1604 s / img. ETA=0:27:09
[07/01 10:54:06] detectron2 INFO: Inference done 16470/26446. 0.1604 s / img. ETA=0:27:04
[07/01 10:54:12] detectron2 INFO: Inference done 16500/26446. 0.1604 s / img. ETA=0:27:00
[07/01 10:54:17] detectron2 INFO: Inference done 16531/26446. 0.1604 s / img. ETA=0:26:55
[07/01 10:54:22] detectron2 INFO: Inference done 16561/26446. 0.1604 s / img. ETA=0:26:50
[07/01 10:54:27] detectron2 INFO: Inference done 16591/26446. 0.1604 s / img. ETA=0:26:45
[07/01 10:54:32] detectron2 INFO: Inference done 16622/26446. 0.1604 s / img. ETA=0:26:40
[07/01 10:54:37] detectron2 INFO: Inference done 16653/26446. 0.1605 s / img. ETA=0:26:35
[07/01 10:54:42] detectron2 INFO: Inference done 16683/26446. 0.1605 s / img. ETA=0:26:30
[07/01 10:54:47] detectron2 INFO: Inference done 16714/26446. 0.1605 s / img. ETA=0:26:25
[07/01 10:54:52] detectron2 INFO: Inference done 16745/26446. 0.1605 s / img. ETA=0:26:20
[07/01 10:54:57] detectron2 INFO: Inference done 16775/26446. 0.1605 s / img. ETA=0:26:15
[07/01 10:55:02] detectron2 INFO: Inference done 16806/26446. 0.1605 s / img. ETA=0:26:10
[07/01 10:55:07] detectron2 INFO: Inference done 16836/26446. 0.1605 s / img. ETA=0:26:06
[07/01 10:55:13] detectron2 INFO: Inference done 16867/26446. 0.1605 s / img. ETA=0:26:01
[07/01 10:55:18] detectron2 INFO: Inference done 16898/26446. 0.1605 s / img. ETA=0:25:56
[07/01 10:55:23] detectron2 INFO: Inference done 16929/26446. 0.1605 s / img. ETA=0:25:51
[07/01 10:55:28] detectron2 INFO: Inference done 16959/26446. 0.1605 s / img. ETA=0:25:46
[07/01 10:55:33] detectron2 INFO: Inference done 16988/26446. 0.1605 s / img. ETA=0:25:41
[07/01 10:55:38] detectron2 INFO: Inference done 17018/26446. 0.1606 s / img. ETA=0:25:36
[07/01 10:55:43] detectron2 INFO: Inference done 17049/26446. 0.1606 s / img. ETA=0:25:31
[07/01 10:55:48] detectron2 INFO: Inference done 17079/26446. 0.1606 s / img. ETA=0:25:27
[07/01 10:55:53] detectron2 INFO: Inference done 17110/26446. 0.1606 s / img. ETA=0:25:22
[07/01 10:55:59] detectron2 INFO: Inference done 17141/26446. 0.1606 s / img. ETA=0:25:17
[07/01 10:56:04] detectron2 INFO: Inference done 17171/26446. 0.1606 s / img. ETA=0:25:12
[07/01 10:56:09] detectron2 INFO: Inference done 17202/26446. 0.1606 s / img. ETA=0:25:07
[07/01 10:56:14] detectron2 INFO: Inference done 17233/26446. 0.1606 s / img. ETA=0:25:02
[07/01 10:56:19] detectron2 INFO: Inference done 17263/26446. 0.1606 s / img. ETA=0:24:57
[07/01 10:56:24] detectron2 INFO: Inference done 17294/26446. 0.1606 s / img. ETA=0:24:52
[07/01 10:56:29] detectron2 INFO: Inference done 17325/26446. 0.1606 s / img. ETA=0:24:47
[07/01 10:56:34] detectron2 INFO: Inference done 17354/26446. 0.1606 s / img. ETA=0:24:42
[07/01 10:56:39] detectron2 INFO: Inference done 17384/26446. 0.1606 s / img. ETA=0:24:38
[07/01 10:56:44] detectron2 INFO: Inference done 17414/26446. 0.1607 s / img. ETA=0:24:33
[07/01 10:56:50] detectron2 INFO: Inference done 17445/26446. 0.1607 s / img. ETA=0:24:28
[07/01 10:56:55] detectron2 INFO: Inference done 17476/26446. 0.1607 s / img. ETA=0:24:23
[07/01 10:57:00] detectron2 INFO: Inference done 17504/26446. 0.1607 s / img. ETA=0:24:18
[07/01 10:57:05] detectron2 INFO: Inference done 17534/26446. 0.1607 s / img. ETA=0:24:14
[07/01 10:57:10] detectron2 INFO: Inference done 17563/26446. 0.1607 s / img. ETA=0:24:09
[07/01 10:57:15] detectron2 INFO: Inference done 17593/26446. 0.1607 s / img. ETA=0:24:04
[07/01 10:57:20] detectron2 INFO: Inference done 17623/26446. 0.1607 s / img. ETA=0:23:59
[07/01 10:57:25] detectron2 INFO: Inference done 17653/26446. 0.1607 s / img. ETA=0:23:55
[07/01 10:57:30] detectron2 INFO: Inference done 17683/26446. 0.1608 s / img. ETA=0:23:50
[07/01 10:57:35] detectron2 INFO: Inference done 17713/26446. 0.1608 s / img. ETA=0:23:45
[07/01 10:57:40] detectron2 INFO: Inference done 17743/26446. 0.1608 s / img. ETA=0:23:40
[07/01 10:57:45] detectron2 INFO: Inference done 17774/26446. 0.1608 s / img. ETA=0:23:35
[07/01 10:57:50] detectron2 INFO: Inference done 17804/26446. 0.1608 s / img. ETA=0:23:30
[07/01 10:57:55] detectron2 INFO: Inference done 17834/26446. 0.1608 s / img. ETA=0:23:25
[07/01 10:58:01] detectron2 INFO: Inference done 17863/26446. 0.1608 s / img. ETA=0:23:21
[07/01 10:58:06] detectron2 INFO: Inference done 17891/26446. 0.1608 s / img. ETA=0:23:17
[07/01 10:58:11] detectron2 INFO: Inference done 17922/26446. 0.1608 s / img. ETA=0:23:12
[07/01 10:58:16] detectron2 INFO: Inference done 17953/26446. 0.1608 s / img. ETA=0:23:07
[07/01 10:58:21] detectron2 INFO: Inference done 17984/26446. 0.1608 s / img. ETA=0:23:01
[07/01 10:58:26] detectron2 INFO: Inference done 18015/26446. 0.1609 s / img. ETA=0:22:56
[07/01 10:58:31] detectron2 INFO: Inference done 18047/26446. 0.1608 s / img. ETA=0:22:51
[07/01 10:58:36] detectron2 INFO: Inference done 18078/26446. 0.1608 s / img. ETA=0:22:46
[07/01 10:58:41] detectron2 INFO: Inference done 18110/26446. 0.1608 s / img. ETA=0:22:41
[07/01 10:58:46] detectron2 INFO: Inference done 18141/26446. 0.1608 s / img. ETA=0:22:36
[07/01 10:58:52] detectron2 INFO: Inference done 18173/26446. 0.1608 s / img. ETA=0:22:30
[07/01 10:58:57] detectron2 INFO: Inference done 18205/26446. 0.1608 s / img. ETA=0:22:25
[07/01 10:59:02] detectron2 INFO: Inference done 18237/26446. 0.1608 s / img. ETA=0:22:20
[07/01 10:59:07] detectron2 INFO: Inference done 18268/26446. 0.1608 s / img. ETA=0:22:15
[07/01 10:59:12] detectron2 INFO: Inference done 18300/26446. 0.1608 s / img. ETA=0:22:10
[07/01 10:59:17] detectron2 INFO: Inference done 18332/26446. 0.1608 s / img. ETA=0:22:04
[07/01 10:59:22] detectron2 INFO: Inference done 18364/26446. 0.1608 s / img. ETA=0:21:59
[07/01 10:59:27] detectron2 INFO: Inference done 18395/26446. 0.1608 s / img. ETA=0:21:54
[07/01 10:59:32] detectron2 INFO: Inference done 18426/26446. 0.1608 s / img. ETA=0:21:49
[07/01 10:59:37] detectron2 INFO: Inference done 18457/26446. 0.1608 s / img. ETA=0:21:44
[07/01 10:59:42] detectron2 INFO: Inference done 18488/26446. 0.1608 s / img. ETA=0:21:39
[07/01 10:59:47] detectron2 INFO: Inference done 18519/26446. 0.1608 s / img. ETA=0:21:34
[07/01 10:59:53] detectron2 INFO: Inference done 18551/26446. 0.1608 s / img. ETA=0:21:28
[07/01 10:59:58] detectron2 INFO: Inference done 18583/26446. 0.1608 s / img. ETA=0:21:23
[07/01 11:00:03] detectron2 INFO: Inference done 18614/26446. 0.1608 s / img. ETA=0:21:18
[07/01 11:00:08] detectron2 INFO: Inference done 18645/26446. 0.1608 s / img. ETA=0:21:13
[07/01 11:00:13] detectron2 INFO: Inference done 18676/26446. 0.1608 s / img. ETA=0:21:08
[07/01 11:00:18] detectron2 INFO: Inference done 18707/26446. 0.1608 s / img. ETA=0:21:03
[07/01 11:00:23] detectron2 INFO: Inference done 18738/26446. 0.1608 s / img. ETA=0:20:58
[07/01 11:00:28] detectron2 INFO: Inference done 18769/26446. 0.1608 s / img. ETA=0:20:53
[07/01 11:00:33] detectron2 INFO: Inference done 18800/26446. 0.1608 s / img. ETA=0:20:48
[07/01 11:00:38] detectron2 INFO: Inference done 18831/26446. 0.1608 s / img. ETA=0:20:43
[07/01 11:00:43] detectron2 INFO: Inference done 18862/26446. 0.1608 s / img. ETA=0:20:38
[07/01 11:00:48] detectron2 INFO: Inference done 18893/26446. 0.1608 s / img. ETA=0:20:32
[07/01 11:00:53] detectron2 INFO: Inference done 18924/26446. 0.1608 s / img. ETA=0:20:27
[07/01 11:00:58] detectron2 INFO: Inference done 18955/26446. 0.1608 s / img. ETA=0:20:22
[07/01 11:01:03] detectron2 INFO: Inference done 18986/26446. 0.1608 s / img. ETA=0:20:17
[07/01 11:01:08] detectron2 INFO: Inference done 19018/26446. 0.1608 s / img. ETA=0:20:12
[07/01 11:01:13] detectron2 INFO: Inference done 19049/26446. 0.1608 s / img. ETA=0:20:07
[07/01 11:01:18] detectron2 INFO: Inference done 19080/26446. 0.1608 s / img. ETA=0:20:02
[07/01 11:01:24] detectron2 INFO: Inference done 19111/26446. 0.1608 s / img. ETA=0:19:57
[07/01 11:01:29] detectron2 INFO: Inference done 19142/26446. 0.1608 s / img. ETA=0:19:52
[07/01 11:01:34] detectron2 INFO: Inference done 19173/26446. 0.1608 s / img. ETA=0:19:47
[07/01 11:01:39] detectron2 INFO: Inference done 19204/26446. 0.1608 s / img. ETA=0:19:42
[07/01 11:01:44] detectron2 INFO: Inference done 19235/26446. 0.1608 s / img. ETA=0:19:37
[07/01 11:01:49] detectron2 INFO: Inference done 19266/26446. 0.1608 s / img. ETA=0:19:32
[07/01 11:01:54] detectron2 INFO: Inference done 19297/26446. 0.1608 s / img. ETA=0:19:27
[07/01 11:01:59] detectron2 INFO: Inference done 19328/26446. 0.1608 s / img. ETA=0:19:21
[07/01 11:02:04] detectron2 INFO: Inference done 19359/26446. 0.1608 s / img. ETA=0:19:16
[07/01 11:02:09] detectron2 INFO: Inference done 19390/26446. 0.1608 s / img. ETA=0:19:11
[07/01 11:02:14] detectron2 INFO: Inference done 19422/26446. 0.1608 s / img. ETA=0:19:06
[07/01 11:02:20] detectron2 INFO: Inference done 19452/26446. 0.1608 s / img. ETA=0:19:01
[07/01 11:02:25] detectron2 INFO: Inference done 19483/26446. 0.1608 s / img. ETA=0:18:56
[07/01 11:02:30] detectron2 INFO: Inference done 19514/26446. 0.1608 s / img. ETA=0:18:51
[07/01 11:02:35] detectron2 INFO: Inference done 19544/26446. 0.1608 s / img. ETA=0:18:46
[07/01 11:02:40] detectron2 INFO: Inference done 19574/26446. 0.1608 s / img. ETA=0:18:41
[07/01 11:02:45] detectron2 INFO: Inference done 19604/26446. 0.1608 s / img. ETA=0:18:37
[07/01 11:02:50] detectron2 INFO: Inference done 19635/26446. 0.1608 s / img. ETA=0:18:32
[07/01 11:02:55] detectron2 INFO: Inference done 19665/26446. 0.1608 s / img. ETA=0:18:27
[07/01 11:03:00] detectron2 INFO: Inference done 19695/26446. 0.1608 s / img. ETA=0:18:22
[07/01 11:03:05] detectron2 INFO: Inference done 19725/26446. 0.1608 s / img. ETA=0:18:17
[07/01 11:03:10] detectron2 INFO: Inference done 19756/26446. 0.1608 s / img. ETA=0:18:12
[07/01 11:03:15] detectron2 INFO: Inference done 19786/26446. 0.1609 s / img. ETA=0:18:07
[07/01 11:03:20] detectron2 INFO: Inference done 19817/26446. 0.1609 s / img. ETA=0:18:02
[07/01 11:03:25] detectron2 INFO: Inference done 19847/26446. 0.1609 s / img. ETA=0:17:57
[07/01 11:03:31] detectron2 INFO: Inference done 19877/26446. 0.1609 s / img. ETA=0:17:52
[07/01 11:03:36] detectron2 INFO: Inference done 19908/26446. 0.1609 s / img. ETA=0:17:47
[07/01 11:03:41] detectron2 INFO: Inference done 19939/26446. 0.1609 s / img. ETA=0:17:42
[07/01 11:03:46] detectron2 INFO: Inference done 19970/26446. 0.1609 s / img. ETA=0:17:37
[07/01 11:03:51] detectron2 INFO: Inference done 20000/26446. 0.1609 s / img. ETA=0:17:32
[07/01 11:03:56] detectron2 INFO: Inference done 20030/26446. 0.1609 s / img. ETA=0:17:28
[07/01 11:04:01] detectron2 INFO: Inference done 20060/26446. 0.1609 s / img. ETA=0:17:23
[07/01 11:04:06] detectron2 INFO: Inference done 20090/26446. 0.1609 s / img. ETA=0:17:18
[07/01 11:04:11] detectron2 INFO: Inference done 20120/26446. 0.1609 s / img. ETA=0:17:13
[07/01 11:04:16] detectron2 INFO: Inference done 20150/26446. 0.1609 s / img. ETA=0:17:08
[07/01 11:04:21] detectron2 INFO: Inference done 20180/26446. 0.1609 s / img. ETA=0:17:03
[07/01 11:04:27] detectron2 INFO: Inference done 20211/26446. 0.1609 s / img. ETA=0:16:58
[07/01 11:04:32] detectron2 INFO: Inference done 20241/26446. 0.1610 s / img. ETA=0:16:54
[07/01 11:04:37] detectron2 INFO: Inference done 20271/26446. 0.1610 s / img. ETA=0:16:49
[07/01 11:04:42] detectron2 INFO: Inference done 20302/26446. 0.1610 s / img. ETA=0:16:44
[07/01 11:04:47] detectron2 INFO: Inference done 20333/26446. 0.1610 s / img. ETA=0:16:39
[07/01 11:04:52] detectron2 INFO: Inference done 20363/26446. 0.1610 s / img. ETA=0:16:34
[07/01 11:04:57] detectron2 INFO: Inference done 20393/26446. 0.1610 s / img. ETA=0:16:29
[07/01 11:05:02] detectron2 INFO: Inference done 20424/26446. 0.1610 s / img. ETA=0:16:24
[07/01 11:05:07] detectron2 INFO: Inference done 20454/26446. 0.1610 s / img. ETA=0:16:19
[07/01 11:05:13] detectron2 INFO: Inference done 20485/26446. 0.1610 s / img. ETA=0:16:14
[07/01 11:05:18] detectron2 INFO: Inference done 20515/26446. 0.1610 s / img. ETA=0:16:09
[07/01 11:05:23] detectron2 INFO: Inference done 20545/26446. 0.1610 s / img. ETA=0:16:04
[07/01 11:05:28] detectron2 INFO: Inference done 20575/26446. 0.1610 s / img. ETA=0:15:59
[07/01 11:05:33] detectron2 INFO: Inference done 20606/26446. 0.1610 s / img. ETA=0:15:54
[07/01 11:05:38] detectron2 INFO: Inference done 20636/26446. 0.1610 s / img. ETA=0:15:49
[07/01 11:05:43] detectron2 INFO: Inference done 20666/26446. 0.1610 s / img. ETA=0:15:45
[07/01 11:05:48] detectron2 INFO: Inference done 20696/26446. 0.1611 s / img. ETA=0:15:40
[07/01 11:05:53] detectron2 INFO: Inference done 20724/26446. 0.1611 s / img. ETA=0:15:35
[07/01 11:05:58] detectron2 INFO: Inference done 20752/26446. 0.1611 s / img. ETA=0:15:31
[07/01 11:06:03] detectron2 INFO: Inference done 20783/26446. 0.1611 s / img. ETA=0:15:26
[07/01 11:06:08] detectron2 INFO: Inference done 20813/26446. 0.1611 s / img. ETA=0:15:21
[07/01 11:06:14] detectron2 INFO: Inference done 20843/26446. 0.1611 s / img. ETA=0:15:16
[07/01 11:06:19] detectron2 INFO: Inference done 20873/26446. 0.1611 s / img. ETA=0:15:11
[07/01 11:06:24] detectron2 INFO: Inference done 20903/26446. 0.1611 s / img. ETA=0:15:06
[07/01 11:06:29] detectron2 INFO: Inference done 20934/26446. 0.1611 s / img. ETA=0:15:01
[07/01 11:06:34] detectron2 INFO: Inference done 20964/26446. 0.1611 s / img. ETA=0:14:56
[07/01 11:06:39] detectron2 INFO: Inference done 20994/26446. 0.1611 s / img. ETA=0:14:52
[07/01 11:06:44] detectron2 INFO: Inference done 21025/26446. 0.1612 s / img. ETA=0:14:46
[07/01 11:06:49] detectron2 INFO: Inference done 21056/26446. 0.1612 s / img. ETA=0:14:41
[07/01 11:06:54] detectron2 INFO: Inference done 21086/26446. 0.1612 s / img. ETA=0:14:37
[07/01 11:06:59] detectron2 INFO: Inference done 21116/26446. 0.1612 s / img. ETA=0:14:32
[07/01 11:07:04] detectron2 INFO: Inference done 21146/26446. 0.1612 s / img. ETA=0:14:27
[07/01 11:07:09] detectron2 INFO: Inference done 21177/26446. 0.1612 s / img. ETA=0:14:22
[07/01 11:07:15] detectron2 INFO: Inference done 21207/26446. 0.1612 s / img. ETA=0:14:17
[07/01 11:07:20] detectron2 INFO: Inference done 21237/26446. 0.1612 s / img. ETA=0:14:12
[07/01 11:07:25] detectron2 INFO: Inference done 21262/26446. 0.1612 s / img. ETA=0:14:08
[07/01 11:07:30] detectron2 INFO: Inference done 21288/26446. 0.1613 s / img. ETA=0:14:04
[07/01 11:07:35] detectron2 INFO: Inference done 21316/26446. 0.1613 s / img. ETA=0:14:00
[07/01 11:07:40] detectron2 INFO: Inference done 21345/26446. 0.1613 s / img. ETA=0:13:55
[07/01 11:07:45] detectron2 INFO: Inference done 21373/26446. 0.1613 s / img. ETA=0:13:50
[07/01 11:07:50] detectron2 INFO: Inference done 21402/26446. 0.1613 s / img. ETA=0:13:46
[07/01 11:07:55] detectron2 INFO: Inference done 21431/26446. 0.1614 s / img. ETA=0:13:41
[07/01 11:08:00] detectron2 INFO: Inference done 21460/26446. 0.1614 s / img. ETA=0:13:36
[07/01 11:08:05] detectron2 INFO: Inference done 21491/26446. 0.1614 s / img. ETA=0:13:31
[07/01 11:08:10] detectron2 INFO: Inference done 21522/26446. 0.1614 s / img. ETA=0:13:26
[07/01 11:08:15] detectron2 INFO: Inference done 21553/26446. 0.1614 s / img. ETA=0:13:21
[07/01 11:08:20] detectron2 INFO: Inference done 21583/26446. 0.1614 s / img. ETA=0:13:16
[07/01 11:08:26] detectron2 INFO: Inference done 21614/26446. 0.1614 s / img. ETA=0:13:11
[07/01 11:08:31] detectron2 INFO: Inference done 21645/26446. 0.1614 s / img. ETA=0:13:06
[07/01 11:08:36] detectron2 INFO: Inference done 21676/26446. 0.1614 s / img. ETA=0:13:01
[07/01 11:08:41] detectron2 INFO: Inference done 21707/26446. 0.1614 s / img. ETA=0:12:56
[07/01 11:08:46] detectron2 INFO: Inference done 21739/26446. 0.1614 s / img. ETA=0:12:51
[07/01 11:08:51] detectron2 INFO: Inference done 21771/26446. 0.1614 s / img. ETA=0:12:45
[07/01 11:08:56] detectron2 INFO: Inference done 21802/26446. 0.1614 s / img. ETA=0:12:40
[07/01 11:09:01] detectron2 INFO: Inference done 21833/26446. 0.1614 s / img. ETA=0:12:35
[07/01 11:09:06] detectron2 INFO: Inference done 21864/26446. 0.1614 s / img. ETA=0:12:30
[07/01 11:09:11] detectron2 INFO: Inference done 21894/26446. 0.1614 s / img. ETA=0:12:25
[07/01 11:09:16] detectron2 INFO: Inference done 21925/26446. 0.1614 s / img. ETA=0:12:20
[07/01 11:09:21] detectron2 INFO: Inference done 21951/26446. 0.1614 s / img. ETA=0:12:16
[07/01 11:09:26] detectron2 INFO: Inference done 21981/26446. 0.1614 s / img. ETA=0:12:11
[07/01 11:09:32] detectron2 INFO: Inference done 22013/26446. 0.1614 s / img. ETA=0:12:06
[07/01 11:09:37] detectron2 INFO: Inference done 22044/26446. 0.1614 s / img. ETA=0:12:01
[07/01 11:09:42] detectron2 INFO: Inference done 22075/26446. 0.1614 s / img. ETA=0:11:56
[07/01 11:09:47] detectron2 INFO: Inference done 22106/26446. 0.1614 s / img. ETA=0:11:51
[07/01 11:09:52] detectron2 INFO: Inference done 22137/26446. 0.1614 s / img. ETA=0:11:46
[07/01 11:09:57] detectron2 INFO: Inference done 22168/26446. 0.1614 s / img. ETA=0:11:41
[07/01 11:10:02] detectron2 INFO: Inference done 22199/26446. 0.1614 s / img. ETA=0:11:36
[07/01 11:10:07] detectron2 INFO: Inference done 22230/26446. 0.1614 s / img. ETA=0:11:30
[07/01 11:10:12] detectron2 INFO: Inference done 22260/26446. 0.1614 s / img. ETA=0:11:26
[07/01 11:10:17] detectron2 INFO: Inference done 22288/26446. 0.1615 s / img. ETA=0:11:21
[07/01 11:10:23] detectron2 INFO: Inference done 22318/26446. 0.1615 s / img. ETA=0:11:16
[07/01 11:10:28] detectron2 INFO: Inference done 22348/26446. 0.1615 s / img. ETA=0:11:11
[07/01 11:10:33] detectron2 INFO: Inference done 22379/26446. 0.1615 s / img. ETA=0:11:06
[07/01 11:10:38] detectron2 INFO: Inference done 22410/26446. 0.1615 s / img. ETA=0:11:01
[07/01 11:10:43] detectron2 INFO: Inference done 22441/26446. 0.1615 s / img. ETA=0:10:56
[07/01 11:10:48] detectron2 INFO: Inference done 22472/26446. 0.1615 s / img. ETA=0:10:51
[07/01 11:10:53] detectron2 INFO: Inference done 22503/26446. 0.1615 s / img. ETA=0:10:46
[07/01 11:10:58] detectron2 INFO: Inference done 22534/26446. 0.1615 s / img. ETA=0:10:41
[07/01 11:11:03] detectron2 INFO: Inference done 22565/26446. 0.1615 s / img. ETA=0:10:36
[07/01 11:11:08] detectron2 INFO: Inference done 22596/26446. 0.1615 s / img. ETA=0:10:31
[07/01 11:11:13] detectron2 INFO: Inference done 22628/26446. 0.1615 s / img. ETA=0:10:25
[07/01 11:11:19] detectron2 INFO: Inference done 22659/26446. 0.1615 s / img. ETA=0:10:20
[07/01 11:11:24] detectron2 INFO: Inference done 22691/26446. 0.1615 s / img. ETA=0:10:15
[07/01 11:11:29] detectron2 INFO: Inference done 22722/26446. 0.1615 s / img. ETA=0:10:10
[07/01 11:11:34] detectron2 INFO: Inference done 22753/26446. 0.1615 s / img. ETA=0:10:05
[07/01 11:11:39] detectron2 INFO: Inference done 22784/26446. 0.1615 s / img. ETA=0:10:00
[07/01 11:11:44] detectron2 INFO: Inference done 22814/26446. 0.1615 s / img. ETA=0:09:55
[07/01 11:11:49] detectron2 INFO: Inference done 22845/26446. 0.1615 s / img. ETA=0:09:50
[07/01 11:11:54] detectron2 INFO: Inference done 22876/26446. 0.1615 s / img. ETA=0:09:45
[07/01 11:11:59] detectron2 INFO: Inference done 22907/26446. 0.1615 s / img. ETA=0:09:40
[07/01 11:12:04] detectron2 INFO: Inference done 22938/26446. 0.1615 s / img. ETA=0:09:35
[07/01 11:12:09] detectron2 INFO: Inference done 22968/26446. 0.1615 s / img. ETA=0:09:30
[07/01 11:12:14] detectron2 INFO: Inference done 22999/26446. 0.1615 s / img. ETA=0:09:25
[07/01 11:12:19] detectron2 INFO: Inference done 23030/26446. 0.1615 s / img. ETA=0:09:19
[07/01 11:12:24] detectron2 INFO: Inference done 23061/26446. 0.1615 s / img. ETA=0:09:14
[07/01 11:12:29] detectron2 INFO: Inference done 23091/26446. 0.1615 s / img. ETA=0:09:09
[07/01 11:12:34] detectron2 INFO: Inference done 23123/26446. 0.1615 s / img. ETA=0:09:04
[07/01 11:12:39] detectron2 INFO: Inference done 23154/26446. 0.1614 s / img. ETA=0:08:59
[07/01 11:12:44] detectron2 INFO: Inference done 23185/26446. 0.1614 s / img. ETA=0:08:54
[07/01 11:12:49] detectron2 INFO: Inference done 23216/26446. 0.1614 s / img. ETA=0:08:49
[07/01 11:12:55] detectron2 INFO: Inference done 23248/26446. 0.1614 s / img. ETA=0:08:44
[07/01 11:13:00] detectron2 INFO: Inference done 23279/26446. 0.1614 s / img. ETA=0:08:39
[07/01 11:13:05] detectron2 INFO: Inference done 23310/26446. 0.1614 s / img. ETA=0:08:34
[07/01 11:13:10] detectron2 INFO: Inference done 23341/26446. 0.1614 s / img. ETA=0:08:28
[07/01 11:13:15] detectron2 INFO: Inference done 23372/26446. 0.1614 s / img. ETA=0:08:23
[07/01 11:13:20] detectron2 INFO: Inference done 23403/26446. 0.1614 s / img. ETA=0:08:18
[07/01 11:13:25] detectron2 INFO: Inference done 23434/26446. 0.1614 s / img. ETA=0:08:13
[07/01 11:13:30] detectron2 INFO: Inference done 23465/26446. 0.1614 s / img. ETA=0:08:08
[07/01 11:13:35] detectron2 INFO: Inference done 23496/26446. 0.1614 s / img. ETA=0:08:03
[07/01 11:13:40] detectron2 INFO: Inference done 23527/26446. 0.1614 s / img. ETA=0:07:58
[07/01 11:13:45] detectron2 INFO: Inference done 23558/26446. 0.1614 s / img. ETA=0:07:53
[07/01 11:13:50] detectron2 INFO: Inference done 23590/26446. 0.1614 s / img. ETA=0:07:48
[07/01 11:13:55] detectron2 INFO: Inference done 23621/26446. 0.1614 s / img. ETA=0:07:43
[07/01 11:14:00] detectron2 INFO: Inference done 23653/26446. 0.1614 s / img. ETA=0:07:37
[07/01 11:14:06] detectron2 INFO: Inference done 23685/26446. 0.1614 s / img. ETA=0:07:32
[07/01 11:14:11] detectron2 INFO: Inference done 23717/26446. 0.1614 s / img. ETA=0:07:27
[07/01 11:14:16] detectron2 INFO: Inference done 23748/26446. 0.1614 s / img. ETA=0:07:22
[07/01 11:14:21] detectron2 INFO: Inference done 23779/26446. 0.1614 s / img. ETA=0:07:17
[07/01 11:14:26] detectron2 INFO: Inference done 23810/26446. 0.1614 s / img. ETA=0:07:11
[07/01 11:14:31] detectron2 INFO: Inference done 23841/26446. 0.1614 s / img. ETA=0:07:06
[07/01 11:14:36] detectron2 INFO: Inference done 23872/26446. 0.1614 s / img. ETA=0:07:01
[07/01 11:14:41] detectron2 INFO: Inference done 23904/26446. 0.1614 s / img. ETA=0:06:56
[07/01 11:14:46] detectron2 INFO: Inference done 23936/26446. 0.1614 s / img. ETA=0:06:51
[07/01 11:14:51] detectron2 INFO: Inference done 23968/26446. 0.1614 s / img. ETA=0:06:46
[07/01 11:14:56] detectron2 INFO: Inference done 23999/26446. 0.1614 s / img. ETA=0:06:40
[07/01 11:15:01] detectron2 INFO: Inference done 24030/26446. 0.1614 s / img. ETA=0:06:35
[07/01 11:15:06] detectron2 INFO: Inference done 24062/26446. 0.1614 s / img. ETA=0:06:30
[07/01 11:15:12] detectron2 INFO: Inference done 24093/26446. 0.1614 s / img. ETA=0:06:25
[07/01 11:15:17] detectron2 INFO: Inference done 24123/26446. 0.1614 s / img. ETA=0:06:20
[07/01 11:15:22] detectron2 INFO: Inference done 24155/26446. 0.1614 s / img. ETA=0:06:15
[07/01 11:15:27] detectron2 INFO: Inference done 24187/26446. 0.1614 s / img. ETA=0:06:10
[07/01 11:15:32] detectron2 INFO: Inference done 24218/26446. 0.1614 s / img. ETA=0:06:05
[07/01 11:15:37] detectron2 INFO: Inference done 24249/26446. 0.1614 s / img. ETA=0:05:59
[07/01 11:15:42] detectron2 INFO: Inference done 24281/26446. 0.1614 s / img. ETA=0:05:54
[07/01 11:15:47] detectron2 INFO: Inference done 24313/26446. 0.1614 s / img. ETA=0:05:49
[07/01 11:15:52] detectron2 INFO: Inference done 24344/26446. 0.1614 s / img. ETA=0:05:44
[07/01 11:15:58] detectron2 INFO: Inference done 24375/26446. 0.1614 s / img. ETA=0:05:39
[07/01 11:16:03] detectron2 INFO: Inference done 24406/26446. 0.1614 s / img. ETA=0:05:34
[07/01 11:16:08] detectron2 INFO: Inference done 24438/26446. 0.1614 s / img. ETA=0:05:28
[07/01 11:16:13] detectron2 INFO: Inference done 24469/26446. 0.1614 s / img. ETA=0:05:23
[07/01 11:16:18] detectron2 INFO: Inference done 24500/26446. 0.1614 s / img. ETA=0:05:18
[07/01 11:16:23] detectron2 INFO: Inference done 24532/26446. 0.1614 s / img. ETA=0:05:13
[07/01 11:16:28] detectron2 INFO: Inference done 24564/26446. 0.1614 s / img. ETA=0:05:08
[07/01 11:16:33] detectron2 INFO: Inference done 24595/26446. 0.1614 s / img. ETA=0:05:03
[07/01 11:16:38] detectron2 INFO: Inference done 24627/26446. 0.1613 s / img. ETA=0:04:57
[07/01 11:16:43] detectron2 INFO: Inference done 24658/26446. 0.1613 s / img. ETA=0:04:52
[07/01 11:16:48] detectron2 INFO: Inference done 24689/26446. 0.1613 s / img. ETA=0:04:47
[07/01 11:16:53] detectron2 INFO: Inference done 24720/26446. 0.1613 s / img. ETA=0:04:42
[07/01 11:16:58] detectron2 INFO: Inference done 24751/26446. 0.1613 s / img. ETA=0:04:37
[07/01 11:17:04] detectron2 INFO: Inference done 24782/26446. 0.1613 s / img. ETA=0:04:32
[07/01 11:17:09] detectron2 INFO: Inference done 24813/26446. 0.1613 s / img. ETA=0:04:27
[07/01 11:17:14] detectron2 INFO: Inference done 24844/26446. 0.1613 s / img. ETA=0:04:22
[07/01 11:17:19] detectron2 INFO: Inference done 24875/26446. 0.1613 s / img. ETA=0:04:17
[07/01 11:17:24] detectron2 INFO: Inference done 24907/26446. 0.1613 s / img. ETA=0:04:12
[07/01 11:17:29] detectron2 INFO: Inference done 24939/26446. 0.1613 s / img. ETA=0:04:06
[07/01 11:17:34] detectron2 INFO: Inference done 24970/26446. 0.1613 s / img. ETA=0:04:01
[07/01 11:17:39] detectron2 INFO: Inference done 25002/26446. 0.1613 s / img. ETA=0:03:56
[07/01 11:17:44] detectron2 INFO: Inference done 25033/26446. 0.1613 s / img. ETA=0:03:51
[07/01 11:17:50] detectron2 INFO: Inference done 25065/26446. 0.1613 s / img. ETA=0:03:46
[07/01 11:17:55] detectron2 INFO: Inference done 25095/26446. 0.1613 s / img. ETA=0:03:41
[07/01 11:18:00] detectron2 INFO: Inference done 25126/26446. 0.1613 s / img. ETA=0:03:36
[07/01 11:18:05] detectron2 INFO: Inference done 25157/26446. 0.1613 s / img. ETA=0:03:31
[07/01 11:18:10] detectron2 INFO: Inference done 25188/26446. 0.1613 s / img. ETA=0:03:26
[07/01 11:18:15] detectron2 INFO: Inference done 25220/26446. 0.1613 s / img. ETA=0:03:20
[07/01 11:18:20] detectron2 INFO: Inference done 25251/26446. 0.1613 s / img. ETA=0:03:15
[07/01 11:18:25] detectron2 INFO: Inference done 25282/26446. 0.1613 s / img. ETA=0:03:10
[07/01 11:18:30] detectron2 INFO: Inference done 25313/26446. 0.1613 s / img. ETA=0:03:05
[07/01 11:18:35] detectron2 INFO: Inference done 25344/26446. 0.1613 s / img. ETA=0:03:00
[07/01 11:18:40] detectron2 INFO: Inference done 25375/26446. 0.1613 s / img. ETA=0:02:55
[07/01 11:18:45] detectron2 INFO: Inference done 25406/26446. 0.1613 s / img. ETA=0:02:50
[07/01 11:18:50] detectron2 INFO: Inference done 25437/26446. 0.1613 s / img. ETA=0:02:45
[07/01 11:18:56] detectron2 INFO: Inference done 25467/26446. 0.1613 s / img. ETA=0:02:40
[07/01 11:19:01] detectron2 INFO: Inference done 25488/26446. 0.1614 s / img. ETA=0:02:36
[07/01 11:19:06] detectron2 INFO: Inference done 25519/26446. 0.1614 s / img. ETA=0:02:31
[07/01 11:19:11] detectron2 INFO: Inference done 25550/26446. 0.1614 s / img. ETA=0:02:26
[07/01 11:19:16] detectron2 INFO: Inference done 25581/26446. 0.1614 s / img. ETA=0:02:21
[07/01 11:19:21] detectron2 INFO: Inference done 25613/26446. 0.1614 s / img. ETA=0:02:16
[07/01 11:19:26] detectron2 INFO: Inference done 25645/26446. 0.1614 s / img. ETA=0:02:11
[07/01 11:19:31] detectron2 INFO: Inference done 25675/26446. 0.1614 s / img. ETA=0:02:06
[07/01 11:19:36] detectron2 INFO: Inference done 25707/26446. 0.1614 s / img. ETA=0:02:01
[07/01 11:19:41] detectron2 INFO: Inference done 25739/26446. 0.1614 s / img. ETA=0:01:55
[07/01 11:19:46] detectron2 INFO: Inference done 25770/26446. 0.1614 s / img. ETA=0:01:50
[07/01 11:19:51] detectron2 INFO: Inference done 25801/26446. 0.1614 s / img. ETA=0:01:45
[07/01 11:19:57] detectron2 INFO: Inference done 25833/26446. 0.1614 s / img. ETA=0:01:40
[07/01 11:20:02] detectron2 INFO: Inference done 25864/26446. 0.1614 s / img. ETA=0:01:35
[07/01 11:20:07] detectron2 INFO: Inference done 25896/26446. 0.1614 s / img. ETA=0:01:30
[07/01 11:20:12] detectron2 INFO: Inference done 25927/26446. 0.1614 s / img. ETA=0:01:25
[07/01 11:20:17] detectron2 INFO: Inference done 25959/26446. 0.1614 s / img. ETA=0:01:19
[07/01 11:20:22] detectron2 INFO: Inference done 25990/26446. 0.1614 s / img. ETA=0:01:14
[07/01 11:20:27] detectron2 INFO: Inference done 26021/26446. 0.1614 s / img. ETA=0:01:09
[07/01 11:20:32] detectron2 INFO: Inference done 26052/26446. 0.1614 s / img. ETA=0:01:04
[07/01 11:20:37] detectron2 INFO: Inference done 26084/26446. 0.1614 s / img. ETA=0:00:59
[07/01 11:20:42] detectron2 INFO: Inference done 26115/26446. 0.1614 s / img. ETA=0:00:54
[07/01 11:20:47] detectron2 INFO: Inference done 26145/26446. 0.1614 s / img. ETA=0:00:49
[07/01 11:20:53] detectron2 INFO: Inference done 26176/26446. 0.1614 s / img. ETA=0:00:44
[07/01 11:20:58] detectron2 INFO: Inference done 26207/26446. 0.1614 s / img. ETA=0:00:39
[07/01 11:21:03] detectron2 INFO: Inference done 26239/26446. 0.1614 s / img. ETA=0:00:33
[07/01 11:21:08] detectron2 INFO: Inference done 26270/26446. 0.1614 s / img. ETA=0:00:28
[07/01 11:21:13] detectron2 INFO: Inference done 26301/26446. 0.1614 s / img. ETA=0:00:23
[07/01 11:21:18] detectron2 INFO: Inference done 26333/26446. 0.1614 s / img. ETA=0:00:18
[07/01 11:21:23] detectron2 INFO: Inference done 26364/26446. 0.1614 s / img. ETA=0:00:13
[07/01 11:21:28] detectron2 INFO: Inference done 26395/26446. 0.1614 s / img. ETA=0:00:08
[07/01 11:21:33] detectron2 INFO: Inference done 26427/26446. 0.1614 s / img. ETA=0:00:03
[07/01 11:21:37] detectron2 INFO: Total inference time: 1:12:12.065145 (0.163839 s / img per device, on 1 devices)
[07/01 11:21:37] detectron2 INFO: Total inference pure compute time: 1:11:06 (0.161350 s / img per device, on 1 devices)
[07/01 11:21:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/01 11:21:43] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[07/01 11:21:50] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[07/01 11:25:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.296 | 27.002 | 12.948 | 3.812 | 10.084 | 19.611 |
[07/01 11:25:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| airplane   | 1.159  | animal     | 1.291  | arm        | 2.925  |
| bag        | 7.026  | banana     | 9.344  | basket     | 9.427  |
| beach      | 29.426 | bear       | 33.102 | bed        | 43.519 |
| bench      | 20.936 | bike       | 19.099 | bird       | 22.826 |
| board      | 2.734  | boat       | 17.579 | book       | 4.531  |
| boot       | 7.260  | bottle     | 15.198 | bowl       | 21.492 |
| box        | 5.950  | boy        | 19.128 | branch     | 0.612  |
| building   | 21.364 | bus        | 42.112 | cabinet    | 6.051  |
| cap        | 5.055  | car        | 21.257 | cat        | 42.913 |
| chair      | 18.264 | child      | 3.365  | clock      | 21.904 |
| coat       | 3.062  | counter    | 10.818 | cow        | 30.261 |
| cup        | 15.509 | curtain    | 14.126 | desk       | 16.403 |
| dog        | 34.876 | door       | 8.800  | drawer     | 6.086  |
| ear        | 19.475 | elephant   | 39.545 | engine     | 15.459 |
| eye        | 10.423 | face       | 7.800  | fence      | 17.621 |
| finger     | 1.518  | flag       | 6.537  | flower     | 5.836  |
| food       | 12.741 | fork       | 22.512 | fruit      | 2.042  |
| giraffe    | 42.230 | girl       | 11.561 | glass      | 15.874 |
| glove      | 10.970 | guy        | 0.000  | hair       | 21.925 |
| hand       | 11.239 | handle     | 4.016  | hat        | 19.874 |
| head       | 15.772 | helmet     | 24.466 | hill       | 4.205  |
| horse      | 34.030 | house      | 7.006  | jacket     | 18.267 |
| jean       | 18.832 | kid        | 0.292  | kite       | 19.610 |
| lady       | 0.000  | lamp       | 15.340 | laptop     | 38.350 |
| leaf       | 0.890  | leg        | 5.520  | letter     | 1.024  |
| light      | 2.153  | logo       | 3.100  | man        | 33.687 |
| men        | 0.580  | motorcycle | 24.938 | mountain   | 8.513  |
| mouth      | 6.103  | neck       | 8.230  | nose       | 12.622 |
| number     | 2.780  | orange     | 15.133 | pant       | 19.950 |
| paper      | 4.255  | paw        | 6.849  | people     | 1.265  |
| person     | 5.697  | phone      | 9.838  | pillow     | 17.739 |
| pizza      | 32.390 | plane      | 32.878 | plant      | 5.100  |
| plate      | 30.822 | player     | 7.041  | pole       | 5.674  |
| post       | 1.350  | pot        | 4.523  | racket     | 25.661 |
| railing    | 1.258  | rock       | 5.164  | roof       | 6.247  |
| room       | 21.338 | screen     | 20.861 | seat       | 8.284  |
| sheep      | 23.719 | shelf      | 2.515  | shirt      | 28.724 |
| shoe       | 11.906 | short      | 29.029 | sidewalk   | 10.211 |
| sign       | 17.302 | sink       | 15.638 | skateboard | 24.640 |
| ski        | 11.158 | skier      | 4.940  | sneaker    | 0.176  |
| snow       | 19.527 | sock       | 9.179  | stand      | 1.611  |
| street     | 16.803 | surfboard  | 17.048 | table      | 27.979 |
| tail       | 14.791 | tie        | 20.408 | tile       | 0.760  |
| tire       | 11.766 | toilet     | 35.544 | towel      | 8.871  |
| tower      | 19.614 | track      | 11.036 | train      | 36.090 |
| tree       | 9.307  | truck      | 23.974 | trunk      | 11.167 |
| umbrella   | 19.679 | vase       | 21.136 | vegetable  | 1.532  |
| vehicle    | 0.568  | wave       | 11.729 | wheel      | 9.311  |
| window     | 6.838  | windshield | 11.129 | wing       | 11.737 |
| wire       | 0.770  | woman      | 24.078 | zebra      | 38.858 |
[07/01 11:25:41] detectron2 INFO: Gathering data
[07/01 11:25:41] detectron2 INFO: Predictions Gathered
[07/01 11:26:00] detectron2 INFO: Saving output prediction
[07/01 11:26:00] detectron2 INFO: Computing Scene Graph Metrics
[07/01 11:26:00] detectron2 INFO: Preparing Global Container
[07/01 11:33:10] detectron2 INFO: Scene Graph Metric Evaluation Complete. Computing recall statistics...
[07/01 11:34:05] detectron2 INFO: Scene Graph Results for mode: sgdet
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: 14.2961,27.0024,12.9478,3.8116,10.0838,19.6112
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: Task: SG
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: SGMeanRecall@20,SGMeanRecall@50,SGMeanRecall@100,SGRecall@20,SGRecall@50,SGRecall@100
[07/01 11:34:13] d2.evaluation.testing INFO: copypaste: 0.1011,0.1508,0.1758,0.2507,0.3205,0.3552
[07/01 12:22:39] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:22:40] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:22:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:22:40] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:22:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:22:40] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:22:40] d2.utils.env INFO: Using a generated random seed 40386912
[07/01 12:22:44] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:22:44] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:22:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:22:45] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:22:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:22:45] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:22:47] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:22:47] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:22:47] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:22:47] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:22:47] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:22:47] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:22:47] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:22:49] detectron2 INFO: Loading zero shot triplets
[07/01 12:22:49] detectron2 INFO: Start inference on 26446 images
[07/01 12:25:33] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:25:34] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:25:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:25:34] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:25:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:25:34] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:25:34] d2.utils.env INFO: Using a generated random seed 34320994
[07/01 12:25:37] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:25:37] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:25:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:25:39] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:25:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:25:39] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:25:41] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:25:41] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:25:41] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:25:41] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:25:41] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:25:41] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:25:41] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:25:43] detectron2 INFO: Loading zero shot triplets
[07/01 12:25:43] detectron2 INFO: Start inference on 26446 images
[07/01 12:28:12] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:28:13] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:28:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:28:13] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:28:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:28:13] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:28:13] d2.utils.env INFO: Using a generated random seed 13789749
[07/01 12:28:17] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:28:17] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:28:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:28:18] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:28:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:28:18] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:28:20] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:28:20] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:28:20] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:28:20] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:28:20] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:28:20] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:28:20] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:28:22] detectron2 INFO: Loading zero shot triplets
[07/01 12:28:22] detectron2 INFO: Start inference on 26446 images
[07/01 12:28:53] detectron2 INFO: Inference done 1/26446. 17.7945 s / img. ETA=9 days, 8:10:27
[07/01 12:29:00] detectron2 INFO: Inference done 3/26446. 8.4067 s / img. ETA=3 days, 20:54:38
[07/01 12:29:42] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:29:43] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:29:43] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:29:43] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:29:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:29:43] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:29:43] d2.utils.env INFO: Using a generated random seed 43446974
[07/01 12:29:46] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:29:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:29:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:29:48] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:29:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:29:48] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:29:49] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:29:49] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:29:49] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:29:49] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:29:49] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:29:49] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:29:49] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:29:51] detectron2 INFO: Loading zero shot triplets
[07/01 12:29:51] detectron2 INFO: Start inference on 26446 images
[07/01 12:31:28] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:31:28] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:31:28] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:31:28] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:31:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:31:29] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:31:29] d2.utils.env INFO: Using a generated random seed 29246102
[07/01 12:31:32] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:31:32] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:31:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:31:34] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:31:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:31:34] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:31:36] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:31:36] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:31:36] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:31:36] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:31:36] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:31:36] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:31:36] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:31:38] detectron2 INFO: Loading zero shot triplets
[07/01 12:31:38] detectron2 INFO: Start inference on 26446 images
[07/01 12:32:23] detectron2 INFO: Inference done 1/26446. 29.6123 s / img. ETA=13 days, 14:44:36
[07/01 12:32:30] detectron2 INFO: Inference done 3/26446. 12.2234 s / img. ETA=5 days, 6:12:13
[07/01 12:34:55] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 12:34:56] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 12:34:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '2', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 12:34:56] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 12:34:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 12:34:56] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 12:34:57] d2.utils.env INFO: Using a generated random seed 57075503
[07/01 12:34:59] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 12:34:59] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:34:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 12:35:01] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 12:35:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 12:35:01] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 12:35:02] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 12:35:02] detectron2 INFO: Following metrics will be use for evaluation
[07/01 12:35:02] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 12:35:02] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 12:35:02] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 12:35:02] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 12:35:02] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 12:35:04] detectron2 INFO: Loading zero shot triplets
[07/01 12:35:04] detectron2 INFO: Start inference on 26446 images
[07/01 12:35:31] detectron2 INFO: Inference done 1/26446. 5.9874 s / img. ETA=8 days, 3:31:26
[07/01 12:35:36] detectron2 INFO: Inference done 31/26446. 0.1667 s / img. ETA=1:14:22
[07/01 12:35:41] detectron2 INFO: Inference done 61/26446. 0.1683 s / img. ETA=1:14:59
[07/01 12:35:46] detectron2 INFO: Inference done 91/26446. 0.1674 s / img. ETA=1:14:32
[07/01 12:35:51] detectron2 INFO: Inference done 122/26446. 0.1665 s / img. ETA=1:14:03
[07/01 12:35:56] detectron2 INFO: Inference done 152/26446. 0.1663 s / img. ETA=1:13:51
[07/01 12:36:02] detectron2 INFO: Inference done 182/26446. 0.1661 s / img. ETA=1:13:41
[07/01 12:36:07] detectron2 INFO: Inference done 213/26446. 0.1655 s / img. ETA=1:13:17
[07/01 12:36:12] detectron2 INFO: Inference done 244/26446. 0.1648 s / img. ETA=1:12:55
[07/01 12:36:17] detectron2 INFO: Inference done 275/26446. 0.1644 s / img. ETA=1:12:38
[07/01 12:36:22] detectron2 INFO: Inference done 306/26446. 0.1642 s / img. ETA=1:12:29
[07/01 12:36:27] detectron2 INFO: Inference done 336/26446. 0.1645 s / img. ETA=1:12:31
[07/01 12:36:32] detectron2 INFO: Inference done 366/26446. 0.1645 s / img. ETA=1:12:26
[07/01 12:36:37] detectron2 INFO: Inference done 397/26446. 0.1643 s / img. ETA=1:12:15
[07/01 12:36:42] detectron2 INFO: Inference done 428/26446. 0.1642 s / img. ETA=1:12:07
[07/01 12:36:47] detectron2 INFO: Inference done 459/26446. 0.1641 s / img. ETA=1:12:00
[07/01 12:36:52] detectron2 INFO: Inference done 490/26446. 0.1639 s / img. ETA=1:11:50
[07/01 12:36:57] detectron2 INFO: Inference done 521/26446. 0.1639 s / img. ETA=1:11:45
[07/01 12:37:03] detectron2 INFO: Inference done 552/26446. 0.1640 s / img. ETA=1:11:40
[07/01 12:37:08] detectron2 INFO: Inference done 583/26446. 0.1638 s / img. ETA=1:11:33
[07/01 12:37:13] detectron2 INFO: Inference done 613/26446. 0.1639 s / img. ETA=1:11:30
[07/01 12:37:18] detectron2 INFO: Inference done 644/26446. 0.1638 s / img. ETA=1:11:21
[07/01 12:37:23] detectron2 INFO: Inference done 675/26446. 0.1638 s / img. ETA=1:11:15
[07/01 12:37:28] detectron2 INFO: Inference done 706/26446. 0.1638 s / img. ETA=1:11:10
[07/01 12:37:33] detectron2 INFO: Inference done 737/26446. 0.1638 s / img. ETA=1:11:05
[07/01 12:37:38] detectron2 INFO: Inference done 768/26446. 0.1636 s / img. ETA=1:10:57
[07/01 12:37:43] detectron2 INFO: Inference done 798/26446. 0.1637 s / img. ETA=1:10:53
[07/01 12:37:48] detectron2 INFO: Inference done 829/26446. 0.1636 s / img. ETA=1:10:45
[07/01 12:37:53] detectron2 INFO: Inference done 860/26446. 0.1636 s / img. ETA=1:10:39
[07/01 12:37:59] detectron2 INFO: Inference done 891/26446. 0.1636 s / img. ETA=1:10:35
[07/01 12:38:04] detectron2 INFO: Inference done 921/26446. 0.1636 s / img. ETA=1:10:31
[07/01 12:38:09] detectron2 INFO: Inference done 952/26446. 0.1636 s / img. ETA=1:10:24
[07/01 12:38:14] detectron2 INFO: Inference done 983/26446. 0.1636 s / img. ETA=1:10:19
[07/01 12:38:19] detectron2 INFO: Inference done 1014/26446. 0.1635 s / img. ETA=1:10:12
[07/01 12:38:24] detectron2 INFO: Inference done 1045/26446. 0.1634 s / img. ETA=1:10:05
[07/01 12:38:29] detectron2 INFO: Inference done 1075/26446. 0.1635 s / img. ETA=1:10:01
[07/01 12:38:34] detectron2 INFO: Inference done 1104/26446. 0.1637 s / img. ETA=1:10:02
[07/01 12:38:39] detectron2 INFO: Inference done 1134/26446. 0.1638 s / img. ETA=1:09:59
[07/01 12:38:44] detectron2 INFO: Inference done 1165/26446. 0.1638 s / img. ETA=1:09:54
[07/01 12:38:49] detectron2 INFO: Inference done 1196/26446. 0.1637 s / img. ETA=1:09:48
[07/01 12:38:54] detectron2 INFO: Inference done 1227/26446. 0.1637 s / img. ETA=1:09:43
[07/01 12:39:00] detectron2 INFO: Inference done 1257/26446. 0.1639 s / img. ETA=1:09:41
[07/01 12:39:05] detectron2 INFO: Inference done 1288/26446. 0.1639 s / img. ETA=1:09:36
[07/01 12:39:10] detectron2 INFO: Inference done 1319/26446. 0.1639 s / img. ETA=1:09:31
[07/01 12:39:15] detectron2 INFO: Inference done 1349/26446. 0.1639 s / img. ETA=1:09:26
[07/01 12:39:20] detectron2 INFO: Inference done 1380/26446. 0.1638 s / img. ETA=1:09:20
[07/01 12:39:25] detectron2 INFO: Inference done 1410/26446. 0.1639 s / img. ETA=1:09:16
[07/01 12:39:30] detectron2 INFO: Inference done 1441/26446. 0.1639 s / img. ETA=1:09:11
[07/01 12:39:35] detectron2 INFO: Inference done 1471/26446. 0.1639 s / img. ETA=1:09:07
[07/01 12:39:40] detectron2 INFO: Inference done 1501/26446. 0.1640 s / img. ETA=1:09:03
[07/01 12:39:45] detectron2 INFO: Inference done 1532/26446. 0.1639 s / img. ETA=1:08:57
[07/01 12:39:50] detectron2 INFO: Inference done 1563/26446. 0.1639 s / img. ETA=1:08:51
[07/01 12:39:55] detectron2 INFO: Inference done 1594/26446. 0.1638 s / img. ETA=1:08:45
[07/01 12:40:01] detectron2 INFO: Inference done 1625/26446. 0.1638 s / img. ETA=1:08:39
[07/01 12:40:06] detectron2 INFO: Inference done 1656/26446. 0.1638 s / img. ETA=1:08:34
[07/01 12:40:11] detectron2 INFO: Inference done 1687/26446. 0.1638 s / img. ETA=1:08:29
[07/01 12:40:16] detectron2 INFO: Inference done 1718/26446. 0.1638 s / img. ETA=1:08:23
[07/01 12:40:21] detectron2 INFO: Inference done 1748/26446. 0.1638 s / img. ETA=1:08:19
[07/01 12:40:26] detectron2 INFO: Inference done 1779/26446. 0.1638 s / img. ETA=1:08:14
[07/01 12:40:31] detectron2 INFO: Inference done 1810/26446. 0.1638 s / img. ETA=1:08:08
[07/01 12:40:36] detectron2 INFO: Inference done 1840/26446. 0.1639 s / img. ETA=1:08:04
[07/01 12:40:41] detectron2 INFO: Inference done 1870/26446. 0.1639 s / img. ETA=1:08:00
[07/01 12:40:46] detectron2 INFO: Inference done 1900/26446. 0.1639 s / img. ETA=1:07:55
[07/01 12:40:51] detectron2 INFO: Inference done 1931/26446. 0.1639 s / img. ETA=1:07:49
[07/01 12:40:57] detectron2 INFO: Inference done 1962/26446. 0.1639 s / img. ETA=1:07:44
[07/01 12:41:02] detectron2 INFO: Inference done 1993/26446. 0.1638 s / img. ETA=1:07:37
[07/01 12:41:07] detectron2 INFO: Inference done 2009/26446. 0.1638 s / img. ETA=1:08:05
[07/01 12:41:12] detectron2 INFO: Inference done 2039/26446. 0.1639 s / img. ETA=1:08:01
[07/01 12:41:17] detectron2 INFO: Inference done 2069/26446. 0.1639 s / img. ETA=1:07:56
[07/01 12:41:22] detectron2 INFO: Inference done 2099/26446. 0.1639 s / img. ETA=1:07:51
[07/01 12:41:27] detectron2 INFO: Inference done 2129/26446. 0.1640 s / img. ETA=1:07:47
[07/01 12:41:32] detectron2 INFO: Inference done 2159/26446. 0.1640 s / img. ETA=1:07:42
[07/01 12:41:37] detectron2 INFO: Inference done 2189/26446. 0.1641 s / img. ETA=1:07:39
[07/01 12:41:42] detectron2 INFO: Inference done 2220/26446. 0.1640 s / img. ETA=1:07:32
[07/01 12:41:47] detectron2 INFO: Inference done 2251/26446. 0.1640 s / img. ETA=1:07:26
[07/01 12:41:52] detectron2 INFO: Inference done 2281/26446. 0.1641 s / img. ETA=1:07:22
[07/01 12:41:57] detectron2 INFO: Inference done 2311/26446. 0.1641 s / img. ETA=1:07:17
[07/01 12:42:02] detectron2 INFO: Inference done 2341/26446. 0.1641 s / img. ETA=1:07:12
[07/01 12:42:08] detectron2 INFO: Inference done 2370/26446. 0.1642 s / img. ETA=1:07:09
[07/01 12:42:13] detectron2 INFO: Inference done 2400/26446. 0.1642 s / img. ETA=1:07:04
[07/01 12:42:18] detectron2 INFO: Inference done 2430/26446. 0.1643 s / img. ETA=1:07:00
[07/01 12:42:23] detectron2 INFO: Inference done 2460/26446. 0.1643 s / img. ETA=1:06:55
[07/01 12:42:28] detectron2 INFO: Inference done 2490/26446. 0.1643 s / img. ETA=1:06:51
[07/01 12:42:33] detectron2 INFO: Inference done 2521/26446. 0.1643 s / img. ETA=1:06:45
[07/01 12:42:38] detectron2 INFO: Inference done 2552/26446. 0.1643 s / img. ETA=1:06:39
[07/01 12:42:43] detectron2 INFO: Inference done 2582/26446. 0.1643 s / img. ETA=1:06:34
[07/01 12:42:48] detectron2 INFO: Inference done 2613/26446. 0.1643 s / img. ETA=1:06:28
[07/01 12:42:53] detectron2 INFO: Inference done 2643/26446. 0.1643 s / img. ETA=1:06:24
[07/01 12:42:58] detectron2 INFO: Inference done 2674/26446. 0.1643 s / img. ETA=1:06:19
[07/01 12:43:04] detectron2 INFO: Inference done 2704/26446. 0.1644 s / img. ETA=1:06:14
[07/01 12:43:09] detectron2 INFO: Inference done 2734/26446. 0.1644 s / img. ETA=1:06:09
[07/01 12:43:14] detectron2 INFO: Inference done 2764/26446. 0.1644 s / img. ETA=1:06:04
[07/01 12:43:19] detectron2 INFO: Inference done 2794/26446. 0.1644 s / img. ETA=1:05:59
[07/01 12:43:24] detectron2 INFO: Inference done 2824/26446. 0.1644 s / img. ETA=1:05:54
[07/01 12:43:29] detectron2 INFO: Inference done 2854/26446. 0.1644 s / img. ETA=1:05:49
[07/01 12:43:34] detectron2 INFO: Inference done 2885/26446. 0.1644 s / img. ETA=1:05:43
[07/01 12:43:39] detectron2 INFO: Inference done 2915/26446. 0.1644 s / img. ETA=1:05:39
[07/01 12:43:44] detectron2 INFO: Inference done 2942/26446. 0.1646 s / img. ETA=1:05:39
[07/01 12:43:49] detectron2 INFO: Inference done 2972/26446. 0.1647 s / img. ETA=1:05:34
[07/01 12:43:54] detectron2 INFO: Inference done 3002/26446. 0.1647 s / img. ETA=1:05:29
[07/01 12:43:59] detectron2 INFO: Inference done 3032/26446. 0.1647 s / img. ETA=1:05:24
[07/01 12:44:04] detectron2 INFO: Inference done 3062/26446. 0.1647 s / img. ETA=1:05:19
[07/01 12:44:09] detectron2 INFO: Inference done 3092/26446. 0.1647 s / img. ETA=1:05:14
[07/01 12:44:14] detectron2 INFO: Inference done 3123/26446. 0.1647 s / img. ETA=1:05:08
[07/01 12:44:19] detectron2 INFO: Inference done 3154/26446. 0.1647 s / img. ETA=1:05:03
[07/01 12:44:24] detectron2 INFO: Inference done 3184/26446. 0.1647 s / img. ETA=1:04:58
[07/01 12:44:30] detectron2 INFO: Inference done 3215/26446. 0.1647 s / img. ETA=1:04:52
[07/01 12:44:35] detectron2 INFO: Inference done 3246/26446. 0.1647 s / img. ETA=1:04:47
[07/01 12:44:40] detectron2 INFO: Inference done 3276/26446. 0.1647 s / img. ETA=1:04:41
[07/01 12:44:45] detectron2 INFO: Inference done 3306/26446. 0.1647 s / img. ETA=1:04:36
[07/01 12:44:50] detectron2 INFO: Inference done 3337/26446. 0.1646 s / img. ETA=1:04:30
[07/01 12:44:55] detectron2 INFO: Inference done 3368/26446. 0.1646 s / img. ETA=1:04:25
[07/01 12:45:00] detectron2 INFO: Inference done 3399/26446. 0.1646 s / img. ETA=1:04:19
[07/01 12:45:05] detectron2 INFO: Inference done 3429/26446. 0.1646 s / img. ETA=1:04:15
[07/01 12:45:10] detectron2 INFO: Inference done 3459/26446. 0.1646 s / img. ETA=1:04:10
[07/01 12:45:15] detectron2 INFO: Inference done 3490/26446. 0.1646 s / img. ETA=1:04:04
[07/01 12:45:20] detectron2 INFO: Inference done 3520/26446. 0.1646 s / img. ETA=1:03:59
[07/01 12:45:26] detectron2 INFO: Inference done 3550/26446. 0.1647 s / img. ETA=1:03:55
[07/01 12:45:31] detectron2 INFO: Inference done 3581/26446. 0.1647 s / img. ETA=1:03:49
[07/01 12:45:36] detectron2 INFO: Inference done 3612/26446. 0.1647 s / img. ETA=1:03:44
[07/01 12:45:41] detectron2 INFO: Inference done 3642/26446. 0.1647 s / img. ETA=1:03:39
[07/01 12:45:46] detectron2 INFO: Inference done 3672/26446. 0.1647 s / img. ETA=1:03:34
[07/01 12:45:51] detectron2 INFO: Inference done 3702/26446. 0.1647 s / img. ETA=1:03:29
[07/01 12:45:56] detectron2 INFO: Inference done 3733/26446. 0.1647 s / img. ETA=1:03:23
[07/01 12:46:01] detectron2 INFO: Inference done 3763/26446. 0.1647 s / img. ETA=1:03:19
[07/01 12:46:06] detectron2 INFO: Inference done 3794/26446. 0.1647 s / img. ETA=1:03:14
[07/01 12:46:11] detectron2 INFO: Inference done 3824/26446. 0.1647 s / img. ETA=1:03:09
[07/01 12:46:16] detectron2 INFO: Inference done 3854/26446. 0.1647 s / img. ETA=1:03:04
[07/01 12:46:22] detectron2 INFO: Inference done 3884/26446. 0.1648 s / img. ETA=1:02:59
[07/01 12:46:27] detectron2 INFO: Inference done 3914/26446. 0.1648 s / img. ETA=1:02:54
[07/01 12:46:32] detectron2 INFO: Inference done 3944/26446. 0.1648 s / img. ETA=1:02:49
[07/01 12:46:37] detectron2 INFO: Inference done 3974/26446. 0.1648 s / img. ETA=1:02:45
[07/01 12:46:42] detectron2 INFO: Inference done 4004/26446. 0.1648 s / img. ETA=1:02:39
[07/01 12:46:47] detectron2 INFO: Inference done 4035/26446. 0.1648 s / img. ETA=1:02:34
[07/01 12:46:52] detectron2 INFO: Inference done 4065/26446. 0.1648 s / img. ETA=1:02:29
[07/01 12:46:57] detectron2 INFO: Inference done 4096/26446. 0.1648 s / img. ETA=1:02:24
[07/01 12:47:02] detectron2 INFO: Inference done 4127/26446. 0.1648 s / img. ETA=1:02:18
[07/01 12:47:07] detectron2 INFO: Inference done 4158/26446. 0.1648 s / img. ETA=1:02:12
[07/01 12:47:12] detectron2 INFO: Inference done 4188/26446. 0.1648 s / img. ETA=1:02:08
[07/01 12:47:17] detectron2 INFO: Inference done 4218/26446. 0.1648 s / img. ETA=1:02:03
[07/01 12:47:22] detectron2 INFO: Inference done 4248/26446. 0.1648 s / img. ETA=1:01:58
[07/01 12:47:28] detectron2 INFO: Inference done 4279/26446. 0.1648 s / img. ETA=1:01:52
[07/01 12:47:33] detectron2 INFO: Inference done 4309/26446. 0.1648 s / img. ETA=1:01:47
[07/01 12:47:38] detectron2 INFO: Inference done 4339/26446. 0.1648 s / img. ETA=1:01:43
[07/01 12:47:43] detectron2 INFO: Inference done 4369/26446. 0.1648 s / img. ETA=1:01:38
[07/01 12:47:48] detectron2 INFO: Inference done 4400/26446. 0.1648 s / img. ETA=1:01:32
[07/01 12:47:53] detectron2 INFO: Inference done 4430/26446. 0.1648 s / img. ETA=1:01:27
[07/01 12:47:58] detectron2 INFO: Inference done 4460/26446. 0.1648 s / img. ETA=1:01:23
[07/01 12:48:03] detectron2 INFO: Inference done 4491/26446. 0.1648 s / img. ETA=1:01:17
[07/01 12:48:08] detectron2 INFO: Inference done 4521/26446. 0.1648 s / img. ETA=1:01:12
[07/01 12:48:13] detectron2 INFO: Inference done 4551/26446. 0.1648 s / img. ETA=1:01:07
[07/01 12:48:18] detectron2 INFO: Inference done 4582/26446. 0.1648 s / img. ETA=1:01:02
[07/01 12:48:23] detectron2 INFO: Inference done 4613/26446. 0.1648 s / img. ETA=1:00:56
[07/01 12:48:28] detectron2 INFO: Inference done 4643/26446. 0.1648 s / img. ETA=1:00:51
[07/01 12:48:34] detectron2 INFO: Inference done 4674/26446. 0.1648 s / img. ETA=1:00:46
[07/01 12:48:39] detectron2 INFO: Inference done 4704/26446. 0.1648 s / img. ETA=1:00:41
[07/01 12:48:44] detectron2 INFO: Inference done 4735/26446. 0.1648 s / img. ETA=1:00:35
[07/01 12:48:49] detectron2 INFO: Inference done 4765/26446. 0.1648 s / img. ETA=1:00:31
[07/01 12:48:54] detectron2 INFO: Inference done 4795/26446. 0.1648 s / img. ETA=1:00:26
[07/01 12:48:59] detectron2 INFO: Inference done 4825/26446. 0.1648 s / img. ETA=1:00:21
[07/01 12:49:04] detectron2 INFO: Inference done 4855/26446. 0.1649 s / img. ETA=1:00:16
[07/01 12:49:09] detectron2 INFO: Inference done 4885/26446. 0.1649 s / img. ETA=1:00:11
[07/01 12:49:14] detectron2 INFO: Inference done 4916/26446. 0.1649 s / img. ETA=1:00:06
[07/01 12:49:19] detectron2 INFO: Inference done 4946/26446. 0.1649 s / img. ETA=1:00:01
[07/01 12:49:24] detectron2 INFO: Inference done 4976/26446. 0.1649 s / img. ETA=0:59:56
[07/01 12:49:29] detectron2 INFO: Inference done 5006/26446. 0.1649 s / img. ETA=0:59:51
[07/01 12:49:35] detectron2 INFO: Inference done 5037/26446. 0.1649 s / img. ETA=0:59:45
[07/01 12:49:40] detectron2 INFO: Inference done 5068/26446. 0.1649 s / img. ETA=0:59:40
[07/01 12:49:45] detectron2 INFO: Inference done 5098/26446. 0.1649 s / img. ETA=0:59:35
[07/01 12:49:50] detectron2 INFO: Inference done 5128/26446. 0.1649 s / img. ETA=0:59:30
[07/01 12:49:55] detectron2 INFO: Inference done 5158/26446. 0.1649 s / img. ETA=0:59:26
[07/01 12:50:00] detectron2 INFO: Inference done 5188/26446. 0.1649 s / img. ETA=0:59:20
[07/01 12:50:05] detectron2 INFO: Inference done 5218/26446. 0.1649 s / img. ETA=0:59:16
[07/01 12:50:10] detectron2 INFO: Inference done 5249/26446. 0.1649 s / img. ETA=0:59:10
[07/01 12:50:15] detectron2 INFO: Inference done 5279/26446. 0.1649 s / img. ETA=0:59:05
[07/01 12:50:20] detectron2 INFO: Inference done 5309/26446. 0.1649 s / img. ETA=0:59:00
[07/01 12:50:25] detectron2 INFO: Inference done 5339/26446. 0.1649 s / img. ETA=0:58:55
[07/01 12:50:30] detectron2 INFO: Inference done 5369/26446. 0.1649 s / img. ETA=0:58:50
[07/01 12:50:35] detectron2 INFO: Inference done 5399/26446. 0.1649 s / img. ETA=0:58:45
[07/01 12:50:40] detectron2 INFO: Inference done 5429/26446. 0.1649 s / img. ETA=0:58:40
[07/01 12:50:45] detectron2 INFO: Inference done 5459/26446. 0.1649 s / img. ETA=0:58:35
[07/01 12:50:50] detectron2 INFO: Inference done 5489/26446. 0.1649 s / img. ETA=0:58:30
[07/01 12:50:56] detectron2 INFO: Inference done 5520/26446. 0.1649 s / img. ETA=0:58:25
[07/01 12:51:01] detectron2 INFO: Inference done 5550/26446. 0.1650 s / img. ETA=0:58:20
[07/01 12:51:06] detectron2 INFO: Inference done 5580/26446. 0.1650 s / img. ETA=0:58:16
[07/01 12:51:11] detectron2 INFO: Inference done 5611/26446. 0.1650 s / img. ETA=0:58:10
[07/01 12:51:16] detectron2 INFO: Inference done 5641/26446. 0.1650 s / img. ETA=0:58:05
[07/01 12:51:21] detectron2 INFO: Inference done 5672/26446. 0.1649 s / img. ETA=0:57:59
[07/01 12:51:26] detectron2 INFO: Inference done 5703/26446. 0.1649 s / img. ETA=0:57:54
[07/01 12:51:31] detectron2 INFO: Inference done 5733/26446. 0.1649 s / img. ETA=0:57:49
[07/01 12:51:36] detectron2 INFO: Inference done 5763/26446. 0.1650 s / img. ETA=0:57:44
[07/01 12:51:41] detectron2 INFO: Inference done 5793/26446. 0.1650 s / img. ETA=0:57:39
[07/01 12:51:46] detectron2 INFO: Inference done 5824/26446. 0.1650 s / img. ETA=0:57:34
[07/01 12:51:51] detectron2 INFO: Inference done 5854/26446. 0.1650 s / img. ETA=0:57:29
[07/01 12:51:57] detectron2 INFO: Inference done 5884/26446. 0.1650 s / img. ETA=0:57:24
[07/01 12:52:02] detectron2 INFO: Inference done 5914/26446. 0.1650 s / img. ETA=0:57:19
[07/01 12:52:07] detectron2 INFO: Inference done 5945/26446. 0.1650 s / img. ETA=0:57:14
[07/01 12:52:12] detectron2 INFO: Inference done 5974/26446. 0.1650 s / img. ETA=0:57:09
[07/01 12:52:17] detectron2 INFO: Inference done 6005/26446. 0.1650 s / img. ETA=0:57:04
[07/01 12:52:22] detectron2 INFO: Inference done 6035/26446. 0.1650 s / img. ETA=0:56:59
[07/01 12:52:27] detectron2 INFO: Inference done 6065/26446. 0.1650 s / img. ETA=0:56:54
[07/01 12:52:32] detectron2 INFO: Inference done 6096/26446. 0.1650 s / img. ETA=0:56:49
[07/01 12:52:37] detectron2 INFO: Inference done 6126/26446. 0.1650 s / img. ETA=0:56:44
[07/01 12:52:42] detectron2 INFO: Inference done 6157/26446. 0.1650 s / img. ETA=0:56:39
[07/01 12:52:48] detectron2 INFO: Inference done 6187/26446. 0.1650 s / img. ETA=0:56:34
[07/01 12:52:53] detectron2 INFO: Inference done 6217/26446. 0.1650 s / img. ETA=0:56:29
[07/01 12:52:58] detectron2 INFO: Inference done 6247/26446. 0.1650 s / img. ETA=0:56:24
[07/01 12:53:03] detectron2 INFO: Inference done 6278/26446. 0.1650 s / img. ETA=0:56:19
[07/01 12:53:08] detectron2 INFO: Inference done 6308/26446. 0.1650 s / img. ETA=0:56:14
[07/01 12:53:13] detectron2 INFO: Inference done 6339/26446. 0.1650 s / img. ETA=0:56:08
[07/01 12:53:18] detectron2 INFO: Inference done 6369/26446. 0.1650 s / img. ETA=0:56:03
[07/01 12:53:23] detectron2 INFO: Inference done 6399/26446. 0.1650 s / img. ETA=0:55:58
[07/01 12:53:28] detectron2 INFO: Inference done 6430/26446. 0.1650 s / img. ETA=0:55:53
[07/01 12:53:33] detectron2 INFO: Inference done 6460/26446. 0.1650 s / img. ETA=0:55:48
[07/01 12:53:38] detectron2 INFO: Inference done 6490/26446. 0.1650 s / img. ETA=0:55:43
[07/01 12:53:43] detectron2 INFO: Inference done 6521/26446. 0.1650 s / img. ETA=0:55:37
[07/01 12:53:48] detectron2 INFO: Inference done 6551/26446. 0.1650 s / img. ETA=0:55:32
[07/01 12:53:53] detectron2 INFO: Inference done 6581/26446. 0.1650 s / img. ETA=0:55:27
[07/01 12:53:58] detectron2 INFO: Inference done 6612/26446. 0.1650 s / img. ETA=0:55:22
[07/01 12:54:03] detectron2 INFO: Inference done 6642/26446. 0.1650 s / img. ETA=0:55:17
[07/01 12:54:09] detectron2 INFO: Inference done 6672/26446. 0.1650 s / img. ETA=0:55:12
[07/01 12:54:14] detectron2 INFO: Inference done 6702/26446. 0.1650 s / img. ETA=0:55:07
[07/01 12:54:19] detectron2 INFO: Inference done 6733/26446. 0.1650 s / img. ETA=0:55:01
[07/01 12:54:24] detectron2 INFO: Inference done 6763/26446. 0.1650 s / img. ETA=0:54:57
[07/01 12:54:29] detectron2 INFO: Inference done 6793/26446. 0.1650 s / img. ETA=0:54:52
[07/01 12:54:34] detectron2 INFO: Inference done 6824/26446. 0.1650 s / img. ETA=0:54:46
[07/01 12:54:39] detectron2 INFO: Inference done 6854/26446. 0.1650 s / img. ETA=0:54:41
[07/01 12:54:44] detectron2 INFO: Inference done 6885/26446. 0.1650 s / img. ETA=0:54:36
[07/01 12:54:49] detectron2 INFO: Inference done 6916/26446. 0.1650 s / img. ETA=0:54:31
[07/01 12:54:54] detectron2 INFO: Inference done 6946/26446. 0.1650 s / img. ETA=0:54:26
[07/01 12:55:00] detectron2 INFO: Inference done 6977/26446. 0.1650 s / img. ETA=0:54:21
[07/01 12:55:05] detectron2 INFO: Inference done 7007/26446. 0.1650 s / img. ETA=0:54:16
[07/01 12:55:10] detectron2 INFO: Inference done 7037/26446. 0.1650 s / img. ETA=0:54:11
[07/01 12:55:15] detectron2 INFO: Inference done 7067/26446. 0.1650 s / img. ETA=0:54:06
[07/01 12:55:20] detectron2 INFO: Inference done 7097/26446. 0.1651 s / img. ETA=0:54:01
[07/01 12:55:25] detectron2 INFO: Inference done 7127/26446. 0.1651 s / img. ETA=0:53:57
[07/01 12:55:30] detectron2 INFO: Inference done 7158/26446. 0.1651 s / img. ETA=0:53:51
[07/01 12:55:35] detectron2 INFO: Inference done 7189/26446. 0.1651 s / img. ETA=0:53:46
[07/01 12:55:40] detectron2 INFO: Inference done 7219/26446. 0.1651 s / img. ETA=0:53:41
[07/01 12:55:45] detectron2 INFO: Inference done 7248/26446. 0.1651 s / img. ETA=0:53:37
[07/01 12:55:51] detectron2 INFO: Inference done 7278/26446. 0.1651 s / img. ETA=0:53:32
[07/01 12:55:56] detectron2 INFO: Inference done 7309/26446. 0.1651 s / img. ETA=0:53:26
[07/01 12:56:01] detectron2 INFO: Inference done 7338/26446. 0.1651 s / img. ETA=0:53:22
[07/01 12:56:06] detectron2 INFO: Inference done 7368/26446. 0.1651 s / img. ETA=0:53:17
[07/01 12:56:11] detectron2 INFO: Inference done 7398/26446. 0.1651 s / img. ETA=0:53:12
[07/01 12:56:16] detectron2 INFO: Inference done 7428/26446. 0.1651 s / img. ETA=0:53:07
[07/01 12:56:21] detectron2 INFO: Inference done 7458/26446. 0.1651 s / img. ETA=0:53:02
[07/01 12:56:26] detectron2 INFO: Inference done 7488/26446. 0.1651 s / img. ETA=0:52:57
[07/01 12:56:31] detectron2 INFO: Inference done 7518/26446. 0.1651 s / img. ETA=0:52:52
[07/01 12:56:36] detectron2 INFO: Inference done 7548/26446. 0.1651 s / img. ETA=0:52:47
[07/01 12:56:41] detectron2 INFO: Inference done 7578/26446. 0.1651 s / img. ETA=0:52:42
[07/01 12:56:46] detectron2 INFO: Inference done 7607/26446. 0.1652 s / img. ETA=0:52:38
[07/01 12:56:51] detectron2 INFO: Inference done 7638/26446. 0.1652 s / img. ETA=0:52:32
[07/01 12:56:56] detectron2 INFO: Inference done 7669/26446. 0.1652 s / img. ETA=0:52:27
[07/01 12:57:01] detectron2 INFO: Inference done 7699/26446. 0.1652 s / img. ETA=0:52:22
[07/01 12:57:07] detectron2 INFO: Inference done 7729/26446. 0.1652 s / img. ETA=0:52:17
[07/01 12:57:12] detectron2 INFO: Inference done 7758/26446. 0.1652 s / img. ETA=0:52:13
[07/01 12:57:17] detectron2 INFO: Inference done 7788/26446. 0.1652 s / img. ETA=0:52:08
[07/01 12:57:22] detectron2 INFO: Inference done 7818/26446. 0.1652 s / img. ETA=0:52:03
[07/01 12:57:27] detectron2 INFO: Inference done 7848/26446. 0.1652 s / img. ETA=0:51:58
[07/01 12:57:32] detectron2 INFO: Inference done 7878/26446. 0.1652 s / img. ETA=0:51:53
[07/01 12:57:37] detectron2 INFO: Inference done 7909/26446. 0.1652 s / img. ETA=0:51:47
[07/01 12:57:42] detectron2 INFO: Inference done 7939/26446. 0.1652 s / img. ETA=0:51:42
[07/01 12:57:47] detectron2 INFO: Inference done 7970/26446. 0.1652 s / img. ETA=0:51:37
[07/01 12:57:52] detectron2 INFO: Inference done 8000/26446. 0.1652 s / img. ETA=0:51:32
[07/01 12:57:57] detectron2 INFO: Inference done 8030/26446. 0.1652 s / img. ETA=0:51:27
[07/01 12:58:02] detectron2 INFO: Inference done 8060/26446. 0.1652 s / img. ETA=0:51:22
[07/01 12:58:07] detectron2 INFO: Inference done 8090/26446. 0.1652 s / img. ETA=0:51:17
[07/01 12:58:12] detectron2 INFO: Inference done 8120/26446. 0.1652 s / img. ETA=0:51:12
[07/01 12:58:17] detectron2 INFO: Inference done 8150/26446. 0.1652 s / img. ETA=0:51:07
[07/01 12:58:22] detectron2 INFO: Inference done 8180/26446. 0.1652 s / img. ETA=0:51:02
[07/01 12:58:27] detectron2 INFO: Inference done 8211/26446. 0.1652 s / img. ETA=0:50:57
[07/01 12:58:33] detectron2 INFO: Inference done 8242/26446. 0.1652 s / img. ETA=0:50:51
[07/01 12:58:38] detectron2 INFO: Inference done 8271/26446. 0.1652 s / img. ETA=0:50:47
[07/01 12:58:43] detectron2 INFO: Inference done 8302/26446. 0.1652 s / img. ETA=0:50:41
[07/01 12:58:48] detectron2 INFO: Inference done 8325/26446. 0.1654 s / img. ETA=0:50:40
[07/01 12:58:53] detectron2 INFO: Inference done 8356/26446. 0.1653 s / img. ETA=0:50:35
[07/01 12:58:58] detectron2 INFO: Inference done 8387/26446. 0.1653 s / img. ETA=0:50:30
[07/01 12:59:03] detectron2 INFO: Inference done 8417/26446. 0.1653 s / img. ETA=0:50:25
[07/01 12:59:08] detectron2 INFO: Inference done 8447/26446. 0.1653 s / img. ETA=0:50:20
[07/01 12:59:13] detectron2 INFO: Inference done 8477/26446. 0.1653 s / img. ETA=0:50:14
[07/01 12:59:18] detectron2 INFO: Inference done 8508/26446. 0.1653 s / img. ETA=0:50:09
[07/01 12:59:23] detectron2 INFO: Inference done 8539/26446. 0.1653 s / img. ETA=0:50:04
[07/01 12:59:29] detectron2 INFO: Inference done 8569/26446. 0.1653 s / img. ETA=0:49:59
[07/01 12:59:34] detectron2 INFO: Inference done 8599/26446. 0.1653 s / img. ETA=0:49:54
[07/01 12:59:39] detectron2 INFO: Inference done 8629/26446. 0.1653 s / img. ETA=0:49:49
[07/01 12:59:44] detectron2 INFO: Inference done 8659/26446. 0.1653 s / img. ETA=0:49:44
[07/01 12:59:49] detectron2 INFO: Inference done 8690/26446. 0.1653 s / img. ETA=0:49:38
[07/01 12:59:54] detectron2 INFO: Inference done 8720/26446. 0.1653 s / img. ETA=0:49:33
[07/01 12:59:59] detectron2 INFO: Inference done 8750/26446. 0.1653 s / img. ETA=0:49:29
[07/01 13:00:04] detectron2 INFO: Inference done 8780/26446. 0.1654 s / img. ETA=0:49:24
[07/01 13:00:09] detectron2 INFO: Inference done 8811/26446. 0.1653 s / img. ETA=0:49:18
[07/01 13:00:14] detectron2 INFO: Inference done 8842/26446. 0.1653 s / img. ETA=0:49:13
[07/01 13:00:19] detectron2 INFO: Inference done 8872/26446. 0.1653 s / img. ETA=0:49:08
[07/01 13:00:24] detectron2 INFO: Inference done 8902/26446. 0.1653 s / img. ETA=0:49:03
[07/01 13:00:29] detectron2 INFO: Inference done 8932/26446. 0.1654 s / img. ETA=0:48:58
[07/01 13:00:35] detectron2 INFO: Inference done 8963/26446. 0.1653 s / img. ETA=0:48:53
[07/01 13:00:40] detectron2 INFO: Inference done 8994/26446. 0.1653 s / img. ETA=0:48:47
[07/01 13:00:45] detectron2 INFO: Inference done 9024/26446. 0.1653 s / img. ETA=0:48:42
[07/01 13:00:50] detectron2 INFO: Inference done 9054/26446. 0.1653 s / img. ETA=0:48:37
[07/01 13:00:55] detectron2 INFO: Inference done 9085/26446. 0.1653 s / img. ETA=0:48:32
[07/01 13:01:00] detectron2 INFO: Inference done 9116/26446. 0.1653 s / img. ETA=0:48:26
[07/01 13:01:05] detectron2 INFO: Inference done 9146/26446. 0.1653 s / img. ETA=0:48:22
[07/01 13:01:10] detectron2 INFO: Inference done 9176/26446. 0.1653 s / img. ETA=0:48:17
[07/01 13:01:15] detectron2 INFO: Inference done 9206/26446. 0.1653 s / img. ETA=0:48:12
[07/01 13:01:20] detectron2 INFO: Inference done 9236/26446. 0.1653 s / img. ETA=0:48:07
[07/01 13:01:25] detectron2 INFO: Inference done 9267/26446. 0.1653 s / img. ETA=0:48:01
[07/01 13:01:31] detectron2 INFO: Inference done 9298/26446. 0.1653 s / img. ETA=0:47:56
[07/01 13:01:36] detectron2 INFO: Inference done 9328/26446. 0.1653 s / img. ETA=0:47:51
[07/01 13:01:41] detectron2 INFO: Inference done 9358/26446. 0.1653 s / img. ETA=0:47:46
[07/01 13:01:46] detectron2 INFO: Inference done 9389/26446. 0.1653 s / img. ETA=0:47:41
[07/01 13:01:51] detectron2 INFO: Inference done 9419/26446. 0.1653 s / img. ETA=0:47:36
[07/01 13:01:56] detectron2 INFO: Inference done 9449/26446. 0.1653 s / img. ETA=0:47:31
[07/01 13:02:01] detectron2 INFO: Inference done 9479/26446. 0.1653 s / img. ETA=0:47:26
[07/01 13:02:06] detectron2 INFO: Inference done 9510/26446. 0.1653 s / img. ETA=0:47:20
[07/01 13:02:11] detectron2 INFO: Inference done 9540/26446. 0.1653 s / img. ETA=0:47:15
[07/01 13:02:16] detectron2 INFO: Inference done 9570/26446. 0.1653 s / img. ETA=0:47:10
[07/01 13:02:21] detectron2 INFO: Inference done 9600/26446. 0.1653 s / img. ETA=0:47:05
[07/01 13:02:26] detectron2 INFO: Inference done 9631/26446. 0.1653 s / img. ETA=0:47:00
[07/01 13:02:31] detectron2 INFO: Inference done 9661/26446. 0.1653 s / img. ETA=0:46:55
[07/01 13:02:36] detectron2 INFO: Inference done 9691/26446. 0.1653 s / img. ETA=0:46:50
[07/01 13:02:41] detectron2 INFO: Inference done 9721/26446. 0.1653 s / img. ETA=0:46:45
[07/01 13:02:47] detectron2 INFO: Inference done 9751/26446. 0.1653 s / img. ETA=0:46:40
[07/01 13:02:52] detectron2 INFO: Inference done 9781/26446. 0.1653 s / img. ETA=0:46:35
[07/01 13:02:57] detectron2 INFO: Inference done 9811/26446. 0.1654 s / img. ETA=0:46:30
[07/01 13:03:02] detectron2 INFO: Inference done 9842/26446. 0.1653 s / img. ETA=0:46:25
[07/01 13:03:07] detectron2 INFO: Inference done 9872/26446. 0.1654 s / img. ETA=0:46:20
[07/01 13:03:12] detectron2 INFO: Inference done 9903/26446. 0.1654 s / img. ETA=0:46:15
[07/01 13:03:17] detectron2 INFO: Inference done 9934/26446. 0.1653 s / img. ETA=0:46:09
[07/01 13:03:22] detectron2 INFO: Inference done 9964/26446. 0.1654 s / img. ETA=0:46:05
[07/01 13:03:28] detectron2 INFO: Inference done 9995/26446. 0.1654 s / img. ETA=0:45:59
[07/01 13:03:33] detectron2 INFO: Inference done 10025/26446. 0.1654 s / img. ETA=0:45:54
[07/01 13:03:38] detectron2 INFO: Inference done 10055/26446. 0.1654 s / img. ETA=0:45:49
[07/01 13:03:43] detectron2 INFO: Inference done 10086/26446. 0.1654 s / img. ETA=0:45:44
[07/01 13:03:48] detectron2 INFO: Inference done 10116/26446. 0.1654 s / img. ETA=0:45:39
[07/01 13:03:53] detectron2 INFO: Inference done 10147/26446. 0.1653 s / img. ETA=0:45:33
[07/01 13:03:58] detectron2 INFO: Inference done 10177/26446. 0.1653 s / img. ETA=0:45:28
[07/01 13:04:03] detectron2 INFO: Inference done 10207/26446. 0.1653 s / img. ETA=0:45:23
[07/01 13:04:08] detectron2 INFO: Inference done 10237/26446. 0.1653 s / img. ETA=0:45:18
[07/01 13:04:13] detectron2 INFO: Inference done 10268/26446. 0.1653 s / img. ETA=0:45:13
[07/01 13:04:18] detectron2 INFO: Inference done 10298/26446. 0.1654 s / img. ETA=0:45:08
[07/01 13:04:23] detectron2 INFO: Inference done 10329/26446. 0.1653 s / img. ETA=0:45:03
[07/01 13:04:29] detectron2 INFO: Inference done 10360/26446. 0.1653 s / img. ETA=0:44:58
[07/01 13:04:34] detectron2 INFO: Inference done 10390/26446. 0.1653 s / img. ETA=0:44:53
[07/01 13:04:39] detectron2 INFO: Inference done 10420/26446. 0.1654 s / img. ETA=0:44:48
[07/01 13:04:44] detectron2 INFO: Inference done 10450/26446. 0.1654 s / img. ETA=0:44:43
[07/01 13:04:49] detectron2 INFO: Inference done 10481/26446. 0.1654 s / img. ETA=0:44:38
[07/01 13:04:54] detectron2 INFO: Inference done 10510/26446. 0.1654 s / img. ETA=0:44:33
[07/01 13:04:59] detectron2 INFO: Inference done 10540/26446. 0.1654 s / img. ETA=0:44:28
[07/01 13:05:04] detectron2 INFO: Inference done 10570/26446. 0.1654 s / img. ETA=0:44:23
[07/01 13:05:09] detectron2 INFO: Inference done 10601/26446. 0.1654 s / img. ETA=0:44:18
[07/01 13:05:14] detectron2 INFO: Inference done 10632/26446. 0.1654 s / img. ETA=0:44:12
[07/01 13:05:19] detectron2 INFO: Inference done 10662/26446. 0.1654 s / img. ETA=0:44:07
[07/01 13:05:24] detectron2 INFO: Inference done 10692/26446. 0.1654 s / img. ETA=0:44:02
[07/01 13:05:30] detectron2 INFO: Inference done 10722/26446. 0.1654 s / img. ETA=0:43:57
[07/01 13:05:35] detectron2 INFO: Inference done 10752/26446. 0.1654 s / img. ETA=0:43:52
[07/01 13:05:40] detectron2 INFO: Inference done 10782/26446. 0.1654 s / img. ETA=0:43:47
[07/01 13:05:45] detectron2 INFO: Inference done 10812/26446. 0.1654 s / img. ETA=0:43:42
[07/01 13:05:50] detectron2 INFO: Inference done 10841/26446. 0.1654 s / img. ETA=0:43:38
[07/01 13:05:55] detectron2 INFO: Inference done 10869/26446. 0.1654 s / img. ETA=0:43:34
[07/01 14:12:18] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 14:12:19] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 14:12:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 14:12:19] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 14:12:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 14:12:19] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 14:12:19] d2.utils.env INFO: Using a generated random seed 19699640
[07/01 14:12:23] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 14:12:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 14:12:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 14:12:25] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 14:12:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 14:12:25] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 14:12:27] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 14:12:27] detectron2 INFO: Following metrics will be use for evaluation
[07/01 14:12:27] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 14:12:27] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 14:12:27] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 14:12:27] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 14:12:27] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 14:12:29] detectron2 INFO: Loading zero shot triplets
[07/01 14:12:29] detectron2 INFO: Start inference on 26446 images
[07/01 14:13:03] detectron2 INFO: Inference done 1/26446. 6.3039 s / img. ETA=10 days, 12:04:25
[07/01 14:13:08] detectron2 INFO: Inference done 30/26446. 0.1704 s / img. ETA=1:16:03
[07/01 14:13:13] detectron2 INFO: Inference done 60/26446. 0.1695 s / img. ETA=1:15:35
[07/01 14:13:18] detectron2 INFO: Inference done 90/26446. 0.1685 s / img. ETA=1:15:01
[07/01 14:13:23] detectron2 INFO: Inference done 121/26446. 0.1673 s / img. ETA=1:14:25
[07/01 14:13:28] detectron2 INFO: Inference done 152/26446. 0.1658 s / img. ETA=1:13:37
[07/01 14:13:34] detectron2 INFO: Inference done 183/26446. 0.1654 s / img. ETA=1:13:22
[07/01 14:13:39] detectron2 INFO: Inference done 214/26446. 0.1652 s / img. ETA=1:13:11
[07/01 14:13:44] detectron2 INFO: Inference done 245/26446. 0.1651 s / img. ETA=1:13:03
[07/01 14:13:49] detectron2 INFO: Inference done 276/26446. 0.1648 s / img. ETA=1:12:52
[07/01 14:13:54] detectron2 INFO: Inference done 307/26446. 0.1646 s / img. ETA=1:12:39
[07/01 14:13:59] detectron2 INFO: Inference done 337/26446. 0.1648 s / img. ETA=1:12:40
[07/01 14:14:04] detectron2 INFO: Inference done 368/26446. 0.1646 s / img. ETA=1:12:31
[07/01 14:14:09] detectron2 INFO: Inference done 399/26446. 0.1645 s / img. ETA=1:12:21
[07/01 14:14:15] detectron2 INFO: Inference done 430/26446. 0.1643 s / img. ETA=1:12:12
[07/01 14:14:20] detectron2 INFO: Inference done 461/26446. 0.1643 s / img. ETA=1:12:06
[07/01 14:14:25] detectron2 INFO: Inference done 492/26446. 0.1642 s / img. ETA=1:11:59
[07/01 14:14:30] detectron2 INFO: Inference done 523/26446. 0.1641 s / img. ETA=1:11:50
[07/01 14:14:35] detectron2 INFO: Inference done 554/26446. 0.1640 s / img. ETA=1:11:43
[07/01 14:14:40] detectron2 INFO: Inference done 585/26446. 0.1638 s / img. ETA=1:11:32
[07/01 14:14:45] detectron2 INFO: Inference done 615/26446. 0.1640 s / img. ETA=1:11:31
[07/01 14:14:50] detectron2 INFO: Inference done 646/26446. 0.1639 s / img. ETA=1:11:26
[07/01 14:14:55] detectron2 INFO: Inference done 677/26446. 0.1640 s / img. ETA=1:11:21
[07/01 14:15:00] detectron2 INFO: Inference done 707/26446. 0.1640 s / img. ETA=1:11:19
[07/01 14:15:06] detectron2 INFO: Inference done 738/26446. 0.1640 s / img. ETA=1:11:13
[07/01 14:15:11] detectron2 INFO: Inference done 769/26446. 0.1639 s / img. ETA=1:11:05
[07/01 14:15:16] detectron2 INFO: Inference done 800/26446. 0.1639 s / img. ETA=1:10:59
[07/01 14:15:21] detectron2 INFO: Inference done 832/26446. 0.1637 s / img. ETA=1:10:48
[07/01 14:15:26] detectron2 INFO: Inference done 863/26446. 0.1636 s / img. ETA=1:10:42
[07/01 14:15:31] detectron2 INFO: Inference done 893/26446. 0.1637 s / img. ETA=1:10:38
[07/01 14:15:36] detectron2 INFO: Inference done 923/26446. 0.1637 s / img. ETA=1:10:35
[07/01 14:15:41] detectron2 INFO: Inference done 954/26446. 0.1637 s / img. ETA=1:10:28
[07/01 14:15:46] detectron2 INFO: Inference done 984/26446. 0.1639 s / img. ETA=1:10:28
[07/01 14:15:51] detectron2 INFO: Inference done 1015/26446. 0.1638 s / img. ETA=1:10:22
[07/01 14:15:56] detectron2 INFO: Inference done 1044/26446. 0.1640 s / img. ETA=1:10:22
[07/01 14:16:02] detectron2 INFO: Inference done 1075/26446. 0.1640 s / img. ETA=1:10:15
[07/01 14:16:07] detectron2 INFO: Inference done 1105/26446. 0.1640 s / img. ETA=1:10:11
[07/01 14:16:12] detectron2 INFO: Inference done 1136/26446. 0.1640 s / img. ETA=1:10:06
[07/01 14:16:17] detectron2 INFO: Inference done 1166/26446. 0.1640 s / img. ETA=1:10:02
[07/01 14:16:22] detectron2 INFO: Inference done 1196/26446. 0.1641 s / img. ETA=1:09:59
[07/01 14:16:27] detectron2 INFO: Inference done 1226/26446. 0.1642 s / img. ETA=1:09:56
[07/01 14:16:32] detectron2 INFO: Inference done 1256/26446. 0.1642 s / img. ETA=1:09:51
[07/01 14:16:37] detectron2 INFO: Inference done 1286/26446. 0.1642 s / img. ETA=1:09:46
[07/01 14:16:42] detectron2 INFO: Inference done 1317/26446. 0.1642 s / img. ETA=1:09:40
[07/01 14:16:47] detectron2 INFO: Inference done 1347/26446. 0.1642 s / img. ETA=1:09:36
[07/01 14:16:52] detectron2 INFO: Inference done 1378/26446. 0.1642 s / img. ETA=1:09:30
[07/01 14:16:57] detectron2 INFO: Inference done 1408/26446. 0.1642 s / img. ETA=1:09:26
[07/01 14:17:02] detectron2 INFO: Inference done 1439/26446. 0.1642 s / img. ETA=1:09:20
[07/01 14:17:07] detectron2 INFO: Inference done 1469/26446. 0.1642 s / img. ETA=1:09:15
[07/01 14:17:12] detectron2 INFO: Inference done 1500/26446. 0.1642 s / img. ETA=1:09:09
[07/01 14:17:18] detectron2 INFO: Inference done 1531/26446. 0.1642 s / img. ETA=1:09:04
[07/01 14:17:23] detectron2 INFO: Inference done 1561/26446. 0.1642 s / img. ETA=1:09:00
[07/01 14:17:28] detectron2 INFO: Inference done 1591/26446. 0.1642 s / img. ETA=1:08:55
[07/01 14:17:33] detectron2 INFO: Inference done 1622/26446. 0.1642 s / img. ETA=1:08:49
[07/01 14:17:38] detectron2 INFO: Inference done 1653/26446. 0.1642 s / img. ETA=1:08:44
[07/01 14:17:43] detectron2 INFO: Inference done 1683/26446. 0.1642 s / img. ETA=1:08:39
[07/01 14:17:48] detectron2 INFO: Inference done 1714/26446. 0.1642 s / img. ETA=1:08:34
[07/01 14:17:53] detectron2 INFO: Inference done 1744/26446. 0.1642 s / img. ETA=1:08:29
[07/01 14:17:58] detectron2 INFO: Inference done 1774/26446. 0.1642 s / img. ETA=1:08:24
[07/01 14:18:03] detectron2 INFO: Inference done 1805/26446. 0.1642 s / img. ETA=1:08:19
[07/01 14:18:08] detectron2 INFO: Inference done 1835/26446. 0.1642 s / img. ETA=1:08:14
[07/01 14:18:13] detectron2 INFO: Inference done 1865/26446. 0.1642 s / img. ETA=1:08:10
[07/01 14:18:18] detectron2 INFO: Inference done 1896/26446. 0.1642 s / img. ETA=1:08:04
[07/01 14:18:23] detectron2 INFO: Inference done 1926/26446. 0.1642 s / img. ETA=1:08:00
[07/01 14:18:28] detectron2 INFO: Inference done 1956/26446. 0.1642 s / img. ETA=1:07:55
[07/01 14:18:34] detectron2 INFO: Inference done 1988/26446. 0.1642 s / img. ETA=1:07:48
[07/01 14:18:40] detectron2 INFO: Inference done 2009/26446. 0.1642 s / img. ETA=1:08:15
[07/01 14:18:45] detectron2 INFO: Inference done 2038/26446. 0.1643 s / img. ETA=1:08:12
[07/01 14:18:50] detectron2 INFO: Inference done 2069/26446. 0.1643 s / img. ETA=1:08:06
[07/01 14:18:55] detectron2 INFO: Inference done 2099/26446. 0.1643 s / img. ETA=1:08:01
[07/01 14:19:00] detectron2 INFO: Inference done 2129/26446. 0.1644 s / img. ETA=1:07:58
[07/01 14:19:05] detectron2 INFO: Inference done 2160/26446. 0.1644 s / img. ETA=1:07:52
[07/01 14:19:10] detectron2 INFO: Inference done 2190/26446. 0.1644 s / img. ETA=1:07:47
[07/01 14:19:15] detectron2 INFO: Inference done 2221/26446. 0.1643 s / img. ETA=1:07:40
[07/01 14:19:20] detectron2 INFO: Inference done 2251/26446. 0.1643 s / img. ETA=1:07:35
[07/01 14:19:25] detectron2 INFO: Inference done 2281/26446. 0.1644 s / img. ETA=1:07:30
[07/01 14:19:30] detectron2 INFO: Inference done 2312/26446. 0.1644 s / img. ETA=1:07:24
[07/01 14:19:36] detectron2 INFO: Inference done 2343/26446. 0.1643 s / img. ETA=1:07:18
[07/01 14:19:41] detectron2 INFO: Inference done 2374/26446. 0.1643 s / img. ETA=1:07:12
[07/01 14:19:46] detectron2 INFO: Inference done 2405/26446. 0.1643 s / img. ETA=1:07:06
[07/01 14:19:51] detectron2 INFO: Inference done 2435/26446. 0.1643 s / img. ETA=1:07:01
[07/01 14:19:56] detectron2 INFO: Inference done 2466/26446. 0.1643 s / img. ETA=1:06:55
[07/01 14:20:01] detectron2 INFO: Inference done 2497/26446. 0.1643 s / img. ETA=1:06:50
[07/01 14:20:06] detectron2 INFO: Inference done 2527/26446. 0.1643 s / img. ETA=1:06:45
[07/01 14:20:11] detectron2 INFO: Inference done 2558/26446. 0.1643 s / img. ETA=1:06:39
[07/01 14:20:16] detectron2 INFO: Inference done 2588/26446. 0.1643 s / img. ETA=1:06:34
[07/01 14:20:21] detectron2 INFO: Inference done 2619/26446. 0.1643 s / img. ETA=1:06:28
[07/01 14:20:26] detectron2 INFO: Inference done 2649/26446. 0.1643 s / img. ETA=1:06:23
[07/01 14:20:31] detectron2 INFO: Inference done 2680/26446. 0.1643 s / img. ETA=1:06:17
[07/01 14:20:37] detectron2 INFO: Inference done 2710/26446. 0.1643 s / img. ETA=1:06:13
[07/01 14:20:42] detectron2 INFO: Inference done 2740/26446. 0.1643 s / img. ETA=1:06:08
[07/01 14:20:47] detectron2 INFO: Inference done 2770/26446. 0.1644 s / img. ETA=1:06:04
[07/01 14:20:52] detectron2 INFO: Inference done 2800/26446. 0.1644 s / img. ETA=1:05:59
[07/01 14:20:57] detectron2 INFO: Inference done 2830/26446. 0.1644 s / img. ETA=1:05:54
[07/01 14:21:02] detectron2 INFO: Inference done 2861/26446. 0.1644 s / img. ETA=1:05:48
[07/01 14:21:07] detectron2 INFO: Inference done 2891/26446. 0.1644 s / img. ETA=1:05:43
[07/01 14:21:12] detectron2 INFO: Inference done 2922/26446. 0.1644 s / img. ETA=1:05:37
[07/01 14:21:17] detectron2 INFO: Inference done 2952/26446. 0.1644 s / img. ETA=1:05:32
[07/01 14:21:22] detectron2 INFO: Inference done 2982/26446. 0.1644 s / img. ETA=1:05:27
[07/01 14:21:27] detectron2 INFO: Inference done 3013/26446. 0.1644 s / img. ETA=1:05:22
[07/01 14:21:32] detectron2 INFO: Inference done 3044/26446. 0.1644 s / img. ETA=1:05:16
[07/01 14:21:37] detectron2 INFO: Inference done 3074/26446. 0.1644 s / img. ETA=1:05:12
[07/01 14:21:43] detectron2 INFO: Inference done 3105/26446. 0.1644 s / img. ETA=1:05:06
[07/01 14:21:48] detectron2 INFO: Inference done 3135/26446. 0.1644 s / img. ETA=1:05:01
[07/01 14:21:53] detectron2 INFO: Inference done 3165/26446. 0.1644 s / img. ETA=1:04:56
[07/01 14:21:58] detectron2 INFO: Inference done 3196/26446. 0.1644 s / img. ETA=1:04:51
[07/01 14:22:03] detectron2 INFO: Inference done 3227/26446. 0.1644 s / img. ETA=1:04:45
[07/01 14:22:08] detectron2 INFO: Inference done 3257/26446. 0.1644 s / img. ETA=1:04:40
[07/01 14:22:13] detectron2 INFO: Inference done 3288/26446. 0.1644 s / img. ETA=1:04:34
[07/01 14:22:18] detectron2 INFO: Inference done 3319/26446. 0.1644 s / img. ETA=1:04:28
[07/01 14:22:23] detectron2 INFO: Inference done 3349/26446. 0.1644 s / img. ETA=1:04:24
[07/01 14:22:28] detectron2 INFO: Inference done 3380/26446. 0.1644 s / img. ETA=1:04:18
[07/01 14:22:33] detectron2 INFO: Inference done 3410/26446. 0.1644 s / img. ETA=1:04:13
[07/01 14:22:38] detectron2 INFO: Inference done 3441/26446. 0.1644 s / img. ETA=1:04:07
[07/01 14:22:44] detectron2 INFO: Inference done 3472/26446. 0.1644 s / img. ETA=1:04:02
[07/01 14:22:49] detectron2 INFO: Inference done 3503/26446. 0.1644 s / img. ETA=1:03:56
[07/01 14:22:54] detectron2 INFO: Inference done 3533/26446. 0.1644 s / img. ETA=1:03:52
[07/01 14:22:59] detectron2 INFO: Inference done 3563/26446. 0.1644 s / img. ETA=1:03:47
[07/01 14:23:04] detectron2 INFO: Inference done 3593/26446. 0.1644 s / img. ETA=1:03:42
[07/01 14:23:09] detectron2 INFO: Inference done 3624/26446. 0.1644 s / img. ETA=1:03:37
[07/01 14:23:14] detectron2 INFO: Inference done 3654/26446. 0.1644 s / img. ETA=1:03:32
[07/01 14:23:19] detectron2 INFO: Inference done 3685/26446. 0.1644 s / img. ETA=1:03:27
[07/01 14:23:24] detectron2 INFO: Inference done 3715/26446. 0.1644 s / img. ETA=1:03:22
[07/01 14:23:29] detectron2 INFO: Inference done 3745/26446. 0.1644 s / img. ETA=1:03:17
[07/01 14:23:34] detectron2 INFO: Inference done 3775/26446. 0.1645 s / img. ETA=1:03:12
[07/01 14:23:40] detectron2 INFO: Inference done 3806/26446. 0.1644 s / img. ETA=1:03:06
[07/01 14:23:45] detectron2 INFO: Inference done 3836/26446. 0.1645 s / img. ETA=1:03:02
[07/01 14:23:50] detectron2 INFO: Inference done 3867/26446. 0.1645 s / img. ETA=1:02:56
[07/01 14:23:55] detectron2 INFO: Inference done 3898/26446. 0.1644 s / img. ETA=1:02:50
[07/01 14:24:00] detectron2 INFO: Inference done 3928/26446. 0.1645 s / img. ETA=1:02:46
[07/01 14:24:05] detectron2 INFO: Inference done 3958/26446. 0.1645 s / img. ETA=1:02:42
[07/01 14:24:10] detectron2 INFO: Inference done 3989/26446. 0.1645 s / img. ETA=1:02:36
[07/01 14:24:15] detectron2 INFO: Inference done 4019/26446. 0.1645 s / img. ETA=1:02:31
[07/01 14:24:20] detectron2 INFO: Inference done 4049/26446. 0.1645 s / img. ETA=1:02:27
[07/01 14:24:25] detectron2 INFO: Inference done 4079/26446. 0.1645 s / img. ETA=1:02:22
[07/01 14:24:31] detectron2 INFO: Inference done 4110/26446. 0.1645 s / img. ETA=1:02:16
[07/01 14:24:36] detectron2 INFO: Inference done 4140/26446. 0.1645 s / img. ETA=1:02:12
[07/01 14:24:41] detectron2 INFO: Inference done 4170/26446. 0.1645 s / img. ETA=1:02:07
[07/01 14:24:46] detectron2 INFO: Inference done 4200/26446. 0.1646 s / img. ETA=1:02:02
[07/01 14:24:51] detectron2 INFO: Inference done 4231/26446. 0.1645 s / img. ETA=1:01:56
[07/01 14:24:56] detectron2 INFO: Inference done 4262/26446. 0.1645 s / img. ETA=1:01:51
[07/01 14:25:01] detectron2 INFO: Inference done 4293/26446. 0.1645 s / img. ETA=1:01:45
[07/01 14:25:06] detectron2 INFO: Inference done 4323/26446. 0.1645 s / img. ETA=1:01:40
[07/01 14:25:11] detectron2 INFO: Inference done 4353/26446. 0.1645 s / img. ETA=1:01:35
[07/01 14:25:16] detectron2 INFO: Inference done 4383/26446. 0.1646 s / img. ETA=1:01:30
[07/01 14:25:21] detectron2 INFO: Inference done 4414/26446. 0.1645 s / img. ETA=1:01:25
[07/01 14:25:26] detectron2 INFO: Inference done 4444/26446. 0.1645 s / img. ETA=1:01:20
[07/01 14:25:31] detectron2 INFO: Inference done 4474/26446. 0.1646 s / img. ETA=1:01:15
[07/01 14:25:36] detectron2 INFO: Inference done 4505/26446. 0.1645 s / img. ETA=1:01:10
[07/01 14:25:42] detectron2 INFO: Inference done 4535/26446. 0.1646 s / img. ETA=1:01:05
[07/01 14:25:47] detectron2 INFO: Inference done 4565/26446. 0.1646 s / img. ETA=1:01:00
[07/01 14:25:52] detectron2 INFO: Inference done 4595/26446. 0.1646 s / img. ETA=1:00:55
[07/01 14:25:57] detectron2 INFO: Inference done 4626/26446. 0.1646 s / img. ETA=1:00:50
[07/01 14:26:02] detectron2 INFO: Inference done 4656/26446. 0.1646 s / img. ETA=1:00:46
[07/01 14:26:07] detectron2 INFO: Inference done 4686/26446. 0.1646 s / img. ETA=1:00:41
[07/01 14:26:12] detectron2 INFO: Inference done 4716/26446. 0.1646 s / img. ETA=1:00:36
[07/01 14:26:17] detectron2 INFO: Inference done 4746/26446. 0.1646 s / img. ETA=1:00:31
[07/01 14:26:22] detectron2 INFO: Inference done 4776/26446. 0.1646 s / img. ETA=1:00:26
[07/01 14:26:27] detectron2 INFO: Inference done 4806/26446. 0.1647 s / img. ETA=1:00:21
[07/01 14:26:32] detectron2 INFO: Inference done 4836/26446. 0.1647 s / img. ETA=1:00:17
[07/01 14:26:37] detectron2 INFO: Inference done 4866/26446. 0.1647 s / img. ETA=1:00:12
[07/01 14:26:42] detectron2 INFO: Inference done 4896/26446. 0.1647 s / img. ETA=1:00:07
[07/01 14:26:47] detectron2 INFO: Inference done 4926/26446. 0.1647 s / img. ETA=1:00:02
[07/01 14:26:53] detectron2 INFO: Inference done 4956/26446. 0.1647 s / img. ETA=0:59:57
[07/01 14:26:58] detectron2 INFO: Inference done 4986/26446. 0.1647 s / img. ETA=0:59:52
[07/01 14:27:03] detectron2 INFO: Inference done 5017/26446. 0.1647 s / img. ETA=0:59:46
[07/01 14:27:08] detectron2 INFO: Inference done 5046/26446. 0.1648 s / img. ETA=0:59:43
[07/01 14:27:13] detectron2 INFO: Inference done 5076/26446. 0.1648 s / img. ETA=0:59:38
[07/01 14:27:18] detectron2 INFO: Inference done 5106/26446. 0.1648 s / img. ETA=0:59:33
[07/01 14:27:23] detectron2 INFO: Inference done 5136/26446. 0.1648 s / img. ETA=0:59:28
[07/01 14:27:28] detectron2 INFO: Inference done 5166/26446. 0.1648 s / img. ETA=0:59:23
[07/01 14:27:33] detectron2 INFO: Inference done 5196/26446. 0.1648 s / img. ETA=0:59:18
[07/01 14:27:38] detectron2 INFO: Inference done 5226/26446. 0.1648 s / img. ETA=0:59:13
[07/01 14:27:43] detectron2 INFO: Inference done 5257/26446. 0.1648 s / img. ETA=0:59:08
[07/01 14:27:48] detectron2 INFO: Inference done 5287/26446. 0.1648 s / img. ETA=0:59:03
[07/01 14:27:53] detectron2 INFO: Inference done 5317/26446. 0.1648 s / img. ETA=0:58:58
[07/01 14:27:58] detectron2 INFO: Inference done 5347/26446. 0.1648 s / img. ETA=0:58:53
[07/01 14:28:04] detectron2 INFO: Inference done 5378/26446. 0.1648 s / img. ETA=0:58:48
[07/01 14:28:09] detectron2 INFO: Inference done 5408/26446. 0.1648 s / img. ETA=0:58:43
[07/01 14:28:14] detectron2 INFO: Inference done 5438/26446. 0.1648 s / img. ETA=0:58:38
[07/01 14:28:19] detectron2 INFO: Inference done 5468/26446. 0.1649 s / img. ETA=0:58:33
[07/01 14:28:24] detectron2 INFO: Inference done 5499/26446. 0.1649 s / img. ETA=0:58:28
[07/01 14:28:29] detectron2 INFO: Inference done 5530/26446. 0.1649 s / img. ETA=0:58:23
[07/01 14:28:34] detectron2 INFO: Inference done 5560/26446. 0.1649 s / img. ETA=0:58:18
[07/01 14:28:39] detectron2 INFO: Inference done 5590/26446. 0.1649 s / img. ETA=0:58:13
[07/01 14:28:44] detectron2 INFO: Inference done 5621/26446. 0.1649 s / img. ETA=0:58:08
[07/01 14:28:50] detectron2 INFO: Inference done 5652/26446. 0.1649 s / img. ETA=0:58:02
[07/01 14:28:55] detectron2 INFO: Inference done 5682/26446. 0.1649 s / img. ETA=0:57:57
[07/01 14:29:00] detectron2 INFO: Inference done 5712/26446. 0.1649 s / img. ETA=0:57:52
[07/01 14:29:05] detectron2 INFO: Inference done 5742/26446. 0.1649 s / img. ETA=0:57:48
[07/01 14:29:10] detectron2 INFO: Inference done 5772/26446. 0.1649 s / img. ETA=0:57:43
[07/01 14:29:15] detectron2 INFO: Inference done 5802/26446. 0.1649 s / img. ETA=0:57:38
[07/01 14:29:20] detectron2 INFO: Inference done 5832/26446. 0.1649 s / img. ETA=0:57:33
[07/01 14:29:25] detectron2 INFO: Inference done 5862/26446. 0.1649 s / img. ETA=0:57:28
[07/01 14:29:30] detectron2 INFO: Inference done 5893/26446. 0.1649 s / img. ETA=0:57:22
[07/01 14:29:35] detectron2 INFO: Inference done 5924/26446. 0.1649 s / img. ETA=0:57:17
[07/01 14:29:40] detectron2 INFO: Inference done 5955/26446. 0.1649 s / img. ETA=0:57:12
[07/01 14:29:45] detectron2 INFO: Inference done 5985/26446. 0.1649 s / img. ETA=0:57:07
[07/01 14:29:51] detectron2 INFO: Inference done 6016/26446. 0.1649 s / img. ETA=0:57:02
[07/01 14:29:56] detectron2 INFO: Inference done 6047/26446. 0.1649 s / img. ETA=0:56:56
[07/01 14:30:01] detectron2 INFO: Inference done 6077/26446. 0.1649 s / img. ETA=0:56:51
[07/01 14:30:06] detectron2 INFO: Inference done 6107/26446. 0.1649 s / img. ETA=0:56:46
[07/01 14:30:11] detectron2 INFO: Inference done 6138/26446. 0.1649 s / img. ETA=0:56:41
[07/01 14:30:16] detectron2 INFO: Inference done 6168/26446. 0.1649 s / img. ETA=0:56:36
[07/01 14:30:21] detectron2 INFO: Inference done 6198/26446. 0.1649 s / img. ETA=0:56:31
[07/01 14:30:26] detectron2 INFO: Inference done 6228/26446. 0.1649 s / img. ETA=0:56:26
[07/01 14:30:31] detectron2 INFO: Inference done 6258/26446. 0.1649 s / img. ETA=0:56:21
[07/01 14:30:36] detectron2 INFO: Inference done 6288/26446. 0.1649 s / img. ETA=0:56:16
[07/01 14:30:41] detectron2 INFO: Inference done 6319/26446. 0.1649 s / img. ETA=0:56:10
[07/01 14:30:46] detectron2 INFO: Inference done 6349/26446. 0.1649 s / img. ETA=0:56:05
[07/01 14:30:51] detectron2 INFO: Inference done 6379/26446. 0.1649 s / img. ETA=0:56:00
[07/01 14:30:56] detectron2 INFO: Inference done 6410/26446. 0.1649 s / img. ETA=0:55:55
[07/01 14:31:02] detectron2 INFO: Inference done 6440/26446. 0.1649 s / img. ETA=0:55:50
[07/01 14:31:07] detectron2 INFO: Inference done 6471/26446. 0.1649 s / img. ETA=0:55:45
[07/01 14:31:12] detectron2 INFO: Inference done 6502/26446. 0.1649 s / img. ETA=0:55:40
[07/01 14:31:17] detectron2 INFO: Inference done 6532/26446. 0.1649 s / img. ETA=0:55:35
[07/01 14:31:22] detectron2 INFO: Inference done 6562/26446. 0.1649 s / img. ETA=0:55:30
[07/01 14:31:27] detectron2 INFO: Inference done 6592/26446. 0.1649 s / img. ETA=0:55:25
[07/01 14:31:32] detectron2 INFO: Inference done 6622/26446. 0.1649 s / img. ETA=0:55:20
[07/01 14:31:37] detectron2 INFO: Inference done 6652/26446. 0.1649 s / img. ETA=0:55:15
[07/01 14:31:42] detectron2 INFO: Inference done 6683/26446. 0.1649 s / img. ETA=0:55:10
[07/01 14:31:47] detectron2 INFO: Inference done 6713/26446. 0.1649 s / img. ETA=0:55:05
[07/01 14:31:52] detectron2 INFO: Inference done 6743/26446. 0.1649 s / img. ETA=0:55:00
[07/01 14:31:57] detectron2 INFO: Inference done 6773/26446. 0.1650 s / img. ETA=0:54:55
[07/01 14:32:03] detectron2 INFO: Inference done 6804/26446. 0.1649 s / img. ETA=0:54:50
[07/01 14:32:08] detectron2 INFO: Inference done 6835/26446. 0.1649 s / img. ETA=0:54:44
[07/01 14:32:13] detectron2 INFO: Inference done 6865/26446. 0.1650 s / img. ETA=0:54:39
[07/01 14:32:18] detectron2 INFO: Inference done 6896/26446. 0.1649 s / img. ETA=0:54:34
[07/01 14:32:23] detectron2 INFO: Inference done 6926/26446. 0.1649 s / img. ETA=0:54:29
[07/01 14:32:28] detectron2 INFO: Inference done 6956/26446. 0.1649 s / img. ETA=0:54:24
[07/01 14:32:33] detectron2 INFO: Inference done 6986/26446. 0.1649 s / img. ETA=0:54:19
[07/01 14:32:38] detectron2 INFO: Inference done 7017/26446. 0.1649 s / img. ETA=0:54:13
[07/01 14:32:43] detectron2 INFO: Inference done 7047/26446. 0.1649 s / img. ETA=0:54:09
[07/01 14:32:48] detectron2 INFO: Inference done 7077/26446. 0.1650 s / img. ETA=0:54:04
[07/01 14:32:53] detectron2 INFO: Inference done 7105/26446. 0.1650 s / img. ETA=0:54:00
[07/01 14:32:58] detectron2 INFO: Inference done 7133/26446. 0.1651 s / img. ETA=0:53:56
[07/01 14:33:03] detectron2 INFO: Inference done 7162/26446. 0.1651 s / img. ETA=0:53:52
[07/01 14:33:08] detectron2 INFO: Inference done 7191/26446. 0.1651 s / img. ETA=0:53:47
[07/01 14:33:14] detectron2 INFO: Inference done 7219/26446. 0.1652 s / img. ETA=0:53:44
[07/01 14:33:19] detectron2 INFO: Inference done 7247/26446. 0.1652 s / img. ETA=0:53:40
[07/01 14:33:24] detectron2 INFO: Inference done 7276/26446. 0.1653 s / img. ETA=0:53:36
[07/01 14:33:29] detectron2 INFO: Inference done 7304/26446. 0.1653 s / img. ETA=0:53:32
[07/01 14:33:34] detectron2 INFO: Inference done 7333/26446. 0.1653 s / img. ETA=0:53:28
[07/01 14:33:39] detectron2 INFO: Inference done 7362/26446. 0.1654 s / img. ETA=0:53:24
[07/01 14:33:44] detectron2 INFO: Inference done 7392/26446. 0.1654 s / img. ETA=0:53:19
[07/01 14:33:49] detectron2 INFO: Inference done 7422/26446. 0.1654 s / img. ETA=0:53:14
[07/01 14:33:54] detectron2 INFO: Inference done 7452/26446. 0.1654 s / img. ETA=0:53:09
[07/01 14:33:59] detectron2 INFO: Inference done 7483/26446. 0.1654 s / img. ETA=0:53:04
[07/01 14:34:05] detectron2 INFO: Inference done 7514/26446. 0.1654 s / img. ETA=0:52:58
[07/01 14:34:10] detectron2 INFO: Inference done 7544/26446. 0.1654 s / img. ETA=0:52:53
[07/01 14:34:15] detectron2 INFO: Inference done 7574/26446. 0.1654 s / img. ETA=0:52:48
[07/01 14:34:20] detectron2 INFO: Inference done 7604/26446. 0.1654 s / img. ETA=0:52:43
[07/01 14:34:25] detectron2 INFO: Inference done 7634/26446. 0.1654 s / img. ETA=0:52:38
[07/01 14:34:30] detectron2 INFO: Inference done 7665/26446. 0.1654 s / img. ETA=0:52:33
[07/01 14:34:35] detectron2 INFO: Inference done 7695/26446. 0.1654 s / img. ETA=0:52:28
[07/01 14:34:40] detectron2 INFO: Inference done 7725/26446. 0.1654 s / img. ETA=0:52:23
[07/01 14:34:45] detectron2 INFO: Inference done 7755/26446. 0.1654 s / img. ETA=0:52:18
[07/01 14:34:50] detectron2 INFO: Inference done 7785/26446. 0.1654 s / img. ETA=0:52:13
[07/01 14:34:55] detectron2 INFO: Inference done 7815/26446. 0.1654 s / img. ETA=0:52:08
[07/01 14:35:00] detectron2 INFO: Inference done 7845/26446. 0.1654 s / img. ETA=0:52:03
[07/01 14:35:05] detectron2 INFO: Inference done 7875/26446. 0.1654 s / img. ETA=0:51:58
[07/01 14:35:11] detectron2 INFO: Inference done 7906/26446. 0.1654 s / img. ETA=0:51:53
[07/01 14:35:16] detectron2 INFO: Inference done 7935/26446. 0.1654 s / img. ETA=0:51:48
[07/01 14:35:21] detectron2 INFO: Inference done 7966/26446. 0.1654 s / img. ETA=0:51:43
[07/01 14:35:26] detectron2 INFO: Inference done 7996/26446. 0.1654 s / img. ETA=0:51:38
[07/01 14:35:31] detectron2 INFO: Inference done 8027/26446. 0.1654 s / img. ETA=0:51:32
[07/01 14:35:36] detectron2 INFO: Inference done 8057/26446. 0.1654 s / img. ETA=0:51:27
[07/01 14:35:41] detectron2 INFO: Inference done 8086/26446. 0.1654 s / img. ETA=0:51:23
[07/01 14:35:46] detectron2 INFO: Inference done 8115/26446. 0.1654 s / img. ETA=0:51:18
[07/01 14:35:51] detectron2 INFO: Inference done 8145/26446. 0.1655 s / img. ETA=0:51:13
[07/01 14:35:56] detectron2 INFO: Inference done 8175/26446. 0.1655 s / img. ETA=0:51:08
[07/01 14:36:01] detectron2 INFO: Inference done 8206/26446. 0.1654 s / img. ETA=0:51:03
[07/01 14:36:06] detectron2 INFO: Inference done 8236/26446. 0.1654 s / img. ETA=0:50:58
[07/01 14:36:11] detectron2 INFO: Inference done 8266/26446. 0.1654 s / img. ETA=0:50:53
[07/01 14:36:16] detectron2 INFO: Inference done 8297/26446. 0.1654 s / img. ETA=0:50:47
[07/01 14:36:22] detectron2 INFO: Inference done 8321/26446. 0.1656 s / img. ETA=0:50:46
[07/01 14:36:27] detectron2 INFO: Inference done 8351/26446. 0.1656 s / img. ETA=0:50:41
[07/01 14:36:32] detectron2 INFO: Inference done 8381/26446. 0.1656 s / img. ETA=0:50:36
[07/01 14:36:37] detectron2 INFO: Inference done 8411/26446. 0.1656 s / img. ETA=0:50:31
[07/01 14:36:42] detectron2 INFO: Inference done 8441/26446. 0.1656 s / img. ETA=0:50:26
[07/01 14:36:47] detectron2 INFO: Inference done 8471/26446. 0.1656 s / img. ETA=0:50:21
[07/01 14:36:52] detectron2 INFO: Inference done 8501/26446. 0.1656 s / img. ETA=0:50:16
[07/01 14:36:57] detectron2 INFO: Inference done 8531/26446. 0.1656 s / img. ETA=0:50:11
[07/01 14:37:02] detectron2 INFO: Inference done 8562/26446. 0.1656 s / img. ETA=0:50:06
[07/01 14:37:08] detectron2 INFO: Inference done 8593/26446. 0.1656 s / img. ETA=0:50:01
[07/01 14:37:13] detectron2 INFO: Inference done 8623/26446. 0.1656 s / img. ETA=0:49:56
[07/01 14:37:18] detectron2 INFO: Inference done 8653/26446. 0.1656 s / img. ETA=0:49:51
[07/01 14:37:23] detectron2 INFO: Inference done 8683/26446. 0.1656 s / img. ETA=0:49:46
[07/01 14:37:28] detectron2 INFO: Inference done 8713/26446. 0.1656 s / img. ETA=0:49:41
[07/01 14:37:33] detectron2 INFO: Inference done 8743/26446. 0.1656 s / img. ETA=0:49:36
[07/01 14:37:38] detectron2 INFO: Inference done 8773/26446. 0.1657 s / img. ETA=0:49:31
[07/01 14:37:43] detectron2 INFO: Inference done 8803/26446. 0.1657 s / img. ETA=0:49:26
[07/01 14:37:48] detectron2 INFO: Inference done 8833/26446. 0.1657 s / img. ETA=0:49:21
[07/01 14:37:53] detectron2 INFO: Inference done 8864/26446. 0.1656 s / img. ETA=0:49:16
[07/01 14:37:58] detectron2 INFO: Inference done 8893/26446. 0.1657 s / img. ETA=0:49:11
[07/01 14:38:03] detectron2 INFO: Inference done 8923/26446. 0.1657 s / img. ETA=0:49:06
[07/01 14:38:08] detectron2 INFO: Inference done 8953/26446. 0.1657 s / img. ETA=0:49:01
[07/01 14:38:13] detectron2 INFO: Inference done 8983/26446. 0.1657 s / img. ETA=0:48:56
[07/01 14:38:19] detectron2 INFO: Inference done 9014/26446. 0.1657 s / img. ETA=0:48:51
[07/01 14:38:24] detectron2 INFO: Inference done 9044/26446. 0.1657 s / img. ETA=0:48:46
[07/01 14:38:29] detectron2 INFO: Inference done 9074/26446. 0.1657 s / img. ETA=0:48:41
[07/01 14:38:34] detectron2 INFO: Inference done 9104/26446. 0.1657 s / img. ETA=0:48:36
[07/01 14:38:39] detectron2 INFO: Inference done 9134/26446. 0.1657 s / img. ETA=0:48:31
[07/01 14:38:44] detectron2 INFO: Inference done 9164/26446. 0.1657 s / img. ETA=0:48:26
[07/01 14:38:49] detectron2 INFO: Inference done 9194/26446. 0.1657 s / img. ETA=0:48:21
[07/01 14:38:54] detectron2 INFO: Inference done 9224/26446. 0.1657 s / img. ETA=0:48:16
[07/01 14:38:59] detectron2 INFO: Inference done 9255/26446. 0.1657 s / img. ETA=0:48:11
[07/01 14:39:04] detectron2 INFO: Inference done 9285/26446. 0.1657 s / img. ETA=0:48:06
[07/01 14:39:09] detectron2 INFO: Inference done 9315/26446. 0.1657 s / img. ETA=0:48:00
[07/01 14:39:15] detectron2 INFO: Inference done 9346/26446. 0.1657 s / img. ETA=0:47:55
[07/01 14:39:20] detectron2 INFO: Inference done 9376/26446. 0.1657 s / img. ETA=0:47:50
[07/01 14:39:25] detectron2 INFO: Inference done 9406/26446. 0.1657 s / img. ETA=0:47:45
[07/01 14:39:30] detectron2 INFO: Inference done 9436/26446. 0.1657 s / img. ETA=0:47:40
[07/01 14:39:35] detectron2 INFO: Inference done 9466/26446. 0.1657 s / img. ETA=0:47:35
[07/01 14:39:40] detectron2 INFO: Inference done 9496/26446. 0.1657 s / img. ETA=0:47:30
[07/01 14:39:45] detectron2 INFO: Inference done 9527/26446. 0.1657 s / img. ETA=0:47:25
[07/01 14:39:50] detectron2 INFO: Inference done 9557/26446. 0.1657 s / img. ETA=0:47:20
[07/01 14:39:55] detectron2 INFO: Inference done 9587/26446. 0.1657 s / img. ETA=0:47:15
[07/01 14:40:00] detectron2 INFO: Inference done 9617/26446. 0.1657 s / img. ETA=0:47:10
[07/01 14:40:05] detectron2 INFO: Inference done 9647/26446. 0.1657 s / img. ETA=0:47:05
[07/01 14:40:10] detectron2 INFO: Inference done 9677/26446. 0.1657 s / img. ETA=0:47:00
[07/01 14:40:16] detectron2 INFO: Inference done 9707/26446. 0.1657 s / img. ETA=0:46:55
[07/01 14:40:21] detectron2 INFO: Inference done 9737/26446. 0.1657 s / img. ETA=0:46:50
[07/01 14:40:26] detectron2 INFO: Inference done 9767/26446. 0.1657 s / img. ETA=0:46:45
[07/01 14:40:31] detectron2 INFO: Inference done 9797/26446. 0.1657 s / img. ETA=0:46:40
[07/01 14:40:36] detectron2 INFO: Inference done 9827/26446. 0.1657 s / img. ETA=0:46:35
[07/01 14:40:41] detectron2 INFO: Inference done 9858/26446. 0.1657 s / img. ETA=0:46:30
[07/01 14:40:46] detectron2 INFO: Inference done 9889/26446. 0.1657 s / img. ETA=0:46:24
[07/01 14:40:51] detectron2 INFO: Inference done 9919/26446. 0.1657 s / img. ETA=0:46:19
[07/01 14:40:56] detectron2 INFO: Inference done 9950/26446. 0.1657 s / img. ETA=0:46:14
[07/01 14:41:02] detectron2 INFO: Inference done 9981/26446. 0.1657 s / img. ETA=0:46:09
[07/01 14:41:07] detectron2 INFO: Inference done 10011/26446. 0.1657 s / img. ETA=0:46:04
[07/01 14:41:12] detectron2 INFO: Inference done 10041/26446. 0.1657 s / img. ETA=0:45:58
[07/01 14:41:17] detectron2 INFO: Inference done 10071/26446. 0.1657 s / img. ETA=0:45:53
[07/01 14:41:22] detectron2 INFO: Inference done 10101/26446. 0.1657 s / img. ETA=0:45:48
[07/01 14:41:27] detectron2 INFO: Inference done 10132/26446. 0.1657 s / img. ETA=0:45:43
[07/01 14:41:32] detectron2 INFO: Inference done 10162/26446. 0.1657 s / img. ETA=0:45:38
[07/01 14:41:37] detectron2 INFO: Inference done 10192/26446. 0.1657 s / img. ETA=0:45:33
[07/01 14:41:42] detectron2 INFO: Inference done 10222/26446. 0.1657 s / img. ETA=0:45:28
[07/01 14:41:47] detectron2 INFO: Inference done 10252/26446. 0.1657 s / img. ETA=0:45:23
[07/01 14:41:52] detectron2 INFO: Inference done 10282/26446. 0.1657 s / img. ETA=0:45:18
[07/01 14:41:57] detectron2 INFO: Inference done 10313/26446. 0.1657 s / img. ETA=0:45:13
[07/01 14:42:02] detectron2 INFO: Inference done 10343/26446. 0.1657 s / img. ETA=0:45:08
[07/01 14:47:31] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 14:47:32] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 14:47:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 14:47:32] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 1
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 14:47:32] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 14:47:32] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 14:47:32] d2.utils.env INFO: Using a generated random seed 32634784
[07/01 14:47:36] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 14:47:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 14:47:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 14:47:38] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 14:47:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 14:47:38] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 14:47:40] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 14:47:40] detectron2 INFO: Following metrics will be use for evaluation
[07/01 14:47:40] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 14:47:40] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 14:47:40] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 14:47:40] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 14:47:40] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 14:47:42] detectron2 INFO: Loading zero shot triplets
[07/01 14:47:42] detectron2 INFO: Start inference on 26446 images
[07/01 14:48:20] detectron2 INFO: Inference done 1/26446. 6.1780 s / img. ETA=11 days, 17:22:25
[07/01 14:48:25] detectron2 INFO: Inference done 31/26446. 0.1683 s / img. ETA=1:15:01
[07/01 14:48:31] detectron2 INFO: Inference done 61/26446. 0.1691 s / img. ETA=1:15:20
[07/01 14:48:36] detectron2 INFO: Inference done 91/26446. 0.1688 s / img. ETA=1:15:07
[07/01 14:48:41] detectron2 INFO: Inference done 121/26446. 0.1678 s / img. ETA=1:14:36
[07/01 14:48:46] detectron2 INFO: Inference done 152/26446. 0.1670 s / img. ETA=1:14:09
[07/01 14:48:51] detectron2 INFO: Inference done 182/26446. 0.1666 s / img. ETA=1:13:55
[07/01 14:48:56] detectron2 INFO: Inference done 212/26446. 0.1665 s / img. ETA=1:13:46
[07/01 14:49:01] detectron2 INFO: Inference done 243/26446. 0.1658 s / img. ETA=1:13:23
[07/01 14:49:06] detectron2 INFO: Inference done 274/26446. 0.1655 s / img. ETA=1:13:10
[07/01 14:49:11] detectron2 INFO: Inference done 305/26446. 0.1654 s / img. ETA=1:13:02
[07/01 14:49:16] detectron2 INFO: Inference done 335/26446. 0.1655 s / img. ETA=1:12:59
[07/01 14:49:21] detectron2 INFO: Inference done 365/26446. 0.1655 s / img. ETA=1:12:54
[07/01 14:49:26] detectron2 INFO: Inference done 396/26446. 0.1653 s / img. ETA=1:12:42
[07/01 14:49:32] detectron2 INFO: Inference done 427/26446. 0.1651 s / img. ETA=1:12:34
[07/01 14:49:37] detectron2 INFO: Inference done 458/26446. 0.1650 s / img. ETA=1:12:26
[07/01 14:49:42] detectron2 INFO: Inference done 488/26446. 0.1650 s / img. ETA=1:12:21
[07/01 14:49:47] detectron2 INFO: Inference done 518/26446. 0.1651 s / img. ETA=1:12:18
[07/01 14:49:52] detectron2 INFO: Inference done 548/26446. 0.1651 s / img. ETA=1:12:13
[07/01 14:49:57] detectron2 INFO: Inference done 579/26446. 0.1650 s / img. ETA=1:12:05
[07/01 14:50:02] detectron2 INFO: Inference done 609/26446. 0.1651 s / img. ETA=1:12:02
[07/01 14:50:07] detectron2 INFO: Inference done 640/26446. 0.1649 s / img. ETA=1:11:53
[07/01 14:50:12] detectron2 INFO: Inference done 670/26446. 0.1650 s / img. ETA=1:11:50
[07/01 14:50:17] detectron2 INFO: Inference done 700/26446. 0.1650 s / img. ETA=1:11:45
[07/01 14:50:22] detectron2 INFO: Inference done 730/26446. 0.1651 s / img. ETA=1:11:42
[07/01 14:50:27] detectron2 INFO: Inference done 761/26446. 0.1650 s / img. ETA=1:11:34
[07/01 14:50:32] detectron2 INFO: Inference done 791/26446. 0.1650 s / img. ETA=1:11:31
[07/01 14:50:37] detectron2 INFO: Inference done 822/26446. 0.1649 s / img. ETA=1:11:22
[07/01 14:50:43] detectron2 INFO: Inference done 853/26446. 0.1649 s / img. ETA=1:11:16
[07/01 14:50:48] detectron2 INFO: Inference done 884/26446. 0.1648 s / img. ETA=1:11:08
[07/01 14:50:53] detectron2 INFO: Inference done 914/26446. 0.1648 s / img. ETA=1:11:04
[07/01 14:50:58] detectron2 INFO: Inference done 945/26446. 0.1647 s / img. ETA=1:10:56
[07/01 14:51:03] detectron2 INFO: Inference done 976/26446. 0.1646 s / img. ETA=1:10:49
[07/01 14:51:08] detectron2 INFO: Inference done 1007/26446. 0.1646 s / img. ETA=1:10:43
[07/01 14:51:13] detectron2 INFO: Inference done 1038/26446. 0.1646 s / img. ETA=1:10:37
[07/01 14:51:18] detectron2 INFO: Inference done 1069/26446. 0.1645 s / img. ETA=1:10:31
[07/01 14:51:23] detectron2 INFO: Inference done 1099/26446. 0.1645 s / img. ETA=1:10:26
[07/01 14:51:28] detectron2 INFO: Inference done 1128/26446. 0.1647 s / img. ETA=1:10:27
[07/01 14:51:34] detectron2 INFO: Inference done 1155/26446. 0.1652 s / img. ETA=1:10:35
[07/01 14:51:39] detectron2 INFO: Inference done 1182/26446. 0.1657 s / img. ETA=1:10:42
[07/01 14:51:44] detectron2 INFO: Inference done 1211/26446. 0.1658 s / img. ETA=1:10:40
[07/01 14:51:49] detectron2 INFO: Inference done 1242/26446. 0.1658 s / img. ETA=1:10:34
[07/01 14:51:54] detectron2 INFO: Inference done 1272/26446. 0.1658 s / img. ETA=1:10:29
[07/01 14:51:59] detectron2 INFO: Inference done 1302/26446. 0.1658 s / img. ETA=1:10:24
[07/01 14:52:04] detectron2 INFO: Inference done 1332/26446. 0.1658 s / img. ETA=1:10:18
[07/01 14:52:09] detectron2 INFO: Inference done 1363/26446. 0.1657 s / img. ETA=1:10:12
[07/01 14:52:14] detectron2 INFO: Inference done 1393/26446. 0.1657 s / img. ETA=1:10:06
[07/01 14:52:19] detectron2 INFO: Inference done 1423/26446. 0.1657 s / img. ETA=1:10:02
[07/01 14:52:24] detectron2 INFO: Inference done 1450/26446. 0.1661 s / img. ETA=1:10:07
[07/01 14:52:29] detectron2 INFO: Inference done 1480/26446. 0.1661 s / img. ETA=1:10:03
[07/01 14:52:34] detectron2 INFO: Inference done 1510/26446. 0.1662 s / img. ETA=1:10:00
[07/01 14:52:39] detectron2 INFO: Inference done 1539/26446. 0.1663 s / img. ETA=1:09:58
[07/01 14:52:45] detectron2 INFO: Inference done 1568/26446. 0.1664 s / img. ETA=1:09:55
[07/01 14:52:50] detectron2 INFO: Inference done 1598/26446. 0.1665 s / img. ETA=1:09:52
[07/01 14:52:55] detectron2 INFO: Inference done 1627/26446. 0.1666 s / img. ETA=1:09:51
[07/01 14:53:00] detectron2 INFO: Inference done 1656/26446. 0.1667 s / img. ETA=1:09:49
[07/01 14:53:05] detectron2 INFO: Inference done 1686/26446. 0.1668 s / img. ETA=1:09:45
[07/01 14:53:10] detectron2 INFO: Inference done 1716/26446. 0.1668 s / img. ETA=1:09:40
[07/01 14:53:15] detectron2 INFO: Inference done 1744/26446. 0.1670 s / img. ETA=1:09:40
[07/01 14:53:20] detectron2 INFO: Inference done 1770/26446. 0.1674 s / img. ETA=1:09:46
[07/01 14:53:25] detectron2 INFO: Inference done 1797/26446. 0.1676 s / img. ETA=1:09:48
[07/01 14:53:30] detectron2 INFO: Inference done 1826/26446. 0.1677 s / img. ETA=1:09:45
[07/01 14:53:36] detectron2 INFO: Inference done 1855/26446. 0.1678 s / img. ETA=1:09:42
[07/01 14:53:41] detectron2 INFO: Inference done 1885/26446. 0.1678 s / img. ETA=1:09:37
[07/01 14:53:46] detectron2 INFO: Inference done 1915/26446. 0.1678 s / img. ETA=1:09:32
[07/01 14:53:51] detectron2 INFO: Inference done 1945/26446. 0.1678 s / img. ETA=1:09:27
[07/01 14:53:56] detectron2 INFO: Inference done 1976/26446. 0.1678 s / img. ETA=1:09:21
[07/01 14:54:01] detectron2 INFO: Inference done 2005/26446. 0.1679 s / img. ETA=1:09:17
[07/01 14:54:06] detectron2 INFO: Inference done 2018/26446. 0.1679 s / img. ETA=1:09:50
[07/01 14:54:11] detectron2 INFO: Inference done 2047/26446. 0.1680 s / img. ETA=1:09:46
[07/01 14:54:16] detectron2 INFO: Inference done 2076/26446. 0.1680 s / img. ETA=1:09:42
[07/01 14:54:21] detectron2 INFO: Inference done 2105/26446. 0.1681 s / img. ETA=1:09:37
[07/01 14:54:26] detectron2 INFO: Inference done 2134/26446. 0.1682 s / img. ETA=1:09:33
[07/01 14:54:32] detectron2 INFO: Inference done 2164/26446. 0.1682 s / img. ETA=1:09:28
[07/01 14:54:37] detectron2 INFO: Inference done 2194/26446. 0.1682 s / img. ETA=1:09:23
[07/01 14:54:42] detectron2 INFO: Inference done 2224/26446. 0.1681 s / img. ETA=1:09:16
[07/01 14:54:47] detectron2 INFO: Inference done 2254/26446. 0.1681 s / img. ETA=1:09:11
[07/01 14:54:52] detectron2 INFO: Inference done 2283/26446. 0.1682 s / img. ETA=1:09:07
[07/01 14:54:57] detectron2 INFO: Inference done 2312/26446. 0.1683 s / img. ETA=1:09:04
[07/01 14:55:02] detectron2 INFO: Inference done 2339/26446. 0.1685 s / img. ETA=1:09:05
[07/01 14:55:07] detectron2 INFO: Inference done 2368/26446. 0.1686 s / img. ETA=1:09:01
[07/01 14:55:12] detectron2 INFO: Inference done 2398/26446. 0.1686 s / img. ETA=1:08:55
[07/01 14:55:18] detectron2 INFO: Inference done 2427/26446. 0.1686 s / img. ETA=1:08:51
[07/01 14:55:23] detectron2 INFO: Inference done 2457/26446. 0.1686 s / img. ETA=1:08:46
[07/01 14:55:28] detectron2 INFO: Inference done 2486/26446. 0.1687 s / img. ETA=1:08:41
[07/01 14:55:33] detectron2 INFO: Inference done 2516/26446. 0.1687 s / img. ETA=1:08:36
[07/01 14:55:38] detectron2 INFO: Inference done 2546/26446. 0.1687 s / img. ETA=1:08:31
[07/01 14:55:43] detectron2 INFO: Inference done 2575/26446. 0.1688 s / img. ETA=1:08:27
[07/01 14:55:48] detectron2 INFO: Inference done 2604/26446. 0.1688 s / img. ETA=1:08:23
[07/01 14:55:53] detectron2 INFO: Inference done 2633/26446. 0.1688 s / img. ETA=1:08:18
[07/01 14:55:58] detectron2 INFO: Inference done 2663/26446. 0.1688 s / img. ETA=1:08:13
[07/01 14:56:04] detectron2 INFO: Inference done 2693/26446. 0.1688 s / img. ETA=1:08:08
[07/01 14:56:09] detectron2 INFO: Inference done 2722/26446. 0.1688 s / img. ETA=1:08:03
[07/01 14:56:14] detectron2 INFO: Inference done 2751/26446. 0.1689 s / img. ETA=1:07:59
[07/01 14:56:19] detectron2 INFO: Inference done 2780/26446. 0.1689 s / img. ETA=1:07:54
[07/01 14:56:24] detectron2 INFO: Inference done 2809/26446. 0.1689 s / img. ETA=1:07:50
[07/01 14:56:29] detectron2 INFO: Inference done 2838/26446. 0.1690 s / img. ETA=1:07:45
[07/01 14:56:34] detectron2 INFO: Inference done 2868/26446. 0.1690 s / img. ETA=1:07:39
[07/01 14:56:39] detectron2 INFO: Inference done 2897/26446. 0.1690 s / img. ETA=1:07:35
[07/01 14:56:44] detectron2 INFO: Inference done 2927/26446. 0.1690 s / img. ETA=1:07:30
[07/01 14:56:49] detectron2 INFO: Inference done 2956/26446. 0.1690 s / img. ETA=1:07:25
[07/01 14:56:54] detectron2 INFO: Inference done 2985/26446. 0.1690 s / img. ETA=1:07:20
[07/01 14:56:59] detectron2 INFO: Inference done 3015/26446. 0.1690 s / img. ETA=1:07:15
[07/01 14:57:04] detectron2 INFO: Inference done 3044/26446. 0.1690 s / img. ETA=1:07:10
[07/01 14:57:09] detectron2 INFO: Inference done 3072/26446. 0.1692 s / img. ETA=1:07:07
[07/01 14:57:14] detectron2 INFO: Inference done 3101/26446. 0.1692 s / img. ETA=1:07:02
[07/01 14:57:19] detectron2 INFO: Inference done 3130/26446. 0.1692 s / img. ETA=1:06:58
[07/01 14:57:25] detectron2 INFO: Inference done 3159/26446. 0.1692 s / img. ETA=1:06:53
[07/01 14:57:30] detectron2 INFO: Inference done 3188/26446. 0.1693 s / img. ETA=1:06:49
[07/01 14:57:35] detectron2 INFO: Inference done 3217/26446. 0.1693 s / img. ETA=1:06:44
[07/01 14:57:40] detectron2 INFO: Inference done 3246/26446. 0.1693 s / img. ETA=1:06:39
[07/01 14:57:45] detectron2 INFO: Inference done 3275/26446. 0.1693 s / img. ETA=1:06:35
[07/01 14:57:50] detectron2 INFO: Inference done 3305/26446. 0.1693 s / img. ETA=1:06:29
[07/01 14:57:55] detectron2 INFO: Inference done 3335/26446. 0.1693 s / img. ETA=1:06:24
[07/01 14:58:00] detectron2 INFO: Inference done 3365/26446. 0.1693 s / img. ETA=1:06:18
[07/01 14:58:05] detectron2 INFO: Inference done 3394/26446. 0.1693 s / img. ETA=1:06:14
[07/01 14:58:10] detectron2 INFO: Inference done 3424/26446. 0.1693 s / img. ETA=1:06:08
[07/01 14:58:15] detectron2 INFO: Inference done 3454/26446. 0.1693 s / img. ETA=1:06:03
[07/01 14:58:21] detectron2 INFO: Inference done 3483/26446. 0.1693 s / img. ETA=1:05:58
[07/01 14:58:26] detectron2 INFO: Inference done 3512/26446. 0.1694 s / img. ETA=1:05:54
[07/01 14:58:31] detectron2 INFO: Inference done 3541/26446. 0.1694 s / img. ETA=1:05:50
[07/01 14:58:36] detectron2 INFO: Inference done 3570/26446. 0.1694 s / img. ETA=1:05:45
[07/01 14:58:41] detectron2 INFO: Inference done 3600/26446. 0.1694 s / img. ETA=1:05:40
[07/01 14:58:46] detectron2 INFO: Inference done 3629/26446. 0.1694 s / img. ETA=1:05:35
[07/01 14:58:51] detectron2 INFO: Inference done 3658/26446. 0.1695 s / img. ETA=1:05:30
[07/01 14:58:56] detectron2 INFO: Inference done 3687/26446. 0.1695 s / img. ETA=1:05:26
[07/01 14:59:01] detectron2 INFO: Inference done 3717/26446. 0.1695 s / img. ETA=1:05:20
[07/01 14:59:06] detectron2 INFO: Inference done 3746/26446. 0.1695 s / img. ETA=1:05:16
[07/01 14:59:11] detectron2 INFO: Inference done 3775/26446. 0.1695 s / img. ETA=1:05:11
[07/01 14:59:16] detectron2 INFO: Inference done 3805/26446. 0.1695 s / img. ETA=1:05:05
[07/01 14:59:21] detectron2 INFO: Inference done 3834/26446. 0.1695 s / img. ETA=1:05:00
[07/01 14:59:26] detectron2 INFO: Inference done 3863/26446. 0.1695 s / img. ETA=1:04:55
[07/01 14:59:32] detectron2 INFO: Inference done 3892/26446. 0.1695 s / img. ETA=1:04:51
[07/01 14:59:37] detectron2 INFO: Inference done 3921/26446. 0.1696 s / img. ETA=1:04:46
[07/01 14:59:42] detectron2 INFO: Inference done 3950/26446. 0.1696 s / img. ETA=1:04:41
[07/01 14:59:47] detectron2 INFO: Inference done 3980/26446. 0.1696 s / img. ETA=1:04:36
[07/01 14:59:52] detectron2 INFO: Inference done 4010/26446. 0.1696 s / img. ETA=1:04:30
[07/01 14:59:57] detectron2 INFO: Inference done 4040/26446. 0.1696 s / img. ETA=1:04:25
[07/01 15:00:02] detectron2 INFO: Inference done 4069/26446. 0.1696 s / img. ETA=1:04:21
[07/01 15:00:07] detectron2 INFO: Inference done 4099/26446. 0.1696 s / img. ETA=1:04:16
[07/01 15:00:12] detectron2 INFO: Inference done 4128/26446. 0.1696 s / img. ETA=1:04:10
[07/01 15:00:17] detectron2 INFO: Inference done 4158/26446. 0.1696 s / img. ETA=1:04:05
[07/01 15:00:23] detectron2 INFO: Inference done 4187/26446. 0.1696 s / img. ETA=1:04:01
[07/01 15:00:28] detectron2 INFO: Inference done 4216/26446. 0.1696 s / img. ETA=1:03:56
[07/01 15:00:33] detectron2 INFO: Inference done 4245/26446. 0.1696 s / img. ETA=1:03:51
[07/01 15:00:38] detectron2 INFO: Inference done 4274/26446. 0.1696 s / img. ETA=1:03:46
[07/01 15:00:43] detectron2 INFO: Inference done 4303/26446. 0.1697 s / img. ETA=1:03:41
[07/01 15:00:48] detectron2 INFO: Inference done 4333/26446. 0.1697 s / img. ETA=1:03:36
[07/01 15:00:53] detectron2 INFO: Inference done 4362/26446. 0.1697 s / img. ETA=1:03:31
[07/01 15:00:58] detectron2 INFO: Inference done 4392/26446. 0.1697 s / img. ETA=1:03:26
[07/01 15:01:03] detectron2 INFO: Inference done 4421/26446. 0.1697 s / img. ETA=1:03:21
[07/01 15:01:08] detectron2 INFO: Inference done 4450/26446. 0.1697 s / img. ETA=1:03:16
[07/01 15:01:13] detectron2 INFO: Inference done 4479/26446. 0.1697 s / img. ETA=1:03:12
[07/01 15:01:18] detectron2 INFO: Inference done 4508/26446. 0.1697 s / img. ETA=1:03:07
[07/01 15:01:23] detectron2 INFO: Inference done 4537/26446. 0.1698 s / img. ETA=1:03:02
[07/01 15:01:28] detectron2 INFO: Inference done 4565/26446. 0.1698 s / img. ETA=1:02:59
[07/01 15:01:34] detectron2 INFO: Inference done 4595/26446. 0.1698 s / img. ETA=1:02:53
[07/01 15:01:39] detectron2 INFO: Inference done 4625/26446. 0.1698 s / img. ETA=1:02:48
[07/01 15:01:44] detectron2 INFO: Inference done 4654/26446. 0.1698 s / img. ETA=1:02:43
[07/01 15:01:49] detectron2 INFO: Inference done 4684/26446. 0.1698 s / img. ETA=1:02:38
[07/01 15:01:54] detectron2 INFO: Inference done 4713/26446. 0.1698 s / img. ETA=1:02:33
[07/01 15:01:59] detectron2 INFO: Inference done 4742/26446. 0.1699 s / img. ETA=1:02:29
[07/01 15:02:04] detectron2 INFO: Inference done 4771/26446. 0.1699 s / img. ETA=1:02:24
[07/01 15:02:09] detectron2 INFO: Inference done 4800/26446. 0.1699 s / img. ETA=1:02:20
[07/01 15:02:15] detectron2 INFO: Inference done 4829/26446. 0.1699 s / img. ETA=1:02:15
[07/01 15:02:20] detectron2 INFO: Inference done 4858/26446. 0.1700 s / img. ETA=1:02:10
[07/01 15:02:25] detectron2 INFO: Inference done 4887/26446. 0.1700 s / img. ETA=1:02:05
[07/01 15:02:30] detectron2 INFO: Inference done 4916/26446. 0.1700 s / img. ETA=1:02:01
[07/01 15:02:35] detectron2 INFO: Inference done 4945/26446. 0.1700 s / img. ETA=1:01:55
[07/01 15:02:40] detectron2 INFO: Inference done 4975/26446. 0.1700 s / img. ETA=1:01:50
[07/01 15:02:45] detectron2 INFO: Inference done 5005/26446. 0.1700 s / img. ETA=1:01:45
[07/01 15:02:50] detectron2 INFO: Inference done 5034/26446. 0.1700 s / img. ETA=1:01:40
[07/01 15:02:55] detectron2 INFO: Inference done 5063/26446. 0.1700 s / img. ETA=1:01:35
[07/01 15:03:00] detectron2 INFO: Inference done 5093/26446. 0.1700 s / img. ETA=1:01:30
[07/01 15:03:05] detectron2 INFO: Inference done 5122/26446. 0.1700 s / img. ETA=1:01:25
[07/01 15:03:10] detectron2 INFO: Inference done 5151/26446. 0.1700 s / img. ETA=1:01:20
[07/01 15:03:15] detectron2 INFO: Inference done 5180/26446. 0.1700 s / img. ETA=1:01:15
[07/01 15:03:20] detectron2 INFO: Inference done 5209/26446. 0.1700 s / img. ETA=1:01:10
[07/01 15:03:25] detectron2 INFO: Inference done 5238/26446. 0.1700 s / img. ETA=1:01:05
[07/01 15:03:30] detectron2 INFO: Inference done 5267/26446. 0.1700 s / img. ETA=1:01:00
[07/01 15:03:35] detectron2 INFO: Inference done 5296/26446. 0.1700 s / img. ETA=1:00:55
[07/01 15:03:40] detectron2 INFO: Inference done 5325/26446. 0.1700 s / img. ETA=1:00:50
[07/01 15:03:46] detectron2 INFO: Inference done 5354/26446. 0.1700 s / img. ETA=1:00:45
[07/01 15:03:51] detectron2 INFO: Inference done 5383/26446. 0.1700 s / img. ETA=1:00:41
[07/01 15:03:56] detectron2 INFO: Inference done 5412/26446. 0.1701 s / img. ETA=1:00:36
[07/01 15:04:01] detectron2 INFO: Inference done 5441/26446. 0.1701 s / img. ETA=1:00:31
[07/01 15:04:06] detectron2 INFO: Inference done 5470/26446. 0.1701 s / img. ETA=1:00:26
[07/01 15:04:11] detectron2 INFO: Inference done 5499/26446. 0.1701 s / img. ETA=1:00:21
[07/01 15:04:16] detectron2 INFO: Inference done 5528/26446. 0.1701 s / img. ETA=1:00:16
[07/01 15:04:21] detectron2 INFO: Inference done 5557/26446. 0.1701 s / img. ETA=1:00:12
[07/01 15:04:26] detectron2 INFO: Inference done 5586/26446. 0.1701 s / img. ETA=1:00:07
[07/01 15:04:31] detectron2 INFO: Inference done 5616/26446. 0.1701 s / img. ETA=1:00:02
[07/01 15:04:36] detectron2 INFO: Inference done 5646/26446. 0.1701 s / img. ETA=0:59:56
[07/01 15:04:42] detectron2 INFO: Inference done 5675/26446. 0.1702 s / img. ETA=0:59:52
[07/01 15:04:47] detectron2 INFO: Inference done 5705/26446. 0.1701 s / img. ETA=0:59:46
[07/01 15:04:52] detectron2 INFO: Inference done 5734/26446. 0.1702 s / img. ETA=0:59:42
[07/01 15:04:57] detectron2 INFO: Inference done 5764/26446. 0.1702 s / img. ETA=0:59:36
[07/01 15:05:02] detectron2 INFO: Inference done 5793/26446. 0.1702 s / img. ETA=0:59:31
[07/01 15:05:07] detectron2 INFO: Inference done 5822/26446. 0.1702 s / img. ETA=0:59:26
[07/01 15:05:12] detectron2 INFO: Inference done 5851/26446. 0.1702 s / img. ETA=0:59:21
[07/01 15:05:17] detectron2 INFO: Inference done 5881/26446. 0.1702 s / img. ETA=0:59:16
[07/01 15:05:22] detectron2 INFO: Inference done 5910/26446. 0.1702 s / img. ETA=0:59:11
[07/01 15:05:27] detectron2 INFO: Inference done 5939/26446. 0.1702 s / img. ETA=0:59:06
[07/01 15:05:32] detectron2 INFO: Inference done 5968/26446. 0.1702 s / img. ETA=0:59:01
[07/01 15:05:37] detectron2 INFO: Inference done 5998/26446. 0.1702 s / img. ETA=0:58:56
[07/01 15:05:42] detectron2 INFO: Inference done 6027/26446. 0.1702 s / img. ETA=0:58:51
[07/01 15:05:48] detectron2 INFO: Inference done 6056/26446. 0.1702 s / img. ETA=0:58:46
[07/01 15:05:53] detectron2 INFO: Inference done 6083/26446. 0.1703 s / img. ETA=0:58:43
[07/01 15:05:58] detectron2 INFO: Inference done 6111/26446. 0.1703 s / img. ETA=0:58:39
[07/01 15:06:03] detectron2 INFO: Inference done 6141/26446. 0.1703 s / img. ETA=0:58:33
[07/01 15:06:08] detectron2 INFO: Inference done 6170/26446. 0.1703 s / img. ETA=0:58:28
[07/01 15:06:13] detectron2 INFO: Inference done 6199/26446. 0.1703 s / img. ETA=0:58:23
[07/01 15:06:18] detectron2 INFO: Inference done 6228/26446. 0.1703 s / img. ETA=0:58:18
[07/01 15:06:23] detectron2 INFO: Inference done 6258/26446. 0.1703 s / img. ETA=0:58:13
[07/01 15:06:28] detectron2 INFO: Inference done 6288/26446. 0.1703 s / img. ETA=0:58:08
[07/01 15:06:33] detectron2 INFO: Inference done 6318/26446. 0.1703 s / img. ETA=0:58:02
[07/01 15:06:38] detectron2 INFO: Inference done 6348/26446. 0.1703 s / img. ETA=0:57:57
[07/01 15:06:43] detectron2 INFO: Inference done 6377/26446. 0.1703 s / img. ETA=0:57:52
[07/01 15:06:49] detectron2 INFO: Inference done 6406/26446. 0.1703 s / img. ETA=0:57:47
[07/01 15:06:54] detectron2 INFO: Inference done 6435/26446. 0.1703 s / img. ETA=0:57:42
[07/01 15:06:59] detectron2 INFO: Inference done 6465/26446. 0.1703 s / img. ETA=0:57:37
[07/01 15:07:04] detectron2 INFO: Inference done 6494/26446. 0.1703 s / img. ETA=0:57:32
[07/01 15:07:09] detectron2 INFO: Inference done 6523/26446. 0.1703 s / img. ETA=0:57:27
[07/01 15:07:14] detectron2 INFO: Inference done 6552/26446. 0.1703 s / img. ETA=0:57:22
[07/01 15:07:19] detectron2 INFO: Inference done 6581/26446. 0.1703 s / img. ETA=0:57:17
[07/01 15:07:24] detectron2 INFO: Inference done 6610/26446. 0.1703 s / img. ETA=0:57:12
[07/01 15:07:29] detectron2 INFO: Inference done 6639/26446. 0.1703 s / img. ETA=0:57:07
[07/01 15:07:34] detectron2 INFO: Inference done 6668/26446. 0.1703 s / img. ETA=0:57:02
[07/01 15:07:39] detectron2 INFO: Inference done 6697/26446. 0.1703 s / img. ETA=0:56:57
[07/01 15:07:44] detectron2 INFO: Inference done 6726/26446. 0.1703 s / img. ETA=0:56:52
[07/01 15:07:49] detectron2 INFO: Inference done 6755/26446. 0.1703 s / img. ETA=0:56:47
[07/01 15:07:54] detectron2 INFO: Inference done 6784/26446. 0.1703 s / img. ETA=0:56:42
[07/01 15:07:59] detectron2 INFO: Inference done 6814/26446. 0.1703 s / img. ETA=0:56:37
[07/01 15:08:04] detectron2 INFO: Inference done 6843/26446. 0.1704 s / img. ETA=0:56:32
[07/01 15:08:09] detectron2 INFO: Inference done 6872/26446. 0.1704 s / img. ETA=0:56:27
[07/01 15:08:15] detectron2 INFO: Inference done 6902/26446. 0.1703 s / img. ETA=0:56:22
[07/01 15:08:20] detectron2 INFO: Inference done 6932/26446. 0.1703 s / img. ETA=0:56:17
[07/01 15:08:25] detectron2 INFO: Inference done 6961/26446. 0.1704 s / img. ETA=0:56:12
[07/01 15:08:30] detectron2 INFO: Inference done 6990/26446. 0.1704 s / img. ETA=0:56:07
[07/01 15:08:35] detectron2 INFO: Inference done 7020/26446. 0.1704 s / img. ETA=0:56:02
[07/01 15:08:40] detectron2 INFO: Inference done 7049/26446. 0.1704 s / img. ETA=0:55:57
[07/01 15:08:45] detectron2 INFO: Inference done 7078/26446. 0.1704 s / img. ETA=0:55:52
[07/01 15:08:50] detectron2 INFO: Inference done 7107/26446. 0.1704 s / img. ETA=0:55:47
[07/01 15:08:55] detectron2 INFO: Inference done 7137/26446. 0.1704 s / img. ETA=0:55:42
[07/01 15:09:01] detectron2 INFO: Inference done 7167/26446. 0.1704 s / img. ETA=0:55:36
[07/01 15:09:06] detectron2 INFO: Inference done 7197/26446. 0.1704 s / img. ETA=0:55:31
[07/01 15:09:11] detectron2 INFO: Inference done 7226/26446. 0.1704 s / img. ETA=0:55:26
[07/01 15:09:16] detectron2 INFO: Inference done 7255/26446. 0.1704 s / img. ETA=0:55:21
[07/01 15:09:21] detectron2 INFO: Inference done 7284/26446. 0.1704 s / img. ETA=0:55:16
[07/01 15:09:26] detectron2 INFO: Inference done 7313/26446. 0.1704 s / img. ETA=0:55:11
[07/01 15:09:31] detectron2 INFO: Inference done 7342/26446. 0.1704 s / img. ETA=0:55:06
[07/01 15:09:36] detectron2 INFO: Inference done 7371/26446. 0.1704 s / img. ETA=0:55:01
[07/01 15:09:41] detectron2 INFO: Inference done 7400/26446. 0.1704 s / img. ETA=0:54:56
[07/01 15:09:46] detectron2 INFO: Inference done 7429/26446. 0.1704 s / img. ETA=0:54:51
[07/01 15:09:51] detectron2 INFO: Inference done 7458/26446. 0.1704 s / img. ETA=0:54:47
[07/01 15:09:56] detectron2 INFO: Inference done 7487/26446. 0.1704 s / img. ETA=0:54:42
[07/01 15:10:01] detectron2 INFO: Inference done 7516/26446. 0.1704 s / img. ETA=0:54:37
[07/01 15:10:06] detectron2 INFO: Inference done 7545/26446. 0.1704 s / img. ETA=0:54:32
[07/01 15:10:11] detectron2 INFO: Inference done 7574/26446. 0.1704 s / img. ETA=0:54:27
[07/01 15:10:16] detectron2 INFO: Inference done 7603/26446. 0.1705 s / img. ETA=0:54:22
[07/01 15:10:21] detectron2 INFO: Inference done 7631/26446. 0.1705 s / img. ETA=0:54:18
[07/01 15:10:27] detectron2 INFO: Inference done 7660/26446. 0.1705 s / img. ETA=0:54:13
[07/01 15:10:32] detectron2 INFO: Inference done 7689/26446. 0.1705 s / img. ETA=0:54:08
[07/01 15:10:37] detectron2 INFO: Inference done 7718/26446. 0.1705 s / img. ETA=0:54:03
[07/01 15:10:42] detectron2 INFO: Inference done 7747/26446. 0.1705 s / img. ETA=0:53:58
[07/01 15:10:47] detectron2 INFO: Inference done 7776/26446. 0.1705 s / img. ETA=0:53:53
[07/01 15:10:52] detectron2 INFO: Inference done 7805/26446. 0.1705 s / img. ETA=0:53:48
[07/01 15:10:57] detectron2 INFO: Inference done 7834/26446. 0.1705 s / img. ETA=0:53:43
[07/01 15:52:26] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 15:52:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 15:52:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 15:52:27] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 1
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 15:52:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 15:52:27] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 15:52:27] d2.utils.env INFO: Using a generated random seed 27976923
[07/01 15:52:31] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 15:52:31] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 15:52:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 15:52:33] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 15:52:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 15:52:33] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 15:52:35] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 15:52:35] detectron2 INFO: Following metrics will be use for evaluation
[07/01 15:52:35] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 15:52:35] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 15:52:35] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 15:52:35] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 15:52:35] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 15:52:37] detectron2 INFO: Loading zero shot triplets
[07/01 15:52:37] detectron2 INFO: Start inference on 26446 images
[07/01 15:53:46] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 15:53:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 15:53:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 15:53:47] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 1
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 15:53:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 15:53:47] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 15:53:47] d2.utils.env INFO: Using a generated random seed 47386574
[07/01 15:53:50] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 15:53:50] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 15:53:50] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 15:53:52] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 15:53:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 15:53:52] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 15:53:54] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 15:53:54] detectron2 INFO: Following metrics will be use for evaluation
[07/01 15:53:54] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 15:53:54] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 15:53:54] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 15:53:54] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 15:53:54] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 15:53:56] detectron2 INFO: Loading zero shot triplets
[07/01 15:53:56] detectron2 INFO: Start inference on 26446 images
[07/01 15:54:12] detectron2 INFO: Inference done 1/26446. 6.0934 s / img. ETA=4 days, 20:30:24
[07/01 15:54:17] detectron2 INFO: Inference done 31/26446. 0.1677 s / img. ETA=1:14:45
[07/01 15:54:22] detectron2 INFO: Inference done 61/26446. 0.1680 s / img. ETA=1:14:48
[07/01 15:54:27] detectron2 INFO: Inference done 91/26446. 0.1676 s / img. ETA=1:14:33
[07/01 15:54:32] detectron2 INFO: Inference done 122/26446. 0.1660 s / img. ETA=1:13:45
[07/01 15:54:37] detectron2 INFO: Inference done 153/26446. 0.1650 s / img. ETA=1:13:14
[07/01 15:54:42] detectron2 INFO: Inference done 183/26446. 0.1650 s / img. ETA=1:13:09
[07/01 15:54:47] detectron2 INFO: Inference done 213/26446. 0.1655 s / img. ETA=1:13:18
[07/01 15:54:52] detectron2 INFO: Inference done 243/26446. 0.1656 s / img. ETA=1:13:14
[07/01 15:54:57] detectron2 INFO: Inference done 273/26446. 0.1656 s / img. ETA=1:13:11
[07/01 15:55:02] detectron2 INFO: Inference done 303/26446. 0.1656 s / img. ETA=1:13:06
[07/01 15:55:07] detectron2 INFO: Inference done 333/26446. 0.1658 s / img. ETA=1:13:06
[07/01 15:55:13] detectron2 INFO: Inference done 363/26446. 0.1659 s / img. ETA=1:13:02
[07/01 15:55:18] detectron2 INFO: Inference done 393/26446. 0.1661 s / img. ETA=1:13:02
[07/01 15:55:23] detectron2 INFO: Inference done 424/26446. 0.1659 s / img. ETA=1:12:54
[07/01 15:55:28] detectron2 INFO: Inference done 454/26446. 0.1660 s / img. ETA=1:12:50
[07/01 15:55:33] detectron2 INFO: Inference done 485/26446. 0.1658 s / img. ETA=1:12:41
[07/01 15:55:38] detectron2 INFO: Inference done 516/26446. 0.1658 s / img. ETA=1:12:34
[07/01 15:55:43] detectron2 INFO: Inference done 547/26446. 0.1657 s / img. ETA=1:12:26
[07/01 15:55:48] detectron2 INFO: Inference done 578/26446. 0.1655 s / img. ETA=1:12:17
[07/01 15:55:54] detectron2 INFO: Inference done 608/26446. 0.1657 s / img. ETA=1:12:16
[07/01 15:55:59] detectron2 INFO: Inference done 638/26446. 0.1657 s / img. ETA=1:12:10
[07/01 15:56:04] detectron2 INFO: Inference done 668/26446. 0.1656 s / img. ETA=1:12:04
[07/01 15:56:09] detectron2 INFO: Inference done 698/26446. 0.1656 s / img. ETA=1:12:00
[07/01 15:56:14] detectron2 INFO: Inference done 728/26446. 0.1656 s / img. ETA=1:11:55
[07/01 15:56:19] detectron2 INFO: Inference done 758/26446. 0.1656 s / img. ETA=1:11:49
[07/01 15:56:24] detectron2 INFO: Inference done 789/26446. 0.1655 s / img. ETA=1:11:42
[07/01 15:56:29] detectron2 INFO: Inference done 819/26446. 0.1655 s / img. ETA=1:11:37
[07/01 15:56:34] detectron2 INFO: Inference done 849/26446. 0.1655 s / img. ETA=1:11:31
[07/01 15:56:39] detectron2 INFO: Inference done 879/26446. 0.1656 s / img. ETA=1:11:28
[07/01 15:56:44] detectron2 INFO: Inference done 909/26446. 0.1657 s / img. ETA=1:11:26
[07/01 15:56:49] detectron2 INFO: Inference done 938/26446. 0.1659 s / img. ETA=1:11:27
[07/01 15:56:54] detectron2 INFO: Inference done 968/26446. 0.1660 s / img. ETA=1:11:24
[07/01 15:56:59] detectron2 INFO: Inference done 996/26446. 0.1663 s / img. ETA=1:11:27
[07/01 15:57:04] detectron2 INFO: Inference done 1025/26446. 0.1665 s / img. ETA=1:11:28
[07/01 15:57:10] detectron2 INFO: Inference done 1054/26446. 0.1667 s / img. ETA=1:11:28
[07/01 15:57:15] detectron2 INFO: Inference done 1084/26446. 0.1667 s / img. ETA=1:11:23
[07/01 15:57:20] detectron2 INFO: Inference done 1114/26446. 0.1668 s / img. ETA=1:11:20
[07/01 15:57:25] detectron2 INFO: Inference done 1141/26446. 0.1672 s / img. ETA=1:11:26
[07/01 15:57:30] detectron2 INFO: Inference done 1169/26446. 0.1674 s / img. ETA=1:11:27
[07/01 15:57:35] detectron2 INFO: Inference done 1198/26446. 0.1676 s / img. ETA=1:11:25
[07/01 15:57:40] detectron2 INFO: Inference done 1225/26446. 0.1681 s / img. ETA=1:11:33
[07/01 15:57:45] detectron2 INFO: Inference done 1252/26446. 0.1684 s / img. ETA=1:11:37
[07/01 15:57:50] detectron2 INFO: Inference done 1282/26446. 0.1683 s / img. ETA=1:11:31
[07/01 15:57:55] detectron2 INFO: Inference done 1312/26446. 0.1683 s / img. ETA=1:11:26
[07/01 15:58:00] detectron2 INFO: Inference done 1337/26446. 0.1689 s / img. ETA=1:11:37
[07/01 15:58:05] detectron2 INFO: Inference done 1363/26446. 0.1694 s / img. ETA=1:11:44
[07/01 15:58:10] detectron2 INFO: Inference done 1391/26446. 0.1696 s / img. ETA=1:11:44
[07/01 15:58:15] detectron2 INFO: Inference done 1418/26446. 0.1698 s / img. ETA=1:11:45
[07/01 15:58:21] detectron2 INFO: Inference done 1449/26446. 0.1697 s / img. ETA=1:11:37
[07/01 15:58:26] detectron2 INFO: Inference done 1479/26446. 0.1696 s / img. ETA=1:11:30
[07/01 15:58:31] detectron2 INFO: Inference done 1508/26446. 0.1697 s / img. ETA=1:11:27
[07/01 15:58:36] detectron2 INFO: Inference done 1538/26446. 0.1696 s / img. ETA=1:11:20
[07/01 15:58:41] detectron2 INFO: Inference done 1568/26446. 0.1696 s / img. ETA=1:11:14
[07/01 15:58:46] detectron2 INFO: Inference done 1598/26446. 0.1695 s / img. ETA=1:11:07
[07/01 15:58:51] detectron2 INFO: Inference done 1628/26446. 0.1695 s / img. ETA=1:11:01
[07/01 15:58:56] detectron2 INFO: Inference done 1658/26446. 0.1694 s / img. ETA=1:10:54
[07/01 15:59:01] detectron2 INFO: Inference done 1688/26446. 0.1694 s / img. ETA=1:10:48
[07/01 15:59:06] detectron2 INFO: Inference done 1718/26446. 0.1693 s / img. ETA=1:10:41
[07/01 15:59:11] detectron2 INFO: Inference done 1748/26446. 0.1693 s / img. ETA=1:10:36
[07/01 15:59:16] detectron2 INFO: Inference done 1778/26446. 0.1692 s / img. ETA=1:10:29
[07/01 15:59:21] detectron2 INFO: Inference done 1808/26446. 0.1692 s / img. ETA=1:10:23
[07/01 15:59:27] detectron2 INFO: Inference done 1838/26446. 0.1692 s / img. ETA=1:10:17
[07/01 15:59:32] detectron2 INFO: Inference done 1868/26446. 0.1691 s / img. ETA=1:10:11
[07/01 15:59:37] detectron2 INFO: Inference done 1898/26446. 0.1691 s / img. ETA=1:10:05
[07/01 15:59:42] detectron2 INFO: Inference done 1928/26446. 0.1691 s / img. ETA=1:09:59
[07/01 15:59:47] detectron2 INFO: Inference done 1958/26446. 0.1690 s / img. ETA=1:09:53
[07/01 15:59:52] detectron2 INFO: Inference done 1989/26446. 0.1690 s / img. ETA=1:09:46
[07/01 15:59:58] detectron2 INFO: Inference done 2015/26446. 0.1699 s / img. ETA=1:10:05
[07/01 16:00:03] detectron2 INFO: Inference done 2045/26446. 0.1699 s / img. ETA=1:09:58
[07/01 16:00:09] detectron2 INFO: Inference done 2075/26446. 0.1699 s / img. ETA=1:09:53
[07/01 16:00:14] detectron2 INFO: Inference done 2105/26446. 0.1698 s / img. ETA=1:09:47
[07/01 16:00:19] detectron2 INFO: Inference done 2135/26446. 0.1698 s / img. ETA=1:09:41
[07/01 16:00:24] detectron2 INFO: Inference done 2165/26446. 0.1697 s / img. ETA=1:09:35
[07/01 16:00:29] detectron2 INFO: Inference done 2196/26446. 0.1697 s / img. ETA=1:09:27
[07/01 16:00:34] detectron2 INFO: Inference done 2227/26446. 0.1696 s / img. ETA=1:09:21
[07/01 16:00:39] detectron2 INFO: Inference done 2257/26446. 0.1696 s / img. ETA=1:09:15
[07/01 16:00:44] detectron2 INFO: Inference done 2287/26446. 0.1696 s / img. ETA=1:09:09
[07/01 16:00:49] detectron2 INFO: Inference done 2317/26446. 0.1695 s / img. ETA=1:09:03
[07/01 16:00:54] detectron2 INFO: Inference done 2347/26446. 0.1695 s / img. ETA=1:08:57
[07/01 16:01:00] detectron2 INFO: Inference done 2377/26446. 0.1694 s / img. ETA=1:08:51
[07/01 16:01:05] detectron2 INFO: Inference done 2407/26446. 0.1694 s / img. ETA=1:08:45
[07/01 16:01:10] detectron2 INFO: Inference done 2436/26446. 0.1694 s / img. ETA=1:08:41
[07/01 16:01:15] detectron2 INFO: Inference done 2466/26446. 0.1694 s / img. ETA=1:08:35
[07/01 16:01:20] detectron2 INFO: Inference done 2497/26446. 0.1694 s / img. ETA=1:08:28
[07/01 16:01:25] detectron2 INFO: Inference done 2527/26446. 0.1693 s / img. ETA=1:08:22
[07/01 16:01:30] detectron2 INFO: Inference done 2557/26446. 0.1693 s / img. ETA=1:08:16
[07/01 16:01:35] detectron2 INFO: Inference done 2587/26446. 0.1692 s / img. ETA=1:08:10
[07/01 16:01:40] detectron2 INFO: Inference done 2617/26446. 0.1692 s / img. ETA=1:08:04
[07/01 16:01:45] detectron2 INFO: Inference done 2647/26446. 0.1692 s / img. ETA=1:07:58
[07/01 16:01:50] detectron2 INFO: Inference done 2677/26446. 0.1691 s / img. ETA=1:07:52
[07/01 16:01:55] detectron2 INFO: Inference done 2707/26446. 0.1691 s / img. ETA=1:07:46
[07/01 16:02:00] detectron2 INFO: Inference done 2737/26446. 0.1691 s / img. ETA=1:07:41
[07/01 16:02:05] detectron2 INFO: Inference done 2767/26446. 0.1691 s / img. ETA=1:07:35
[07/01 16:02:10] detectron2 INFO: Inference done 2797/26446. 0.1690 s / img. ETA=1:07:29
[07/01 16:02:16] detectron2 INFO: Inference done 2827/26446. 0.1690 s / img. ETA=1:07:23
[07/01 16:02:21] detectron2 INFO: Inference done 2857/26446. 0.1690 s / img. ETA=1:07:17
[07/01 16:02:26] detectron2 INFO: Inference done 2886/26446. 0.1690 s / img. ETA=1:07:13
[07/01 16:02:31] detectron2 INFO: Inference done 2916/26446. 0.1689 s / img. ETA=1:07:07
[07/01 16:02:36] detectron2 INFO: Inference done 2944/26446. 0.1690 s / img. ETA=1:07:04
[07/01 16:02:41] detectron2 INFO: Inference done 2974/26446. 0.1690 s / img. ETA=1:06:58
[07/01 16:02:46] detectron2 INFO: Inference done 3004/26446. 0.1690 s / img. ETA=1:06:52
[07/01 16:02:51] detectron2 INFO: Inference done 3034/26446. 0.1689 s / img. ETA=1:06:46
[07/01 16:02:56] detectron2 INFO: Inference done 3063/26446. 0.1690 s / img. ETA=1:06:42
[07/01 16:03:01] detectron2 INFO: Inference done 3093/26446. 0.1689 s / img. ETA=1:06:36
[07/01 16:03:06] detectron2 INFO: Inference done 3123/26446. 0.1689 s / img. ETA=1:06:31
[07/01 16:03:11] detectron2 INFO: Inference done 3153/26446. 0.1689 s / img. ETA=1:06:26
[07/01 16:03:16] detectron2 INFO: Inference done 3182/26446. 0.1689 s / img. ETA=1:06:21
[07/01 16:03:21] detectron2 INFO: Inference done 3212/26446. 0.1689 s / img. ETA=1:06:16
[07/01 16:03:26] detectron2 INFO: Inference done 3242/26446. 0.1689 s / img. ETA=1:06:10
[07/01 16:03:31] detectron2 INFO: Inference done 3272/26446. 0.1689 s / img. ETA=1:06:04
[07/01 16:03:36] detectron2 INFO: Inference done 3302/26446. 0.1689 s / img. ETA=1:05:59
[07/01 16:03:41] detectron2 INFO: Inference done 3332/26446. 0.1688 s / img. ETA=1:05:53
[07/01 16:03:46] detectron2 INFO: Inference done 3362/26446. 0.1688 s / img. ETA=1:05:47
[07/01 16:03:52] detectron2 INFO: Inference done 3392/26446. 0.1688 s / img. ETA=1:05:42
[07/01 16:03:57] detectron2 INFO: Inference done 3422/26446. 0.1688 s / img. ETA=1:05:37
[07/01 16:04:02] detectron2 INFO: Inference done 3452/26446. 0.1688 s / img. ETA=1:05:32
[07/01 16:04:07] detectron2 INFO: Inference done 3482/26446. 0.1688 s / img. ETA=1:05:26
[07/01 16:04:12] detectron2 INFO: Inference done 3512/26446. 0.1688 s / img. ETA=1:05:20
[07/01 16:04:17] detectron2 INFO: Inference done 3542/26446. 0.1688 s / img. ETA=1:05:15
[07/01 16:04:22] detectron2 INFO: Inference done 3572/26446. 0.1688 s / img. ETA=1:05:10
[07/01 16:04:27] detectron2 INFO: Inference done 3602/26446. 0.1688 s / img. ETA=1:05:05
[07/01 16:04:32] detectron2 INFO: Inference done 3632/26446. 0.1688 s / img. ETA=1:05:00
[07/01 16:04:37] detectron2 INFO: Inference done 3662/26446. 0.1687 s / img. ETA=1:04:54
[07/01 16:04:43] detectron2 INFO: Inference done 3692/26446. 0.1687 s / img. ETA=1:04:49
[07/01 16:04:48] detectron2 INFO: Inference done 3722/26446. 0.1687 s / img. ETA=1:04:44
[07/01 16:04:53] detectron2 INFO: Inference done 3752/26446. 0.1687 s / img. ETA=1:04:38
[07/01 16:04:58] detectron2 INFO: Inference done 3782/26446. 0.1687 s / img. ETA=1:04:33
[07/01 16:05:03] detectron2 INFO: Inference done 3812/26446. 0.1687 s / img. ETA=1:04:28
[07/01 16:05:08] detectron2 INFO: Inference done 3842/26446. 0.1687 s / img. ETA=1:04:22
[07/01 16:05:13] detectron2 INFO: Inference done 3872/26446. 0.1687 s / img. ETA=1:04:17
[07/01 16:05:18] detectron2 INFO: Inference done 3902/26446. 0.1687 s / img. ETA=1:04:12
[07/01 16:05:23] detectron2 INFO: Inference done 3932/26446. 0.1687 s / img. ETA=1:04:07
[07/01 16:05:28] detectron2 INFO: Inference done 3961/26446. 0.1687 s / img. ETA=1:04:02
[07/01 16:05:33] detectron2 INFO: Inference done 3990/26446. 0.1687 s / img. ETA=1:03:57
[07/01 16:05:38] detectron2 INFO: Inference done 4020/26446. 0.1687 s / img. ETA=1:03:51
[07/01 16:05:44] detectron2 INFO: Inference done 4050/26446. 0.1687 s / img. ETA=1:03:46
[07/01 16:05:49] detectron2 INFO: Inference done 4079/26446. 0.1687 s / img. ETA=1:03:42
[07/01 16:05:54] detectron2 INFO: Inference done 4107/26446. 0.1688 s / img. ETA=1:03:39
[07/01 16:05:59] detectron2 INFO: Inference done 4136/26446. 0.1688 s / img. ETA=1:03:35
[07/01 16:06:04] detectron2 INFO: Inference done 4167/26446. 0.1688 s / img. ETA=1:03:29
[07/01 16:06:09] detectron2 INFO: Inference done 4197/26446. 0.1688 s / img. ETA=1:03:24
[07/01 16:06:14] detectron2 INFO: Inference done 4227/26446. 0.1688 s / img. ETA=1:03:19
[07/01 16:06:19] detectron2 INFO: Inference done 4257/26446. 0.1688 s / img. ETA=1:03:13
[07/01 16:06:24] detectron2 INFO: Inference done 4287/26446. 0.1688 s / img. ETA=1:03:08
[07/01 16:06:30] detectron2 INFO: Inference done 4317/26446. 0.1688 s / img. ETA=1:03:03
[07/01 16:06:35] detectron2 INFO: Inference done 4347/26446. 0.1688 s / img. ETA=1:02:58
[07/01 16:06:40] detectron2 INFO: Inference done 4377/26446. 0.1688 s / img. ETA=1:02:52
[07/01 16:06:45] detectron2 INFO: Inference done 4407/26446. 0.1687 s / img. ETA=1:02:47
[07/01 16:06:50] detectron2 INFO: Inference done 4437/26446. 0.1687 s / img. ETA=1:02:41
[07/01 16:06:55] detectron2 INFO: Inference done 4466/26446. 0.1687 s / img. ETA=1:02:37
[07/01 16:07:00] detectron2 INFO: Inference done 4496/26446. 0.1687 s / img. ETA=1:02:31
[07/01 16:07:05] detectron2 INFO: Inference done 4525/26446. 0.1688 s / img. ETA=1:02:27
[07/01 16:07:10] detectron2 INFO: Inference done 4555/26446. 0.1688 s / img. ETA=1:02:22
[07/01 16:07:15] detectron2 INFO: Inference done 4585/26446. 0.1688 s / img. ETA=1:02:17
[07/01 16:07:20] detectron2 INFO: Inference done 4615/26446. 0.1687 s / img. ETA=1:02:11
[07/01 16:07:26] detectron2 INFO: Inference done 4644/26446. 0.1688 s / img. ETA=1:02:07
[07/01 16:07:31] detectron2 INFO: Inference done 4672/26446. 0.1688 s / img. ETA=1:02:03
[07/01 16:07:36] detectron2 INFO: Inference done 4702/26446. 0.1688 s / img. ETA=1:01:58
[07/01 16:07:41] detectron2 INFO: Inference done 4732/26446. 0.1688 s / img. ETA=1:01:53
[07/01 16:07:46] detectron2 INFO: Inference done 4761/26446. 0.1688 s / img. ETA=1:01:48
[07/01 16:07:51] detectron2 INFO: Inference done 4791/26446. 0.1688 s / img. ETA=1:01:43
[07/01 16:07:56] detectron2 INFO: Inference done 4820/26446. 0.1688 s / img. ETA=1:01:38
[07/01 16:08:01] detectron2 INFO: Inference done 4849/26446. 0.1689 s / img. ETA=1:01:34
[07/01 16:08:06] detectron2 INFO: Inference done 4879/26446. 0.1689 s / img. ETA=1:01:29
[07/01 16:08:11] detectron2 INFO: Inference done 4909/26446. 0.1688 s / img. ETA=1:01:23
[07/01 16:08:16] detectron2 INFO: Inference done 4939/26446. 0.1688 s / img. ETA=1:01:18
[07/01 16:08:21] detectron2 INFO: Inference done 4969/26446. 0.1688 s / img. ETA=1:01:13
[07/01 16:08:26] detectron2 INFO: Inference done 4999/26446. 0.1688 s / img. ETA=1:01:07
[07/01 16:08:32] detectron2 INFO: Inference done 5029/26446. 0.1688 s / img. ETA=1:01:02
[07/01 16:08:37] detectron2 INFO: Inference done 5059/26446. 0.1688 s / img. ETA=1:00:57
[07/01 16:08:42] detectron2 INFO: Inference done 5089/26446. 0.1688 s / img. ETA=1:00:51
[07/01 16:08:47] detectron2 INFO: Inference done 5119/26446. 0.1688 s / img. ETA=1:00:46
[07/01 16:08:52] detectron2 INFO: Inference done 5149/26446. 0.1688 s / img. ETA=1:00:41
[07/01 16:08:57] detectron2 INFO: Inference done 5179/26446. 0.1687 s / img. ETA=1:00:35
[07/01 16:09:02] detectron2 INFO: Inference done 5209/26446. 0.1687 s / img. ETA=1:00:30
[07/01 16:09:07] detectron2 INFO: Inference done 5239/26446. 0.1687 s / img. ETA=1:00:25
[07/01 16:09:12] detectron2 INFO: Inference done 5269/26446. 0.1687 s / img. ETA=1:00:19
[07/01 16:09:17] detectron2 INFO: Inference done 5299/26446. 0.1687 s / img. ETA=1:00:14
[07/01 16:09:22] detectron2 INFO: Inference done 5329/26446. 0.1687 s / img. ETA=1:00:09
[07/01 16:09:27] detectron2 INFO: Inference done 5359/26446. 0.1687 s / img. ETA=1:00:04
[07/01 16:09:33] detectron2 INFO: Inference done 5389/26446. 0.1687 s / img. ETA=0:59:58
[07/01 16:09:38] detectron2 INFO: Inference done 5419/26446. 0.1687 s / img. ETA=0:59:53
[07/01 16:09:43] detectron2 INFO: Inference done 5448/26446. 0.1687 s / img. ETA=0:59:48
[07/01 16:09:48] detectron2 INFO: Inference done 5478/26446. 0.1687 s / img. ETA=0:59:43
[07/01 16:09:53] detectron2 INFO: Inference done 5508/26446. 0.1687 s / img. ETA=0:59:38
[07/01 16:09:58] detectron2 INFO: Inference done 5537/26446. 0.1687 s / img. ETA=0:59:33
[07/01 16:10:03] detectron2 INFO: Inference done 5567/26446. 0.1687 s / img. ETA=0:59:28
[07/01 16:10:08] detectron2 INFO: Inference done 5597/26446. 0.1687 s / img. ETA=0:59:23
[07/01 16:10:13] detectron2 INFO: Inference done 5628/26446. 0.1687 s / img. ETA=0:59:17
[07/01 16:10:18] detectron2 INFO: Inference done 5657/26446. 0.1687 s / img. ETA=0:59:13
[07/01 16:10:23] detectron2 INFO: Inference done 5686/26446. 0.1687 s / img. ETA=0:59:08
[07/01 16:10:28] detectron2 INFO: Inference done 5715/26446. 0.1687 s / img. ETA=0:59:03
[07/01 16:10:34] detectron2 INFO: Inference done 5745/26446. 0.1687 s / img. ETA=0:58:58
[07/01 16:10:39] detectron2 INFO: Inference done 5775/26446. 0.1687 s / img. ETA=0:58:53
[07/01 16:10:44] detectron2 INFO: Inference done 5804/26446. 0.1687 s / img. ETA=0:58:48
[07/01 16:10:49] detectron2 INFO: Inference done 5834/26446. 0.1687 s / img. ETA=0:58:43
[07/01 16:10:54] detectron2 INFO: Inference done 5864/26446. 0.1687 s / img. ETA=0:58:38
[07/01 16:10:59] detectron2 INFO: Inference done 5894/26446. 0.1687 s / img. ETA=0:58:33
[07/01 16:11:04] detectron2 INFO: Inference done 5924/26446. 0.1687 s / img. ETA=0:58:27
[07/01 16:11:09] detectron2 INFO: Inference done 5954/26446. 0.1687 s / img. ETA=0:58:22
[07/01 16:11:14] detectron2 INFO: Inference done 5984/26446. 0.1687 s / img. ETA=0:58:17
[07/01 16:11:19] detectron2 INFO: Inference done 6014/26446. 0.1687 s / img. ETA=0:58:12
[07/01 16:11:25] detectron2 INFO: Inference done 6044/26446. 0.1687 s / img. ETA=0:58:07
[07/01 16:11:30] detectron2 INFO: Inference done 6074/26446. 0.1687 s / img. ETA=0:58:01
[07/01 16:11:35] detectron2 INFO: Inference done 6105/26446. 0.1687 s / img. ETA=0:57:55
[07/01 16:11:40] detectron2 INFO: Inference done 6135/26446. 0.1687 s / img. ETA=0:57:50
[07/01 16:11:45] detectron2 INFO: Inference done 6165/26446. 0.1687 s / img. ETA=0:57:45
[07/01 16:11:50] detectron2 INFO: Inference done 6195/26446. 0.1686 s / img. ETA=0:57:40
[07/01 16:11:55] detectron2 INFO: Inference done 6224/26446. 0.1687 s / img. ETA=0:57:35
[07/01 16:12:00] detectron2 INFO: Inference done 6254/26446. 0.1687 s / img. ETA=0:57:30
[07/01 16:12:05] detectron2 INFO: Inference done 6283/26446. 0.1687 s / img. ETA=0:57:25
[07/01 16:12:10] detectron2 INFO: Inference done 6313/26446. 0.1687 s / img. ETA=0:57:20
[07/01 16:12:15] detectron2 INFO: Inference done 6343/26446. 0.1686 s / img. ETA=0:57:14
[07/01 16:12:20] detectron2 INFO: Inference done 6372/26446. 0.1687 s / img. ETA=0:57:10
[07/01 16:12:25] detectron2 INFO: Inference done 6402/26446. 0.1687 s / img. ETA=0:57:04
[07/01 16:12:31] detectron2 INFO: Inference done 6432/26446. 0.1687 s / img. ETA=0:56:59
[07/01 16:12:36] detectron2 INFO: Inference done 6463/26446. 0.1686 s / img. ETA=0:56:54
[07/01 16:12:41] detectron2 INFO: Inference done 6493/26446. 0.1686 s / img. ETA=0:56:48
[07/01 16:12:46] detectron2 INFO: Inference done 6523/26446. 0.1686 s / img. ETA=0:56:43
[07/01 16:12:51] detectron2 INFO: Inference done 6552/26446. 0.1686 s / img. ETA=0:56:39
[07/01 16:12:56] detectron2 INFO: Inference done 6582/26446. 0.1686 s / img. ETA=0:56:33
[07/01 16:13:01] detectron2 INFO: Inference done 6612/26446. 0.1686 s / img. ETA=0:56:28
[07/01 16:13:06] detectron2 INFO: Inference done 6642/26446. 0.1686 s / img. ETA=0:56:23
[07/01 16:13:11] detectron2 INFO: Inference done 6671/26446. 0.1686 s / img. ETA=0:56:18
[07/01 16:13:16] detectron2 INFO: Inference done 6700/26446. 0.1687 s / img. ETA=0:56:14
[07/01 16:13:21] detectron2 INFO: Inference done 6728/26446. 0.1687 s / img. ETA=0:56:10
[07/01 16:13:27] detectron2 INFO: Inference done 6757/26446. 0.1687 s / img. ETA=0:56:05
[07/01 16:13:32] detectron2 INFO: Inference done 6785/26446. 0.1688 s / img. ETA=0:56:01
[07/01 16:13:37] detectron2 INFO: Inference done 6814/26446. 0.1688 s / img. ETA=0:55:56
[07/01 16:13:42] detectron2 INFO: Inference done 6842/26446. 0.1688 s / img. ETA=0:55:52
[07/01 16:13:47] detectron2 INFO: Inference done 6870/26446. 0.1688 s / img. ETA=0:55:48
[07/01 16:13:52] detectron2 INFO: Inference done 6899/26446. 0.1689 s / img. ETA=0:55:44
[07/01 16:13:57] detectron2 INFO: Inference done 6928/26446. 0.1689 s / img. ETA=0:55:39
[07/01 16:14:02] detectron2 INFO: Inference done 6957/26446. 0.1689 s / img. ETA=0:55:35
[07/01 16:14:07] detectron2 INFO: Inference done 6987/26446. 0.1689 s / img. ETA=0:55:29
[07/01 16:14:12] detectron2 INFO: Inference done 7017/26446. 0.1689 s / img. ETA=0:55:24
[07/01 16:14:17] detectron2 INFO: Inference done 7047/26446. 0.1689 s / img. ETA=0:55:19
[07/01 16:14:22] detectron2 INFO: Inference done 7077/26446. 0.1689 s / img. ETA=0:55:14
[07/01 16:14:27] detectron2 INFO: Inference done 7107/26446. 0.1689 s / img. ETA=0:55:08
[07/01 16:14:33] detectron2 INFO: Inference done 7137/26446. 0.1689 s / img. ETA=0:55:03
[07/01 16:14:38] detectron2 INFO: Inference done 7167/26446. 0.1689 s / img. ETA=0:54:58
[07/01 16:14:43] detectron2 INFO: Inference done 7197/26446. 0.1688 s / img. ETA=0:54:52
[07/01 16:14:48] detectron2 INFO: Inference done 7227/26446. 0.1688 s / img. ETA=0:54:47
[07/01 16:14:53] detectron2 INFO: Inference done 7257/26446. 0.1688 s / img. ETA=0:54:42
[07/01 16:14:58] detectron2 INFO: Inference done 7287/26446. 0.1688 s / img. ETA=0:54:37
[07/01 16:15:03] detectron2 INFO: Inference done 7316/26446. 0.1689 s / img. ETA=0:54:32
[07/01 16:15:08] detectron2 INFO: Inference done 7345/26446. 0.1689 s / img. ETA=0:54:27
[07/01 16:15:13] detectron2 INFO: Inference done 7375/26446. 0.1689 s / img. ETA=0:54:22
[07/01 16:15:18] detectron2 INFO: Inference done 7405/26446. 0.1688 s / img. ETA=0:54:17
[07/01 16:15:23] detectron2 INFO: Inference done 7434/26446. 0.1689 s / img. ETA=0:54:12
[07/01 16:15:28] detectron2 INFO: Inference done 7464/26446. 0.1688 s / img. ETA=0:54:07
[07/01 16:15:33] detectron2 INFO: Inference done 7494/26446. 0.1688 s / img. ETA=0:54:01
[07/01 16:15:39] detectron2 INFO: Inference done 7524/26446. 0.1688 s / img. ETA=0:53:56
[07/01 16:15:44] detectron2 INFO: Inference done 7554/26446. 0.1688 s / img. ETA=0:53:51
[07/01 16:15:49] detectron2 INFO: Inference done 7584/26446. 0.1688 s / img. ETA=0:53:46
[07/01 16:15:54] detectron2 INFO: Inference done 7614/26446. 0.1688 s / img. ETA=0:53:41
[07/01 16:15:59] detectron2 INFO: Inference done 7644/26446. 0.1688 s / img. ETA=0:53:36
[07/01 16:16:04] detectron2 INFO: Inference done 7674/26446. 0.1688 s / img. ETA=0:53:30
[07/01 16:16:09] detectron2 INFO: Inference done 7703/26446. 0.1688 s / img. ETA=0:53:25
[07/01 16:16:14] detectron2 INFO: Inference done 7733/26446. 0.1688 s / img. ETA=0:53:20
[07/01 16:16:19] detectron2 INFO: Inference done 7763/26446. 0.1688 s / img. ETA=0:53:15
[07/01 16:16:24] detectron2 INFO: Inference done 7794/26446. 0.1688 s / img. ETA=0:53:09
[07/01 16:16:29] detectron2 INFO: Inference done 7823/26446. 0.1688 s / img. ETA=0:53:05
[07/01 16:16:35] detectron2 INFO: Inference done 7853/26446. 0.1688 s / img. ETA=0:52:59
[07/01 16:16:40] detectron2 INFO: Inference done 7883/26446. 0.1688 s / img. ETA=0:52:54
[07/01 16:16:45] detectron2 INFO: Inference done 7914/26446. 0.1688 s / img. ETA=0:52:48
[07/01 16:16:50] detectron2 INFO: Inference done 7944/26446. 0.1688 s / img. ETA=0:52:43
[07/01 16:16:55] detectron2 INFO: Inference done 7975/26446. 0.1687 s / img. ETA=0:52:38
[07/01 16:17:00] detectron2 INFO: Inference done 8005/26446. 0.1687 s / img. ETA=0:52:32
[07/01 16:17:05] detectron2 INFO: Inference done 8035/26446. 0.1687 s / img. ETA=0:52:27
[07/01 16:17:10] detectron2 INFO: Inference done 8064/26446. 0.1687 s / img. ETA=0:52:22
[07/01 16:17:15] detectron2 INFO: Inference done 8094/26446. 0.1688 s / img. ETA=0:52:17
[07/01 16:17:21] detectron2 INFO: Inference done 8124/26446. 0.1688 s / img. ETA=0:52:12
[07/01 16:17:26] detectron2 INFO: Inference done 8153/26446. 0.1688 s / img. ETA=0:52:07
[07/01 16:17:31] detectron2 INFO: Inference done 8182/26446. 0.1688 s / img. ETA=0:52:03
[07/01 16:17:36] detectron2 INFO: Inference done 8212/26446. 0.1688 s / img. ETA=0:51:58
[07/01 16:17:41] detectron2 INFO: Inference done 8243/26446. 0.1688 s / img. ETA=0:51:52
[07/01 16:17:46] detectron2 INFO: Inference done 8272/26446. 0.1688 s / img. ETA=0:51:47
[07/01 16:17:51] detectron2 INFO: Inference done 8302/26446. 0.1688 s / img. ETA=0:51:42
[07/01 16:17:56] detectron2 INFO: Inference done 8331/26446. 0.1688 s / img. ETA=0:51:37
[07/01 16:18:01] detectron2 INFO: Inference done 8354/26446. 0.1689 s / img. ETA=0:51:36
[07/01 16:18:06] detectron2 INFO: Inference done 8384/26446. 0.1689 s / img. ETA=0:51:31
[07/01 16:18:11] detectron2 INFO: Inference done 8414/26446. 0.1689 s / img. ETA=0:51:25
[07/01 16:18:16] detectron2 INFO: Inference done 8443/26446. 0.1689 s / img. ETA=0:51:21
[07/01 16:18:22] detectron2 INFO: Inference done 8473/26446. 0.1689 s / img. ETA=0:51:15
[07/01 16:18:27] detectron2 INFO: Inference done 8503/26446. 0.1689 s / img. ETA=0:51:10
[07/01 16:18:32] detectron2 INFO: Inference done 8533/26446. 0.1689 s / img. ETA=0:51:05
[07/01 16:18:37] detectron2 INFO: Inference done 8563/26446. 0.1689 s / img. ETA=0:51:00
[07/01 16:18:42] detectron2 INFO: Inference done 8593/26446. 0.1689 s / img. ETA=0:50:54
[07/01 16:18:47] detectron2 INFO: Inference done 8622/26446. 0.1689 s / img. ETA=0:50:50
[07/01 16:18:52] detectron2 INFO: Inference done 8652/26446. 0.1689 s / img. ETA=0:50:44
[07/01 16:18:57] detectron2 INFO: Inference done 8682/26446. 0.1689 s / img. ETA=0:50:39
[07/01 16:19:02] detectron2 INFO: Inference done 8712/26446. 0.1689 s / img. ETA=0:50:34
[07/01 16:19:07] detectron2 INFO: Inference done 8742/26446. 0.1689 s / img. ETA=0:50:29
[07/01 16:19:12] detectron2 INFO: Inference done 8772/26446. 0.1689 s / img. ETA=0:50:23
[07/01 16:19:18] detectron2 INFO: Inference done 8802/26446. 0.1689 s / img. ETA=0:50:18
[07/01 16:19:23] detectron2 INFO: Inference done 8832/26446. 0.1689 s / img. ETA=0:50:13
[07/01 16:19:28] detectron2 INFO: Inference done 8863/26446. 0.1688 s / img. ETA=0:50:08
[07/01 16:19:33] detectron2 INFO: Inference done 8893/26446. 0.1688 s / img. ETA=0:50:02
[07/01 16:19:38] detectron2 INFO: Inference done 8922/26446. 0.1689 s / img. ETA=0:49:58
[07/01 16:19:43] detectron2 INFO: Inference done 8952/26446. 0.1689 s / img. ETA=0:49:52
[07/01 16:19:48] detectron2 INFO: Inference done 8982/26446. 0.1689 s / img. ETA=0:49:47
[07/01 16:19:53] detectron2 INFO: Inference done 9012/26446. 0.1688 s / img. ETA=0:49:42
[07/01 16:19:58] detectron2 INFO: Inference done 9042/26446. 0.1688 s / img. ETA=0:49:37
[07/01 16:20:03] detectron2 INFO: Inference done 9072/26446. 0.1688 s / img. ETA=0:49:32
[07/01 16:20:09] detectron2 INFO: Inference done 9102/26446. 0.1688 s / img. ETA=0:49:26
[07/01 16:20:14] detectron2 INFO: Inference done 9132/26446. 0.1688 s / img. ETA=0:49:21
[07/01 16:20:19] detectron2 INFO: Inference done 9162/26446. 0.1688 s / img. ETA=0:49:16
[07/01 16:20:24] detectron2 INFO: Inference done 9191/26446. 0.1688 s / img. ETA=0:49:11
[07/01 16:20:29] detectron2 INFO: Inference done 9221/26446. 0.1688 s / img. ETA=0:49:06
[07/01 16:20:34] detectron2 INFO: Inference done 9251/26446. 0.1688 s / img. ETA=0:49:01
[07/01 16:20:39] detectron2 INFO: Inference done 9280/26446. 0.1688 s / img. ETA=0:48:56
[07/01 16:20:44] detectron2 INFO: Inference done 9310/26446. 0.1688 s / img. ETA=0:48:51
[07/01 16:20:49] detectron2 INFO: Inference done 9340/26446. 0.1688 s / img. ETA=0:48:46
[07/01 16:20:54] detectron2 INFO: Inference done 9370/26446. 0.1688 s / img. ETA=0:48:40
[07/01 16:20:59] detectron2 INFO: Inference done 9400/26446. 0.1688 s / img. ETA=0:48:35
[07/01 16:21:04] detectron2 INFO: Inference done 9430/26446. 0.1688 s / img. ETA=0:48:30
[07/01 16:21:10] detectron2 INFO: Inference done 9460/26446. 0.1688 s / img. ETA=0:48:25
[07/01 16:21:15] detectron2 INFO: Inference done 9490/26446. 0.1688 s / img. ETA=0:48:20
[07/01 16:21:20] detectron2 INFO: Inference done 9520/26446. 0.1688 s / img. ETA=0:48:14
[07/01 16:21:25] detectron2 INFO: Inference done 9549/26446. 0.1688 s / img. ETA=0:48:09
[07/01 16:21:30] detectron2 INFO: Inference done 9578/26446. 0.1688 s / img. ETA=0:48:05
[07/01 16:21:35] detectron2 INFO: Inference done 9607/26446. 0.1688 s / img. ETA=0:48:00
[07/01 16:21:40] detectron2 INFO: Inference done 9637/26446. 0.1688 s / img. ETA=0:47:55
[07/01 16:21:45] detectron2 INFO: Inference done 9667/26446. 0.1688 s / img. ETA=0:47:50
[07/01 16:21:50] detectron2 INFO: Inference done 9697/26446. 0.1688 s / img. ETA=0:47:44
[07/01 16:21:55] detectron2 INFO: Inference done 9727/26446. 0.1688 s / img. ETA=0:47:39
[07/01 16:22:00] detectron2 INFO: Inference done 9757/26446. 0.1688 s / img. ETA=0:47:34
[07/01 16:22:05] detectron2 INFO: Inference done 9786/26446. 0.1688 s / img. ETA=0:47:29
[07/01 16:22:11] detectron2 INFO: Inference done 9815/26446. 0.1688 s / img. ETA=0:47:25
[07/01 16:22:16] detectron2 INFO: Inference done 9845/26446. 0.1688 s / img. ETA=0:47:19
[07/01 16:22:21] detectron2 INFO: Inference done 9875/26446. 0.1688 s / img. ETA=0:47:14
[07/01 16:22:26] detectron2 INFO: Inference done 9905/26446. 0.1688 s / img. ETA=0:47:09
[07/01 16:22:31] detectron2 INFO: Inference done 9935/26446. 0.1688 s / img. ETA=0:47:04
[07/01 16:22:36] detectron2 INFO: Inference done 9964/26446. 0.1688 s / img. ETA=0:46:59
[07/01 16:22:41] detectron2 INFO: Inference done 9994/26446. 0.1688 s / img. ETA=0:46:54
[07/01 16:22:46] detectron2 INFO: Inference done 10024/26446. 0.1688 s / img. ETA=0:46:49
[07/01 16:22:51] detectron2 INFO: Inference done 10054/26446. 0.1688 s / img. ETA=0:46:43
[07/01 16:22:56] detectron2 INFO: Inference done 10084/26446. 0.1688 s / img. ETA=0:46:38
[07/01 16:23:02] detectron2 INFO: Inference done 10114/26446. 0.1688 s / img. ETA=0:46:33
[07/01 16:23:07] detectron2 INFO: Inference done 10144/26446. 0.1688 s / img. ETA=0:46:28
[07/01 16:23:12] detectron2 INFO: Inference done 10175/26446. 0.1688 s / img. ETA=0:46:22
[07/01 16:23:17] detectron2 INFO: Inference done 10205/26446. 0.1688 s / img. ETA=0:46:17
[07/01 16:23:22] detectron2 INFO: Inference done 10235/26446. 0.1688 s / img. ETA=0:46:12
[07/01 16:23:27] detectron2 INFO: Inference done 10265/26446. 0.1688 s / img. ETA=0:46:07
[07/01 16:23:32] detectron2 INFO: Inference done 10295/26446. 0.1688 s / img. ETA=0:46:02
[07/01 16:23:37] detectron2 INFO: Inference done 10324/26446. 0.1688 s / img. ETA=0:45:57
[07/01 16:23:42] detectron2 INFO: Inference done 10354/26446. 0.1688 s / img. ETA=0:45:52
[07/01 16:23:48] detectron2 INFO: Inference done 10384/26446. 0.1688 s / img. ETA=0:45:47
[07/01 16:23:53] detectron2 INFO: Inference done 10414/26446. 0.1688 s / img. ETA=0:45:41
[07/01 16:23:58] detectron2 INFO: Inference done 10444/26446. 0.1688 s / img. ETA=0:45:36
[07/01 16:24:03] detectron2 INFO: Inference done 10473/26446. 0.1688 s / img. ETA=0:45:31
[07/01 16:24:08] detectron2 INFO: Inference done 10503/26446. 0.1688 s / img. ETA=0:45:26
[07/01 16:24:13] detectron2 INFO: Inference done 10533/26446. 0.1688 s / img. ETA=0:45:21
[07/01 16:24:18] detectron2 INFO: Inference done 10563/26446. 0.1688 s / img. ETA=0:45:16
[07/01 16:24:23] detectron2 INFO: Inference done 10594/26446. 0.1688 s / img. ETA=0:45:10
[07/01 16:24:28] detectron2 INFO: Inference done 10624/26446. 0.1688 s / img. ETA=0:45:05
[07/01 16:24:33] detectron2 INFO: Inference done 10655/26446. 0.1687 s / img. ETA=0:44:59
[07/01 16:24:38] detectron2 INFO: Inference done 10686/26446. 0.1687 s / img. ETA=0:44:54
[07/01 16:24:43] detectron2 INFO: Inference done 10716/26446. 0.1687 s / img. ETA=0:44:49
[07/01 16:24:48] detectron2 INFO: Inference done 10746/26446. 0.1687 s / img. ETA=0:44:43
[07/01 16:24:54] detectron2 INFO: Inference done 10776/26446. 0.1687 s / img. ETA=0:44:38
[07/01 16:24:59] detectron2 INFO: Inference done 10806/26446. 0.1687 s / img. ETA=0:44:33
[07/01 16:25:04] detectron2 INFO: Inference done 10836/26446. 0.1687 s / img. ETA=0:44:28
[07/01 16:25:09] detectron2 INFO: Inference done 10866/26446. 0.1687 s / img. ETA=0:44:22
[07/01 16:25:14] detectron2 INFO: Inference done 10897/26446. 0.1687 s / img. ETA=0:44:17
[07/01 16:25:19] detectron2 INFO: Inference done 10927/26446. 0.1687 s / img. ETA=0:44:12
[07/01 16:25:24] detectron2 INFO: Inference done 10956/26446. 0.1687 s / img. ETA=0:44:07
[07/01 16:25:29] detectron2 INFO: Inference done 10986/26446. 0.1687 s / img. ETA=0:44:02
[07/01 16:25:34] detectron2 INFO: Inference done 11016/26446. 0.1687 s / img. ETA=0:43:57
[07/01 16:25:39] detectron2 INFO: Inference done 11046/26446. 0.1687 s / img. ETA=0:43:51
[07/01 16:25:44] detectron2 INFO: Inference done 11076/26446. 0.1687 s / img. ETA=0:43:46
[07/01 16:25:49] detectron2 INFO: Inference done 11107/26446. 0.1686 s / img. ETA=0:43:40
[07/01 16:25:55] detectron2 INFO: Inference done 11137/26446. 0.1686 s / img. ETA=0:43:35
[07/01 16:26:00] detectron2 INFO: Inference done 11167/26446. 0.1686 s / img. ETA=0:43:30
[07/01 16:26:05] detectron2 INFO: Inference done 11197/26446. 0.1686 s / img. ETA=0:43:25
[07/01 16:26:10] detectron2 INFO: Inference done 11227/26446. 0.1686 s / img. ETA=0:43:20
[07/01 16:26:15] detectron2 INFO: Inference done 11256/26446. 0.1686 s / img. ETA=0:43:15
[07/01 16:26:20] detectron2 INFO: Inference done 11286/26446. 0.1686 s / img. ETA=0:43:10
[07/01 16:26:25] detectron2 INFO: Inference done 11315/26446. 0.1686 s / img. ETA=0:43:05
[07/01 16:26:30] detectron2 INFO: Inference done 11345/26446. 0.1686 s / img. ETA=0:43:00
[07/01 16:26:35] detectron2 INFO: Inference done 11375/26446. 0.1686 s / img. ETA=0:42:54
[07/01 16:26:40] detectron2 INFO: Inference done 11405/26446. 0.1686 s / img. ETA=0:42:49
[07/01 16:26:45] detectron2 INFO: Inference done 11436/26446. 0.1686 s / img. ETA=0:42:44
[07/01 16:26:50] detectron2 INFO: Inference done 11466/26446. 0.1686 s / img. ETA=0:42:38
[07/01 16:26:55] detectron2 INFO: Inference done 11496/26446. 0.1686 s / img. ETA=0:42:33
[07/01 16:27:00] detectron2 INFO: Inference done 11527/26446. 0.1686 s / img. ETA=0:42:28
[07/01 16:27:06] detectron2 INFO: Inference done 11556/26446. 0.1686 s / img. ETA=0:42:23
[07/01 16:27:11] detectron2 INFO: Inference done 11586/26446. 0.1686 s / img. ETA=0:42:18
[07/01 16:27:16] detectron2 INFO: Inference done 11616/26446. 0.1686 s / img. ETA=0:42:13
[07/01 16:27:21] detectron2 INFO: Inference done 11646/26446. 0.1686 s / img. ETA=0:42:08
[07/01 16:27:26] detectron2 INFO: Inference done 11676/26446. 0.1686 s / img. ETA=0:42:02
[07/01 16:27:31] detectron2 INFO: Inference done 11707/26446. 0.1686 s / img. ETA=0:41:57
[07/01 16:27:36] detectron2 INFO: Inference done 11737/26446. 0.1686 s / img. ETA=0:41:52
[07/01 16:27:41] detectron2 INFO: Inference done 11767/26446. 0.1686 s / img. ETA=0:41:47
[07/01 16:27:46] detectron2 INFO: Inference done 11797/26446. 0.1686 s / img. ETA=0:41:41
[07/01 16:27:51] detectron2 INFO: Inference done 11827/26446. 0.1686 s / img. ETA=0:41:36
[07/01 16:27:57] detectron2 INFO: Inference done 11858/26446. 0.1685 s / img. ETA=0:41:31
[07/01 16:28:02] detectron2 INFO: Inference done 11888/26446. 0.1685 s / img. ETA=0:41:26
[07/01 16:28:07] detectron2 INFO: Inference done 11918/26446. 0.1685 s / img. ETA=0:41:20
[07/01 16:28:12] detectron2 INFO: Inference done 11948/26446. 0.1685 s / img. ETA=0:41:15
[07/01 16:28:17] detectron2 INFO: Inference done 11978/26446. 0.1685 s / img. ETA=0:41:10
[07/01 16:28:22] detectron2 INFO: Inference done 12008/26446. 0.1685 s / img. ETA=0:41:05
[07/01 16:28:27] detectron2 INFO: Inference done 12038/26446. 0.1685 s / img. ETA=0:41:00
[07/01 16:28:32] detectron2 INFO: Inference done 12069/26446. 0.1685 s / img. ETA=0:40:54
[07/01 16:28:37] detectron2 INFO: Inference done 12099/26446. 0.1685 s / img. ETA=0:40:49
[07/01 16:28:42] detectron2 INFO: Inference done 12129/26446. 0.1685 s / img. ETA=0:40:44
[07/01 16:28:47] detectron2 INFO: Inference done 12159/26446. 0.1685 s / img. ETA=0:40:39
[07/01 16:28:52] detectron2 INFO: Inference done 12189/26446. 0.1685 s / img. ETA=0:40:33
[07/01 16:28:57] detectron2 INFO: Inference done 12219/26446. 0.1685 s / img. ETA=0:40:28
[07/01 16:29:03] detectron2 INFO: Inference done 12250/26446. 0.1685 s / img. ETA=0:40:23
[07/01 16:29:08] detectron2 INFO: Inference done 12280/26446. 0.1685 s / img. ETA=0:40:18
[07/01 16:29:13] detectron2 INFO: Inference done 12310/26446. 0.1685 s / img. ETA=0:40:12
[07/01 16:29:18] detectron2 INFO: Inference done 12339/26446. 0.1685 s / img. ETA=0:40:08
[07/01 16:29:23] detectron2 INFO: Inference done 12369/26446. 0.1685 s / img. ETA=0:40:02
[07/01 16:29:28] detectron2 INFO: Inference done 12400/26446. 0.1685 s / img. ETA=0:39:57
[07/01 16:29:33] detectron2 INFO: Inference done 12430/26446. 0.1685 s / img. ETA=0:39:52
[07/01 16:29:38] detectron2 INFO: Inference done 12460/26446. 0.1684 s / img. ETA=0:39:47
[07/01 16:29:43] detectron2 INFO: Inference done 12490/26446. 0.1684 s / img. ETA=0:39:42
[07/01 16:29:48] detectron2 INFO: Inference done 12520/26446. 0.1684 s / img. ETA=0:39:36
[07/01 16:29:54] detectron2 INFO: Inference done 12550/26446. 0.1684 s / img. ETA=0:39:31
[07/01 16:29:59] detectron2 INFO: Inference done 12581/26446. 0.1684 s / img. ETA=0:39:26
[07/01 16:30:04] detectron2 INFO: Inference done 12611/26446. 0.1684 s / img. ETA=0:39:21
[07/01 16:30:09] detectron2 INFO: Inference done 12641/26446. 0.1684 s / img. ETA=0:39:15
[07/01 16:30:14] detectron2 INFO: Inference done 12671/26446. 0.1684 s / img. ETA=0:39:10
[07/01 16:30:19] detectron2 INFO: Inference done 12701/26446. 0.1684 s / img. ETA=0:39:05
[07/01 16:30:24] detectron2 INFO: Inference done 12731/26446. 0.1684 s / img. ETA=0:39:00
[07/01 16:30:29] detectron2 INFO: Inference done 12761/26446. 0.1684 s / img. ETA=0:38:55
[07/01 16:30:34] detectron2 INFO: Inference done 12791/26446. 0.1684 s / img. ETA=0:38:50
[07/01 16:30:39] detectron2 INFO: Inference done 12821/26446. 0.1684 s / img. ETA=0:38:44
[07/01 16:30:44] detectron2 INFO: Inference done 12851/26446. 0.1684 s / img. ETA=0:38:39
[07/01 16:30:49] detectron2 INFO: Inference done 12881/26446. 0.1684 s / img. ETA=0:38:34
[07/01 16:30:54] detectron2 INFO: Inference done 12911/26446. 0.1684 s / img. ETA=0:38:29
[07/01 16:30:59] detectron2 INFO: Inference done 12941/26446. 0.1684 s / img. ETA=0:38:24
[07/01 16:31:04] detectron2 INFO: Inference done 12971/26446. 0.1684 s / img. ETA=0:38:18
[07/01 16:31:10] detectron2 INFO: Inference done 13001/26446. 0.1684 s / img. ETA=0:38:13
[07/01 16:31:15] detectron2 INFO: Inference done 13031/26446. 0.1684 s / img. ETA=0:38:08
[07/01 16:31:20] detectron2 INFO: Inference done 13060/26446. 0.1684 s / img. ETA=0:38:03
[07/01 16:31:25] detectron2 INFO: Inference done 13089/26446. 0.1684 s / img. ETA=0:37:58
[07/01 16:31:30] detectron2 INFO: Inference done 13119/26446. 0.1684 s / img. ETA=0:37:53
[07/01 16:31:35] detectron2 INFO: Inference done 13150/26446. 0.1684 s / img. ETA=0:37:48
[07/01 16:31:40] detectron2 INFO: Inference done 13181/26446. 0.1683 s / img. ETA=0:37:42
[07/01 16:31:45] detectron2 INFO: Inference done 13211/26446. 0.1683 s / img. ETA=0:37:37
[07/01 16:31:50] detectron2 INFO: Inference done 13242/26446. 0.1683 s / img. ETA=0:37:32
[07/01 16:31:55] detectron2 INFO: Inference done 13272/26446. 0.1683 s / img. ETA=0:37:27
[07/01 16:32:00] detectron2 INFO: Inference done 13301/26446. 0.1683 s / img. ETA=0:37:22
[07/01 16:32:05] detectron2 INFO: Inference done 13331/26446. 0.1683 s / img. ETA=0:37:17
[07/01 16:32:11] detectron2 INFO: Inference done 13361/26446. 0.1683 s / img. ETA=0:37:11
[07/01 16:32:16] detectron2 INFO: Inference done 13391/26446. 0.1683 s / img. ETA=0:37:06
[07/01 16:32:21] detectron2 INFO: Inference done 13422/26446. 0.1683 s / img. ETA=0:37:01
[07/01 16:32:26] detectron2 INFO: Inference done 13452/26446. 0.1683 s / img. ETA=0:36:56
[07/01 16:32:31] detectron2 INFO: Inference done 13482/26446. 0.1683 s / img. ETA=0:36:50
[07/01 16:32:36] detectron2 INFO: Inference done 13513/26446. 0.1683 s / img. ETA=0:36:45
[07/01 16:32:41] detectron2 INFO: Inference done 13544/26446. 0.1683 s / img. ETA=0:36:40
[07/01 16:32:46] detectron2 INFO: Inference done 13574/26446. 0.1683 s / img. ETA=0:36:34
[07/01 16:32:51] detectron2 INFO: Inference done 13604/26446. 0.1683 s / img. ETA=0:36:29
[07/01 16:32:56] detectron2 INFO: Inference done 13634/26446. 0.1683 s / img. ETA=0:36:24
[07/01 16:33:01] detectron2 INFO: Inference done 13664/26446. 0.1683 s / img. ETA=0:36:19
[07/01 16:33:06] detectron2 INFO: Inference done 13694/26446. 0.1683 s / img. ETA=0:36:14
[07/01 16:33:12] detectron2 INFO: Inference done 13724/26446. 0.1683 s / img. ETA=0:36:09
[07/01 16:33:17] detectron2 INFO: Inference done 13754/26446. 0.1683 s / img. ETA=0:36:04
[07/01 16:33:22] detectron2 INFO: Inference done 13784/26446. 0.1683 s / img. ETA=0:35:58
[07/01 16:33:27] detectron2 INFO: Inference done 13814/26446. 0.1683 s / img. ETA=0:35:53
[07/01 16:33:32] detectron2 INFO: Inference done 13844/26446. 0.1683 s / img. ETA=0:35:48
[07/01 16:33:37] detectron2 INFO: Inference done 13874/26446. 0.1683 s / img. ETA=0:35:43
[07/01 16:33:42] detectron2 INFO: Inference done 13904/26446. 0.1682 s / img. ETA=0:35:38
[07/01 16:33:47] detectron2 INFO: Inference done 13934/26446. 0.1682 s / img. ETA=0:35:33
[07/01 16:33:52] detectron2 INFO: Inference done 13964/26446. 0.1682 s / img. ETA=0:35:27
[07/01 16:33:57] detectron2 INFO: Inference done 13994/26446. 0.1682 s / img. ETA=0:35:22
[07/01 16:34:02] detectron2 INFO: Inference done 14024/26446. 0.1682 s / img. ETA=0:35:17
[07/01 16:34:07] detectron2 INFO: Inference done 14054/26446. 0.1682 s / img. ETA=0:35:12
[07/01 16:34:12] detectron2 INFO: Inference done 14084/26446. 0.1682 s / img. ETA=0:35:07
[07/01 16:34:17] detectron2 INFO: Inference done 14114/26446. 0.1682 s / img. ETA=0:35:02
[07/01 16:34:23] detectron2 INFO: Inference done 14144/26446. 0.1682 s / img. ETA=0:34:57
[07/01 16:34:28] detectron2 INFO: Inference done 14174/26446. 0.1682 s / img. ETA=0:34:51
[07/01 16:34:33] detectron2 INFO: Inference done 14204/26446. 0.1682 s / img. ETA=0:34:46
[07/01 16:34:38] detectron2 INFO: Inference done 14234/26446. 0.1682 s / img. ETA=0:34:41
[07/01 16:34:43] detectron2 INFO: Inference done 14264/26446. 0.1682 s / img. ETA=0:34:36
[07/01 16:34:48] detectron2 INFO: Inference done 14294/26446. 0.1682 s / img. ETA=0:34:31
[07/01 16:34:53] detectron2 INFO: Inference done 14324/26446. 0.1682 s / img. ETA=0:34:26
[07/01 16:34:58] detectron2 INFO: Inference done 14354/26446. 0.1682 s / img. ETA=0:34:21
[07/01 16:35:03] detectron2 INFO: Inference done 14385/26446. 0.1682 s / img. ETA=0:34:15
[07/01 16:35:08] detectron2 INFO: Inference done 14415/26446. 0.1682 s / img. ETA=0:34:10
[07/01 16:35:14] detectron2 INFO: Inference done 14446/26446. 0.1682 s / img. ETA=0:34:05
[07/01 16:35:19] detectron2 INFO: Inference done 14477/26446. 0.1682 s / img. ETA=0:33:59
[07/01 16:35:24] detectron2 INFO: Inference done 14508/26446. 0.1682 s / img. ETA=0:33:54
[07/01 16:35:29] detectron2 INFO: Inference done 14538/26446. 0.1682 s / img. ETA=0:33:49
[07/01 16:35:34] detectron2 INFO: Inference done 14568/26446. 0.1682 s / img. ETA=0:33:44
[07/01 16:35:39] detectron2 INFO: Inference done 14599/26446. 0.1682 s / img. ETA=0:33:38
[07/01 16:35:44] detectron2 INFO: Inference done 14629/26446. 0.1682 s / img. ETA=0:33:33
[07/01 16:35:49] detectron2 INFO: Inference done 14659/26446. 0.1681 s / img. ETA=0:33:28
[07/01 16:35:54] detectron2 INFO: Inference done 14689/26446. 0.1681 s / img. ETA=0:33:23
[07/01 16:35:59] detectron2 INFO: Inference done 14719/26446. 0.1681 s / img. ETA=0:33:17
[07/01 16:36:04] detectron2 INFO: Inference done 14749/26446. 0.1681 s / img. ETA=0:33:12
[07/01 16:36:10] detectron2 INFO: Inference done 14779/26446. 0.1681 s / img. ETA=0:33:07
[07/01 16:36:15] detectron2 INFO: Inference done 14809/26446. 0.1681 s / img. ETA=0:33:02
[07/01 16:36:20] detectron2 INFO: Inference done 14839/26446. 0.1681 s / img. ETA=0:32:57
[07/01 16:36:25] detectron2 INFO: Inference done 14870/26446. 0.1681 s / img. ETA=0:32:52
[07/01 16:36:30] detectron2 INFO: Inference done 14900/26446. 0.1681 s / img. ETA=0:32:46
[07/01 16:36:35] detectron2 INFO: Inference done 14930/26446. 0.1681 s / img. ETA=0:32:41
[07/01 16:36:40] detectron2 INFO: Inference done 14960/26446. 0.1681 s / img. ETA=0:32:36
[07/01 16:36:45] detectron2 INFO: Inference done 14990/26446. 0.1681 s / img. ETA=0:32:31
[07/01 16:36:50] detectron2 INFO: Inference done 15020/26446. 0.1681 s / img. ETA=0:32:26
[07/01 16:36:55] detectron2 INFO: Inference done 15051/26446. 0.1681 s / img. ETA=0:32:21
[07/01 16:37:00] detectron2 INFO: Inference done 15081/26446. 0.1681 s / img. ETA=0:32:15
[07/01 16:37:05] detectron2 INFO: Inference done 15111/26446. 0.1681 s / img. ETA=0:32:10
[07/01 16:37:10] detectron2 INFO: Inference done 15140/26446. 0.1681 s / img. ETA=0:32:05
[07/01 16:37:16] detectron2 INFO: Inference done 15170/26446. 0.1681 s / img. ETA=0:32:00
[07/01 16:37:21] detectron2 INFO: Inference done 15200/26446. 0.1681 s / img. ETA=0:31:55
[07/01 16:37:26] detectron2 INFO: Inference done 15230/26446. 0.1681 s / img. ETA=0:31:50
[07/01 16:37:31] detectron2 INFO: Inference done 15260/26446. 0.1681 s / img. ETA=0:31:45
[07/01 16:37:36] detectron2 INFO: Inference done 15290/26446. 0.1681 s / img. ETA=0:31:40
[07/01 16:37:41] detectron2 INFO: Inference done 15320/26446. 0.1681 s / img. ETA=0:31:35
[07/01 16:37:46] detectron2 INFO: Inference done 15350/26446. 0.1681 s / img. ETA=0:31:29
[07/01 16:37:51] detectron2 INFO: Inference done 15380/26446. 0.1681 s / img. ETA=0:31:24
[07/01 16:37:56] detectron2 INFO: Inference done 15410/26446. 0.1681 s / img. ETA=0:31:19
[07/01 16:38:01] detectron2 INFO: Inference done 15440/26446. 0.1681 s / img. ETA=0:31:14
[07/01 16:38:06] detectron2 INFO: Inference done 15470/26446. 0.1681 s / img. ETA=0:31:09
[07/01 16:38:11] detectron2 INFO: Inference done 15500/26446. 0.1681 s / img. ETA=0:31:04
[07/01 16:38:16] detectron2 INFO: Inference done 15530/26446. 0.1681 s / img. ETA=0:30:58
[07/01 16:38:21] detectron2 INFO: Inference done 15559/26446. 0.1681 s / img. ETA=0:30:54
[07/01 16:38:26] detectron2 INFO: Inference done 15589/26446. 0.1681 s / img. ETA=0:30:48
[07/01 16:38:31] detectron2 INFO: Inference done 15620/26446. 0.1680 s / img. ETA=0:30:43
[07/01 16:38:36] detectron2 INFO: Inference done 15650/26446. 0.1680 s / img. ETA=0:30:38
[07/01 16:38:41] detectron2 INFO: Inference done 15680/26446. 0.1680 s / img. ETA=0:30:33
[07/01 16:38:47] detectron2 INFO: Inference done 15710/26446. 0.1680 s / img. ETA=0:30:28
[07/01 16:38:52] detectron2 INFO: Inference done 15740/26446. 0.1680 s / img. ETA=0:30:22
[07/01 16:38:57] detectron2 INFO: Inference done 15770/26446. 0.1680 s / img. ETA=0:30:17
[07/01 16:39:02] detectron2 INFO: Inference done 15801/26446. 0.1680 s / img. ETA=0:30:12
[07/01 16:39:07] detectron2 INFO: Inference done 15831/26446. 0.1680 s / img. ETA=0:30:07
[07/01 16:39:12] detectron2 INFO: Inference done 15861/26446. 0.1680 s / img. ETA=0:30:02
[07/01 16:39:17] detectron2 INFO: Inference done 15891/26446. 0.1680 s / img. ETA=0:29:56
[07/01 16:39:22] detectron2 INFO: Inference done 15921/26446. 0.1680 s / img. ETA=0:29:51
[07/01 16:39:27] detectron2 INFO: Inference done 15951/26446. 0.1680 s / img. ETA=0:29:46
[07/01 16:39:32] detectron2 INFO: Inference done 15981/26446. 0.1680 s / img. ETA=0:29:41
[07/01 16:39:37] detectron2 INFO: Inference done 16011/26446. 0.1680 s / img. ETA=0:29:36
[07/01 16:39:42] detectron2 INFO: Inference done 16041/26446. 0.1680 s / img. ETA=0:29:31
[07/01 16:39:47] detectron2 INFO: Inference done 16071/26446. 0.1680 s / img. ETA=0:29:26
[07/01 16:39:53] detectron2 INFO: Inference done 16101/26446. 0.1680 s / img. ETA=0:29:21
[07/01 16:39:58] detectron2 INFO: Inference done 16131/26446. 0.1680 s / img. ETA=0:29:15
[07/01 16:40:03] detectron2 INFO: Inference done 16154/26446. 0.1681 s / img. ETA=0:29:12
[07/01 16:40:08] detectron2 INFO: Inference done 16184/26446. 0.1681 s / img. ETA=0:29:07
[07/01 16:40:13] detectron2 INFO: Inference done 16214/26446. 0.1681 s / img. ETA=0:29:02
[07/01 16:40:18] detectron2 INFO: Inference done 16244/26446. 0.1681 s / img. ETA=0:28:57
[07/01 16:40:23] detectron2 INFO: Inference done 16274/26446. 0.1681 s / img. ETA=0:28:52
[07/01 16:40:28] detectron2 INFO: Inference done 16304/26446. 0.1681 s / img. ETA=0:28:47
[07/01 16:40:33] detectron2 INFO: Inference done 16334/26446. 0.1681 s / img. ETA=0:28:42
[07/01 16:40:39] detectron2 INFO: Inference done 16364/26446. 0.1681 s / img. ETA=0:28:37
[07/01 16:40:44] detectron2 INFO: Inference done 16394/26446. 0.1681 s / img. ETA=0:28:31
[07/01 16:40:49] detectron2 INFO: Inference done 16424/26446. 0.1681 s / img. ETA=0:28:26
[07/01 16:40:54] detectron2 INFO: Inference done 16455/26446. 0.1681 s / img. ETA=0:28:21
[07/01 16:40:59] detectron2 INFO: Inference done 16485/26446. 0.1681 s / img. ETA=0:28:16
[07/01 16:41:04] detectron2 INFO: Inference done 16515/26446. 0.1681 s / img. ETA=0:28:11
[07/01 16:41:09] detectron2 INFO: Inference done 16545/26446. 0.1681 s / img. ETA=0:28:06
[07/01 16:41:14] detectron2 INFO: Inference done 16575/26446. 0.1681 s / img. ETA=0:28:01
[07/01 16:41:19] detectron2 INFO: Inference done 16605/26446. 0.1681 s / img. ETA=0:27:55
[07/01 16:41:24] detectron2 INFO: Inference done 16634/26446. 0.1681 s / img. ETA=0:27:51
[07/01 16:41:30] detectron2 INFO: Inference done 16664/26446. 0.1681 s / img. ETA=0:27:45
[07/01 16:41:35] detectron2 INFO: Inference done 16694/26446. 0.1681 s / img. ETA=0:27:40
[07/01 16:41:40] detectron2 INFO: Inference done 16724/26446. 0.1681 s / img. ETA=0:27:35
[07/01 16:41:45] detectron2 INFO: Inference done 16754/26446. 0.1681 s / img. ETA=0:27:30
[07/01 16:41:50] detectron2 INFO: Inference done 16785/26446. 0.1680 s / img. ETA=0:27:25
[07/01 16:41:55] detectron2 INFO: Inference done 16815/26446. 0.1680 s / img. ETA=0:27:20
[07/01 16:42:00] detectron2 INFO: Inference done 16845/26446. 0.1680 s / img. ETA=0:27:14
[07/01 16:42:05] detectron2 INFO: Inference done 16874/26446. 0.1681 s / img. ETA=0:27:10
[07/01 16:42:10] detectron2 INFO: Inference done 16904/26446. 0.1681 s / img. ETA=0:27:04
[07/01 16:42:15] detectron2 INFO: Inference done 16935/26446. 0.1680 s / img. ETA=0:26:59
[07/01 16:42:20] detectron2 INFO: Inference done 16965/26446. 0.1680 s / img. ETA=0:26:54
[07/01 16:42:26] detectron2 INFO: Inference done 16995/26446. 0.1680 s / img. ETA=0:26:49
[07/01 16:42:31] detectron2 INFO: Inference done 17026/26446. 0.1680 s / img. ETA=0:26:44
[07/01 16:42:36] detectron2 INFO: Inference done 17057/26446. 0.1680 s / img. ETA=0:26:38
[07/01 16:42:41] detectron2 INFO: Inference done 17087/26446. 0.1680 s / img. ETA=0:26:33
[07/01 16:42:46] detectron2 INFO: Inference done 17117/26446. 0.1680 s / img. ETA=0:26:28
[07/01 16:42:51] detectron2 INFO: Inference done 17147/26446. 0.1680 s / img. ETA=0:26:23
[07/01 16:42:56] detectron2 INFO: Inference done 17177/26446. 0.1680 s / img. ETA=0:26:18
[07/01 16:43:01] detectron2 INFO: Inference done 17207/26446. 0.1680 s / img. ETA=0:26:13
[07/01 16:43:06] detectron2 INFO: Inference done 17238/26446. 0.1680 s / img. ETA=0:26:07
[07/01 16:43:11] detectron2 INFO: Inference done 17268/26446. 0.1680 s / img. ETA=0:26:02
[07/01 16:43:16] detectron2 INFO: Inference done 17298/26446. 0.1680 s / img. ETA=0:25:57
[07/01 16:43:22] detectron2 INFO: Inference done 17328/26446. 0.1680 s / img. ETA=0:25:52
[07/01 16:43:27] detectron2 INFO: Inference done 17358/26446. 0.1680 s / img. ETA=0:25:47
[07/01 16:43:32] detectron2 INFO: Inference done 17387/26446. 0.1680 s / img. ETA=0:25:42
[07/01 16:43:37] detectron2 INFO: Inference done 17417/26446. 0.1680 s / img. ETA=0:25:37
[07/01 16:43:42] detectron2 INFO: Inference done 17448/26446. 0.1680 s / img. ETA=0:25:31
[07/01 16:43:47] detectron2 INFO: Inference done 17479/26446. 0.1680 s / img. ETA=0:25:26
[07/01 16:43:52] detectron2 INFO: Inference done 17509/26446. 0.1680 s / img. ETA=0:25:21
[07/01 16:43:57] detectron2 INFO: Inference done 17539/26446. 0.1680 s / img. ETA=0:25:16
[07/01 16:44:02] detectron2 INFO: Inference done 17569/26446. 0.1680 s / img. ETA=0:25:11
[07/01 16:44:07] detectron2 INFO: Inference done 17599/26446. 0.1680 s / img. ETA=0:25:06
[07/01 16:44:13] detectron2 INFO: Inference done 17629/26446. 0.1680 s / img. ETA=0:25:00
[07/01 16:44:18] detectron2 INFO: Inference done 17659/26446. 0.1680 s / img. ETA=0:24:55
[07/01 16:44:23] detectron2 INFO: Inference done 17689/26446. 0.1680 s / img. ETA=0:24:50
[07/01 16:44:28] detectron2 INFO: Inference done 17719/26446. 0.1680 s / img. ETA=0:24:45
[07/01 16:44:33] detectron2 INFO: Inference done 17749/26446. 0.1680 s / img. ETA=0:24:40
[07/01 16:44:38] detectron2 INFO: Inference done 17779/26446. 0.1680 s / img. ETA=0:24:35
[07/01 16:44:43] detectron2 INFO: Inference done 17809/26446. 0.1680 s / img. ETA=0:24:30
[07/01 16:44:48] detectron2 INFO: Inference done 17839/26446. 0.1680 s / img. ETA=0:24:25
[07/01 16:44:53] detectron2 INFO: Inference done 17869/26446. 0.1680 s / img. ETA=0:24:19
[07/01 16:44:58] detectron2 INFO: Inference done 17899/26446. 0.1680 s / img. ETA=0:24:14
[07/01 16:45:03] detectron2 INFO: Inference done 17930/26446. 0.1680 s / img. ETA=0:24:09
[07/01 16:45:08] detectron2 INFO: Inference done 17960/26446. 0.1680 s / img. ETA=0:24:04
[07/01 16:45:13] detectron2 INFO: Inference done 17990/26446. 0.1680 s / img. ETA=0:23:59
[07/01 16:45:19] detectron2 INFO: Inference done 18020/26446. 0.1680 s / img. ETA=0:23:54
[07/01 16:45:24] detectron2 INFO: Inference done 18050/26446. 0.1680 s / img. ETA=0:23:48
[07/01 16:45:29] detectron2 INFO: Inference done 18080/26446. 0.1679 s / img. ETA=0:23:43
[07/01 16:45:34] detectron2 INFO: Inference done 18110/26446. 0.1679 s / img. ETA=0:23:38
[07/01 16:45:39] detectron2 INFO: Inference done 18140/26446. 0.1679 s / img. ETA=0:23:33
[07/01 16:45:44] detectron2 INFO: Inference done 18170/26446. 0.1679 s / img. ETA=0:23:28
[07/01 16:45:49] detectron2 INFO: Inference done 18200/26446. 0.1679 s / img. ETA=0:23:23
[07/01 16:45:54] detectron2 INFO: Inference done 18230/26446. 0.1679 s / img. ETA=0:23:18
[07/01 16:45:59] detectron2 INFO: Inference done 18260/26446. 0.1679 s / img. ETA=0:23:13
[07/01 16:46:04] detectron2 INFO: Inference done 18291/26446. 0.1679 s / img. ETA=0:23:07
[07/01 16:46:09] detectron2 INFO: Inference done 18321/26446. 0.1679 s / img. ETA=0:23:02
[07/01 16:46:14] detectron2 INFO: Inference done 18351/26446. 0.1679 s / img. ETA=0:22:57
[07/01 16:46:19] detectron2 INFO: Inference done 18381/26446. 0.1679 s / img. ETA=0:22:52
[07/01 16:46:24] detectron2 INFO: Inference done 18411/26446. 0.1679 s / img. ETA=0:22:47
[07/01 16:46:29] detectron2 INFO: Inference done 18441/26446. 0.1679 s / img. ETA=0:22:42
[07/01 16:46:35] detectron2 INFO: Inference done 18471/26446. 0.1679 s / img. ETA=0:22:37
[07/01 16:46:40] detectron2 INFO: Inference done 18501/26446. 0.1679 s / img. ETA=0:22:31
[07/01 16:46:45] detectron2 INFO: Inference done 18531/26446. 0.1679 s / img. ETA=0:22:26
[07/01 16:46:50] detectron2 INFO: Inference done 18562/26446. 0.1679 s / img. ETA=0:22:21
[07/01 16:46:55] detectron2 INFO: Inference done 18592/26446. 0.1679 s / img. ETA=0:22:16
[07/01 16:47:00] detectron2 INFO: Inference done 18622/26446. 0.1679 s / img. ETA=0:22:11
[07/01 16:47:05] detectron2 INFO: Inference done 18652/26446. 0.1679 s / img. ETA=0:22:06
[07/01 16:47:10] detectron2 INFO: Inference done 18683/26446. 0.1679 s / img. ETA=0:22:00
[07/01 16:47:15] detectron2 INFO: Inference done 18712/26446. 0.1679 s / img. ETA=0:21:55
[07/01 16:47:20] detectron2 INFO: Inference done 18742/26446. 0.1679 s / img. ETA=0:21:50
[07/01 16:47:25] detectron2 INFO: Inference done 18772/26446. 0.1679 s / img. ETA=0:21:45
[07/01 16:47:30] detectron2 INFO: Inference done 18801/26446. 0.1679 s / img. ETA=0:21:40
[07/01 16:47:36] detectron2 INFO: Inference done 18832/26446. 0.1679 s / img. ETA=0:21:35
[07/01 16:47:41] detectron2 INFO: Inference done 18862/26446. 0.1679 s / img. ETA=0:21:30
[07/01 16:47:46] detectron2 INFO: Inference done 18893/26446. 0.1679 s / img. ETA=0:21:24
[07/01 16:47:51] detectron2 INFO: Inference done 18924/26446. 0.1679 s / img. ETA=0:21:19
[07/01 16:47:56] detectron2 INFO: Inference done 18955/26446. 0.1679 s / img. ETA=0:21:14
[07/01 16:48:01] detectron2 INFO: Inference done 18986/26446. 0.1679 s / img. ETA=0:21:08
[07/01 16:48:06] detectron2 INFO: Inference done 19016/26446. 0.1679 s / img. ETA=0:21:03
[07/01 16:48:11] detectron2 INFO: Inference done 19046/26446. 0.1679 s / img. ETA=0:20:58
[07/01 16:48:16] detectron2 INFO: Inference done 19075/26446. 0.1679 s / img. ETA=0:20:53
[07/01 16:48:21] detectron2 INFO: Inference done 19105/26446. 0.1679 s / img. ETA=0:20:48
[07/01 16:48:27] detectron2 INFO: Inference done 19135/26446. 0.1679 s / img. ETA=0:20:43
[07/01 16:48:32] detectron2 INFO: Inference done 19165/26446. 0.1679 s / img. ETA=0:20:38
[07/01 16:48:37] detectron2 INFO: Inference done 19195/26446. 0.1679 s / img. ETA=0:20:33
[07/01 16:48:42] detectron2 INFO: Inference done 19226/26446. 0.1679 s / img. ETA=0:20:28
[07/01 16:48:47] detectron2 INFO: Inference done 19256/26446. 0.1679 s / img. ETA=0:20:23
[07/01 16:48:52] detectron2 INFO: Inference done 19286/26446. 0.1679 s / img. ETA=0:20:17
[07/01 16:48:57] detectron2 INFO: Inference done 19316/26446. 0.1679 s / img. ETA=0:20:12
[07/01 16:49:02] detectron2 INFO: Inference done 19346/26446. 0.1678 s / img. ETA=0:20:07
[07/01 16:49:07] detectron2 INFO: Inference done 19376/26446. 0.1678 s / img. ETA=0:20:02
[07/01 16:49:12] detectron2 INFO: Inference done 19406/26446. 0.1678 s / img. ETA=0:19:57
[07/01 16:49:17] detectron2 INFO: Inference done 19435/26446. 0.1678 s / img. ETA=0:19:52
[07/01 16:49:22] detectron2 INFO: Inference done 19465/26446. 0.1678 s / img. ETA=0:19:47
[07/01 16:49:28] detectron2 INFO: Inference done 19496/26446. 0.1678 s / img. ETA=0:19:42
[07/01 16:49:33] detectron2 INFO: Inference done 19527/26446. 0.1678 s / img. ETA=0:19:36
[07/01 16:49:38] detectron2 INFO: Inference done 19557/26446. 0.1678 s / img. ETA=0:19:31
[07/01 16:49:43] detectron2 INFO: Inference done 19587/26446. 0.1678 s / img. ETA=0:19:26
[07/01 16:49:48] detectron2 INFO: Inference done 19615/26446. 0.1678 s / img. ETA=0:19:21
[07/01 16:49:53] detectron2 INFO: Inference done 19645/26446. 0.1678 s / img. ETA=0:19:16
[07/01 16:49:58] detectron2 INFO: Inference done 19675/26446. 0.1678 s / img. ETA=0:19:11
[07/01 16:50:03] detectron2 INFO: Inference done 19704/26446. 0.1679 s / img. ETA=0:19:06
[07/01 16:50:08] detectron2 INFO: Inference done 19731/26446. 0.1679 s / img. ETA=0:19:02
[07/01 16:50:13] detectron2 INFO: Inference done 19760/26446. 0.1679 s / img. ETA=0:18:57
[07/01 16:50:19] detectron2 INFO: Inference done 19788/26446. 0.1679 s / img. ETA=0:18:52
[07/01 16:50:24] detectron2 INFO: Inference done 19816/26446. 0.1679 s / img. ETA=0:18:48
[07/01 16:50:29] detectron2 INFO: Inference done 19844/26446. 0.1679 s / img. ETA=0:18:43
[07/01 16:50:34] detectron2 INFO: Inference done 19872/26446. 0.1679 s / img. ETA=0:18:38
[07/01 16:50:39] detectron2 INFO: Inference done 19900/26446. 0.1680 s / img. ETA=0:18:34
[07/01 16:50:44] detectron2 INFO: Inference done 19928/26446. 0.1680 s / img. ETA=0:18:29
[07/01 16:50:49] detectron2 INFO: Inference done 19953/26446. 0.1680 s / img. ETA=0:18:25
[07/01 16:50:54] detectron2 INFO: Inference done 19982/26446. 0.1680 s / img. ETA=0:18:20
[07/01 16:50:59] detectron2 INFO: Inference done 20011/26446. 0.1680 s / img. ETA=0:18:15
[07/01 16:51:04] detectron2 INFO: Inference done 20041/26446. 0.1680 s / img. ETA=0:18:10
[07/01 16:51:09] detectron2 INFO: Inference done 20071/26446. 0.1680 s / img. ETA=0:18:05
[07/01 16:51:14] detectron2 INFO: Inference done 20101/26446. 0.1680 s / img. ETA=0:18:00
[07/01 16:51:19] detectron2 INFO: Inference done 20130/26446. 0.1680 s / img. ETA=0:17:55
[07/01 16:51:24] detectron2 INFO: Inference done 20160/26446. 0.1680 s / img. ETA=0:17:50
[07/01 16:51:30] detectron2 INFO: Inference done 20190/26446. 0.1680 s / img. ETA=0:17:45
[07/01 16:51:35] detectron2 INFO: Inference done 20220/26446. 0.1680 s / img. ETA=0:17:40
[07/01 16:51:40] detectron2 INFO: Inference done 20250/26446. 0.1680 s / img. ETA=0:17:35
[07/01 16:51:45] detectron2 INFO: Inference done 20280/26446. 0.1680 s / img. ETA=0:17:29
[07/01 16:51:50] detectron2 INFO: Inference done 20310/26446. 0.1680 s / img. ETA=0:17:24
[07/01 16:51:55] detectron2 INFO: Inference done 20339/26446. 0.1680 s / img. ETA=0:17:19
[07/01 16:52:00] detectron2 INFO: Inference done 20369/26446. 0.1680 s / img. ETA=0:17:14
[07/01 16:52:05] detectron2 INFO: Inference done 20399/26446. 0.1680 s / img. ETA=0:17:09
[07/01 16:52:10] detectron2 INFO: Inference done 20429/26446. 0.1680 s / img. ETA=0:17:04
[07/01 16:52:15] detectron2 INFO: Inference done 20459/26446. 0.1680 s / img. ETA=0:16:59
[07/01 16:52:21] detectron2 INFO: Inference done 20489/26446. 0.1680 s / img. ETA=0:16:54
[07/01 16:52:26] detectron2 INFO: Inference done 20519/26446. 0.1680 s / img. ETA=0:16:49
[07/01 16:52:31] detectron2 INFO: Inference done 20549/26446. 0.1680 s / img. ETA=0:16:44
[07/01 16:52:36] detectron2 INFO: Inference done 20579/26446. 0.1680 s / img. ETA=0:16:39
[07/01 16:52:41] detectron2 INFO: Inference done 20609/26446. 0.1680 s / img. ETA=0:16:33
[07/01 16:52:46] detectron2 INFO: Inference done 20639/26446. 0.1680 s / img. ETA=0:16:28
[07/01 16:52:51] detectron2 INFO: Inference done 20669/26446. 0.1680 s / img. ETA=0:16:23
[07/01 16:52:56] detectron2 INFO: Inference done 20698/26446. 0.1680 s / img. ETA=0:16:18
[07/01 16:53:01] detectron2 INFO: Inference done 20727/26446. 0.1680 s / img. ETA=0:16:13
[07/01 16:53:06] detectron2 INFO: Inference done 20757/26446. 0.1680 s / img. ETA=0:16:08
[07/01 16:53:11] detectron2 INFO: Inference done 20787/26446. 0.1680 s / img. ETA=0:16:03
[07/01 16:53:16] detectron2 INFO: Inference done 20816/26446. 0.1680 s / img. ETA=0:15:58
[07/01 16:53:21] detectron2 INFO: Inference done 20845/26446. 0.1680 s / img. ETA=0:15:53
[07/01 16:53:26] detectron2 INFO: Inference done 20875/26446. 0.1680 s / img. ETA=0:15:48
[07/01 16:53:32] detectron2 INFO: Inference done 20905/26446. 0.1680 s / img. ETA=0:15:43
[07/01 16:53:37] detectron2 INFO: Inference done 20935/26446. 0.1680 s / img. ETA=0:15:38
[07/01 16:53:42] detectron2 INFO: Inference done 20965/26446. 0.1680 s / img. ETA=0:15:33
[07/01 16:53:47] detectron2 INFO: Inference done 20995/26446. 0.1680 s / img. ETA=0:15:28
[07/01 16:53:52] detectron2 INFO: Inference done 21025/26446. 0.1680 s / img. ETA=0:15:23
[07/01 16:53:57] detectron2 INFO: Inference done 21055/26446. 0.1680 s / img. ETA=0:15:18
[07/01 16:54:02] detectron2 INFO: Inference done 21085/26446. 0.1680 s / img. ETA=0:15:12
[07/01 16:54:07] detectron2 INFO: Inference done 21114/26446. 0.1680 s / img. ETA=0:15:08
[07/01 16:54:12] detectron2 INFO: Inference done 21144/26446. 0.1680 s / img. ETA=0:15:02
[07/01 16:54:17] detectron2 INFO: Inference done 21174/26446. 0.1680 s / img. ETA=0:14:57
[07/01 16:54:23] detectron2 INFO: Inference done 21204/26446. 0.1680 s / img. ETA=0:14:52
[07/01 16:54:28] detectron2 INFO: Inference done 21234/26446. 0.1680 s / img. ETA=0:14:47
[07/01 16:54:33] detectron2 INFO: Inference done 21264/26446. 0.1680 s / img. ETA=0:14:42
[07/01 16:54:38] detectron2 INFO: Inference done 21293/26446. 0.1680 s / img. ETA=0:14:37
[07/01 16:54:43] detectron2 INFO: Inference done 21324/26446. 0.1680 s / img. ETA=0:14:32
[07/01 16:54:48] detectron2 INFO: Inference done 21353/26446. 0.1680 s / img. ETA=0:14:27
[07/01 16:54:53] detectron2 INFO: Inference done 21383/26446. 0.1680 s / img. ETA=0:14:22
[07/01 16:54:58] detectron2 INFO: Inference done 21413/26446. 0.1680 s / img. ETA=0:14:17
[07/01 16:55:03] detectron2 INFO: Inference done 21442/26446. 0.1681 s / img. ETA=0:14:12
[07/01 16:55:08] detectron2 INFO: Inference done 21472/26446. 0.1681 s / img. ETA=0:14:07
[07/01 16:55:13] detectron2 INFO: Inference done 21502/26446. 0.1681 s / img. ETA=0:14:01
[07/01 16:55:19] detectron2 INFO: Inference done 21532/26446. 0.1681 s / img. ETA=0:13:56
[07/01 16:55:24] detectron2 INFO: Inference done 21562/26446. 0.1680 s / img. ETA=0:13:51
[07/01 16:55:29] detectron2 INFO: Inference done 21592/26446. 0.1680 s / img. ETA=0:13:46
[07/01 16:55:34] detectron2 INFO: Inference done 21622/26446. 0.1681 s / img. ETA=0:13:41
[07/01 16:55:39] detectron2 INFO: Inference done 21652/26446. 0.1680 s / img. ETA=0:13:36
[07/01 16:55:44] detectron2 INFO: Inference done 21682/26446. 0.1680 s / img. ETA=0:13:31
[07/01 16:55:49] detectron2 INFO: Inference done 21712/26446. 0.1680 s / img. ETA=0:13:26
[07/01 16:55:54] detectron2 INFO: Inference done 21742/26446. 0.1680 s / img. ETA=0:13:21
[07/01 16:55:59] detectron2 INFO: Inference done 21772/26446. 0.1680 s / img. ETA=0:13:15
[07/01 16:56:04] detectron2 INFO: Inference done 21801/26446. 0.1681 s / img. ETA=0:13:11
[07/01 16:56:10] detectron2 INFO: Inference done 21831/26446. 0.1681 s / img. ETA=0:13:05
[07/01 16:56:15] detectron2 INFO: Inference done 21861/26446. 0.1681 s / img. ETA=0:13:00
[07/01 16:56:20] detectron2 INFO: Inference done 21891/26446. 0.1681 s / img. ETA=0:12:55
[07/01 16:56:25] detectron2 INFO: Inference done 21921/26446. 0.1681 s / img. ETA=0:12:50
[07/01 16:56:30] detectron2 INFO: Inference done 21951/26446. 0.1681 s / img. ETA=0:12:45
[07/01 16:56:35] detectron2 INFO: Inference done 21981/26446. 0.1680 s / img. ETA=0:12:40
[07/01 16:56:40] detectron2 INFO: Inference done 22011/26446. 0.1680 s / img. ETA=0:12:35
[07/01 16:56:45] detectron2 INFO: Inference done 22041/26446. 0.1680 s / img. ETA=0:12:30
[07/01 16:56:50] detectron2 INFO: Inference done 22071/26446. 0.1680 s / img. ETA=0:12:25
[07/01 16:56:55] detectron2 INFO: Inference done 22101/26446. 0.1680 s / img. ETA=0:12:19
[07/01 16:57:00] detectron2 INFO: Inference done 22130/26446. 0.1680 s / img. ETA=0:12:15
[07/01 16:57:05] detectron2 INFO: Inference done 22159/26446. 0.1681 s / img. ETA=0:12:10
[07/01 16:57:11] detectron2 INFO: Inference done 22188/26446. 0.1681 s / img. ETA=0:12:05
[07/01 16:57:16] detectron2 INFO: Inference done 22218/26446. 0.1681 s / img. ETA=0:12:00
[07/01 16:57:21] detectron2 INFO: Inference done 22248/26446. 0.1681 s / img. ETA=0:11:55
[07/01 16:57:26] detectron2 INFO: Inference done 22277/26446. 0.1681 s / img. ETA=0:11:50
[07/01 16:57:31] detectron2 INFO: Inference done 22306/26446. 0.1681 s / img. ETA=0:11:45
[07/01 16:57:36] detectron2 INFO: Inference done 22336/26446. 0.1681 s / img. ETA=0:11:40
[07/01 16:57:41] detectron2 INFO: Inference done 22366/26446. 0.1681 s / img. ETA=0:11:34
[07/01 16:57:46] detectron2 INFO: Inference done 22396/26446. 0.1681 s / img. ETA=0:11:29
[07/01 16:57:51] detectron2 INFO: Inference done 22426/26446. 0.1681 s / img. ETA=0:11:24
[07/01 16:57:56] detectron2 INFO: Inference done 22456/26446. 0.1681 s / img. ETA=0:11:19
[07/01 16:58:02] detectron2 INFO: Inference done 22486/26446. 0.1681 s / img. ETA=0:11:14
[07/01 16:58:07] detectron2 INFO: Inference done 22516/26446. 0.1681 s / img. ETA=0:11:09
[07/01 16:58:12] detectron2 INFO: Inference done 22547/26446. 0.1681 s / img. ETA=0:11:04
[07/01 16:58:17] detectron2 INFO: Inference done 22577/26446. 0.1681 s / img. ETA=0:10:59
[07/01 16:58:22] detectron2 INFO: Inference done 22607/26446. 0.1681 s / img. ETA=0:10:53
[07/01 16:58:27] detectron2 INFO: Inference done 22636/26446. 0.1681 s / img. ETA=0:10:48
[07/01 16:58:32] detectron2 INFO: Inference done 22666/26446. 0.1681 s / img. ETA=0:10:43
[07/01 16:58:37] detectron2 INFO: Inference done 22696/26446. 0.1681 s / img. ETA=0:10:38
[07/01 16:58:42] detectron2 INFO: Inference done 22726/26446. 0.1681 s / img. ETA=0:10:33
[07/01 16:58:48] detectron2 INFO: Inference done 22755/26446. 0.1681 s / img. ETA=0:10:28
[07/01 16:58:53] detectron2 INFO: Inference done 22785/26446. 0.1681 s / img. ETA=0:10:23
[07/01 16:58:58] detectron2 INFO: Inference done 22815/26446. 0.1681 s / img. ETA=0:10:18
[07/01 16:59:03] detectron2 INFO: Inference done 22846/26446. 0.1681 s / img. ETA=0:10:13
[07/01 16:59:08] detectron2 INFO: Inference done 22876/26446. 0.1681 s / img. ETA=0:10:08
[07/01 16:59:13] detectron2 INFO: Inference done 22906/26446. 0.1681 s / img. ETA=0:10:02
[07/01 16:59:18] detectron2 INFO: Inference done 22936/26446. 0.1681 s / img. ETA=0:09:57
[07/01 16:59:23] detectron2 INFO: Inference done 22966/26446. 0.1681 s / img. ETA=0:09:52
[07/01 16:59:28] detectron2 INFO: Inference done 22996/26446. 0.1681 s / img. ETA=0:09:47
[07/01 16:59:33] detectron2 INFO: Inference done 23026/26446. 0.1681 s / img. ETA=0:09:42
[07/01 16:59:38] detectron2 INFO: Inference done 23057/26446. 0.1681 s / img. ETA=0:09:37
[07/01 16:59:44] detectron2 INFO: Inference done 23087/26446. 0.1681 s / img. ETA=0:09:32
[07/01 16:59:49] detectron2 INFO: Inference done 23117/26446. 0.1681 s / img. ETA=0:09:26
[07/01 16:59:54] detectron2 INFO: Inference done 23147/26446. 0.1681 s / img. ETA=0:09:21
[07/01 16:59:59] detectron2 INFO: Inference done 23177/26446. 0.1681 s / img. ETA=0:09:16
[07/01 17:00:04] detectron2 INFO: Inference done 23207/26446. 0.1681 s / img. ETA=0:09:11
[07/01 17:00:09] detectron2 INFO: Inference done 23237/26446. 0.1681 s / img. ETA=0:09:06
[07/01 17:00:14] detectron2 INFO: Inference done 23267/26446. 0.1681 s / img. ETA=0:09:01
[07/01 17:00:19] detectron2 INFO: Inference done 23297/26446. 0.1681 s / img. ETA=0:08:56
[07/01 17:00:25] detectron2 INFO: Inference done 23327/26446. 0.1681 s / img. ETA=0:08:51
[07/01 17:00:30] detectron2 INFO: Inference done 23356/26446. 0.1681 s / img. ETA=0:08:46
[07/01 17:00:35] detectron2 INFO: Inference done 23386/26446. 0.1681 s / img. ETA=0:08:41
[07/01 17:00:40] detectron2 INFO: Inference done 23416/26446. 0.1681 s / img. ETA=0:08:36
[07/01 17:00:45] detectron2 INFO: Inference done 23446/26446. 0.1681 s / img. ETA=0:08:30
[07/01 17:00:50] detectron2 INFO: Inference done 23476/26446. 0.1681 s / img. ETA=0:08:25
[07/01 17:00:55] detectron2 INFO: Inference done 23506/26446. 0.1681 s / img. ETA=0:08:20
[07/01 17:10:17] detectron2 INFO: Rank of current process: 0. World size: 1
[07/01 17:10:19] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/01 17:10:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '1', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/01 17:10:19] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 1
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/01 17:10:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 1
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/01 17:10:19] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/01 17:10:19] d2.utils.env INFO: Using a generated random seed 19574890
[07/01 17:10:25] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/01 17:10:25] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 17:10:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/01 17:10:28] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/01 17:10:28] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/01 17:10:28] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/01 17:10:32] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/01 17:10:32] detectron2 INFO: Following metrics will be use for evaluation
[07/01 17:10:32] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/01 17:10:32] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/01 17:10:32] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/01 17:10:32] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/01 17:10:32] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/01 17:10:37] detectron2 INFO: Loading zero shot triplets
[07/01 17:10:37] detectron2 INFO: Start inference on 26446 images
[07/01 17:11:25] detectron2 INFO: Inference done 1/26446. 7.1289 s / img. ETA=14 days, 15:14:45
[07/01 17:11:30] detectron2 INFO: Inference done 25/26446. 0.2065 s / img. ETA=1:32:12
[07/01 17:11:35] detectron2 INFO: Inference done 50/26446. 0.2033 s / img. ETA=1:30:45
[07/01 17:11:40] detectron2 INFO: Inference done 76/26446. 0.2008 s / img. ETA=1:29:29
[07/01 17:11:45] detectron2 INFO: Inference done 103/26446. 0.1973 s / img. ETA=1:27:51
[07/01 17:11:50] detectron2 INFO: Inference done 132/26446. 0.1913 s / img. ETA=1:25:04
[07/01 17:11:55] detectron2 INFO: Inference done 162/26446. 0.1874 s / img. ETA=1:23:13
[07/01 17:12:00] detectron2 INFO: Inference done 189/26446. 0.1870 s / img. ETA=1:22:59
[07/01 17:12:05] detectron2 INFO: Inference done 218/26446. 0.1850 s / img. ETA=1:21:57
[07/01 17:12:11] detectron2 INFO: Inference done 246/26446. 0.1845 s / img. ETA=1:21:41
[07/01 17:12:16] detectron2 INFO: Inference done 277/26446. 0.1821 s / img. ETA=1:20:31
[07/01 17:12:21] detectron2 INFO: Inference done 308/26446. 0.1802 s / img. ETA=1:19:34
[07/01 17:12:26] detectron2 INFO: Inference done 338/26446. 0.1788 s / img. ETA=1:18:52
[07/01 17:12:31] detectron2 INFO: Inference done 369/26446. 0.1774 s / img. ETA=1:18:08
[07/01 17:12:36] detectron2 INFO: Inference done 399/26446. 0.1764 s / img. ETA=1:17:36
[07/01 17:12:41] detectron2 INFO: Inference done 430/26446. 0.1754 s / img. ETA=1:17:05
[07/01 17:12:46] detectron2 INFO: Inference done 460/26446. 0.1748 s / img. ETA=1:16:43
[07/01 17:12:51] detectron2 INFO: Inference done 491/26446. 0.1739 s / img. ETA=1:16:15
[07/01 17:12:56] detectron2 INFO: Inference done 522/26446. 0.1732 s / img. ETA=1:15:50
[07/01 17:13:01] detectron2 INFO: Inference done 553/26446. 0.1726 s / img. ETA=1:15:28
[07/01 17:13:06] detectron2 INFO: Inference done 584/26446. 0.1719 s / img. ETA=1:15:06
[07/01 17:13:11] detectron2 INFO: Inference done 614/26446. 0.1716 s / img. ETA=1:14:52
[07/01 17:13:16] detectron2 INFO: Inference done 643/26446. 0.1716 s / img. ETA=1:14:47
[07/01 17:13:22] detectron2 INFO: Inference done 670/26446. 0.1722 s / img. ETA=1:14:59
[07/01 17:13:27] detectron2 INFO: Inference done 697/26446. 0.1727 s / img. ETA=1:15:06
[07/01 17:13:32] detectron2 INFO: Inference done 723/26446. 0.1734 s / img. ETA=1:15:21
[07/01 17:13:37] detectron2 INFO: Inference done 749/26446. 0.1742 s / img. ETA=1:15:37
[07/01 17:13:42] detectron2 INFO: Inference done 777/26446. 0.1745 s / img. ETA=1:15:39
[07/01 17:13:47] detectron2 INFO: Inference done 804/26446. 0.1748 s / img. ETA=1:15:43
[07/01 17:13:52] detectron2 INFO: Inference done 833/26446. 0.1747 s / img. ETA=1:15:36
[07/01 17:13:57] detectron2 INFO: Inference done 863/26446. 0.1744 s / img. ETA=1:15:23
[07/01 17:14:02] detectron2 INFO: Inference done 893/26446. 0.1741 s / img. ETA=1:15:09
[07/01 17:14:07] detectron2 INFO: Inference done 923/26446. 0.1738 s / img. ETA=1:14:56
[07/01 17:14:12] detectron2 INFO: Inference done 954/26446. 0.1734 s / img. ETA=1:14:41
[07/01 17:14:17] detectron2 INFO: Inference done 984/26446. 0.1732 s / img. ETA=1:14:29
[07/01 17:14:22] detectron2 INFO: Inference done 1015/26446. 0.1728 s / img. ETA=1:14:14
[07/01 17:14:28] detectron2 INFO: Inference done 1046/26446. 0.1725 s / img. ETA=1:14:01
[07/01 17:14:33] detectron2 INFO: Inference done 1075/26446. 0.1725 s / img. ETA=1:13:55
[07/01 17:14:38] detectron2 INFO: Inference done 1105/26446. 0.1724 s / img. ETA=1:13:47
[07/01 17:14:43] detectron2 INFO: Inference done 1135/26446. 0.1722 s / img. ETA=1:13:37
[07/01 17:14:48] detectron2 INFO: Inference done 1165/26446. 0.1720 s / img. ETA=1:13:27
[07/01 17:14:53] detectron2 INFO: Inference done 1195/26446. 0.1719 s / img. ETA=1:13:20
[07/01 17:14:58] detectron2 INFO: Inference done 1225/26446. 0.1719 s / img. ETA=1:13:13
[07/01 17:15:03] detectron2 INFO: Inference done 1253/26446. 0.1721 s / img. ETA=1:13:14
[07/01 17:15:08] detectron2 INFO: Inference done 1278/26446. 0.1728 s / img. ETA=1:13:27
[07/01 17:15:13] detectron2 INFO: Inference done 1302/26446. 0.1734 s / img. ETA=1:13:39
[07/01 17:15:19] detectron2 INFO: Inference done 1327/26446. 0.1740 s / img. ETA=1:13:48
[07/01 17:15:24] detectron2 INFO: Inference done 1352/26446. 0.1744 s / img. ETA=1:13:55
[07/01 17:15:29] detectron2 INFO: Inference done 1377/26446. 0.1748 s / img. ETA=1:14:01
[07/01 17:15:34] detectron2 INFO: Inference done 1402/26446. 0.1753 s / img. ETA=1:14:08
[07/01 17:15:39] detectron2 INFO: Inference done 1428/26446. 0.1757 s / img. ETA=1:14:13
[07/01 17:15:44] detectron2 INFO: Inference done 1455/26446. 0.1759 s / img. ETA=1:14:15
[07/01 17:15:49] detectron2 INFO: Inference done 1485/26446. 0.1757 s / img. ETA=1:14:04
[07/01 17:15:54] detectron2 INFO: Inference done 1516/26446. 0.1754 s / img. ETA=1:13:51
[07/01 17:15:59] detectron2 INFO: Inference done 1547/26446. 0.1751 s / img. ETA=1:13:39
[07/01 17:16:04] detectron2 INFO: Inference done 1578/26446. 0.1749 s / img. ETA=1:13:27
[07/01 17:16:09] detectron2 INFO: Inference done 1610/26446. 0.1746 s / img. ETA=1:13:14
[07/01 17:16:15] detectron2 INFO: Inference done 1640/26446. 0.1744 s / img. ETA=1:13:05
[07/01 17:16:20] detectron2 INFO: Inference done 1670/26446. 0.1743 s / img. ETA=1:12:57
[07/01 17:16:25] detectron2 INFO: Inference done 1700/26446. 0.1742 s / img. ETA=1:12:49
[07/01 17:16:30] detectron2 INFO: Inference done 1730/26446. 0.1741 s / img. ETA=1:12:41
[07/01 17:16:35] detectron2 INFO: Inference done 1760/26446. 0.1740 s / img. ETA=1:12:34
[07/01 17:16:40] detectron2 INFO: Inference done 1789/26446. 0.1740 s / img. ETA=1:12:28
[07/01 17:16:45] detectron2 INFO: Inference done 1815/26446. 0.1743 s / img. ETA=1:12:29
[07/01 17:16:50] detectron2 INFO: Inference done 1841/26446. 0.1745 s / img. ETA=1:12:32
[07/01 17:16:55] detectron2 INFO: Inference done 1867/26446. 0.1749 s / img. ETA=1:12:35
[07/01 17:17:01] detectron2 INFO: Inference done 1893/26446. 0.1751 s / img. ETA=1:12:37
[07/01 17:17:06] detectron2 INFO: Inference done 1920/26446. 0.1753 s / img. ETA=1:12:38
[07/01 17:17:11] detectron2 INFO: Inference done 1946/26446. 0.1756 s / img. ETA=1:12:40
[07/01 17:17:16] detectron2 INFO: Inference done 1972/26446. 0.1758 s / img. ETA=1:12:41
[07/01 17:17:21] detectron2 INFO: Inference done 1998/26446. 0.1760 s / img. ETA=1:12:41
[07/01 17:17:27] detectron2 INFO: Inference done 2015/26446. 0.1774 s / img. ETA=1:13:11
[07/01 17:17:32] detectron2 INFO: Inference done 2045/26446. 0.1772 s / img. ETA=1:13:02
[07/01 17:17:37] detectron2 INFO: Inference done 2074/26446. 0.1772 s / img. ETA=1:12:55
[07/01 17:17:42] detectron2 INFO: Inference done 2103/26446. 0.1771 s / img. ETA=1:12:49
[07/01 17:17:47] detectron2 INFO: Inference done 2131/26446. 0.1771 s / img. ETA=1:12:44
[07/01 17:17:52] detectron2 INFO: Inference done 2161/26446. 0.1770 s / img. ETA=1:12:35
[07/01 17:17:57] detectron2 INFO: Inference done 2191/26446. 0.1768 s / img. ETA=1:12:26
[07/01 17:18:02] detectron2 INFO: Inference done 2222/26446. 0.1766 s / img. ETA=1:12:16
[07/01 17:18:07] detectron2 INFO: Inference done 2252/26446. 0.1765 s / img. ETA=1:12:07
[07/01 17:18:13] detectron2 INFO: Inference done 2282/26446. 0.1764 s / img. ETA=1:11:59
[07/01 17:18:18] detectron2 INFO: Inference done 2313/26446. 0.1762 s / img. ETA=1:11:49
[07/01 17:18:23] detectron2 INFO: Inference done 2339/26446. 0.1764 s / img. ETA=1:11:49
[07/01 17:18:28] detectron2 INFO: Inference done 2366/26446. 0.1765 s / img. ETA=1:11:47
[07/01 17:18:33] detectron2 INFO: Inference done 2394/26446. 0.1765 s / img. ETA=1:11:43
[07/01 17:18:38] detectron2 INFO: Inference done 2418/26446. 0.1769 s / img. ETA=1:11:46
[07/01 17:18:43] detectron2 INFO: Inference done 2439/26446. 0.1774 s / img. ETA=1:11:56
[07/01 17:18:48] detectron2 INFO: Inference done 2464/26446. 0.1776 s / img. ETA=1:11:57
[07/01 17:18:53] detectron2 INFO: Inference done 2490/26446. 0.1778 s / img. ETA=1:11:56
[07/01 17:18:58] detectron2 INFO: Inference done 2516/26446. 0.1780 s / img. ETA=1:11:55
[07/01 17:19:03] detectron2 INFO: Inference done 2542/26446. 0.1781 s / img. ETA=1:11:54
[07/01 17:19:09] detectron2 INFO: Inference done 2569/26446. 0.1782 s / img. ETA=1:11:52
[07/01 17:19:14] detectron2 INFO: Inference done 2595/26446. 0.1784 s / img. ETA=1:11:51
[07/01 17:19:19] detectron2 INFO: Inference done 2625/26446. 0.1783 s / img. ETA=1:11:43
[07/01 17:19:24] detectron2 INFO: Inference done 2656/26446. 0.1781 s / img. ETA=1:11:33
[07/01 17:19:29] detectron2 INFO: Inference done 2686/26446. 0.1779 s / img. ETA=1:11:23
[07/01 17:19:34] detectron2 INFO: Inference done 2715/26446. 0.1778 s / img. ETA=1:11:17
[07/01 17:19:39] detectron2 INFO: Inference done 2746/26446. 0.1777 s / img. ETA=1:11:07
[07/01 17:19:44] detectron2 INFO: Inference done 2776/26446. 0.1776 s / img. ETA=1:10:59
[07/01 17:19:49] detectron2 INFO: Inference done 2807/26446. 0.1774 s / img. ETA=1:10:50
[07/01 17:19:54] detectron2 INFO: Inference done 2837/26446. 0.1773 s / img. ETA=1:10:42
[07/01 17:19:59] detectron2 INFO: Inference done 2867/26446. 0.1772 s / img. ETA=1:10:33
[07/01 17:20:04] detectron2 INFO: Inference done 2897/26446. 0.1771 s / img. ETA=1:10:25
[07/01 17:20:10] detectron2 INFO: Inference done 2927/26446. 0.1770 s / img. ETA=1:10:17
[07/01 17:20:15] detectron2 INFO: Inference done 2957/26446. 0.1768 s / img. ETA=1:10:09
[07/01 17:20:20] detectron2 INFO: Inference done 2986/26446. 0.1768 s / img. ETA=1:10:03
[07/01 17:20:25] detectron2 INFO: Inference done 3012/26446. 0.1770 s / img. ETA=1:10:03
[07/01 17:20:30] detectron2 INFO: Inference done 3040/26446. 0.1770 s / img. ETA=1:09:58
[07/01 17:20:35] detectron2 INFO: Inference done 3067/26446. 0.1771 s / img. ETA=1:09:56
[07/01 17:20:40] detectron2 INFO: Inference done 3095/26446. 0.1771 s / img. ETA=1:09:52
[07/01 17:20:45] detectron2 INFO: Inference done 3123/26446. 0.1772 s / img. ETA=1:09:47
[07/01 17:20:50] detectron2 INFO: Inference done 3153/26446. 0.1771 s / img. ETA=1:09:39
[07/01 17:20:56] detectron2 INFO: Inference done 3184/26446. 0.1769 s / img. ETA=1:09:30
[07/01 17:21:01] detectron2 INFO: Inference done 3215/26446. 0.1768 s / img. ETA=1:09:21
[07/01 17:21:06] detectron2 INFO: Inference done 3246/26446. 0.1766 s / img. ETA=1:09:12
[07/01 17:21:11] detectron2 INFO: Inference done 3277/26446. 0.1765 s / img. ETA=1:09:04
[07/01 17:21:16] detectron2 INFO: Inference done 3308/26446. 0.1764 s / img. ETA=1:08:55
[07/01 17:21:21] detectron2 INFO: Inference done 3339/26446. 0.1763 s / img. ETA=1:08:47
[07/01 17:21:26] detectron2 INFO: Inference done 3369/26446. 0.1762 s / img. ETA=1:08:39
[07/01 17:21:31] detectron2 INFO: Inference done 3399/26446. 0.1761 s / img. ETA=1:08:32
[07/01 17:21:36] detectron2 INFO: Inference done 3429/26446. 0.1760 s / img. ETA=1:08:24
[07/01 17:21:41] detectron2 INFO: Inference done 3460/26446. 0.1759 s / img. ETA=1:08:16
[07/01 17:21:46] detectron2 INFO: Inference done 3491/26446. 0.1757 s / img. ETA=1:08:08
[07/01 17:21:51] detectron2 INFO: Inference done 3521/26446. 0.1757 s / img. ETA=1:08:01
[07/01 17:21:56] detectron2 INFO: Inference done 3551/26446. 0.1756 s / img. ETA=1:07:53
[07/01 17:22:02] detectron2 INFO: Inference done 3582/26446. 0.1755 s / img. ETA=1:07:45
[07/01 17:22:07] detectron2 INFO: Inference done 3612/26446. 0.1754 s / img. ETA=1:07:38
[07/01 17:22:12] detectron2 INFO: Inference done 3641/26446. 0.1754 s / img. ETA=1:07:32
[07/01 17:22:17] detectron2 INFO: Inference done 3672/26446. 0.1753 s / img. ETA=1:07:24
[07/01 17:22:22] detectron2 INFO: Inference done 3700/26446. 0.1753 s / img. ETA=1:07:20
[07/01 17:22:27] detectron2 INFO: Inference done 3730/26446. 0.1752 s / img. ETA=1:07:13
[07/01 17:22:32] detectron2 INFO: Inference done 3760/26446. 0.1752 s / img. ETA=1:07:07
[07/01 17:22:37] detectron2 INFO: Inference done 3791/26446. 0.1751 s / img. ETA=1:06:59
[07/01 17:22:42] detectron2 INFO: Inference done 3821/26446. 0.1750 s / img. ETA=1:06:52
[07/01 17:22:47] detectron2 INFO: Inference done 3852/26446. 0.1749 s / img. ETA=1:06:43
[07/01 17:22:52] detectron2 INFO: Inference done 3882/26446. 0.1748 s / img. ETA=1:06:37
[07/01 17:22:57] detectron2 INFO: Inference done 3913/26446. 0.1747 s / img. ETA=1:06:29
[07/01 17:23:02] detectron2 INFO: Inference done 3943/26446. 0.1746 s / img. ETA=1:06:22
[07/01 17:23:08] detectron2 INFO: Inference done 3974/26446. 0.1746 s / img. ETA=1:06:15
[07/01 17:23:13] detectron2 INFO: Inference done 4005/26446. 0.1745 s / img. ETA=1:06:07
[07/01 17:23:18] detectron2 INFO: Inference done 4035/26446. 0.1744 s / img. ETA=1:06:01
[07/01 17:23:23] detectron2 INFO: Inference done 4065/26446. 0.1744 s / img. ETA=1:05:55
[07/01 17:23:28] detectron2 INFO: Inference done 4095/26446. 0.1743 s / img. ETA=1:05:48
[07/01 17:23:33] detectron2 INFO: Inference done 4124/26446. 0.1743 s / img. ETA=1:05:43
[07/01 17:23:38] detectron2 INFO: Inference done 4152/26446. 0.1744 s / img. ETA=1:05:39
[07/01 17:23:43] detectron2 INFO: Inference done 4181/26446. 0.1744 s / img. ETA=1:05:34
[07/01 17:23:48] detectron2 INFO: Inference done 4210/26446. 0.1743 s / img. ETA=1:05:28
[07/01 17:23:54] detectron2 INFO: Inference done 4239/26446. 0.1743 s / img. ETA=1:05:23
[07/01 17:23:59] detectron2 INFO: Inference done 4267/26446. 0.1744 s / img. ETA=1:05:19
[07/01 17:24:04] detectron2 INFO: Inference done 4296/26446. 0.1744 s / img. ETA=1:05:14
[07/01 17:24:09] detectron2 INFO: Inference done 4326/26446. 0.1743 s / img. ETA=1:05:08
[07/01 17:24:14] detectron2 INFO: Inference done 4354/26446. 0.1744 s / img. ETA=1:05:04
[07/01 17:24:19] detectron2 INFO: Inference done 4382/26446. 0.1744 s / img. ETA=1:04:59
[07/01 17:24:24] detectron2 INFO: Inference done 4410/26446. 0.1744 s / img. ETA=1:04:55
[07/01 17:24:29] detectron2 INFO: Inference done 4440/26446. 0.1744 s / img. ETA=1:04:49
[07/01 17:24:34] detectron2 INFO: Inference done 4469/26446. 0.1744 s / img. ETA=1:04:43
[07/01 17:24:39] detectron2 INFO: Inference done 4499/26446. 0.1743 s / img. ETA=1:04:37
[07/01 17:24:45] detectron2 INFO: Inference done 4529/26446. 0.1743 s / img. ETA=1:04:31
[07/01 17:24:50] detectron2 INFO: Inference done 4559/26446. 0.1742 s / img. ETA=1:04:24
[07/01 17:24:55] detectron2 INFO: Inference done 4590/26446. 0.1742 s / img. ETA=1:04:17
[07/01 17:25:00] detectron2 INFO: Inference done 4619/26446. 0.1741 s / img. ETA=1:04:11
[07/01 17:25:05] detectron2 INFO: Inference done 4648/26446. 0.1741 s / img. ETA=1:04:07
[07/01 17:25:10] detectron2 INFO: Inference done 4678/26446. 0.1741 s / img. ETA=1:04:00
[07/01 17:25:15] detectron2 INFO: Inference done 4709/26446. 0.1740 s / img. ETA=1:03:53
[07/01 17:25:20] detectron2 INFO: Inference done 4740/26446. 0.1740 s / img. ETA=1:03:46
[07/01 17:25:25] detectron2 INFO: Inference done 4770/26446. 0.1739 s / img. ETA=1:03:40
[07/01 17:25:30] detectron2 INFO: Inference done 4799/26446. 0.1739 s / img. ETA=1:03:35
[07/01 17:25:35] detectron2 INFO: Inference done 4826/26446. 0.1740 s / img. ETA=1:03:31
[07/01 17:25:40] detectron2 INFO: Inference done 4855/26446. 0.1739 s / img. ETA=1:03:26
[07/01 17:25:46] detectron2 INFO: Inference done 4885/26446. 0.1739 s / img. ETA=1:03:19
[07/01 17:25:51] detectron2 INFO: Inference done 4915/26446. 0.1738 s / img. ETA=1:03:13
[07/01 17:25:56] detectron2 INFO: Inference done 4945/26446. 0.1738 s / img. ETA=1:03:06
[07/01 17:26:01] detectron2 INFO: Inference done 4975/26446. 0.1737 s / img. ETA=1:03:00
[07/01 17:26:06] detectron2 INFO: Inference done 5006/26446. 0.1737 s / img. ETA=1:02:53
[07/01 17:26:11] detectron2 INFO: Inference done 5037/26446. 0.1736 s / img. ETA=1:02:46
[07/01 17:26:16] detectron2 INFO: Inference done 5068/26446. 0.1735 s / img. ETA=1:02:39
[07/01 17:26:21] detectron2 INFO: Inference done 5099/26446. 0.1735 s / img. ETA=1:02:32
[07/01 17:26:26] detectron2 INFO: Inference done 5128/26446. 0.1734 s / img. ETA=1:02:27
[07/01 17:26:31] detectron2 INFO: Inference done 5158/26446. 0.1734 s / img. ETA=1:02:20
[07/01 17:26:36] detectron2 INFO: Inference done 5189/26446. 0.1733 s / img. ETA=1:02:14
[07/01 17:26:41] detectron2 INFO: Inference done 5220/26446. 0.1733 s / img. ETA=1:02:07
[07/01 17:26:46] detectron2 INFO: Inference done 5250/26446. 0.1732 s / img. ETA=1:02:01
[07/01 17:26:52] detectron2 INFO: Inference done 5281/26446. 0.1732 s / img. ETA=1:01:54
[07/01 17:26:57] detectron2 INFO: Inference done 5311/26446. 0.1731 s / img. ETA=1:01:48
[07/01 17:27:02] detectron2 INFO: Inference done 5342/26446. 0.1731 s / img. ETA=1:01:41
[07/01 17:27:07] detectron2 INFO: Inference done 5369/26446. 0.1731 s / img. ETA=1:01:38
[07/01 17:27:12] detectron2 INFO: Inference done 5396/26446. 0.1732 s / img. ETA=1:01:34
[07/01 17:27:17] detectron2 INFO: Inference done 5423/26446. 0.1732 s / img. ETA=1:01:30
[07/01 17:27:22] detectron2 INFO: Inference done 5452/26446. 0.1732 s / img. ETA=1:01:26
[07/01 17:27:27] detectron2 INFO: Inference done 5483/26446. 0.1732 s / img. ETA=1:01:19
[07/01 17:27:32] detectron2 INFO: Inference done 5514/26446. 0.1731 s / img. ETA=1:01:12
[07/01 17:27:37] detectron2 INFO: Inference done 5545/26446. 0.1731 s / img. ETA=1:01:06
[07/01 17:27:42] detectron2 INFO: Inference done 5576/26446. 0.1730 s / img. ETA=1:00:59
[07/01 17:27:47] detectron2 INFO: Inference done 5607/26446. 0.1730 s / img. ETA=1:00:52
[07/01 17:27:53] detectron2 INFO: Inference done 5638/26446. 0.1729 s / img. ETA=1:00:45
[07/01 17:27:58] detectron2 INFO: Inference done 5668/26446. 0.1728 s / img. ETA=1:00:39
[07/01 17:28:03] detectron2 INFO: Inference done 5699/26446. 0.1728 s / img. ETA=1:00:33
[07/01 17:28:08] detectron2 INFO: Inference done 5729/26446. 0.1728 s / img. ETA=1:00:27
[07/01 17:28:13] detectron2 INFO: Inference done 5759/26446. 0.1727 s / img. ETA=1:00:21
[07/01 17:28:18] detectron2 INFO: Inference done 5790/26446. 0.1727 s / img. ETA=1:00:14
[07/01 17:28:23] detectron2 INFO: Inference done 5818/26446. 0.1727 s / img. ETA=1:00:10
[07/01 17:28:28] detectron2 INFO: Inference done 5845/26446. 0.1727 s / img. ETA=1:00:06
[07/01 17:28:33] detectron2 INFO: Inference done 5873/26446. 0.1728 s / img. ETA=1:00:02
[07/01 17:28:38] detectron2 INFO: Inference done 5900/26446. 0.1729 s / img. ETA=0:59:59
[07/01 17:28:43] detectron2 INFO: Inference done 5930/26446. 0.1728 s / img. ETA=0:59:53
[07/01 17:28:48] detectron2 INFO: Inference done 5961/26446. 0.1728 s / img. ETA=0:59:46
[07/01 17:28:53] detectron2 INFO: Inference done 5991/26446. 0.1727 s / img. ETA=0:59:40
[07/01 17:28:59] detectron2 INFO: Inference done 6022/26446. 0.1727 s / img. ETA=0:59:34
[07/01 17:29:04] detectron2 INFO: Inference done 6053/26446. 0.1726 s / img. ETA=0:59:28
[07/01 17:29:09] detectron2 INFO: Inference done 6084/26446. 0.1726 s / img. ETA=0:59:21
[07/01 17:29:14] detectron2 INFO: Inference done 6115/26446. 0.1725 s / img. ETA=0:59:14
[07/01 17:29:19] detectron2 INFO: Inference done 6146/26446. 0.1725 s / img. ETA=0:59:08
[07/01 17:29:24] detectron2 INFO: Inference done 6177/26446. 0.1724 s / img. ETA=0:59:02
[07/01 17:29:29] detectron2 INFO: Inference done 6208/26446. 0.1724 s / img. ETA=0:58:55
[07/01 17:29:34] detectron2 INFO: Inference done 6238/26446. 0.1724 s / img. ETA=0:58:49
[07/01 17:29:39] detectron2 INFO: Inference done 6269/26446. 0.1723 s / img. ETA=0:58:43
[07/01 17:29:44] detectron2 INFO: Inference done 6296/26446. 0.1724 s / img. ETA=0:58:39
[07/01 17:29:49] detectron2 INFO: Inference done 6323/26446. 0.1724 s / img. ETA=0:58:36
[07/01 17:29:55] detectron2 INFO: Inference done 6351/26446. 0.1724 s / img. ETA=0:58:31
[07/01 17:30:00] detectron2 INFO: Inference done 6380/26446. 0.1724 s / img. ETA=0:58:26
[07/01 17:30:05] detectron2 INFO: Inference done 6410/26446. 0.1724 s / img. ETA=0:58:21
[07/01 17:30:10] detectron2 INFO: Inference done 6440/26446. 0.1724 s / img. ETA=0:58:15
[07/01 17:30:15] detectron2 INFO: Inference done 6471/26446. 0.1723 s / img. ETA=0:58:08
[07/01 17:30:20] detectron2 INFO: Inference done 6501/26446. 0.1723 s / img. ETA=0:58:03
[07/01 17:30:25] detectron2 INFO: Inference done 6531/26446. 0.1723 s / img. ETA=0:57:57
[07/01 17:30:30] detectron2 INFO: Inference done 6561/26446. 0.1722 s / img. ETA=0:57:51
[07/01 17:30:35] detectron2 INFO: Inference done 6592/26446. 0.1722 s / img. ETA=0:57:44
[07/01 17:30:40] detectron2 INFO: Inference done 6622/26446. 0.1722 s / img. ETA=0:57:39
[07/01 17:30:45] detectron2 INFO: Inference done 6653/26446. 0.1721 s / img. ETA=0:57:32
[07/01 17:30:50] detectron2 INFO: Inference done 6684/26446. 0.1721 s / img. ETA=0:57:26
[07/01 17:30:56] detectron2 INFO: Inference done 6715/26446. 0.1721 s / img. ETA=0:57:20
[07/01 17:31:01] detectron2 INFO: Inference done 6745/26446. 0.1720 s / img. ETA=0:57:14
[07/01 17:31:06] detectron2 INFO: Inference done 6776/26446. 0.1720 s / img. ETA=0:57:08
[07/01 17:31:11] detectron2 INFO: Inference done 6807/26446. 0.1719 s / img. ETA=0:57:02
[07/01 17:31:16] detectron2 INFO: Inference done 6838/26446. 0.1719 s / img. ETA=0:56:56
[07/01 17:31:21] detectron2 INFO: Inference done 6868/26446. 0.1719 s / img. ETA=0:56:50
[07/01 17:31:26] detectron2 INFO: Inference done 6899/26446. 0.1718 s / img. ETA=0:56:44
[07/01 17:31:31] detectron2 INFO: Inference done 6930/26446. 0.1718 s / img. ETA=0:56:38
[07/01 17:31:36] detectron2 INFO: Inference done 6960/26446. 0.1718 s / img. ETA=0:56:32
[07/01 17:31:41] detectron2 INFO: Inference done 6990/26446. 0.1718 s / img. ETA=0:56:26
[07/01 17:31:46] detectron2 INFO: Inference done 7021/26446. 0.1717 s / img. ETA=0:56:20
[07/01 17:31:52] detectron2 INFO: Inference done 7052/26446. 0.1717 s / img. ETA=0:56:14
[07/01 17:31:57] detectron2 INFO: Inference done 7082/26446. 0.1716 s / img. ETA=0:56:08
[07/01 17:32:02] detectron2 INFO: Inference done 7113/26446. 0.1716 s / img. ETA=0:56:02
[07/01 17:32:07] detectron2 INFO: Inference done 7143/26446. 0.1716 s / img. ETA=0:55:56
[07/01 17:32:12] detectron2 INFO: Inference done 7174/26446. 0.1715 s / img. ETA=0:55:50
[07/01 17:32:17] detectron2 INFO: Inference done 7204/26446. 0.1715 s / img. ETA=0:55:44
[07/01 17:32:22] detectron2 INFO: Inference done 7234/26446. 0.1715 s / img. ETA=0:55:39
[07/01 17:32:27] detectron2 INFO: Inference done 7264/26446. 0.1715 s / img. ETA=0:55:33
[07/01 17:32:32] detectron2 INFO: Inference done 7294/26446. 0.1715 s / img. ETA=0:55:27
[07/01 17:32:37] detectron2 INFO: Inference done 7324/26446. 0.1714 s / img. ETA=0:55:22
[07/01 17:32:42] detectron2 INFO: Inference done 7354/26446. 0.1714 s / img. ETA=0:55:16
[07/01 17:32:47] detectron2 INFO: Inference done 7384/26446. 0.1714 s / img. ETA=0:55:11
[07/01 17:32:52] detectron2 INFO: Inference done 7414/26446. 0.1714 s / img. ETA=0:55:05
[07/01 17:32:57] detectron2 INFO: Inference done 7444/26446. 0.1714 s / img. ETA=0:54:59
[07/01 17:33:02] detectron2 INFO: Inference done 7474/26446. 0.1713 s / img. ETA=0:54:54
[07/01 17:33:08] detectron2 INFO: Inference done 7505/26446. 0.1713 s / img. ETA=0:54:48
[07/01 17:33:13] detectron2 INFO: Inference done 7536/26446. 0.1713 s / img. ETA=0:54:42
[07/01 17:33:18] detectron2 INFO: Inference done 7564/26446. 0.1713 s / img. ETA=0:54:37
[07/01 17:33:23] detectron2 INFO: Inference done 7591/26446. 0.1713 s / img. ETA=0:54:34
[07/01 17:33:28] detectron2 INFO: Inference done 7619/26446. 0.1714 s / img. ETA=0:54:29
[07/01 17:33:33] detectron2 INFO: Inference done 7647/26446. 0.1714 s / img. ETA=0:54:25
[07/01 17:33:38] detectron2 INFO: Inference done 7677/26446. 0.1714 s / img. ETA=0:54:19
[07/01 17:33:43] detectron2 INFO: Inference done 7708/26446. 0.1713 s / img. ETA=0:54:13
[07/01 17:33:48] detectron2 INFO: Inference done 7738/26446. 0.1713 s / img. ETA=0:54:08
[07/01 17:33:53] detectron2 INFO: Inference done 7768/26446. 0.1713 s / img. ETA=0:54:02
[07/01 17:33:58] detectron2 INFO: Inference done 7799/26446. 0.1712 s / img. ETA=0:53:56
[07/01 17:34:03] detectron2 INFO: Inference done 7829/26446. 0.1712 s / img. ETA=0:53:50
[07/01 17:34:08] detectron2 INFO: Inference done 7860/26446. 0.1712 s / img. ETA=0:53:44
[07/01 17:34:14] detectron2 INFO: Inference done 7891/26446. 0.1712 s / img. ETA=0:53:38
[07/01 17:34:19] detectron2 INFO: Inference done 7922/26446. 0.1711 s / img. ETA=0:53:32
[07/01 17:34:24] detectron2 INFO: Inference done 7953/26446. 0.1711 s / img. ETA=0:53:26
[07/01 17:34:29] detectron2 INFO: Inference done 7984/26446. 0.1711 s / img. ETA=0:53:21
[07/01 17:34:34] detectron2 INFO: Inference done 8015/26446. 0.1711 s / img. ETA=0:53:15
[07/01 17:34:39] detectron2 INFO: Inference done 8045/26446. 0.1710 s / img. ETA=0:53:09
[07/01 17:34:44] detectron2 INFO: Inference done 8076/26446. 0.1710 s / img. ETA=0:53:03
[07/01 17:34:49] detectron2 INFO: Inference done 8106/26446. 0.1710 s / img. ETA=0:52:58
[07/01 17:34:54] detectron2 INFO: Inference done 8136/26446. 0.1710 s / img. ETA=0:52:52
[07/01 17:34:59] detectron2 INFO: Inference done 8167/26446. 0.1709 s / img. ETA=0:52:46
[07/01 17:35:04] detectron2 INFO: Inference done 8197/26446. 0.1709 s / img. ETA=0:52:40
[07/01 17:35:09] detectron2 INFO: Inference done 8227/26446. 0.1709 s / img. ETA=0:52:35
[07/01 17:35:14] detectron2 INFO: Inference done 8258/26446. 0.1708 s / img. ETA=0:52:29
[07/01 17:35:20] detectron2 INFO: Inference done 8289/26446. 0.1708 s / img. ETA=0:52:23
[07/01 17:35:25] detectron2 INFO: Inference done 8319/26446. 0.1708 s / img. ETA=0:52:17
[07/01 17:35:30] detectron2 INFO: Inference done 8342/26446. 0.1709 s / img. ETA=0:52:16
[07/01 17:35:35] detectron2 INFO: Inference done 8373/26446. 0.1709 s / img. ETA=0:52:10
[07/01 17:35:40] detectron2 INFO: Inference done 8403/26446. 0.1709 s / img. ETA=0:52:04
[07/01 17:35:45] detectron2 INFO: Inference done 8434/26446. 0.1708 s / img. ETA=0:51:58
[07/01 17:35:50] detectron2 INFO: Inference done 8464/26446. 0.1708 s / img. ETA=0:51:53
[07/01 17:35:55] detectron2 INFO: Inference done 8495/26446. 0.1708 s / img. ETA=0:51:47
[07/01 17:36:00] detectron2 INFO: Inference done 8526/26446. 0.1708 s / img. ETA=0:51:41
[07/01 17:36:05] detectron2 INFO: Inference done 8556/26446. 0.1708 s / img. ETA=0:51:35
[07/01 17:36:10] detectron2 INFO: Inference done 8587/26446. 0.1707 s / img. ETA=0:51:30
[07/01 17:36:15] detectron2 INFO: Inference done 8617/26446. 0.1707 s / img. ETA=0:51:24
[07/01 17:36:20] detectron2 INFO: Inference done 8647/26446. 0.1707 s / img. ETA=0:51:19
[07/01 17:36:26] detectron2 INFO: Inference done 8678/26446. 0.1707 s / img. ETA=0:51:13
[07/01 17:36:31] detectron2 INFO: Inference done 8708/26446. 0.1706 s / img. ETA=0:51:07
[07/01 17:36:36] detectron2 INFO: Inference done 8738/26446. 0.1706 s / img. ETA=0:51:02
[07/01 17:36:41] detectron2 INFO: Inference done 8768/26446. 0.1706 s / img. ETA=0:50:56
[07/01 17:36:46] detectron2 INFO: Inference done 8799/26446. 0.1706 s / img. ETA=0:50:51
[07/01 17:36:51] detectron2 INFO: Inference done 8829/26446. 0.1706 s / img. ETA=0:50:45
[07/01 17:36:56] detectron2 INFO: Inference done 8860/26446. 0.1705 s / img. ETA=0:50:39
[07/01 17:37:01] detectron2 INFO: Inference done 8890/26446. 0.1705 s / img. ETA=0:50:34
[07/01 17:37:06] detectron2 INFO: Inference done 8920/26446. 0.1705 s / img. ETA=0:50:28
[07/01 17:37:11] detectron2 INFO: Inference done 8951/26446. 0.1705 s / img. ETA=0:50:22
[07/01 17:37:16] detectron2 INFO: Inference done 8981/26446. 0.1705 s / img. ETA=0:50:17
[07/01 17:37:21] detectron2 INFO: Inference done 9012/26446. 0.1705 s / img. ETA=0:50:11
[07/01 17:37:26] detectron2 INFO: Inference done 9042/26446. 0.1704 s / img. ETA=0:50:06
[07/01 17:37:32] detectron2 INFO: Inference done 9072/26446. 0.1704 s / img. ETA=0:50:00
[07/01 17:37:37] detectron2 INFO: Inference done 9103/26446. 0.1704 s / img. ETA=0:49:54
[07/01 17:37:42] detectron2 INFO: Inference done 9134/26446. 0.1704 s / img. ETA=0:49:48
[07/01 17:37:47] detectron2 INFO: Inference done 9162/26446. 0.1704 s / img. ETA=0:49:44
[07/01 17:37:52] detectron2 INFO: Inference done 9189/26446. 0.1704 s / img. ETA=0:49:40
[07/01 17:37:57] detectron2 INFO: Inference done 9219/26446. 0.1704 s / img. ETA=0:49:35
[07/01 17:38:02] detectron2 INFO: Inference done 9250/26446. 0.1704 s / img. ETA=0:49:29
[07/01 17:38:07] detectron2 INFO: Inference done 9281/26446. 0.1704 s / img. ETA=0:49:23
[07/01 17:38:12] detectron2 INFO: Inference done 9312/26446. 0.1703 s / img. ETA=0:49:17
[07/01 17:38:17] detectron2 INFO: Inference done 9343/26446. 0.1703 s / img. ETA=0:49:12
[07/01 17:38:22] detectron2 INFO: Inference done 9374/26446. 0.1703 s / img. ETA=0:49:06
[07/01 17:38:28] detectron2 INFO: Inference done 9404/26446. 0.1703 s / img. ETA=0:49:01
[07/01 17:38:33] detectron2 INFO: Inference done 9434/26446. 0.1703 s / img. ETA=0:48:55
[07/01 17:38:38] detectron2 INFO: Inference done 9463/26446. 0.1703 s / img. ETA=0:48:50
[07/01 17:38:43] detectron2 INFO: Inference done 9494/26446. 0.1702 s / img. ETA=0:48:44
[07/01 17:38:48] detectron2 INFO: Inference done 9523/26446. 0.1703 s / img. ETA=0:48:40
[07/01 17:38:53] detectron2 INFO: Inference done 9552/26446. 0.1703 s / img. ETA=0:48:35
[07/01 17:38:58] detectron2 INFO: Inference done 9581/26446. 0.1703 s / img. ETA=0:48:30
[07/01 17:39:03] detectron2 INFO: Inference done 9610/26446. 0.1703 s / img. ETA=0:48:25
[07/01 17:39:08] detectron2 INFO: Inference done 9639/26446. 0.1703 s / img. ETA=0:48:20
[07/01 17:39:13] detectron2 INFO: Inference done 9670/26446. 0.1703 s / img. ETA=0:48:14
[07/01 17:39:18] detectron2 INFO: Inference done 9701/26446. 0.1702 s / img. ETA=0:48:09
[07/01 17:39:24] detectron2 INFO: Inference done 9731/26446. 0.1702 s / img. ETA=0:48:03
[07/01 17:39:29] detectron2 INFO: Inference done 9762/26446. 0.1702 s / img. ETA=0:47:57
[07/01 17:39:34] detectron2 INFO: Inference done 9792/26446. 0.1702 s / img. ETA=0:47:52
[07/01 17:39:39] detectron2 INFO: Inference done 9822/26446. 0.1702 s / img. ETA=0:47:47
[07/01 17:39:44] detectron2 INFO: Inference done 9853/26446. 0.1702 s / img. ETA=0:47:41
[07/01 17:39:49] detectron2 INFO: Inference done 9884/26446. 0.1701 s / img. ETA=0:47:35
[07/01 17:39:54] detectron2 INFO: Inference done 9914/26446. 0.1701 s / img. ETA=0:47:30
[07/01 17:39:59] detectron2 INFO: Inference done 9945/26446. 0.1701 s / img. ETA=0:47:24
[07/01 17:40:04] detectron2 INFO: Inference done 9976/26446. 0.1701 s / img. ETA=0:47:18
[07/01 17:40:09] detectron2 INFO: Inference done 10006/26446. 0.1701 s / img. ETA=0:47:13
[07/01 17:40:14] detectron2 INFO: Inference done 10037/26446. 0.1700 s / img. ETA=0:47:07
[07/01 17:40:19] detectron2 INFO: Inference done 10068/26446. 0.1700 s / img. ETA=0:47:02
[07/01 17:40:25] detectron2 INFO: Inference done 10098/26446. 0.1700 s / img. ETA=0:46:56
[07/01 17:40:30] detectron2 INFO: Inference done 10129/26446. 0.1700 s / img. ETA=0:46:50
[07/01 17:40:35] detectron2 INFO: Inference done 10160/26446. 0.1700 s / img. ETA=0:46:45
[07/01 17:40:40] detectron2 INFO: Inference done 10191/26446. 0.1699 s / img. ETA=0:46:39
[07/01 17:40:45] detectron2 INFO: Inference done 10221/26446. 0.1699 s / img. ETA=0:46:34
[07/01 17:40:50] detectron2 INFO: Inference done 10252/26446. 0.1699 s / img. ETA=0:46:28
[07/01 17:40:55] detectron2 INFO: Inference done 10283/26446. 0.1699 s / img. ETA=0:46:22
[07/01 17:41:00] detectron2 INFO: Inference done 10314/26446. 0.1698 s / img. ETA=0:46:16
[07/01 17:41:05] detectron2 INFO: Inference done 10345/26446. 0.1698 s / img. ETA=0:46:10
[07/01 17:41:10] detectron2 INFO: Inference done 10375/26446. 0.1698 s / img. ETA=0:46:05
[07/01 17:41:15] detectron2 INFO: Inference done 10406/26446. 0.1698 s / img. ETA=0:45:59
[07/01 17:41:20] detectron2 INFO: Inference done 10437/26446. 0.1697 s / img. ETA=0:45:54
[07/01 17:41:25] detectron2 INFO: Inference done 10467/26446. 0.1697 s / img. ETA=0:45:48
[07/01 17:41:30] detectron2 INFO: Inference done 10497/26446. 0.1697 s / img. ETA=0:45:43
[07/01 17:41:35] detectron2 INFO: Inference done 10527/26446. 0.1697 s / img. ETA=0:45:38
[07/01 17:41:40] detectron2 INFO: Inference done 10557/26446. 0.1697 s / img. ETA=0:45:32
[07/01 17:41:46] detectron2 INFO: Inference done 10588/26446. 0.1697 s / img. ETA=0:45:27
[07/01 17:41:51] detectron2 INFO: Inference done 10619/26446. 0.1697 s / img. ETA=0:45:21
[07/01 17:41:56] detectron2 INFO: Inference done 10650/26446. 0.1696 s / img. ETA=0:45:15
[07/01 17:42:01] detectron2 INFO: Inference done 10681/26446. 0.1696 s / img. ETA=0:45:10
[07/01 17:42:06] detectron2 INFO: Inference done 10711/26446. 0.1696 s / img. ETA=0:45:04
[07/01 17:42:11] detectron2 INFO: Inference done 10742/26446. 0.1696 s / img. ETA=0:44:59
[07/01 17:42:16] detectron2 INFO: Inference done 10773/26446. 0.1696 s / img. ETA=0:44:53
[07/01 17:42:21] detectron2 INFO: Inference done 10804/26446. 0.1695 s / img. ETA=0:44:47
[07/01 17:42:26] detectron2 INFO: Inference done 10834/26446. 0.1695 s / img. ETA=0:44:42
[07/01 17:42:31] detectron2 INFO: Inference done 10865/26446. 0.1695 s / img. ETA=0:44:36
[07/01 17:42:36] detectron2 INFO: Inference done 10896/26446. 0.1695 s / img. ETA=0:44:31
[07/01 17:42:41] detectron2 INFO: Inference done 10927/26446. 0.1695 s / img. ETA=0:44:25
[07/01 17:42:47] detectron2 INFO: Inference done 10958/26446. 0.1694 s / img. ETA=0:44:19
[07/01 17:42:52] detectron2 INFO: Inference done 10988/26446. 0.1694 s / img. ETA=0:44:14
[07/01 17:42:57] detectron2 INFO: Inference done 11018/26446. 0.1694 s / img. ETA=0:44:09
[07/01 17:43:02] detectron2 INFO: Inference done 11049/26446. 0.1694 s / img. ETA=0:44:03
[07/01 17:43:07] detectron2 INFO: Inference done 11080/26446. 0.1694 s / img. ETA=0:43:58
[07/01 17:43:12] detectron2 INFO: Inference done 11111/26446. 0.1694 s / img. ETA=0:43:52
[07/01 17:43:17] detectron2 INFO: Inference done 11137/26446. 0.1694 s / img. ETA=0:43:48
[07/01 17:43:22] detectron2 INFO: Inference done 11166/26446. 0.1694 s / img. ETA=0:43:43
[07/01 17:43:27] detectron2 INFO: Inference done 11196/26446. 0.1694 s / img. ETA=0:43:38
[07/01 17:43:32] detectron2 INFO: Inference done 11223/26446. 0.1695 s / img. ETA=0:43:34
[07/01 17:43:37] detectron2 INFO: Inference done 11252/26446. 0.1695 s / img. ETA=0:43:29
[07/01 17:43:42] detectron2 INFO: Inference done 11282/26446. 0.1695 s / img. ETA=0:43:24
[07/01 17:43:48] detectron2 INFO: Inference done 11311/26446. 0.1695 s / img. ETA=0:43:19
[07/01 17:43:53] detectron2 INFO: Inference done 11341/26446. 0.1695 s / img. ETA=0:43:14
[07/01 17:43:58] detectron2 INFO: Inference done 11371/26446. 0.1695 s / img. ETA=0:43:09
[07/01 17:44:03] detectron2 INFO: Inference done 11401/26446. 0.1694 s / img. ETA=0:43:03
[07/01 17:44:08] detectron2 INFO: Inference done 11432/26446. 0.1694 s / img. ETA=0:42:58
[07/01 17:44:13] detectron2 INFO: Inference done 11462/26446. 0.1694 s / img. ETA=0:42:53
[07/01 17:44:18] detectron2 INFO: Inference done 11492/26446. 0.1694 s / img. ETA=0:42:47
[07/01 17:44:23] detectron2 INFO: Inference done 11523/26446. 0.1694 s / img. ETA=0:42:42
[07/01 17:44:28] detectron2 INFO: Inference done 11553/26446. 0.1694 s / img. ETA=0:42:37
[07/01 17:44:33] detectron2 INFO: Inference done 11582/26446. 0.1694 s / img. ETA=0:42:32
[07/01 17:44:38] detectron2 INFO: Inference done 11611/26446. 0.1694 s / img. ETA=0:42:27
[07/01 17:44:43] detectron2 INFO: Inference done 11640/26446. 0.1694 s / img. ETA=0:42:22
[07/01 17:44:49] detectron2 INFO: Inference done 11669/26446. 0.1694 s / img. ETA=0:42:17
[07/01 17:44:54] detectron2 INFO: Inference done 11699/26446. 0.1694 s / img. ETA=0:42:12
[07/01 17:44:59] detectron2 INFO: Inference done 11729/26446. 0.1694 s / img. ETA=0:42:07
[07/01 17:45:04] detectron2 INFO: Inference done 11760/26446. 0.1694 s / img. ETA=0:42:01
[07/01 17:45:09] detectron2 INFO: Inference done 11790/26446. 0.1694 s / img. ETA=0:41:56
[07/01 17:45:14] detectron2 INFO: Inference done 11820/26446. 0.1694 s / img. ETA=0:41:51
[07/01 17:45:19] detectron2 INFO: Inference done 11850/26446. 0.1694 s / img. ETA=0:41:45
[07/01 17:45:24] detectron2 INFO: Inference done 11880/26446. 0.1694 s / img. ETA=0:41:40
[07/01 17:45:29] detectron2 INFO: Inference done 11911/26446. 0.1694 s / img. ETA=0:41:35
[07/01 17:45:34] detectron2 INFO: Inference done 11942/26446. 0.1693 s / img. ETA=0:41:29
[07/01 17:45:39] detectron2 INFO: Inference done 11972/26446. 0.1693 s / img. ETA=0:41:24
[07/01 17:45:45] detectron2 INFO: Inference done 12003/26446. 0.1693 s / img. ETA=0:41:18
[07/01 17:45:50] detectron2 INFO: Inference done 12033/26446. 0.1693 s / img. ETA=0:41:13
[07/01 17:45:55] detectron2 INFO: Inference done 12062/26446. 0.1693 s / img. ETA=0:41:08
[07/01 17:46:00] detectron2 INFO: Inference done 12090/26446. 0.1693 s / img. ETA=0:41:03
[07/01 17:46:05] detectron2 INFO: Inference done 12119/26446. 0.1694 s / img. ETA=0:40:59
[07/01 17:46:10] detectron2 INFO: Inference done 12148/26446. 0.1694 s / img. ETA=0:40:54
[07/01 17:46:15] detectron2 INFO: Inference done 12177/26446. 0.1694 s / img. ETA=0:40:49
[07/01 17:46:20] detectron2 INFO: Inference done 12206/26446. 0.1694 s / img. ETA=0:40:44
[07/01 17:46:25] detectron2 INFO: Inference done 12235/26446. 0.1694 s / img. ETA=0:40:39
[07/01 17:46:30] detectron2 INFO: Inference done 12264/26446. 0.1694 s / img. ETA=0:40:34
[07/01 17:46:35] detectron2 INFO: Inference done 12293/26446. 0.1694 s / img. ETA=0:40:29
[07/01 17:46:40] detectron2 INFO: Inference done 12322/26446. 0.1694 s / img. ETA=0:40:24
[07/01 17:46:45] detectron2 INFO: Inference done 12350/26446. 0.1694 s / img. ETA=0:40:20
[07/01 17:46:50] detectron2 INFO: Inference done 12378/26446. 0.1694 s / img. ETA=0:40:15
[07/01 17:46:55] detectron2 INFO: Inference done 12407/26446. 0.1695 s / img. ETA=0:40:11
[07/01 17:47:01] detectron2 INFO: Inference done 12436/26446. 0.1695 s / img. ETA=0:40:06
[07/01 17:47:06] detectron2 INFO: Inference done 12465/26446. 0.1695 s / img. ETA=0:40:01
[07/01 17:47:11] detectron2 INFO: Inference done 12490/26446. 0.1695 s / img. ETA=0:39:58
[07/01 17:47:16] detectron2 INFO: Inference done 12515/26446. 0.1696 s / img. ETA=0:39:54
[07/01 17:47:21] detectron2 INFO: Inference done 12540/26446. 0.1697 s / img. ETA=0:39:51
[07/01 17:47:26] detectron2 INFO: Inference done 12568/26446. 0.1697 s / img. ETA=0:39:46
[07/01 17:47:31] detectron2 INFO: Inference done 12594/26446. 0.1697 s / img. ETA=0:39:42
[07/01 17:47:36] detectron2 INFO: Inference done 12622/26446. 0.1697 s / img. ETA=0:39:38
[07/01 17:47:41] detectron2 INFO: Inference done 12652/26446. 0.1697 s / img. ETA=0:39:32
[07/01 17:47:46] detectron2 INFO: Inference done 12683/26446. 0.1697 s / img. ETA=0:39:27
[07/01 17:47:51] detectron2 INFO: Inference done 12713/26446. 0.1697 s / img. ETA=0:39:22
[07/01 17:47:56] detectron2 INFO: Inference done 12743/26446. 0.1697 s / img. ETA=0:39:16
[07/01 17:48:01] detectron2 INFO: Inference done 12773/26446. 0.1697 s / img. ETA=0:39:11
[07/01 17:48:06] detectron2 INFO: Inference done 12804/26446. 0.1697 s / img. ETA=0:39:05
[07/01 17:48:12] detectron2 INFO: Inference done 12832/26446. 0.1697 s / img. ETA=0:39:01
[07/01 17:48:17] detectron2 INFO: Inference done 12859/26446. 0.1697 s / img. ETA=0:38:57
[07/01 17:48:22] detectron2 INFO: Inference done 12885/26446. 0.1698 s / img. ETA=0:38:53
[07/01 17:48:27] detectron2 INFO: Inference done 12912/26446. 0.1698 s / img. ETA=0:38:49
[07/01 17:48:32] detectron2 INFO: Inference done 12939/26446. 0.1698 s / img. ETA=0:38:44
[07/01 17:48:37] detectron2 INFO: Inference done 12968/26446. 0.1698 s / img. ETA=0:38:40
[07/01 17:48:42] detectron2 INFO: Inference done 12996/26446. 0.1699 s / img. ETA=0:38:35
[07/01 17:48:47] detectron2 INFO: Inference done 13026/26446. 0.1699 s / img. ETA=0:38:30
[07/01 17:48:52] detectron2 INFO: Inference done 13057/26446. 0.1699 s / img. ETA=0:38:24
[07/01 17:48:57] detectron2 INFO: Inference done 13087/26446. 0.1698 s / img. ETA=0:38:19
[07/01 17:49:02] detectron2 INFO: Inference done 13117/26446. 0.1698 s / img. ETA=0:38:14
[07/01 17:49:08] detectron2 INFO: Inference done 13147/26446. 0.1698 s / img. ETA=0:38:09
[07/01 17:49:13] detectron2 INFO: Inference done 13178/26446. 0.1698 s / img. ETA=0:38:03
[07/01 17:49:18] detectron2 INFO: Inference done 13209/26446. 0.1698 s / img. ETA=0:37:57
[07/01 17:49:23] detectron2 INFO: Inference done 13240/26446. 0.1698 s / img. ETA=0:37:52
[07/01 17:49:28] detectron2 INFO: Inference done 13271/26446. 0.1698 s / img. ETA=0:37:46
[07/01 17:49:33] detectron2 INFO: Inference done 13302/26446. 0.1698 s / img. ETA=0:37:41
[07/01 17:49:38] detectron2 INFO: Inference done 13332/26446. 0.1697 s / img. ETA=0:37:36
[07/01 17:49:43] detectron2 INFO: Inference done 13362/26446. 0.1697 s / img. ETA=0:37:30
[07/01 17:49:48] detectron2 INFO: Inference done 13393/26446. 0.1697 s / img. ETA=0:37:25
[07/01 17:49:54] detectron2 INFO: Inference done 13423/26446. 0.1697 s / img. ETA=0:37:20
[07/01 17:49:59] detectron2 INFO: Inference done 13453/26446. 0.1697 s / img. ETA=0:37:14
[07/01 17:50:04] detectron2 INFO: Inference done 13483/26446. 0.1697 s / img. ETA=0:37:09
[07/01 17:50:09] detectron2 INFO: Inference done 13514/26446. 0.1697 s / img. ETA=0:37:03
[07/01 17:50:14] detectron2 INFO: Inference done 13542/26446. 0.1697 s / img. ETA=0:36:59
[07/01 17:50:19] detectron2 INFO: Inference done 13569/26446. 0.1697 s / img. ETA=0:36:55
[07/01 17:50:24] detectron2 INFO: Inference done 13598/26446. 0.1697 s / img. ETA=0:36:50
[07/01 17:50:29] detectron2 INFO: Inference done 13628/26446. 0.1697 s / img. ETA=0:36:45
[07/01 17:50:34] detectron2 INFO: Inference done 13659/26446. 0.1697 s / img. ETA=0:36:39
[07/01 17:50:39] detectron2 INFO: Inference done 13690/26446. 0.1697 s / img. ETA=0:36:33
[07/01 17:50:44] detectron2 INFO: Inference done 13721/26446. 0.1697 s / img. ETA=0:36:28
[07/01 17:50:49] detectron2 INFO: Inference done 13751/26446. 0.1697 s / img. ETA=0:36:23
[07/01 17:50:54] detectron2 INFO: Inference done 13781/26446. 0.1697 s / img. ETA=0:36:17
[07/01 17:50:59] detectron2 INFO: Inference done 13811/26446. 0.1697 s / img. ETA=0:36:12
[07/01 17:51:05] detectron2 INFO: Inference done 13842/26446. 0.1696 s / img. ETA=0:36:07
[07/01 17:51:10] detectron2 INFO: Inference done 13872/26446. 0.1696 s / img. ETA=0:36:01
[07/01 17:51:15] detectron2 INFO: Inference done 13902/26446. 0.1696 s / img. ETA=0:35:56
[07/01 17:51:20] detectron2 INFO: Inference done 13932/26446. 0.1696 s / img. ETA=0:35:51
[07/01 17:51:25] detectron2 INFO: Inference done 13959/26446. 0.1696 s / img. ETA=0:35:47
[07/01 17:51:30] detectron2 INFO: Inference done 13987/26446. 0.1697 s / img. ETA=0:35:42
[07/01 17:51:35] detectron2 INFO: Inference done 14015/26446. 0.1697 s / img. ETA=0:35:38
[07/01 17:51:40] detectron2 INFO: Inference done 14045/26446. 0.1697 s / img. ETA=0:35:32
[07/01 17:51:45] detectron2 INFO: Inference done 14076/26446. 0.1697 s / img. ETA=0:35:27
[07/01 17:51:51] detectron2 INFO: Inference done 14107/26446. 0.1697 s / img. ETA=0:35:21
[07/01 17:51:56] detectron2 INFO: Inference done 14137/26446. 0.1697 s / img. ETA=0:35:16
[07/01 17:52:01] detectron2 INFO: Inference done 14167/26446. 0.1697 s / img. ETA=0:35:11
[07/01 17:52:06] detectron2 INFO: Inference done 14197/26446. 0.1697 s / img. ETA=0:35:06
[07/01 17:52:11] detectron2 INFO: Inference done 14227/26446. 0.1696 s / img. ETA=0:35:00
[07/01 17:52:16] detectron2 INFO: Inference done 14257/26446. 0.1696 s / img. ETA=0:34:55
[07/01 17:52:21] detectron2 INFO: Inference done 14288/26446. 0.1696 s / img. ETA=0:34:50
[07/01 17:52:26] detectron2 INFO: Inference done 14318/26446. 0.1696 s / img. ETA=0:34:44
[07/01 17:52:31] detectron2 INFO: Inference done 14348/26446. 0.1696 s / img. ETA=0:34:39
[07/01 17:52:36] detectron2 INFO: Inference done 14379/26446. 0.1696 s / img. ETA=0:34:34
[07/01 17:52:41] detectron2 INFO: Inference done 14409/26446. 0.1696 s / img. ETA=0:34:28
[07/01 17:52:46] detectron2 INFO: Inference done 14440/26446. 0.1696 s / img. ETA=0:34:23
[07/01 17:52:52] detectron2 INFO: Inference done 14471/26446. 0.1696 s / img. ETA=0:34:18
[07/01 17:52:57] detectron2 INFO: Inference done 14502/26446. 0.1696 s / img. ETA=0:34:12
[07/01 17:53:02] detectron2 INFO: Inference done 14533/26446. 0.1695 s / img. ETA=0:34:06
[07/01 17:53:07] detectron2 INFO: Inference done 14563/26446. 0.1695 s / img. ETA=0:34:01
[07/01 17:53:12] detectron2 INFO: Inference done 14592/26446. 0.1695 s / img. ETA=0:33:56
[07/01 17:53:17] detectron2 INFO: Inference done 14619/26446. 0.1696 s / img. ETA=0:33:52
[07/01 17:53:22] detectron2 INFO: Inference done 14648/26446. 0.1696 s / img. ETA=0:33:47
[07/01 17:53:27] detectron2 INFO: Inference done 14679/26446. 0.1696 s / img. ETA=0:33:42
[07/01 17:53:32] detectron2 INFO: Inference done 14710/26446. 0.1695 s / img. ETA=0:33:36
[07/01 17:53:37] detectron2 INFO: Inference done 14739/26446. 0.1696 s / img. ETA=0:33:31
[07/01 17:53:42] detectron2 INFO: Inference done 14769/26446. 0.1695 s / img. ETA=0:33:26
[07/01 17:53:48] detectron2 INFO: Inference done 14799/26446. 0.1695 s / img. ETA=0:33:21
[07/01 17:53:53] detectron2 INFO: Inference done 14829/26446. 0.1695 s / img. ETA=0:33:16
[07/01 17:53:58] detectron2 INFO: Inference done 14858/26446. 0.1695 s / img. ETA=0:33:11
[07/01 17:54:03] detectron2 INFO: Inference done 14889/26446. 0.1695 s / img. ETA=0:33:05
[07/01 17:54:08] detectron2 INFO: Inference done 14919/26446. 0.1695 s / img. ETA=0:33:00
[07/01 17:54:13] detectron2 INFO: Inference done 14949/26446. 0.1695 s / img. ETA=0:32:55
[07/01 17:54:18] detectron2 INFO: Inference done 14980/26446. 0.1695 s / img. ETA=0:32:49
[07/01 17:54:23] detectron2 INFO: Inference done 15007/26446. 0.1695 s / img. ETA=0:32:45
[07/01 17:54:28] detectron2 INFO: Inference done 15034/26446. 0.1696 s / img. ETA=0:32:41
[07/01 17:54:34] detectron2 INFO: Inference done 15061/26446. 0.1696 s / img. ETA=0:32:36
[07/01 17:54:39] detectron2 INFO: Inference done 15089/26446. 0.1696 s / img. ETA=0:32:32
[07/01 17:54:44] detectron2 INFO: Inference done 15118/26446. 0.1696 s / img. ETA=0:32:27
[07/01 17:54:49] detectron2 INFO: Inference done 15149/26446. 0.1696 s / img. ETA=0:32:21
[07/01 17:54:54] detectron2 INFO: Inference done 15180/26446. 0.1696 s / img. ETA=0:32:16
[07/01 17:54:59] detectron2 INFO: Inference done 15211/26446. 0.1696 s / img. ETA=0:32:10
[07/01 17:55:04] detectron2 INFO: Inference done 15242/26446. 0.1696 s / img. ETA=0:32:05
[07/01 17:55:09] detectron2 INFO: Inference done 15273/26446. 0.1696 s / img. ETA=0:32:00
[07/01 17:55:14] detectron2 INFO: Inference done 15303/26446. 0.1696 s / img. ETA=0:31:54
[07/01 17:55:19] detectron2 INFO: Inference done 15333/26446. 0.1695 s / img. ETA=0:31:49
[07/01 17:55:25] detectron2 INFO: Inference done 15363/26446. 0.1695 s / img. ETA=0:31:44
[07/01 17:55:30] detectron2 INFO: Inference done 15390/26446. 0.1696 s / img. ETA=0:31:40
[07/01 17:55:35] detectron2 INFO: Inference done 15417/26446. 0.1696 s / img. ETA=0:31:35
[07/01 17:55:40] detectron2 INFO: Inference done 15444/26446. 0.1696 s / img. ETA=0:31:31
[07/01 17:55:45] detectron2 INFO: Inference done 15471/26446. 0.1697 s / img. ETA=0:31:27
[07/01 17:55:50] detectron2 INFO: Inference done 15498/26446. 0.1697 s / img. ETA=0:31:22
[07/01 17:55:55] detectron2 INFO: Inference done 15527/26446. 0.1697 s / img. ETA=0:31:17
[07/01 17:56:00] detectron2 INFO: Inference done 15557/26446. 0.1697 s / img. ETA=0:31:12
[07/01 17:56:05] detectron2 INFO: Inference done 15588/26446. 0.1697 s / img. ETA=0:31:07
[07/01 17:56:10] detectron2 INFO: Inference done 15618/26446. 0.1697 s / img. ETA=0:31:01
[07/01 17:56:15] detectron2 INFO: Inference done 15649/26446. 0.1697 s / img. ETA=0:30:56
[07/01 17:56:20] detectron2 INFO: Inference done 15680/26446. 0.1696 s / img. ETA=0:30:50
[07/01 17:56:25] detectron2 INFO: Inference done 15710/26446. 0.1696 s / img. ETA=0:30:45
[07/01 17:56:31] detectron2 INFO: Inference done 15740/26446. 0.1696 s / img. ETA=0:30:40
[07/01 17:56:36] detectron2 INFO: Inference done 15770/26446. 0.1696 s / img. ETA=0:30:35
[07/01 17:56:41] detectron2 INFO: Inference done 15801/26446. 0.1696 s / img. ETA=0:30:29
[07/01 17:56:46] detectron2 INFO: Inference done 15832/26446. 0.1696 s / img. ETA=0:30:24
[07/01 17:56:51] detectron2 INFO: Inference done 15863/26446. 0.1696 s / img. ETA=0:30:18
[07/01 17:56:56] detectron2 INFO: Inference done 15894/26446. 0.1696 s / img. ETA=0:30:13
[07/01 17:57:01] detectron2 INFO: Inference done 15924/26446. 0.1696 s / img. ETA=0:30:08
[07/01 17:57:06] detectron2 INFO: Inference done 15954/26446. 0.1695 s / img. ETA=0:30:02
[07/01 17:57:11] detectron2 INFO: Inference done 15985/26446. 0.1695 s / img. ETA=0:29:57
[07/01 17:57:16] detectron2 INFO: Inference done 16015/26446. 0.1695 s / img. ETA=0:29:52
[07/01 17:57:21] detectron2 INFO: Inference done 16042/26446. 0.1696 s / img. ETA=0:29:47
[07/01 17:57:26] detectron2 INFO: Inference done 16070/26446. 0.1696 s / img. ETA=0:29:43
[07/01 17:57:32] detectron2 INFO: Inference done 16099/26446. 0.1696 s / img. ETA=0:29:38
[07/01 17:57:37] detectron2 INFO: Inference done 16129/26446. 0.1696 s / img. ETA=0:29:33
[07/01 17:57:42] detectron2 INFO: Inference done 16154/26446. 0.1697 s / img. ETA=0:29:29
[07/01 17:57:47] detectron2 INFO: Inference done 16185/26446. 0.1696 s / img. ETA=0:29:24
[07/01 17:57:53] detectron2 INFO: Inference done 16216/26446. 0.1696 s / img. ETA=0:29:18
[07/01 17:57:58] detectron2 INFO: Inference done 16246/26446. 0.1696 s / img. ETA=0:29:13
[07/01 17:58:03] detectron2 INFO: Inference done 16276/26446. 0.1696 s / img. ETA=0:29:08
[07/01 17:58:08] detectron2 INFO: Inference done 16306/26446. 0.1696 s / img. ETA=0:29:03
[07/01 17:58:13] detectron2 INFO: Inference done 16336/26446. 0.1696 s / img. ETA=0:28:57
[07/01 17:58:18] detectron2 INFO: Inference done 16365/26446. 0.1696 s / img. ETA=0:28:53
[07/01 17:58:23] detectron2 INFO: Inference done 16392/26446. 0.1696 s / img. ETA=0:28:48
[07/01 17:58:28] detectron2 INFO: Inference done 16420/26446. 0.1697 s / img. ETA=0:28:43
[07/01 17:58:33] detectron2 INFO: Inference done 16448/26446. 0.1697 s / img. ETA=0:28:39
[07/01 17:58:38] detectron2 INFO: Inference done 16475/26446. 0.1697 s / img. ETA=0:28:35
[07/01 17:58:44] detectron2 INFO: Inference done 16503/26446. 0.1697 s / img. ETA=0:28:30
[07/01 17:58:49] detectron2 INFO: Inference done 16533/26446. 0.1697 s / img. ETA=0:28:25
[07/01 17:58:54] detectron2 INFO: Inference done 16563/26446. 0.1697 s / img. ETA=0:28:19
[07/01 17:58:59] detectron2 INFO: Inference done 16593/26446. 0.1697 s / img. ETA=0:28:14
[07/01 17:59:04] detectron2 INFO: Inference done 16624/26446. 0.1697 s / img. ETA=0:28:09
[07/01 17:59:09] detectron2 INFO: Inference done 16654/26446. 0.1697 s / img. ETA=0:28:04
[07/01 17:59:14] detectron2 INFO: Inference done 16685/26446. 0.1697 s / img. ETA=0:27:58
[07/01 17:59:19] detectron2 INFO: Inference done 16716/26446. 0.1697 s / img. ETA=0:27:53
[07/01 17:59:24] detectron2 INFO: Inference done 16747/26446. 0.1697 s / img. ETA=0:27:47
[07/01 17:59:29] detectron2 INFO: Inference done 16778/26446. 0.1696 s / img. ETA=0:27:42
[07/01 17:59:34] detectron2 INFO: Inference done 16808/26446. 0.1696 s / img. ETA=0:27:37
[07/01 17:59:39] detectron2 INFO: Inference done 16839/26446. 0.1696 s / img. ETA=0:27:31
[07/01 17:59:45] detectron2 INFO: Inference done 16869/26446. 0.1696 s / img. ETA=0:27:26
[07/01 17:59:50] detectron2 INFO: Inference done 16899/26446. 0.1696 s / img. ETA=0:27:21
[07/01 17:59:55] detectron2 INFO: Inference done 16930/26446. 0.1696 s / img. ETA=0:27:15
[07/01 18:00:00] detectron2 INFO: Inference done 16960/26446. 0.1696 s / img. ETA=0:27:10
[07/01 18:00:05] detectron2 INFO: Inference done 16989/26446. 0.1696 s / img. ETA=0:27:05
[07/01 18:00:10] detectron2 INFO: Inference done 17016/26446. 0.1696 s / img. ETA=0:27:01
[07/01 18:00:15] detectron2 INFO: Inference done 17043/26446. 0.1696 s / img. ETA=0:26:56
[07/01 18:00:20] detectron2 INFO: Inference done 17072/26446. 0.1697 s / img. ETA=0:26:51
[07/01 18:00:25] detectron2 INFO: Inference done 17102/26446. 0.1696 s / img. ETA=0:26:46
[07/01 18:00:30] detectron2 INFO: Inference done 17132/26446. 0.1696 s / img. ETA=0:26:41
[07/01 18:00:35] detectron2 INFO: Inference done 17163/26446. 0.1696 s / img. ETA=0:26:35
[07/01 18:00:40] detectron2 INFO: Inference done 17193/26446. 0.1696 s / img. ETA=0:26:30
[07/01 18:00:45] detectron2 INFO: Inference done 17224/26446. 0.1696 s / img. ETA=0:26:25
[07/01 18:00:50] detectron2 INFO: Inference done 17255/26446. 0.1696 s / img. ETA=0:26:19
[07/01 18:00:55] detectron2 INFO: Inference done 17285/26446. 0.1696 s / img. ETA=0:26:14
[07/01 18:01:01] detectron2 INFO: Inference done 17313/26446. 0.1696 s / img. ETA=0:26:09
[07/01 18:01:06] detectron2 INFO: Inference done 17341/26446. 0.1696 s / img. ETA=0:26:05
[07/01 18:01:11] detectron2 INFO: Inference done 17371/26446. 0.1696 s / img. ETA=0:25:59
[07/01 18:01:16] detectron2 INFO: Inference done 17401/26446. 0.1696 s / img. ETA=0:25:54
[07/01 18:01:21] detectron2 INFO: Inference done 17431/26446. 0.1696 s / img. ETA=0:25:49
[07/01 18:01:26] detectron2 INFO: Inference done 17458/26446. 0.1696 s / img. ETA=0:25:45
[07/01 18:01:31] detectron2 INFO: Inference done 17485/26446. 0.1696 s / img. ETA=0:25:40
[07/01 18:01:36] detectron2 INFO: Inference done 17514/26446. 0.1697 s / img. ETA=0:25:35
[07/01 18:01:41] detectron2 INFO: Inference done 17544/26446. 0.1696 s / img. ETA=0:25:30
[07/01 18:01:46] detectron2 INFO: Inference done 17575/26446. 0.1696 s / img. ETA=0:25:25
[07/01 18:01:51] detectron2 INFO: Inference done 17605/26446. 0.1696 s / img. ETA=0:25:19
[07/01 18:01:56] detectron2 INFO: Inference done 17635/26446. 0.1696 s / img. ETA=0:25:14
[07/01 18:02:01] detectron2 INFO: Inference done 17665/26446. 0.1696 s / img. ETA=0:25:09
[07/01 18:02:07] detectron2 INFO: Inference done 17696/26446. 0.1696 s / img. ETA=0:25:04
[07/01 18:02:12] detectron2 INFO: Inference done 17727/26446. 0.1696 s / img. ETA=0:24:58
[07/01 18:02:17] detectron2 INFO: Inference done 17758/26446. 0.1696 s / img. ETA=0:24:53
[07/01 18:02:22] detectron2 INFO: Inference done 17789/26446. 0.1696 s / img. ETA=0:24:47
[07/01 18:02:27] detectron2 INFO: Inference done 17819/26446. 0.1696 s / img. ETA=0:24:42
[07/01 18:02:32] detectron2 INFO: Inference done 17850/26446. 0.1696 s / img. ETA=0:24:37
[07/01 18:02:37] detectron2 INFO: Inference done 17879/26446. 0.1696 s / img. ETA=0:24:32
[07/01 18:02:42] detectron2 INFO: Inference done 17906/26446. 0.1696 s / img. ETA=0:24:27
[07/01 18:02:47] detectron2 INFO: Inference done 17933/26446. 0.1696 s / img. ETA=0:24:23
[07/01 18:02:52] detectron2 INFO: Inference done 17961/26446. 0.1696 s / img. ETA=0:24:18
[07/01 18:02:58] detectron2 INFO: Inference done 17992/26446. 0.1696 s / img. ETA=0:24:13
[07/01 18:03:03] detectron2 INFO: Inference done 18022/26446. 0.1696 s / img. ETA=0:24:08
[07/01 18:03:08] detectron2 INFO: Inference done 18053/26446. 0.1696 s / img. ETA=0:24:02
[07/01 18:03:13] detectron2 INFO: Inference done 18084/26446. 0.1696 s / img. ETA=0:23:57
[07/01 18:03:18] detectron2 INFO: Inference done 18114/26446. 0.1696 s / img. ETA=0:23:52
[07/01 18:03:23] detectron2 INFO: Inference done 18145/26446. 0.1696 s / img. ETA=0:23:46
[07/01 18:03:28] detectron2 INFO: Inference done 18175/26446. 0.1696 s / img. ETA=0:23:41
[07/01 18:03:33] detectron2 INFO: Inference done 18206/26446. 0.1696 s / img. ETA=0:23:35
[07/01 18:03:38] detectron2 INFO: Inference done 18237/26446. 0.1695 s / img. ETA=0:23:30
[07/01 18:03:43] detectron2 INFO: Inference done 18267/26446. 0.1695 s / img. ETA=0:23:25
[07/01 18:03:48] detectron2 INFO: Inference done 18298/26446. 0.1695 s / img. ETA=0:23:19
[07/01 18:03:53] detectron2 INFO: Inference done 18328/26446. 0.1695 s / img. ETA=0:23:14
[07/01 18:03:58] detectron2 INFO: Inference done 18358/26446. 0.1695 s / img. ETA=0:23:09
[07/01 18:04:04] detectron2 INFO: Inference done 18388/26446. 0.1695 s / img. ETA=0:23:04
[07/01 18:04:09] detectron2 INFO: Inference done 18418/26446. 0.1695 s / img. ETA=0:22:59
[07/01 18:04:14] detectron2 INFO: Inference done 18449/26446. 0.1695 s / img. ETA=0:22:53
[07/01 18:04:19] detectron2 INFO: Inference done 18479/26446. 0.1695 s / img. ETA=0:22:48
[07/01 18:04:24] detectron2 INFO: Inference done 18509/26446. 0.1695 s / img. ETA=0:22:43
[07/01 18:04:29] detectron2 INFO: Inference done 18539/26446. 0.1695 s / img. ETA=0:22:38
[07/01 18:04:34] detectron2 INFO: Inference done 18569/26446. 0.1695 s / img. ETA=0:22:32
[07/01 18:04:39] detectron2 INFO: Inference done 18600/26446. 0.1695 s / img. ETA=0:22:27
[07/01 18:04:44] detectron2 INFO: Inference done 18631/26446. 0.1694 s / img. ETA=0:22:22
[07/01 18:04:49] detectron2 INFO: Inference done 18662/26446. 0.1694 s / img. ETA=0:22:16
[07/01 18:04:54] detectron2 INFO: Inference done 18692/26446. 0.1694 s / img. ETA=0:22:11
[07/01 18:04:59] detectron2 INFO: Inference done 18722/26446. 0.1694 s / img. ETA=0:22:06
[07/01 18:05:04] detectron2 INFO: Inference done 18752/26446. 0.1694 s / img. ETA=0:22:01
[07/01 18:05:09] detectron2 INFO: Inference done 18782/26446. 0.1694 s / img. ETA=0:21:55
[07/01 18:05:15] detectron2 INFO: Inference done 18812/26446. 0.1694 s / img. ETA=0:21:50
[07/01 18:05:20] detectron2 INFO: Inference done 18843/26446. 0.1694 s / img. ETA=0:21:45
[07/01 18:05:25] detectron2 INFO: Inference done 18874/26446. 0.1694 s / img. ETA=0:21:39
[07/01 18:05:30] detectron2 INFO: Inference done 18905/26446. 0.1694 s / img. ETA=0:21:34
[07/01 18:05:35] detectron2 INFO: Inference done 18935/26446. 0.1694 s / img. ETA=0:21:29
[07/01 18:05:40] detectron2 INFO: Inference done 18966/26446. 0.1694 s / img. ETA=0:21:23
[07/01 18:05:45] detectron2 INFO: Inference done 18996/26446. 0.1694 s / img. ETA=0:21:18
[07/01 18:05:50] detectron2 INFO: Inference done 19023/26446. 0.1694 s / img. ETA=0:21:14
[07/01 18:05:55] detectron2 INFO: Inference done 19051/26446. 0.1694 s / img. ETA=0:21:09
[07/01 18:06:00] detectron2 INFO: Inference done 19081/26446. 0.1694 s / img. ETA=0:21:04
[07/01 18:06:05] detectron2 INFO: Inference done 19111/26446. 0.1694 s / img. ETA=0:20:59
[07/01 18:06:10] detectron2 INFO: Inference done 19141/26446. 0.1694 s / img. ETA=0:20:53
[07/01 18:06:16] detectron2 INFO: Inference done 19172/26446. 0.1694 s / img. ETA=0:20:48
[07/01 18:06:21] detectron2 INFO: Inference done 19202/26446. 0.1694 s / img. ETA=0:20:43
[07/01 18:06:26] detectron2 INFO: Inference done 19232/26446. 0.1694 s / img. ETA=0:20:38
[07/01 18:06:31] detectron2 INFO: Inference done 19262/26446. 0.1694 s / img. ETA=0:20:33
[07/01 18:06:36] detectron2 INFO: Inference done 19292/26446. 0.1694 s / img. ETA=0:20:27
[07/01 18:06:41] detectron2 INFO: Inference done 19323/26446. 0.1693 s / img. ETA=0:20:22
[07/01 18:06:46] detectron2 INFO: Inference done 19353/26446. 0.1693 s / img. ETA=0:20:17
[07/01 18:06:51] detectron2 INFO: Inference done 19384/26446. 0.1693 s / img. ETA=0:20:11
[07/01 18:06:56] detectron2 INFO: Inference done 19414/26446. 0.1693 s / img. ETA=0:20:06
[07/01 18:07:01] detectron2 INFO: Inference done 19444/26446. 0.1693 s / img. ETA=0:20:01
[07/01 18:07:07] detectron2 INFO: Inference done 19475/26446. 0.1693 s / img. ETA=0:19:56
[07/01 18:07:12] detectron2 INFO: Inference done 19505/26446. 0.1693 s / img. ETA=0:19:51
[07/01 18:07:17] detectron2 INFO: Inference done 19536/26446. 0.1693 s / img. ETA=0:19:45
[07/01 18:07:22] detectron2 INFO: Inference done 19566/26446. 0.1693 s / img. ETA=0:19:40
[07/01 18:07:27] detectron2 INFO: Inference done 19597/26446. 0.1693 s / img. ETA=0:19:35
[07/01 18:07:32] detectron2 INFO: Inference done 19627/26446. 0.1693 s / img. ETA=0:19:29
[07/01 18:07:37] detectron2 INFO: Inference done 19657/26446. 0.1693 s / img. ETA=0:19:24
[07/01 18:07:42] detectron2 INFO: Inference done 19687/26446. 0.1693 s / img. ETA=0:19:19
[07/01 18:07:47] detectron2 INFO: Inference done 19717/26446. 0.1693 s / img. ETA=0:19:14
[07/01 18:07:52] detectron2 INFO: Inference done 19747/26446. 0.1693 s / img. ETA=0:19:09
[07/01 18:07:57] detectron2 INFO: Inference done 19778/26446. 0.1693 s / img. ETA=0:19:03
[07/01 18:08:02] detectron2 INFO: Inference done 19808/26446. 0.1692 s / img. ETA=0:18:58
[07/01 18:08:07] detectron2 INFO: Inference done 19838/26446. 0.1692 s / img. ETA=0:18:53
[07/01 18:08:12] detectron2 INFO: Inference done 19868/26446. 0.1692 s / img. ETA=0:18:48
[07/01 18:08:18] detectron2 INFO: Inference done 19897/26446. 0.1692 s / img. ETA=0:18:43
[07/01 18:08:23] detectron2 INFO: Inference done 19927/26446. 0.1692 s / img. ETA=0:18:38
[07/01 18:08:28] detectron2 INFO: Inference done 19956/26446. 0.1692 s / img. ETA=0:18:33
[07/01 18:08:33] detectron2 INFO: Inference done 19985/26446. 0.1693 s / img. ETA=0:18:28
[07/01 18:08:38] detectron2 INFO: Inference done 20014/26446. 0.1693 s / img. ETA=0:18:23
[07/01 18:08:43] detectron2 INFO: Inference done 20044/26446. 0.1692 s / img. ETA=0:18:18
[07/01 18:08:48] detectron2 INFO: Inference done 20074/26446. 0.1692 s / img. ETA=0:18:12
[07/01 18:08:53] detectron2 INFO: Inference done 20104/26446. 0.1692 s / img. ETA=0:18:07
[07/01 18:08:58] detectron2 INFO: Inference done 20134/26446. 0.1692 s / img. ETA=0:18:02
[07/01 18:09:03] detectron2 INFO: Inference done 20165/26446. 0.1692 s / img. ETA=0:17:57
[07/01 18:09:08] detectron2 INFO: Inference done 20196/26446. 0.1692 s / img. ETA=0:17:51
[07/01 18:09:14] detectron2 INFO: Inference done 20227/26446. 0.1692 s / img. ETA=0:17:46
[07/01 18:09:19] detectron2 INFO: Inference done 20257/26446. 0.1692 s / img. ETA=0:17:41
[07/01 18:09:24] detectron2 INFO: Inference done 20287/26446. 0.1692 s / img. ETA=0:17:36
[07/01 18:09:29] detectron2 INFO: Inference done 20317/26446. 0.1692 s / img. ETA=0:17:31
[07/01 18:09:34] detectron2 INFO: Inference done 20348/26446. 0.1692 s / img. ETA=0:17:25
[07/01 18:09:39] detectron2 INFO: Inference done 20378/26446. 0.1692 s / img. ETA=0:17:20
[07/01 18:09:44] detectron2 INFO: Inference done 20409/26446. 0.1692 s / img. ETA=0:17:15
[07/01 18:09:49] detectron2 INFO: Inference done 20440/26446. 0.1692 s / img. ETA=0:17:09
[07/01 18:09:54] detectron2 INFO: Inference done 20471/26446. 0.1692 s / img. ETA=0:17:04
[07/01 18:09:59] detectron2 INFO: Inference done 20501/26446. 0.1691 s / img. ETA=0:16:59
[07/01 18:10:04] detectron2 INFO: Inference done 20532/26446. 0.1691 s / img. ETA=0:16:53
[07/01 18:10:09] detectron2 INFO: Inference done 20562/26446. 0.1691 s / img. ETA=0:16:48
[07/01 18:10:14] detectron2 INFO: Inference done 20592/26446. 0.1691 s / img. ETA=0:16:43
[07/01 18:10:19] detectron2 INFO: Inference done 20623/26446. 0.1691 s / img. ETA=0:16:38
[07/01 18:10:24] detectron2 INFO: Inference done 20654/26446. 0.1691 s / img. ETA=0:16:32
[07/01 18:10:30] detectron2 INFO: Inference done 20685/26446. 0.1691 s / img. ETA=0:16:27
[07/01 18:10:35] detectron2 INFO: Inference done 20714/26446. 0.1691 s / img. ETA=0:16:22
[07/01 18:10:40] detectron2 INFO: Inference done 20743/26446. 0.1691 s / img. ETA=0:16:17
[07/01 18:10:45] detectron2 INFO: Inference done 20771/26446. 0.1691 s / img. ETA=0:16:12
[07/01 18:10:50] detectron2 INFO: Inference done 20800/26446. 0.1691 s / img. ETA=0:16:07
[07/01 18:10:55] detectron2 INFO: Inference done 20829/26446. 0.1691 s / img. ETA=0:16:02
[07/01 18:11:00] detectron2 INFO: Inference done 20859/26446. 0.1691 s / img. ETA=0:15:57
[07/01 18:11:05] detectron2 INFO: Inference done 20889/26446. 0.1691 s / img. ETA=0:15:52
[07/01 18:11:10] detectron2 INFO: Inference done 20920/26446. 0.1691 s / img. ETA=0:15:47
[07/01 18:11:15] detectron2 INFO: Inference done 20951/26446. 0.1691 s / img. ETA=0:15:41
[07/01 18:11:20] detectron2 INFO: Inference done 20981/26446. 0.1691 s / img. ETA=0:15:36
[07/01 18:11:25] detectron2 INFO: Inference done 21012/26446. 0.1691 s / img. ETA=0:15:31
[07/01 18:11:31] detectron2 INFO: Inference done 21043/26446. 0.1691 s / img. ETA=0:15:25
[07/01 18:11:36] detectron2 INFO: Inference done 21073/26446. 0.1691 s / img. ETA=0:15:20
[07/01 18:11:41] detectron2 INFO: Inference done 21104/26446. 0.1691 s / img. ETA=0:15:15
[07/01 18:11:46] detectron2 INFO: Inference done 21135/26446. 0.1691 s / img. ETA=0:15:09
[07/01 18:11:51] detectron2 INFO: Inference done 21165/26446. 0.1691 s / img. ETA=0:15:04
[07/01 18:11:56] detectron2 INFO: Inference done 21196/26446. 0.1690 s / img. ETA=0:14:59
[07/01 18:12:01] detectron2 INFO: Inference done 21227/26446. 0.1690 s / img. ETA=0:14:54
[07/01 18:12:06] detectron2 INFO: Inference done 21258/26446. 0.1690 s / img. ETA=0:14:48
[07/01 18:12:11] detectron2 INFO: Inference done 21289/26446. 0.1690 s / img. ETA=0:14:43
[07/01 18:12:17] detectron2 INFO: Inference done 21321/26446. 0.1690 s / img. ETA=0:14:37
[07/01 18:12:22] detectron2 INFO: Inference done 21352/26446. 0.1690 s / img. ETA=0:14:32
[07/01 18:12:27] detectron2 INFO: Inference done 21383/26446. 0.1690 s / img. ETA=0:14:27
[07/01 18:12:32] detectron2 INFO: Inference done 21413/26446. 0.1690 s / img. ETA=0:14:21
[07/01 18:12:37] detectron2 INFO: Inference done 21444/26446. 0.1690 s / img. ETA=0:14:16
[07/01 18:12:42] detectron2 INFO: Inference done 21474/26446. 0.1690 s / img. ETA=0:14:11
[07/01 18:12:47] detectron2 INFO: Inference done 21505/26446. 0.1690 s / img. ETA=0:14:06
[07/01 18:12:52] detectron2 INFO: Inference done 21536/26446. 0.1690 s / img. ETA=0:14:00
[07/01 18:12:57] detectron2 INFO: Inference done 21567/26446. 0.1689 s / img. ETA=0:13:55
[07/01 18:13:03] detectron2 INFO: Inference done 21598/26446. 0.1689 s / img. ETA=0:13:50
[07/01 18:13:08] detectron2 INFO: Inference done 21629/26446. 0.1689 s / img. ETA=0:13:44
[07/01 18:13:13] detectron2 INFO: Inference done 21660/26446. 0.1689 s / img. ETA=0:13:39
[07/01 18:13:18] detectron2 INFO: Inference done 21691/26446. 0.1689 s / img. ETA=0:13:34
[07/01 18:13:23] detectron2 INFO: Inference done 21722/26446. 0.1689 s / img. ETA=0:13:28
[07/01 18:13:28] detectron2 INFO: Inference done 21753/26446. 0.1689 s / img. ETA=0:13:23
[07/01 18:13:33] detectron2 INFO: Inference done 21784/26446. 0.1689 s / img. ETA=0:13:17
[07/01 18:13:38] detectron2 INFO: Inference done 21814/26446. 0.1689 s / img. ETA=0:13:12
[07/01 18:13:43] detectron2 INFO: Inference done 21844/26446. 0.1689 s / img. ETA=0:13:07
[07/01 18:13:49] detectron2 INFO: Inference done 21874/26446. 0.1689 s / img. ETA=0:13:02
[07/01 18:13:54] detectron2 INFO: Inference done 21905/26446. 0.1689 s / img. ETA=0:12:57
[07/01 18:13:59] detectron2 INFO: Inference done 21936/26446. 0.1689 s / img. ETA=0:12:51
[07/01 18:14:04] detectron2 INFO: Inference done 21967/26446. 0.1689 s / img. ETA=0:12:46
[07/01 18:14:09] detectron2 INFO: Inference done 21998/26446. 0.1688 s / img. ETA=0:12:41
[07/01 18:14:14] detectron2 INFO: Inference done 22029/26446. 0.1688 s / img. ETA=0:12:35
[07/01 18:14:19] detectron2 INFO: Inference done 22060/26446. 0.1688 s / img. ETA=0:12:30
[07/01 18:14:24] detectron2 INFO: Inference done 22091/26446. 0.1688 s / img. ETA=0:12:25
[07/01 18:14:29] detectron2 INFO: Inference done 22121/26446. 0.1688 s / img. ETA=0:12:19
[07/01 18:14:34] detectron2 INFO: Inference done 22152/26446. 0.1688 s / img. ETA=0:12:14
[07/01 18:14:40] detectron2 INFO: Inference done 22183/26446. 0.1688 s / img. ETA=0:12:09
[07/01 18:14:45] detectron2 INFO: Inference done 22213/26446. 0.1688 s / img. ETA=0:12:04
[07/01 18:14:50] detectron2 INFO: Inference done 22243/26446. 0.1688 s / img. ETA=0:11:58
[07/01 18:14:55] detectron2 INFO: Inference done 22274/26446. 0.1688 s / img. ETA=0:11:53
[07/01 18:15:00] detectron2 INFO: Inference done 22305/26446. 0.1688 s / img. ETA=0:11:48
[07/01 18:15:05] detectron2 INFO: Inference done 22336/26446. 0.1688 s / img. ETA=0:11:42
[07/01 18:15:10] detectron2 INFO: Inference done 22366/26446. 0.1688 s / img. ETA=0:11:37
[07/01 18:15:15] detectron2 INFO: Inference done 22397/26446. 0.1687 s / img. ETA=0:11:32
[07/01 18:15:20] detectron2 INFO: Inference done 22428/26446. 0.1687 s / img. ETA=0:11:27
[07/01 18:15:25] detectron2 INFO: Inference done 22459/26446. 0.1687 s / img. ETA=0:11:21
[07/01 18:15:30] detectron2 INFO: Inference done 22490/26446. 0.1687 s / img. ETA=0:11:16
[07/01 18:15:36] detectron2 INFO: Inference done 22521/26446. 0.1687 s / img. ETA=0:11:11
[07/01 18:15:41] detectron2 INFO: Inference done 22552/26446. 0.1687 s / img. ETA=0:11:05
[07/01 18:15:46] detectron2 INFO: Inference done 22583/26446. 0.1687 s / img. ETA=0:11:00
[07/01 18:15:51] detectron2 INFO: Inference done 22612/26446. 0.1687 s / img. ETA=0:10:55
[07/01 18:15:56] detectron2 INFO: Inference done 22642/26446. 0.1687 s / img. ETA=0:10:50
[07/01 18:16:01] detectron2 INFO: Inference done 22671/26446. 0.1687 s / img. ETA=0:10:45
[07/01 18:16:06] detectron2 INFO: Inference done 22701/26446. 0.1687 s / img. ETA=0:10:40
[07/01 18:16:11] detectron2 INFO: Inference done 22731/26446. 0.1687 s / img. ETA=0:10:35
[07/01 18:16:16] detectron2 INFO: Inference done 22760/26446. 0.1687 s / img. ETA=0:10:30
[07/01 18:16:21] detectron2 INFO: Inference done 22789/26446. 0.1687 s / img. ETA=0:10:25
[07/01 18:16:26] detectron2 INFO: Inference done 22818/26446. 0.1687 s / img. ETA=0:10:20
[07/01 18:16:32] detectron2 INFO: Inference done 22848/26446. 0.1687 s / img. ETA=0:10:15
[07/01 18:16:37] detectron2 INFO: Inference done 22878/26446. 0.1687 s / img. ETA=0:10:10
[07/01 18:16:42] detectron2 INFO: Inference done 22908/26446. 0.1687 s / img. ETA=0:10:04
[07/01 18:16:47] detectron2 INFO: Inference done 22937/26446. 0.1687 s / img. ETA=0:10:00
[07/01 18:16:52] detectron2 INFO: Inference done 22966/26446. 0.1687 s / img. ETA=0:09:55
[07/01 18:16:57] detectron2 INFO: Inference done 22996/26446. 0.1687 s / img. ETA=0:09:49
[07/01 18:17:02] detectron2 INFO: Inference done 23025/26446. 0.1687 s / img. ETA=0:09:44
[07/01 18:17:07] detectron2 INFO: Inference done 23054/26446. 0.1687 s / img. ETA=0:09:40
[07/01 18:17:12] detectron2 INFO: Inference done 23083/26446. 0.1687 s / img. ETA=0:09:35
[07/01 18:17:17] detectron2 INFO: Inference done 23113/26446. 0.1687 s / img. ETA=0:09:29
[07/01 18:17:22] detectron2 INFO: Inference done 23143/26446. 0.1687 s / img. ETA=0:09:24
[07/01 18:17:28] detectron2 INFO: Inference done 23172/26446. 0.1687 s / img. ETA=0:09:19
[07/01 18:17:33] detectron2 INFO: Inference done 23201/26446. 0.1687 s / img. ETA=0:09:14
[07/01 18:17:38] detectron2 INFO: Inference done 23230/26446. 0.1687 s / img. ETA=0:09:10
[07/01 18:17:43] detectron2 INFO: Inference done 23260/26446. 0.1687 s / img. ETA=0:09:04
[07/01 18:17:48] detectron2 INFO: Inference done 23290/26446. 0.1687 s / img. ETA=0:08:59
[07/01 18:17:53] detectron2 INFO: Inference done 23320/26446. 0.1687 s / img. ETA=0:08:54
[07/01 18:17:58] detectron2 INFO: Inference done 23350/26446. 0.1687 s / img. ETA=0:08:49
[07/01 18:18:03] detectron2 INFO: Inference done 23380/26446. 0.1687 s / img. ETA=0:08:44
[07/01 18:18:08] detectron2 INFO: Inference done 23409/26446. 0.1687 s / img. ETA=0:08:39
[07/01 18:18:13] detectron2 INFO: Inference done 23439/26446. 0.1687 s / img. ETA=0:08:34
[07/01 18:18:18] detectron2 INFO: Inference done 23469/26446. 0.1687 s / img. ETA=0:08:29
[07/01 18:18:23] detectron2 INFO: Inference done 23499/26446. 0.1687 s / img. ETA=0:08:23
[07/01 18:18:28] detectron2 INFO: Inference done 23529/26446. 0.1687 s / img. ETA=0:08:18
[07/01 18:18:34] detectron2 INFO: Inference done 23559/26446. 0.1687 s / img. ETA=0:08:13
[07/01 18:18:39] detectron2 INFO: Inference done 23589/26446. 0.1687 s / img. ETA=0:08:08
[07/01 18:18:44] detectron2 INFO: Inference done 23618/26446. 0.1687 s / img. ETA=0:08:03
[07/01 18:18:49] detectron2 INFO: Inference done 23648/26446. 0.1687 s / img. ETA=0:07:58
[07/01 18:18:54] detectron2 INFO: Inference done 23677/26446. 0.1687 s / img. ETA=0:07:53
[07/01 18:18:59] detectron2 INFO: Inference done 23707/26446. 0.1687 s / img. ETA=0:07:48
[07/01 18:19:04] detectron2 INFO: Inference done 23737/26446. 0.1687 s / img. ETA=0:07:43
[07/01 18:19:09] detectron2 INFO: Inference done 23767/26446. 0.1687 s / img. ETA=0:07:38
[07/01 18:19:14] detectron2 INFO: Inference done 23796/26446. 0.1687 s / img. ETA=0:07:33
[07/01 18:19:19] detectron2 INFO: Inference done 23826/26446. 0.1687 s / img. ETA=0:07:28
[07/01 18:19:24] detectron2 INFO: Inference done 23856/26446. 0.1687 s / img. ETA=0:07:22
[07/01 18:19:29] detectron2 INFO: Inference done 23886/26446. 0.1687 s / img. ETA=0:07:17
[07/01 18:19:34] detectron2 INFO: Inference done 23917/26446. 0.1687 s / img. ETA=0:07:12
[07/01 18:19:39] detectron2 INFO: Inference done 23947/26446. 0.1687 s / img. ETA=0:07:07
[07/01 18:19:45] detectron2 INFO: Inference done 23977/26446. 0.1687 s / img. ETA=0:07:02
[07/01 18:19:50] detectron2 INFO: Inference done 24006/26446. 0.1687 s / img. ETA=0:06:57
[07/01 18:19:55] detectron2 INFO: Inference done 24036/26446. 0.1687 s / img. ETA=0:06:52
[07/01 18:20:00] detectron2 INFO: Inference done 24066/26446. 0.1687 s / img. ETA=0:06:46
[07/01 18:20:05] detectron2 INFO: Inference done 24096/26446. 0.1687 s / img. ETA=0:06:41
[07/01 18:20:10] detectron2 INFO: Inference done 24126/26446. 0.1687 s / img. ETA=0:06:36
[07/01 18:20:15] detectron2 INFO: Inference done 24156/26446. 0.1687 s / img. ETA=0:06:31
[07/01 18:20:20] detectron2 INFO: Inference done 24186/26446. 0.1687 s / img. ETA=0:06:26
[07/01 18:20:25] detectron2 INFO: Inference done 24216/26446. 0.1687 s / img. ETA=0:06:21
[07/01 18:20:30] detectron2 INFO: Inference done 24245/26446. 0.1687 s / img. ETA=0:06:16
[07/01 18:20:36] detectron2 INFO: Inference done 24275/26446. 0.1687 s / img. ETA=0:06:11
[07/01 18:20:41] detectron2 INFO: Inference done 24305/26446. 0.1687 s / img. ETA=0:06:06
[07/01 18:20:46] detectron2 INFO: Inference done 24334/26446. 0.1687 s / img. ETA=0:06:01
[07/01 18:20:51] detectron2 INFO: Inference done 24363/26446. 0.1687 s / img. ETA=0:05:56
[07/01 18:20:56] detectron2 INFO: Inference done 24393/26446. 0.1687 s / img. ETA=0:05:51
[07/01 18:21:01] detectron2 INFO: Inference done 24423/26446. 0.1687 s / img. ETA=0:05:45
[07/01 18:21:06] detectron2 INFO: Inference done 24453/26446. 0.1687 s / img. ETA=0:05:40
[07/01 18:21:11] detectron2 INFO: Inference done 24483/26446. 0.1687 s / img. ETA=0:05:35
[07/01 18:21:16] detectron2 INFO: Inference done 24512/26446. 0.1687 s / img. ETA=0:05:30
[07/01 18:21:21] detectron2 INFO: Inference done 24542/26446. 0.1687 s / img. ETA=0:05:25
[07/01 18:21:26] detectron2 INFO: Inference done 24572/26446. 0.1687 s / img. ETA=0:05:20
[07/01 18:21:32] detectron2 INFO: Inference done 24602/26446. 0.1687 s / img. ETA=0:05:15
[07/01 18:21:37] detectron2 INFO: Inference done 24631/26446. 0.1687 s / img. ETA=0:05:10
[07/01 18:21:42] detectron2 INFO: Inference done 24661/26446. 0.1687 s / img. ETA=0:05:05
[07/01 18:21:47] detectron2 INFO: Inference done 24691/26446. 0.1687 s / img. ETA=0:05:00
[07/01 18:21:52] detectron2 INFO: Inference done 24720/26446. 0.1687 s / img. ETA=0:04:55
[07/01 18:21:57] detectron2 INFO: Inference done 24749/26446. 0.1687 s / img. ETA=0:04:50
[07/01 18:22:02] detectron2 INFO: Inference done 24778/26446. 0.1687 s / img. ETA=0:04:45
[07/01 18:22:07] detectron2 INFO: Inference done 24808/26446. 0.1687 s / img. ETA=0:04:40
[07/01 18:22:12] detectron2 INFO: Inference done 24838/26446. 0.1687 s / img. ETA=0:04:34
[07/01 18:22:17] detectron2 INFO: Inference done 24867/26446. 0.1687 s / img. ETA=0:04:30
[07/01 18:22:22] detectron2 INFO: Inference done 24897/26446. 0.1687 s / img. ETA=0:04:24
[07/01 18:22:27] detectron2 INFO: Inference done 24927/26446. 0.1687 s / img. ETA=0:04:19
[07/01 18:22:32] detectron2 INFO: Inference done 24956/26446. 0.1687 s / img. ETA=0:04:14
[07/01 18:22:38] detectron2 INFO: Inference done 24985/26446. 0.1687 s / img. ETA=0:04:09
[07/01 18:22:43] detectron2 INFO: Inference done 25016/26446. 0.1687 s / img. ETA=0:04:04
[07/01 18:22:48] detectron2 INFO: Inference done 25046/26446. 0.1687 s / img. ETA=0:03:59
[07/01 18:22:53] detectron2 INFO: Inference done 25076/26446. 0.1687 s / img. ETA=0:03:54
[07/01 18:22:58] detectron2 INFO: Inference done 25106/26446. 0.1687 s / img. ETA=0:03:49
[07/01 18:23:03] detectron2 INFO: Inference done 25136/26446. 0.1687 s / img. ETA=0:03:44
[07/01 18:23:08] detectron2 INFO: Inference done 25161/26446. 0.1688 s / img. ETA=0:03:39
[07/01 18:23:13] detectron2 INFO: Inference done 25189/26446. 0.1688 s / img. ETA=0:03:35
[07/01 18:23:18] detectron2 INFO: Inference done 25218/26446. 0.1688 s / img. ETA=0:03:30
[07/01 18:23:24] detectron2 INFO: Inference done 25247/26446. 0.1688 s / img. ETA=0:03:25
[07/01 18:23:29] detectron2 INFO: Inference done 25276/26446. 0.1688 s / img. ETA=0:03:20
[07/01 18:23:34] detectron2 INFO: Inference done 25305/26446. 0.1688 s / img. ETA=0:03:15
[07/01 18:23:39] detectron2 INFO: Inference done 25333/26446. 0.1688 s / img. ETA=0:03:10
[07/01 18:23:44] detectron2 INFO: Inference done 25363/26446. 0.1688 s / img. ETA=0:03:05
[07/01 18:23:49] detectron2 INFO: Inference done 25393/26446. 0.1688 s / img. ETA=0:03:00
[07/01 18:23:54] detectron2 INFO: Inference done 25422/26446. 0.1688 s / img. ETA=0:02:55
[07/01 18:23:59] detectron2 INFO: Inference done 25450/26446. 0.1688 s / img. ETA=0:02:50
[07/01 18:24:04] detectron2 INFO: Inference done 25479/26446. 0.1688 s / img. ETA=0:02:45
[07/01 18:24:10] detectron2 INFO: Inference done 25509/26446. 0.1688 s / img. ETA=0:02:40
[07/01 18:24:15] detectron2 INFO: Inference done 25538/26446. 0.1688 s / img. ETA=0:02:35
[07/01 18:24:20] detectron2 INFO: Inference done 25567/26446. 0.1688 s / img. ETA=0:02:30
[07/01 18:24:25] detectron2 INFO: Inference done 25596/26446. 0.1688 s / img. ETA=0:02:25
[07/01 18:24:30] detectron2 INFO: Inference done 25625/26446. 0.1688 s / img. ETA=0:02:20
[07/01 18:24:35] detectron2 INFO: Inference done 25654/26446. 0.1688 s / img. ETA=0:02:15
[07/01 18:24:40] detectron2 INFO: Inference done 25683/26446. 0.1688 s / img. ETA=0:02:10
[07/01 18:24:45] detectron2 INFO: Inference done 25713/26446. 0.1688 s / img. ETA=0:02:05
[07/01 18:24:50] detectron2 INFO: Inference done 25742/26446. 0.1688 s / img. ETA=0:02:00
[07/01 18:24:55] detectron2 INFO: Inference done 25771/26446. 0.1689 s / img. ETA=0:01:55
[07/01 18:25:00] detectron2 INFO: Inference done 25801/26446. 0.1689 s / img. ETA=0:01:50
[07/01 18:25:05] detectron2 INFO: Inference done 25830/26446. 0.1689 s / img. ETA=0:01:45
[07/01 18:25:10] detectron2 INFO: Inference done 25849/26446. 0.1689 s / img. ETA=0:01:42
[07/01 18:25:16] detectron2 INFO: Inference done 25875/26446. 0.1689 s / img. ETA=0:01:37
[07/01 18:25:21] detectron2 INFO: Inference done 25903/26446. 0.1690 s / img. ETA=0:01:32
[07/01 18:25:26] detectron2 INFO: Inference done 25932/26446. 0.1690 s / img. ETA=0:01:28
[07/01 18:25:31] detectron2 INFO: Inference done 25963/26446. 0.1690 s / img. ETA=0:01:22
[07/01 18:25:36] detectron2 INFO: Inference done 25989/26446. 0.1690 s / img. ETA=0:01:18
[07/01 18:25:41] detectron2 INFO: Inference done 26015/26446. 0.1690 s / img. ETA=0:01:13
[07/01 18:25:46] detectron2 INFO: Inference done 26043/26446. 0.1690 s / img. ETA=0:01:09
[07/01 18:25:51] detectron2 INFO: Inference done 26073/26446. 0.1690 s / img. ETA=0:01:03
[07/01 18:25:56] detectron2 INFO: Inference done 26103/26446. 0.1690 s / img. ETA=0:00:58
[07/01 18:26:01] detectron2 INFO: Inference done 26133/26446. 0.1690 s / img. ETA=0:00:53
[07/01 18:26:06] detectron2 INFO: Inference done 26163/26446. 0.1690 s / img. ETA=0:00:48
[07/01 18:26:12] detectron2 INFO: Inference done 26193/26446. 0.1690 s / img. ETA=0:00:43
[07/01 18:26:17] detectron2 INFO: Inference done 26223/26446. 0.1690 s / img. ETA=0:00:38
[07/01 18:26:22] detectron2 INFO: Inference done 26253/26446. 0.1690 s / img. ETA=0:00:33
[07/01 18:26:27] detectron2 INFO: Inference done 26283/26446. 0.1690 s / img. ETA=0:00:27
[07/01 18:26:32] detectron2 INFO: Inference done 26312/26446. 0.1690 s / img. ETA=0:00:22
[07/01 18:26:37] detectron2 INFO: Inference done 26341/26446. 0.1690 s / img. ETA=0:00:17
[07/01 18:26:42] detectron2 INFO: Inference done 26371/26446. 0.1690 s / img. ETA=0:00:12
[07/01 18:26:47] detectron2 INFO: Inference done 26398/26446. 0.1690 s / img. ETA=0:00:08
[07/01 18:26:52] detectron2 INFO: Inference done 26424/26446. 0.1691 s / img. ETA=0:00:03
[07/01 18:26:58] detectron2 INFO: Total inference time: 1:15:32.374238 (0.171415 s / img per device, on 1 devices)
[07/01 18:26:58] detectron2 INFO: Total inference pure compute time: 1:14:30 (0.169070 s / img per device, on 1 devices)
[07/01 18:27:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/01 18:27:04] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[07/01 18:27:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[07/01 18:31:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.144 | 26.678 | 12.842 | 3.719 | 9.866 | 19.490 |
[07/01 18:31:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| airplane   | 0.895  | animal     | 1.527  | arm        | 2.904  |
| bag        | 6.816  | banana     | 9.249  | basket     | 9.273  |
| beach      | 28.895 | bear       | 32.365 | bed        | 43.617 |
| bench      | 20.625 | bike       | 19.086 | bird       | 20.807 |
| board      | 3.068  | boat       | 16.878 | book       | 4.759  |
| boot       | 7.171  | bottle     | 14.857 | bowl       | 21.461 |
| box        | 5.787  | boy        | 18.968 | branch     | 0.585  |
| building   | 21.224 | bus        | 41.760 | cabinet    | 5.922  |
| cap        | 4.386  | car        | 21.051 | cat        | 43.062 |
| chair      | 18.167 | child      | 3.366  | clock      | 22.045 |
| coat       | 3.323  | counter    | 10.797 | cow        | 29.941 |
| cup        | 15.297 | curtain    | 13.455 | desk       | 16.370 |
| dog        | 34.428 | door       | 8.758  | drawer     | 6.200  |
| ear        | 19.435 | elephant   | 39.308 | engine     | 15.324 |
| eye        | 10.236 | face       | 7.647  | fence      | 17.717 |
| finger     | 1.469  | flag       | 6.732  | flower     | 5.829  |
| food       | 12.515 | fork       | 21.483 | fruit      | 2.076  |
| giraffe    | 41.787 | girl       | 11.339 | glass      | 15.907 |
| glove      | 10.972 | guy        | 0.000  | hair       | 21.924 |
| hand       | 11.238 | handle     | 3.726  | hat        | 20.049 |
| head       | 15.643 | helmet     | 24.297 | hill       | 4.387  |
| horse      | 34.231 | house      | 6.495  | jacket     | 18.326 |
| jean       | 18.795 | kid        | 0.243  | kite       | 17.238 |
| lady       | 0.000  | lamp       | 15.000 | laptop     | 38.182 |
| leaf       | 0.934  | leg        | 5.414  | letter     | 1.026  |
| light      | 2.071  | logo       | 3.151  | man        | 33.762 |
| men        | 0.665  | motorcycle | 24.847 | mountain   | 9.276  |
| mouth      | 6.286  | neck       | 8.322  | nose       | 12.695 |
| number     | 2.677  | orange     | 14.952 | pant       | 20.015 |
| paper      | 4.281  | paw        | 6.741  | people     | 1.237  |
| person     | 5.630  | phone      | 9.606  | pillow     | 17.637 |
| pizza      | 31.836 | plane      | 27.990 | plant      | 4.833  |
| plate      | 30.651 | player     | 6.462  | pole       | 5.563  |
| post       | 1.372  | pot        | 4.601  | racket     | 25.502 |
| railing    | 1.176  | rock       | 5.251  | roof       | 6.328  |
| room       | 21.234 | screen     | 20.992 | seat       | 8.300  |
| sheep      | 23.579 | shelf      | 2.394  | shirt      | 28.677 |
| shoe       | 11.884 | short      | 29.211 | sidewalk   | 10.119 |
| sign       | 17.229 | sink       | 15.545 | skateboard | 24.463 |
| ski        | 11.004 | skier      | 4.790  | sneaker    | 0.167  |
| snow       | 19.481 | sock       | 8.984  | stand      | 1.821  |
| street     | 16.616 | surfboard  | 16.902 | table      | 27.981 |
| tail       | 14.732 | tie        | 20.670 | tile       | 0.762  |
| tire       | 11.820 | toilet     | 35.482 | towel      | 8.618  |
| tower      | 19.900 | track      | 10.863 | train      | 35.978 |
| tree       | 9.248  | truck      | 23.817 | trunk      | 11.049 |
| umbrella   | 19.689 | vase       | 21.008 | vegetable  | 1.345  |
| vehicle    | 0.462  | wave       | 12.027 | wheel      | 9.300  |
| window     | 6.751  | windshield | 11.244 | wing       | 10.510 |
| wire       | 0.645  | woman      | 23.758 | zebra      | 39.046 |
[07/01 18:31:09] detectron2 INFO: Gathering data
[07/01 18:31:09] detectron2 INFO: Predictions Gathered
[07/01 18:31:23] detectron2 INFO: Saving output prediction
[07/01 18:31:23] detectron2 INFO: Computing Scene Graph Metrics
[07/01 18:31:23] detectron2 INFO: Preparing Global Container
[07/01 18:38:59] detectron2 INFO: Scene Graph Metric Evaluation Complete. Computing recall statistics...
[07/01 18:39:55] detectron2 INFO: Scene Graph Results for mode: sgdet
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: 14.1439,26.6782,12.8420,3.7192,9.8663,19.4897
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: Task: SG
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: SGMeanRecall@20,SGMeanRecall@50,SGMeanRecall@100,SGRecall@20,SGRecall@50,SGRecall@100
[07/01 18:40:01] d2.evaluation.testing INFO: copypaste: 0.1020,0.1483,0.1699,0.2489,0.3168,0.3509
