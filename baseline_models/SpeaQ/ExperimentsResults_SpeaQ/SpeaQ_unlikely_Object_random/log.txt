[07/02 15:14:26] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:14:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:14:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:14:27] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:14:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:14:27] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:14:27] d2.utils.env INFO: Using a generated random seed 27503695
[07/02 15:14:31] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:14:31] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:14:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:14:33] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:14:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:14:33] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:14:35] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:14:35] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:14:35] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:14:35] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:14:35] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:14:35] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:14:35] d2.data.datasets.coco INFO: Converting annotations of dataset 'VG_test' to COCO format ...)
[07/02 15:14:35] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[07/02 15:15:20] d2.data.datasets.coco INFO: Conversion finished, #images: 26446, #annotations: 325570
[07/02 15:15:20] d2.data.datasets.coco INFO: Caching COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json' ...
[07/02 15:15:26] detectron2 INFO: Loading zero shot triplets
[07/02 15:15:26] detectron2 INFO: Start inference on 26446 images
[07/02 15:19:42] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:19:43] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:19:43] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:19:43] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:19:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:19:43] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:19:43] d2.utils.env INFO: Using a generated random seed 43253399
[07/02 15:19:46] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:19:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:19:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:19:47] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:19:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:19:47] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:19:49] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:19:49] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:19:49] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:19:49] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:19:49] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:19:49] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:19:49] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:19:51] detectron2 INFO: Loading zero shot triplets
[07/02 15:19:51] detectron2 INFO: Start inference on 26446 images
[07/02 15:28:34] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:28:35] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:28:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:28:35] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:28:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:28:35] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:28:35] d2.utils.env INFO: Using a generated random seed 35356835
[07/02 15:28:38] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:28:38] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:28:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:28:39] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:28:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:28:39] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:28:41] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:28:41] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:28:41] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:28:41] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:28:41] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:28:41] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:28:41] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:28:43] detectron2 INFO: Loading zero shot triplets
[07/02 15:28:43] detectron2 INFO: Start inference on 26446 images
[07/02 15:33:01] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:33:02] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:33:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:33:02] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:33:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:33:02] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:33:02] d2.utils.env INFO: Using a generated random seed 2973040
[07/02 15:33:05] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:33:05] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:33:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:33:07] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:33:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:33:07] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:33:08] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:33:08] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:33:08] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:33:08] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:33:08] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:33:08] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:33:08] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:33:10] detectron2 INFO: Loading zero shot triplets
[07/02 15:33:10] detectron2 INFO: Start inference on 26446 images
[07/02 15:35:56] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:35:57] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:35:57] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:35:57] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:35:57] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:35:57] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:35:57] d2.utils.env INFO: Using a generated random seed 57978529
[07/02 15:36:00] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:36:00] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:36:00] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:36:02] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:36:02] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:36:02] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:36:04] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:36:04] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:36:04] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:36:04] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:36:04] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:36:04] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:36:04] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:36:06] detectron2 INFO: Loading zero shot triplets
[07/02 15:36:06] detectron2 INFO: Start inference on 26446 images
[07/02 15:38:02] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:38:03] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:38:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:38:03] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:38:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:38:03] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:38:04] d2.utils.env INFO: Using a generated random seed 4089326
[07/02 15:38:06] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:38:06] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:38:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:38:09] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:38:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:38:09] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:38:11] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:38:11] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:38:11] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:38:11] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:38:11] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:38:11] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:38:11] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:38:13] detectron2 INFO: Loading zero shot triplets
[07/02 15:38:13] detectron2 INFO: Start inference on 26446 images
[07/02 15:46:13] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:46:14] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:46:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:46:14] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:46:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:46:14] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:46:14] d2.utils.env INFO: Using a generated random seed 14507997
[07/02 15:46:17] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:46:17] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:46:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:46:19] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:46:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:46:19] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:46:20] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:46:20] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:46:20] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:46:20] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:46:20] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:46:20] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:46:20] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:46:22] detectron2 INFO: Loading zero shot triplets
[07/02 15:46:22] detectron2 INFO: Start inference on 26446 images
[07/02 15:51:41] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:51:42] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:51:42] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:51:42] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:51:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:51:42] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:51:42] d2.utils.env INFO: Using a generated random seed 42706952
[07/02 15:51:45] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:51:45] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:51:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:51:47] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:51:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:51:47] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:51:49] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:51:49] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:51:49] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:51:49] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:51:49] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:51:49] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:51:49] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:51:51] detectron2 INFO: Loading zero shot triplets
[07/02 15:51:51] detectron2 INFO: Start inference on 26446 images
[07/02 15:52:18] detectron2 INFO: Inference done 1/26446. 15.4594 s / img. ETA=8 days, 6:38:05
[07/02 15:52:28] detectron2 INFO: Inference done 2/26446. 12.3580 s / img. ETA=5 days, 13:19:09
[07/02 15:52:33] detectron2 INFO: Inference done 4/26446. 7.4695 s / img. ETA=3 days, 4:08:27
[07/02 15:52:41] detectron2 INFO: Inference done 5/26446. 7.6809 s / img. ETA=3 days, 1:26:16
[07/02 15:58:10] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:58:11] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:58:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:58:11] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:58:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:58:11] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:58:11] d2.utils.env INFO: Using a generated random seed 11345185
[07/02 15:58:14] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:58:14] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:58:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:58:15] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:58:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:58:15] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:58:17] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:58:17] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:58:17] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:58:17] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:58:17] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:58:17] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:58:17] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:58:19] detectron2 INFO: Loading zero shot triplets
[07/02 15:58:19] detectron2 INFO: Start inference on 26446 images
[07/02 15:58:34] detectron2 INFO: Inference done 1/26446. 5.0340 s / img. ETA=4 days, 16:58:34
[07/02 15:58:39] detectron2 INFO: Inference done 18/26446. 0.2710 s / img. ETA=2:00:15
[07/02 15:59:19] detectron2 INFO: Rank of current process: 0. World size: 1
[07/02 15:59:20] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/02 15:59:20] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/02 15:59:20] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/02 15:59:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/02 15:59:20] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/02 15:59:20] d2.utils.env INFO: Using a generated random seed 20906567
[07/02 15:59:23] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/02 15:59:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:59:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/02 15:59:25] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/02 15:59:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/02 15:59:25] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/02 15:59:27] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/02 15:59:27] detectron2 INFO: Following metrics will be use for evaluation
[07/02 15:59:27] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/02 15:59:27] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/02 15:59:27] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/02 15:59:27] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/02 15:59:27] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/02 15:59:28] detectron2 INFO: Loading zero shot triplets
[07/02 15:59:28] detectron2 INFO: Start inference on 26446 images
[07/02 15:59:48] detectron2 INFO: Inference done 11/26446. 0.2644 s / img. ETA=1:57:25
[07/02 15:59:53] detectron2 INFO: Inference done 30/26446. 0.2699 s / img. ETA=1:59:48
[07/02 15:59:58] detectron2 INFO: Inference done 49/26446. 0.2676 s / img. ETA=1:58:39
[07/02 16:00:03] detectron2 INFO: Inference done 67/26446. 0.2709 s / img. ETA=2:00:03
[07/02 16:00:08] detectron2 INFO: Inference done 86/26446. 0.2712 s / img. ETA=2:00:05
[07/02 16:00:14] detectron2 INFO: Inference done 105/26446. 0.2708 s / img. ETA=1:59:49
[07/02 16:00:19] detectron2 INFO: Inference done 124/26446. 0.2712 s / img. ETA=1:59:56
[07/02 16:00:24] detectron2 INFO: Inference done 143/26446. 0.2704 s / img. ETA=1:59:29
[07/02 16:00:29] detectron2 INFO: Inference done 162/26446. 0.2703 s / img. ETA=1:59:21
[07/02 16:00:34] detectron2 INFO: Inference done 181/26446. 0.2702 s / img. ETA=1:59:14
[07/02 16:00:39] detectron2 INFO: Inference done 200/26446. 0.2701 s / img. ETA=1:59:05
[07/02 16:00:45] detectron2 INFO: Inference done 219/26446. 0.2704 s / img. ETA=1:59:09
[07/02 16:00:50] detectron2 INFO: Inference done 238/26446. 0.2705 s / img. ETA=1:59:06
[07/02 16:00:55] detectron2 INFO: Inference done 257/26446. 0.2703 s / img. ETA=1:58:56
[07/02 16:01:00] detectron2 INFO: Inference done 276/26446. 0.2700 s / img. ETA=1:58:43
[07/02 16:01:05] detectron2 INFO: Inference done 295/26446. 0.2699 s / img. ETA=1:58:36
[07/02 16:01:10] detectron2 INFO: Inference done 313/26446. 0.2706 s / img. ETA=1:58:47
[07/02 16:01:15] detectron2 INFO: Inference done 331/26446. 0.2713 s / img. ETA=1:59:02
[07/02 16:01:21] detectron2 INFO: Inference done 349/26446. 0.2719 s / img. ETA=1:59:12
[07/02 16:01:26] detectron2 INFO: Inference done 367/26446. 0.2721 s / img. ETA=1:59:13
[07/02 16:01:31] detectron2 INFO: Inference done 386/26446. 0.2722 s / img. ETA=1:59:09
[07/02 16:01:36] detectron2 INFO: Inference done 404/26446. 0.2724 s / img. ETA=1:59:09
[07/02 16:01:41] detectron2 INFO: Inference done 423/26446. 0.2723 s / img. ETA=1:59:01
[07/02 16:01:46] detectron2 INFO: Inference done 442/26446. 0.2723 s / img. ETA=1:58:58
[07/02 16:01:51] detectron2 INFO: Inference done 461/26446. 0.2721 s / img. ETA=1:58:46
[07/02 16:01:57] detectron2 INFO: Inference done 480/26446. 0.2721 s / img. ETA=1:58:43
[07/02 16:02:02] detectron2 INFO: Inference done 499/26446. 0.2720 s / img. ETA=1:58:34
[07/02 16:02:07] detectron2 INFO: Inference done 518/26446. 0.2721 s / img. ETA=1:58:30
[07/02 16:02:12] detectron2 INFO: Inference done 537/26446. 0.2720 s / img. ETA=1:58:24
[07/02 16:02:17] detectron2 INFO: Inference done 556/26446. 0.2721 s / img. ETA=1:58:21
[07/02 16:02:23] detectron2 INFO: Inference done 575/26446. 0.2722 s / img. ETA=1:58:18
[07/02 16:02:28] detectron2 INFO: Inference done 594/26446. 0.2723 s / img. ETA=1:58:16
[07/02 16:02:33] detectron2 INFO: Inference done 613/26446. 0.2724 s / img. ETA=1:58:12
[07/02 16:02:38] detectron2 INFO: Inference done 632/26446. 0.2723 s / img. ETA=1:58:06
[07/02 16:02:44] detectron2 INFO: Inference done 651/26446. 0.2724 s / img. ETA=1:58:03
[07/02 16:02:49] detectron2 INFO: Inference done 670/26446. 0.2725 s / img. ETA=1:58:00
[07/02 16:02:54] detectron2 INFO: Inference done 688/26446. 0.2727 s / img. ETA=1:57:59
[07/02 16:02:59] detectron2 INFO: Inference done 706/26446. 0.2728 s / img. ETA=1:57:57
[07/02 16:03:04] detectron2 INFO: Inference done 724/26446. 0.2729 s / img. ETA=1:57:54
[07/02 16:03:09] detectron2 INFO: Inference done 743/26446. 0.2729 s / img. ETA=1:57:51
[07/02 16:03:14] detectron2 INFO: Inference done 762/26446. 0.2727 s / img. ETA=1:57:41
[07/02 16:03:20] detectron2 INFO: Inference done 781/26446. 0.2727 s / img. ETA=1:57:33
[07/02 16:03:25] detectron2 INFO: Inference done 800/26446. 0.2727 s / img. ETA=1:57:29
[07/02 16:03:30] detectron2 INFO: Inference done 819/26446. 0.2725 s / img. ETA=1:57:19
[07/02 16:03:35] detectron2 INFO: Inference done 838/26446. 0.2725 s / img. ETA=1:57:13
[07/02 16:03:40] detectron2 INFO: Inference done 856/26446. 0.2726 s / img. ETA=1:57:12
[07/02 16:03:45] detectron2 INFO: Inference done 875/26446. 0.2727 s / img. ETA=1:57:07
[07/02 16:03:51] detectron2 INFO: Inference done 894/26446. 0.2727 s / img. ETA=1:57:03
[07/02 16:03:56] detectron2 INFO: Inference done 912/26446. 0.2727 s / img. ETA=1:57:00
[07/02 16:04:01] detectron2 INFO: Inference done 930/26446. 0.2728 s / img. ETA=1:56:56
[07/02 16:04:06] detectron2 INFO: Inference done 949/26446. 0.2727 s / img. ETA=1:56:48
[07/02 16:04:11] detectron2 INFO: Inference done 968/26446. 0.2727 s / img. ETA=1:56:44
[07/02 16:04:16] detectron2 INFO: Inference done 986/26446. 0.2729 s / img. ETA=1:56:43
[07/02 16:04:21] detectron2 INFO: Inference done 1005/26446. 0.2727 s / img. ETA=1:56:33
[07/02 16:04:26] detectron2 INFO: Inference done 1024/26446. 0.2727 s / img. ETA=1:56:27
[07/02 16:04:32] detectron2 INFO: Inference done 1043/26446. 0.2727 s / img. ETA=1:56:22
[07/02 16:04:37] detectron2 INFO: Inference done 1062/26446. 0.2727 s / img. ETA=1:56:17
[07/02 16:04:42] detectron2 INFO: Inference done 1080/26446. 0.2728 s / img. ETA=1:56:14
[07/02 16:04:47] detectron2 INFO: Inference done 1099/26446. 0.2728 s / img. ETA=1:56:09
[07/02 16:04:52] detectron2 INFO: Inference done 1117/26446. 0.2729 s / img. ETA=1:56:07
[07/02 16:04:57] detectron2 INFO: Inference done 1136/26446. 0.2729 s / img. ETA=1:56:03
[07/02 16:05:03] detectron2 INFO: Inference done 1155/26446. 0.2729 s / img. ETA=1:55:56
[07/02 16:05:08] detectron2 INFO: Inference done 1173/26446. 0.2730 s / img. ETA=1:55:54
[07/02 16:05:13] detectron2 INFO: Inference done 1192/26446. 0.2730 s / img. ETA=1:55:49
[07/02 16:05:18] detectron2 INFO: Inference done 1211/26446. 0.2730 s / img. ETA=1:55:44
[07/02 16:05:23] detectron2 INFO: Inference done 1230/26446. 0.2730 s / img. ETA=1:55:40
[07/02 16:05:29] detectron2 INFO: Inference done 1249/26446. 0.2730 s / img. ETA=1:55:33
[07/02 16:05:34] detectron2 INFO: Inference done 1268/26446. 0.2730 s / img. ETA=1:55:29
[07/02 16:05:39] detectron2 INFO: Inference done 1287/26446. 0.2730 s / img. ETA=1:55:23
[07/02 16:05:44] detectron2 INFO: Inference done 1306/26446. 0.2730 s / img. ETA=1:55:18
[07/02 16:05:49] detectron2 INFO: Inference done 1323/26446. 0.2733 s / img. ETA=1:55:21
[07/02 16:05:55] detectron2 INFO: Inference done 1340/26446. 0.2737 s / img. ETA=1:55:26
[07/02 16:06:00] detectron2 INFO: Inference done 1357/26446. 0.2741 s / img. ETA=1:55:31
[07/02 16:06:05] detectron2 INFO: Inference done 1376/26446. 0.2740 s / img. ETA=1:55:23
[07/02 16:06:10] detectron2 INFO: Inference done 1395/26446. 0.2740 s / img. ETA=1:55:18
[07/02 16:06:15] detectron2 INFO: Inference done 1414/26446. 0.2739 s / img. ETA=1:55:11
[07/02 16:06:20] detectron2 INFO: Inference done 1432/26446. 0.2740 s / img. ETA=1:55:07
[07/02 16:06:26] detectron2 INFO: Inference done 1451/26446. 0.2740 s / img. ETA=1:55:03
[07/02 16:06:31] detectron2 INFO: Inference done 1470/26446. 0.2739 s / img. ETA=1:54:55
[07/02 16:06:36] detectron2 INFO: Inference done 1488/26446. 0.2739 s / img. ETA=1:54:51
[07/02 16:06:41] detectron2 INFO: Inference done 1507/26446. 0.2738 s / img. ETA=1:54:42
[07/02 16:06:46] detectron2 INFO: Inference done 1526/26446. 0.2737 s / img. ETA=1:54:36
[07/02 16:06:51] detectron2 INFO: Inference done 1545/26446. 0.2737 s / img. ETA=1:54:30
[07/02 16:06:56] detectron2 INFO: Inference done 1564/26446. 0.2736 s / img. ETA=1:54:23
[07/02 16:07:01] detectron2 INFO: Inference done 1583/26446. 0.2736 s / img. ETA=1:54:17
[07/02 16:07:07] detectron2 INFO: Inference done 1602/26446. 0.2735 s / img. ETA=1:54:10
[07/02 16:07:12] detectron2 INFO: Inference done 1621/26446. 0.2735 s / img. ETA=1:54:04
[07/02 16:07:17] detectron2 INFO: Inference done 1640/26446. 0.2734 s / img. ETA=1:53:57
[07/02 16:07:22] detectron2 INFO: Inference done 1659/26446. 0.2734 s / img. ETA=1:53:51
[07/02 16:07:27] detectron2 INFO: Inference done 1677/26446. 0.2734 s / img. ETA=1:53:47
[07/02 16:07:32] detectron2 INFO: Inference done 1696/26446. 0.2734 s / img. ETA=1:53:41
[07/02 16:07:37] detectron2 INFO: Inference done 1715/26446. 0.2734 s / img. ETA=1:53:34
[07/02 16:07:43] detectron2 INFO: Inference done 1734/26446. 0.2733 s / img. ETA=1:53:28
[07/02 16:07:48] detectron2 INFO: Inference done 1753/26446. 0.2732 s / img. ETA=1:53:21
[07/02 16:07:53] detectron2 INFO: Inference done 1772/26446. 0.2731 s / img. ETA=1:53:13
[07/02 16:07:58] detectron2 INFO: Inference done 1791/26446. 0.2731 s / img. ETA=1:53:08
[07/02 16:08:03] detectron2 INFO: Inference done 1810/26446. 0.2731 s / img. ETA=1:53:02
[07/02 16:08:08] detectron2 INFO: Inference done 1829/26446. 0.2731 s / img. ETA=1:52:56
[07/02 16:08:14] detectron2 INFO: Inference done 1848/26446. 0.2730 s / img. ETA=1:52:50
[07/02 16:08:19] detectron2 INFO: Inference done 1867/26446. 0.2730 s / img. ETA=1:52:45
[07/02 16:08:24] detectron2 INFO: Inference done 1885/26446. 0.2731 s / img. ETA=1:52:40
[07/02 16:08:29] detectron2 INFO: Inference done 1904/26446. 0.2730 s / img. ETA=1:52:35
[07/02 16:08:34] detectron2 INFO: Inference done 1922/26446. 0.2731 s / img. ETA=1:52:32
[07/02 16:08:39] detectron2 INFO: Inference done 1940/26446. 0.2732 s / img. ETA=1:52:28
[07/02 16:08:44] detectron2 INFO: Inference done 1959/26446. 0.2731 s / img. ETA=1:52:22
[07/02 16:08:49] detectron2 INFO: Inference done 1978/26446. 0.2731 s / img. ETA=1:52:16
[07/02 16:08:55] detectron2 INFO: Inference done 1995/26446. 0.2737 s / img. ETA=1:52:25
[07/02 16:09:00] detectron2 INFO: Inference done 2014/26446. 0.2737 s / img. ETA=1:52:19
[07/02 16:09:05] detectron2 INFO: Inference done 2032/26446. 0.2737 s / img. ETA=1:52:15
[07/02 16:09:11] detectron2 INFO: Inference done 2050/26446. 0.2737 s / img. ETA=1:52:11
[07/02 16:09:16] detectron2 INFO: Inference done 2068/26446. 0.2738 s / img. ETA=1:52:08
[07/02 16:09:21] detectron2 INFO: Inference done 2087/26446. 0.2738 s / img. ETA=1:52:02
[07/02 16:09:26] detectron2 INFO: Inference done 2105/26446. 0.2738 s / img. ETA=1:51:58
[07/02 16:09:31] detectron2 INFO: Inference done 2124/26446. 0.2738 s / img. ETA=1:51:53
[07/02 16:09:36] detectron2 INFO: Inference done 2143/26446. 0.2738 s / img. ETA=1:51:47
[07/02 16:09:42] detectron2 INFO: Inference done 2162/26446. 0.2738 s / img. ETA=1:51:41
[07/02 16:09:47] detectron2 INFO: Inference done 2181/26446. 0.2737 s / img. ETA=1:51:35
[07/02 16:09:52] detectron2 INFO: Inference done 2200/26446. 0.2737 s / img. ETA=1:51:29
[07/02 16:09:57] detectron2 INFO: Inference done 2219/26446. 0.2737 s / img. ETA=1:51:23
[07/02 16:10:02] detectron2 INFO: Inference done 2237/26446. 0.2737 s / img. ETA=1:51:19
[07/02 16:10:07] detectron2 INFO: Inference done 2255/26446. 0.2738 s / img. ETA=1:51:16
[07/02 16:10:12] detectron2 INFO: Inference done 2273/26446. 0.2738 s / img. ETA=1:51:12
[07/02 16:10:18] detectron2 INFO: Inference done 2292/26446. 0.2738 s / img. ETA=1:51:07
[07/02 16:10:23] detectron2 INFO: Inference done 2311/26446. 0.2738 s / img. ETA=1:51:02
[07/02 16:10:28] detectron2 INFO: Inference done 2329/26446. 0.2739 s / img. ETA=1:50:58
[07/02 16:10:33] detectron2 INFO: Inference done 2348/26446. 0.2739 s / img. ETA=1:50:52
[07/02 16:10:38] detectron2 INFO: Inference done 2367/26446. 0.2738 s / img. ETA=1:50:47
[07/02 16:10:44] detectron2 INFO: Inference done 2386/26446. 0.2738 s / img. ETA=1:50:41
[07/02 16:10:49] detectron2 INFO: Inference done 2405/26446. 0.2738 s / img. ETA=1:50:35
[07/02 16:10:54] detectron2 INFO: Inference done 2423/26446. 0.2738 s / img. ETA=1:50:31
[07/02 16:10:59] detectron2 INFO: Inference done 2442/26446. 0.2738 s / img. ETA=1:50:25
[07/02 16:11:04] detectron2 INFO: Inference done 2461/26446. 0.2737 s / img. ETA=1:50:18
[07/02 16:11:09] detectron2 INFO: Inference done 2479/26446. 0.2738 s / img. ETA=1:50:14
[07/02 16:11:14] detectron2 INFO: Inference done 2498/26446. 0.2737 s / img. ETA=1:50:08
[07/02 16:11:19] detectron2 INFO: Inference done 2517/26446. 0.2737 s / img. ETA=1:50:03
[07/02 16:11:25] detectron2 INFO: Inference done 2536/26446. 0.2737 s / img. ETA=1:49:56
[07/02 16:11:30] detectron2 INFO: Inference done 2555/26446. 0.2737 s / img. ETA=1:49:50
[07/02 16:11:35] detectron2 INFO: Inference done 2574/26446. 0.2737 s / img. ETA=1:49:45
[07/02 16:11:40] detectron2 INFO: Inference done 2593/26446. 0.2736 s / img. ETA=1:49:38
[07/02 16:11:45] detectron2 INFO: Inference done 2612/26446. 0.2735 s / img. ETA=1:49:32
[07/02 16:11:50] detectron2 INFO: Inference done 2631/26446. 0.2735 s / img. ETA=1:49:26
[07/02 16:11:56] detectron2 INFO: Inference done 2650/26446. 0.2735 s / img. ETA=1:49:21
[07/02 16:12:01] detectron2 INFO: Inference done 2669/26446. 0.2735 s / img. ETA=1:49:15
[07/02 16:12:06] detectron2 INFO: Inference done 2688/26446. 0.2735 s / img. ETA=1:49:10
[07/02 16:12:11] detectron2 INFO: Inference done 2707/26446. 0.2734 s / img. ETA=1:49:03
[07/02 16:12:16] detectron2 INFO: Inference done 2726/26446. 0.2734 s / img. ETA=1:48:56
[07/02 16:12:21] detectron2 INFO: Inference done 2745/26446. 0.2733 s / img. ETA=1:48:50
[07/02 16:12:27] detectron2 INFO: Inference done 2764/26446. 0.2734 s / img. ETA=1:48:45
[07/02 16:12:32] detectron2 INFO: Inference done 2782/26446. 0.2734 s / img. ETA=1:48:41
[07/02 16:12:37] detectron2 INFO: Inference done 2801/26446. 0.2734 s / img. ETA=1:48:35
[07/02 16:12:42] detectron2 INFO: Inference done 2820/26446. 0.2733 s / img. ETA=1:48:30
[07/02 16:12:47] detectron2 INFO: Inference done 2839/26446. 0.2733 s / img. ETA=1:48:24
[07/02 16:12:52] detectron2 INFO: Inference done 2858/26446. 0.2733 s / img. ETA=1:48:18
[07/02 16:12:57] detectron2 INFO: Inference done 2877/26446. 0.2732 s / img. ETA=1:48:12
[07/02 16:13:03] detectron2 INFO: Inference done 2896/26446. 0.2732 s / img. ETA=1:48:06
[07/02 16:13:08] detectron2 INFO: Inference done 2915/26446. 0.2732 s / img. ETA=1:48:01
[07/02 16:13:13] detectron2 INFO: Inference done 2934/26446. 0.2732 s / img. ETA=1:47:55
[07/02 16:13:18] detectron2 INFO: Inference done 2953/26446. 0.2732 s / img. ETA=1:47:49
[07/02 16:13:23] detectron2 INFO: Inference done 2972/26446. 0.2731 s / img. ETA=1:47:43
[07/02 16:13:28] detectron2 INFO: Inference done 2991/26446. 0.2731 s / img. ETA=1:47:37
[07/02 16:13:34] detectron2 INFO: Inference done 3010/26446. 0.2731 s / img. ETA=1:47:31
[07/02 16:13:39] detectron2 INFO: Inference done 3029/26446. 0.2731 s / img. ETA=1:47:26
[07/02 16:13:44] detectron2 INFO: Inference done 3048/26446. 0.2731 s / img. ETA=1:47:20
[07/02 16:13:49] detectron2 INFO: Inference done 3066/26446. 0.2731 s / img. ETA=1:47:16
[07/02 16:13:54] detectron2 INFO: Inference done 3085/26446. 0.2731 s / img. ETA=1:47:10
[07/02 16:13:59] detectron2 INFO: Inference done 3104/26446. 0.2731 s / img. ETA=1:47:05
[07/02 16:14:05] detectron2 INFO: Inference done 3122/26446. 0.2731 s / img. ETA=1:47:02
[07/02 16:14:10] detectron2 INFO: Inference done 3141/26446. 0.2731 s / img. ETA=1:46:57
[07/02 16:14:15] detectron2 INFO: Inference done 3159/26446. 0.2732 s / img. ETA=1:46:52
[07/02 16:14:20] detectron2 INFO: Inference done 3178/26446. 0.2732 s / img. ETA=1:46:47
[07/02 16:14:25] detectron2 INFO: Inference done 3197/26446. 0.2732 s / img. ETA=1:46:42
[07/02 16:14:30] detectron2 INFO: Inference done 3216/26446. 0.2732 s / img. ETA=1:46:36
[07/02 16:14:36] detectron2 INFO: Inference done 3235/26446. 0.2732 s / img. ETA=1:46:31
[07/02 16:14:41] detectron2 INFO: Inference done 3254/26446. 0.2731 s / img. ETA=1:46:25
[07/02 16:14:46] detectron2 INFO: Inference done 3273/26446. 0.2731 s / img. ETA=1:46:19
[07/02 16:14:51] detectron2 INFO: Inference done 3292/26446. 0.2731 s / img. ETA=1:46:14
[07/02 16:14:56] detectron2 INFO: Inference done 3310/26446. 0.2731 s / img. ETA=1:46:09
[07/02 16:15:01] detectron2 INFO: Inference done 3329/26446. 0.2731 s / img. ETA=1:46:04
[07/02 16:15:06] detectron2 INFO: Inference done 3347/26446. 0.2731 s / img. ETA=1:46:00
[07/02 16:15:12] detectron2 INFO: Inference done 3366/26446. 0.2731 s / img. ETA=1:45:54
[07/02 16:15:17] detectron2 INFO: Inference done 3384/26446. 0.2732 s / img. ETA=1:45:50
[07/02 16:15:22] detectron2 INFO: Inference done 3402/26446. 0.2732 s / img. ETA=1:45:46
[07/02 16:15:27] detectron2 INFO: Inference done 3421/26446. 0.2732 s / img. ETA=1:45:41
[07/02 16:15:32] detectron2 INFO: Inference done 3440/26446. 0.2732 s / img. ETA=1:45:36
[07/02 16:15:37] detectron2 INFO: Inference done 3459/26446. 0.2732 s / img. ETA=1:45:30
[07/02 16:15:43] detectron2 INFO: Inference done 3478/26446. 0.2732 s / img. ETA=1:45:24
[07/02 16:15:48] detectron2 INFO: Inference done 3497/26446. 0.2731 s / img. ETA=1:45:19
[07/02 16:15:53] detectron2 INFO: Inference done 3516/26446. 0.2732 s / img. ETA=1:45:14
[07/02 16:15:58] detectron2 INFO: Inference done 3534/26446. 0.2732 s / img. ETA=1:45:10
[07/02 16:16:03] detectron2 INFO: Inference done 3551/26446. 0.2733 s / img. ETA=1:45:08
[07/02 16:16:09] detectron2 INFO: Inference done 3570/26446. 0.2733 s / img. ETA=1:45:03
[07/02 16:16:14] detectron2 INFO: Inference done 3588/26446. 0.2734 s / img. ETA=1:44:59
[07/02 16:16:19] detectron2 INFO: Inference done 3606/26446. 0.2734 s / img. ETA=1:44:54
[07/02 16:16:24] detectron2 INFO: Inference done 3624/26446. 0.2734 s / img. ETA=1:44:50
[07/02 16:16:29] detectron2 INFO: Inference done 3643/26446. 0.2734 s / img. ETA=1:44:45
[07/02 16:16:34] detectron2 INFO: Inference done 3662/26446. 0.2734 s / img. ETA=1:44:39
[07/02 16:16:39] detectron2 INFO: Inference done 3681/26446. 0.2734 s / img. ETA=1:44:34
[07/02 16:16:45] detectron2 INFO: Inference done 3700/26446. 0.2734 s / img. ETA=1:44:28
[07/02 16:16:50] detectron2 INFO: Inference done 3718/26446. 0.2734 s / img. ETA=1:44:24
[07/02 16:16:55] detectron2 INFO: Inference done 3737/26446. 0.2734 s / img. ETA=1:44:19
[07/02 16:17:00] detectron2 INFO: Inference done 3756/26446. 0.2734 s / img. ETA=1:44:14
[07/02 16:17:05] detectron2 INFO: Inference done 3774/26446. 0.2734 s / img. ETA=1:44:09
[07/02 16:17:10] detectron2 INFO: Inference done 3793/26446. 0.2734 s / img. ETA=1:44:03
[07/02 16:17:16] detectron2 INFO: Inference done 3812/26446. 0.2734 s / img. ETA=1:43:58
[07/02 16:17:21] detectron2 INFO: Inference done 3830/26446. 0.2734 s / img. ETA=1:43:54
[07/02 16:17:26] detectron2 INFO: Inference done 3849/26446. 0.2735 s / img. ETA=1:43:49
[07/02 16:17:31] detectron2 INFO: Inference done 3867/26446. 0.2735 s / img. ETA=1:43:45
[07/02 16:17:36] detectron2 INFO: Inference done 3885/26446. 0.2735 s / img. ETA=1:43:40
[07/02 16:17:41] detectron2 INFO: Inference done 3904/26446. 0.2735 s / img. ETA=1:43:34
[07/02 16:17:46] detectron2 INFO: Inference done 3922/26446. 0.2735 s / img. ETA=1:43:30
[07/02 16:17:51] detectron2 INFO: Inference done 3940/26446. 0.2735 s / img. ETA=1:43:25
[07/02 16:17:56] detectron2 INFO: Inference done 3958/26446. 0.2735 s / img. ETA=1:43:21
[07/02 16:18:02] detectron2 INFO: Inference done 3977/26446. 0.2736 s / img. ETA=1:43:16
[07/02 16:18:07] detectron2 INFO: Inference done 3995/26446. 0.2736 s / img. ETA=1:43:12
[07/02 16:18:12] detectron2 INFO: Inference done 4013/26446. 0.2736 s / img. ETA=1:43:07
[07/02 16:18:17] detectron2 INFO: Inference done 4031/26446. 0.2737 s / img. ETA=1:43:03
[07/02 16:18:22] detectron2 INFO: Inference done 4049/26446. 0.2737 s / img. ETA=1:42:59
[07/02 16:18:27] detectron2 INFO: Inference done 4067/26446. 0.2737 s / img. ETA=1:42:55
[07/02 16:18:32] detectron2 INFO: Inference done 4085/26446. 0.2738 s / img. ETA=1:42:52
[07/02 16:18:38] detectron2 INFO: Inference done 4103/26446. 0.2739 s / img. ETA=1:42:48
[07/02 16:18:43] detectron2 INFO: Inference done 4121/26446. 0.2739 s / img. ETA=1:42:44
[07/02 16:18:48] detectron2 INFO: Inference done 4139/26446. 0.2739 s / img. ETA=1:42:40
[07/02 16:18:53] detectron2 INFO: Inference done 4157/26446. 0.2740 s / img. ETA=1:42:37
[07/02 16:18:58] detectron2 INFO: Inference done 4174/26446. 0.2741 s / img. ETA=1:42:34
[07/02 16:19:03] detectron2 INFO: Inference done 4191/26446. 0.2742 s / img. ETA=1:42:31
[07/02 16:19:08] detectron2 INFO: Inference done 4209/26446. 0.2742 s / img. ETA=1:42:27
[07/02 16:19:14] detectron2 INFO: Inference done 4227/26446. 0.2743 s / img. ETA=1:42:23
[07/02 16:19:19] detectron2 INFO: Inference done 4245/26446. 0.2743 s / img. ETA=1:42:18
[07/02 16:19:24] detectron2 INFO: Inference done 4263/26446. 0.2743 s / img. ETA=1:42:14
[07/02 16:19:29] detectron2 INFO: Inference done 4281/26446. 0.2744 s / img. ETA=1:42:10
[07/02 16:19:34] detectron2 INFO: Inference done 4299/26446. 0.2744 s / img. ETA=1:42:06
[07/02 16:19:40] detectron2 INFO: Inference done 4313/26446. 0.2748 s / img. ETA=1:42:12
[07/02 16:19:45] detectron2 INFO: Inference done 4328/26446. 0.2751 s / img. ETA=1:42:13
[07/02 16:19:50] detectron2 INFO: Inference done 4345/26446. 0.2752 s / img. ETA=1:42:10
[07/02 16:19:55] detectron2 INFO: Inference done 4363/26446. 0.2752 s / img. ETA=1:42:05
[07/02 16:20:00] detectron2 INFO: Inference done 4382/26446. 0.2751 s / img. ETA=1:41:59
[07/02 16:20:05] detectron2 INFO: Inference done 4400/26446. 0.2751 s / img. ETA=1:41:55
[07/02 16:20:10] detectron2 INFO: Inference done 4418/26446. 0.2752 s / img. ETA=1:41:50
[07/02 16:20:15] detectron2 INFO: Inference done 4436/26446. 0.2752 s / img. ETA=1:41:45
[07/02 16:20:21] detectron2 INFO: Inference done 4454/26446. 0.2752 s / img. ETA=1:41:41
[07/02 16:20:26] detectron2 INFO: Inference done 4472/26446. 0.2752 s / img. ETA=1:41:36
[07/02 16:20:31] detectron2 INFO: Inference done 4491/26446. 0.2752 s / img. ETA=1:41:31
[07/02 16:20:36] detectron2 INFO: Inference done 4509/26446. 0.2752 s / img. ETA=1:41:26
[07/02 16:20:41] detectron2 INFO: Inference done 4527/26446. 0.2752 s / img. ETA=1:41:22
[07/02 16:20:46] detectron2 INFO: Inference done 4546/26446. 0.2752 s / img. ETA=1:41:16
[07/02 16:20:51] detectron2 INFO: Inference done 4565/26446. 0.2752 s / img. ETA=1:41:10
[07/02 16:20:56] detectron2 INFO: Inference done 4584/26446. 0.2751 s / img. ETA=1:41:03
[07/02 16:21:01] detectron2 INFO: Inference done 4603/26446. 0.2751 s / img. ETA=1:40:57
[07/02 16:21:06] detectron2 INFO: Inference done 4622/26446. 0.2751 s / img. ETA=1:40:51
[07/02 16:21:12] detectron2 INFO: Inference done 4641/26446. 0.2750 s / img. ETA=1:40:45
[07/02 16:21:17] detectron2 INFO: Inference done 4660/26446. 0.2750 s / img. ETA=1:40:38
[07/02 16:21:22] detectron2 INFO: Inference done 4679/26446. 0.2749 s / img. ETA=1:40:32
[07/02 16:21:27] detectron2 INFO: Inference done 4698/26446. 0.2749 s / img. ETA=1:40:26
[07/02 16:21:32] detectron2 INFO: Inference done 4718/26446. 0.2748 s / img. ETA=1:40:20
[07/02 16:21:37] detectron2 INFO: Inference done 4737/26446. 0.2748 s / img. ETA=1:40:13
[07/02 16:21:42] detectron2 INFO: Inference done 4756/26446. 0.2748 s / img. ETA=1:40:07
[07/02 16:21:47] detectron2 INFO: Inference done 4775/26446. 0.2747 s / img. ETA=1:40:01
[07/02 16:21:52] detectron2 INFO: Inference done 4794/26446. 0.2747 s / img. ETA=1:39:55
[07/02 16:21:57] detectron2 INFO: Inference done 4813/26446. 0.2746 s / img. ETA=1:39:49
[07/02 16:22:03] detectron2 INFO: Inference done 4832/26446. 0.2746 s / img. ETA=1:39:43
[07/02 16:22:08] detectron2 INFO: Inference done 4852/26446. 0.2745 s / img. ETA=1:39:36
[07/02 16:22:13] detectron2 INFO: Inference done 4871/26446. 0.2745 s / img. ETA=1:39:30
[07/02 16:22:18] detectron2 INFO: Inference done 4890/26446. 0.2745 s / img. ETA=1:39:24
[07/02 16:22:23] detectron2 INFO: Inference done 4910/26446. 0.2744 s / img. ETA=1:39:17
[07/02 16:22:28] detectron2 INFO: Inference done 4929/26446. 0.2744 s / img. ETA=1:39:11
[07/02 16:22:33] detectron2 INFO: Inference done 4948/26446. 0.2743 s / img. ETA=1:39:05
[07/02 16:22:38] detectron2 INFO: Inference done 4967/26446. 0.2743 s / img. ETA=1:38:59
[07/02 16:22:43] detectron2 INFO: Inference done 4986/26446. 0.2743 s / img. ETA=1:38:53
[07/02 16:22:49] detectron2 INFO: Inference done 5006/26446. 0.2742 s / img. ETA=1:38:46
[07/02 16:22:54] detectron2 INFO: Inference done 5026/26446. 0.2742 s / img. ETA=1:38:40
[07/02 16:22:59] detectron2 INFO: Inference done 5045/26446. 0.2741 s / img. ETA=1:38:33
[07/02 16:23:04] detectron2 INFO: Inference done 5065/26446. 0.2741 s / img. ETA=1:38:26
[07/02 16:23:09] detectron2 INFO: Inference done 5085/26446. 0.2740 s / img. ETA=1:38:20
[07/02 16:23:15] detectron2 INFO: Inference done 5104/26446. 0.2740 s / img. ETA=1:38:14
[07/02 16:23:20] detectron2 INFO: Inference done 5123/26446. 0.2739 s / img. ETA=1:38:08
[07/02 16:23:25] detectron2 INFO: Inference done 5142/26446. 0.2739 s / img. ETA=1:38:02
[07/02 16:23:30] detectron2 INFO: Inference done 5161/26446. 0.2739 s / img. ETA=1:37:56
[07/02 16:23:35] detectron2 INFO: Inference done 5180/26446. 0.2738 s / img. ETA=1:37:50
[07/02 16:23:40] detectron2 INFO: Inference done 5199/26446. 0.2738 s / img. ETA=1:37:44
[07/02 16:23:45] detectron2 INFO: Inference done 5218/26446. 0.2738 s / img. ETA=1:37:38
[07/02 16:23:50] detectron2 INFO: Inference done 5237/26446. 0.2737 s / img. ETA=1:37:32
[07/02 16:23:55] detectron2 INFO: Inference done 5256/26446. 0.2737 s / img. ETA=1:37:26
[07/02 16:24:00] detectron2 INFO: Inference done 5275/26446. 0.2737 s / img. ETA=1:37:21
[07/02 16:24:05] detectron2 INFO: Inference done 5294/26446. 0.2737 s / img. ETA=1:37:15
[07/02 16:24:10] detectron2 INFO: Inference done 5313/26446. 0.2736 s / img. ETA=1:37:09
[07/02 16:24:15] detectron2 INFO: Inference done 5332/26446. 0.2736 s / img. ETA=1:37:03
[07/02 16:24:20] detectron2 INFO: Inference done 5351/26446. 0.2735 s / img. ETA=1:36:56
[07/02 16:24:26] detectron2 INFO: Inference done 5370/26446. 0.2735 s / img. ETA=1:36:51
[07/02 16:24:31] detectron2 INFO: Inference done 5389/26446. 0.2735 s / img. ETA=1:36:45
[07/02 16:24:36] detectron2 INFO: Inference done 5408/26446. 0.2735 s / img. ETA=1:36:39
[07/02 16:24:41] detectron2 INFO: Inference done 5427/26446. 0.2734 s / img. ETA=1:36:33
[07/02 16:24:46] detectron2 INFO: Inference done 5446/26446. 0.2734 s / img. ETA=1:36:28
[07/02 16:24:51] detectron2 INFO: Inference done 5465/26446. 0.2734 s / img. ETA=1:36:22
[07/02 16:24:56] detectron2 INFO: Inference done 5483/26446. 0.2734 s / img. ETA=1:36:17
[07/02 16:25:01] detectron2 INFO: Inference done 5502/26446. 0.2734 s / img. ETA=1:36:12
[07/02 16:25:06] detectron2 INFO: Inference done 5521/26446. 0.2734 s / img. ETA=1:36:06
[07/02 16:25:11] detectron2 INFO: Inference done 5540/26446. 0.2734 s / img. ETA=1:36:00
[07/02 16:25:17] detectron2 INFO: Inference done 5560/26446. 0.2733 s / img. ETA=1:35:54
[07/02 16:25:22] detectron2 INFO: Inference done 5579/26446. 0.2733 s / img. ETA=1:35:48
[07/02 16:25:27] detectron2 INFO: Inference done 5598/26446. 0.2732 s / img. ETA=1:35:42
[07/02 16:25:32] detectron2 INFO: Inference done 5617/26446. 0.2732 s / img. ETA=1:35:36
[07/02 16:25:37] detectron2 INFO: Inference done 5637/26446. 0.2732 s / img. ETA=1:35:29
[07/02 16:25:42] detectron2 INFO: Inference done 5656/26446. 0.2731 s / img. ETA=1:35:23
[07/02 16:25:47] detectron2 INFO: Inference done 5675/26446. 0.2731 s / img. ETA=1:35:18
[07/02 16:25:52] detectron2 INFO: Inference done 5694/26446. 0.2731 s / img. ETA=1:35:12
[07/02 16:25:57] detectron2 INFO: Inference done 5713/26446. 0.2730 s / img. ETA=1:35:06
[07/02 16:26:02] detectron2 INFO: Inference done 5732/26446. 0.2730 s / img. ETA=1:35:00
[07/02 16:26:08] detectron2 INFO: Inference done 5752/26446. 0.2729 s / img. ETA=1:34:54
[07/02 16:26:13] detectron2 INFO: Inference done 5771/26446. 0.2729 s / img. ETA=1:34:48
[07/02 16:26:18] detectron2 INFO: Inference done 5790/26446. 0.2729 s / img. ETA=1:34:42
[07/02 16:26:23] detectron2 INFO: Inference done 5809/26446. 0.2729 s / img. ETA=1:34:36
[07/02 16:26:28] detectron2 INFO: Inference done 5828/26446. 0.2728 s / img. ETA=1:34:30
[07/02 16:26:33] detectron2 INFO: Inference done 5847/26446. 0.2728 s / img. ETA=1:34:25
[07/02 16:26:38] detectron2 INFO: Inference done 5866/26446. 0.2728 s / img. ETA=1:34:19
[07/02 16:26:43] detectron2 INFO: Inference done 5885/26446. 0.2728 s / img. ETA=1:34:13
[07/02 16:26:48] detectron2 INFO: Inference done 5904/26446. 0.2727 s / img. ETA=1:34:07
[07/02 16:26:53] detectron2 INFO: Inference done 5924/26446. 0.2727 s / img. ETA=1:34:01
[07/02 16:26:58] detectron2 INFO: Inference done 5943/26446. 0.2727 s / img. ETA=1:33:55
[07/02 16:27:04] detectron2 INFO: Inference done 5962/26446. 0.2727 s / img. ETA=1:33:50
[07/02 16:27:09] detectron2 INFO: Inference done 5981/26446. 0.2727 s / img. ETA=1:33:44
[07/02 16:27:14] detectron2 INFO: Inference done 6000/26446. 0.2726 s / img. ETA=1:33:39
[07/02 16:27:19] detectron2 INFO: Inference done 6019/26446. 0.2726 s / img. ETA=1:33:33
[07/02 16:27:24] detectron2 INFO: Inference done 6038/26446. 0.2726 s / img. ETA=1:33:27
[07/02 16:27:29] detectron2 INFO: Inference done 6057/26446. 0.2726 s / img. ETA=1:33:22
[07/02 16:27:34] detectron2 INFO: Inference done 6076/26446. 0.2725 s / img. ETA=1:33:16
[07/02 16:27:39] detectron2 INFO: Inference done 6095/26446. 0.2725 s / img. ETA=1:33:10
[07/02 16:27:44] detectron2 INFO: Inference done 6114/26446. 0.2725 s / img. ETA=1:33:05
[07/02 16:27:49] detectron2 INFO: Inference done 6133/26446. 0.2725 s / img. ETA=1:32:59
[07/02 16:27:55] detectron2 INFO: Inference done 6152/26446. 0.2725 s / img. ETA=1:32:53
[07/02 16:28:00] detectron2 INFO: Inference done 6171/26446. 0.2724 s / img. ETA=1:32:48
[07/02 16:28:05] detectron2 INFO: Inference done 6190/26446. 0.2724 s / img. ETA=1:32:42
[07/02 16:28:10] detectron2 INFO: Inference done 6209/26446. 0.2724 s / img. ETA=1:32:37
[07/02 16:28:15] detectron2 INFO: Inference done 6228/26446. 0.2724 s / img. ETA=1:32:31
[07/02 16:28:20] detectron2 INFO: Inference done 6247/26446. 0.2724 s / img. ETA=1:32:26
[07/02 16:28:25] detectron2 INFO: Inference done 6266/26446. 0.2724 s / img. ETA=1:32:20
[07/02 16:28:30] detectron2 INFO: Inference done 6285/26446. 0.2724 s / img. ETA=1:32:15
[07/02 16:28:35] detectron2 INFO: Inference done 6304/26446. 0.2723 s / img. ETA=1:32:09
[07/02 16:28:41] detectron2 INFO: Inference done 6323/26446. 0.2723 s / img. ETA=1:32:03
[07/02 16:28:46] detectron2 INFO: Inference done 6342/26446. 0.2723 s / img. ETA=1:31:58
[07/02 16:28:51] detectron2 INFO: Inference done 6361/26446. 0.2723 s / img. ETA=1:31:52
[07/02 16:28:56] detectron2 INFO: Inference done 6380/26446. 0.2723 s / img. ETA=1:31:47
[07/02 16:29:01] detectron2 INFO: Inference done 6399/26446. 0.2723 s / img. ETA=1:31:41
[07/02 16:29:06] detectron2 INFO: Inference done 6418/26446. 0.2722 s / img. ETA=1:31:36
[07/02 16:29:11] detectron2 INFO: Inference done 6437/26446. 0.2722 s / img. ETA=1:31:30
[07/02 16:29:16] detectron2 INFO: Inference done 6456/26446. 0.2722 s / img. ETA=1:31:24
[07/02 16:29:21] detectron2 INFO: Inference done 6475/26446. 0.2721 s / img. ETA=1:31:18
[07/02 16:29:26] detectron2 INFO: Inference done 6494/26446. 0.2721 s / img. ETA=1:31:13
[07/02 16:29:32] detectron2 INFO: Inference done 6514/26446. 0.2721 s / img. ETA=1:31:06
[07/02 16:29:37] detectron2 INFO: Inference done 6533/26446. 0.2721 s / img. ETA=1:31:01
[07/02 16:29:42] detectron2 INFO: Inference done 6552/26446. 0.2721 s / img. ETA=1:30:56
[07/02 16:29:47] detectron2 INFO: Inference done 6571/26446. 0.2720 s / img. ETA=1:30:50
[07/02 16:29:52] detectron2 INFO: Inference done 6590/26446. 0.2720 s / img. ETA=1:30:44
[07/02 16:29:57] detectron2 INFO: Inference done 6609/26446. 0.2720 s / img. ETA=1:30:39
[07/02 16:30:02] detectron2 INFO: Inference done 6627/26446. 0.2720 s / img. ETA=1:30:34
[07/02 16:30:07] detectron2 INFO: Inference done 6647/26446. 0.2720 s / img. ETA=1:30:28
[07/02 16:30:13] detectron2 INFO: Inference done 6667/26446. 0.2719 s / img. ETA=1:30:22
[07/02 16:30:18] detectron2 INFO: Inference done 6687/26446. 0.2719 s / img. ETA=1:30:15
[07/02 16:30:23] detectron2 INFO: Inference done 6707/26446. 0.2719 s / img. ETA=1:30:09
[07/02 16:30:28] detectron2 INFO: Inference done 6727/26446. 0.2718 s / img. ETA=1:30:03
[07/02 16:30:33] detectron2 INFO: Inference done 6746/26446. 0.2718 s / img. ETA=1:29:57
[07/02 16:30:38] detectron2 INFO: Inference done 6765/26446. 0.2718 s / img. ETA=1:29:52
[07/02 16:30:44] detectron2 INFO: Inference done 6785/26446. 0.2718 s / img. ETA=1:29:45
[07/02 16:30:49] detectron2 INFO: Inference done 6804/26446. 0.2717 s / img. ETA=1:29:40
[07/02 16:30:54] detectron2 INFO: Inference done 6823/26446. 0.2717 s / img. ETA=1:29:34
[07/02 16:30:59] detectron2 INFO: Inference done 6842/26446. 0.2717 s / img. ETA=1:29:28
[07/02 16:31:04] detectron2 INFO: Inference done 6862/26446. 0.2716 s / img. ETA=1:29:22
[07/02 16:31:09] detectron2 INFO: Inference done 6881/26446. 0.2716 s / img. ETA=1:29:16
[07/02 16:31:14] detectron2 INFO: Inference done 6901/26446. 0.2716 s / img. ETA=1:29:10
[07/02 16:31:19] detectron2 INFO: Inference done 6921/26446. 0.2715 s / img. ETA=1:29:04
[07/02 16:31:24] detectron2 INFO: Inference done 6940/26446. 0.2715 s / img. ETA=1:28:58
[07/02 16:31:29] detectron2 INFO: Inference done 6959/26446. 0.2715 s / img. ETA=1:28:53
[07/02 16:31:35] detectron2 INFO: Inference done 6979/26446. 0.2715 s / img. ETA=1:28:47
[07/02 16:31:40] detectron2 INFO: Inference done 6999/26446. 0.2714 s / img. ETA=1:28:40
[07/02 16:31:45] detectron2 INFO: Inference done 7018/26446. 0.2714 s / img. ETA=1:28:35
[07/02 16:31:50] detectron2 INFO: Inference done 7038/26446. 0.2714 s / img. ETA=1:28:28
[07/02 16:31:55] detectron2 INFO: Inference done 7057/26446. 0.2713 s / img. ETA=1:28:23
[07/02 16:32:00] detectron2 INFO: Inference done 7077/26446. 0.2713 s / img. ETA=1:28:17
[07/02 16:32:05] detectron2 INFO: Inference done 7096/26446. 0.2713 s / img. ETA=1:28:11
[07/02 16:32:11] detectron2 INFO: Inference done 7115/26446. 0.2713 s / img. ETA=1:28:06
[07/02 16:32:16] detectron2 INFO: Inference done 7134/26446. 0.2713 s / img. ETA=1:28:00
[07/02 16:32:21] detectron2 INFO: Inference done 7154/26446. 0.2712 s / img. ETA=1:27:54
[07/02 16:32:26] detectron2 INFO: Inference done 7174/26446. 0.2712 s / img. ETA=1:27:48
[07/02 16:32:31] detectron2 INFO: Inference done 7193/26446. 0.2712 s / img. ETA=1:27:43
[07/02 16:32:36] detectron2 INFO: Inference done 7212/26446. 0.2712 s / img. ETA=1:27:37
[07/02 16:32:41] detectron2 INFO: Inference done 7231/26446. 0.2712 s / img. ETA=1:27:32
[07/02 16:32:46] detectron2 INFO: Inference done 7250/26446. 0.2711 s / img. ETA=1:27:26
[07/02 16:32:51] detectron2 INFO: Inference done 7269/26446. 0.2711 s / img. ETA=1:27:20
[07/02 16:32:56] detectron2 INFO: Inference done 7288/26446. 0.2711 s / img. ETA=1:27:15
[07/02 16:33:02] detectron2 INFO: Inference done 7308/26446. 0.2711 s / img. ETA=1:27:09
[07/02 16:33:07] detectron2 INFO: Inference done 7327/26446. 0.2710 s / img. ETA=1:27:03
[07/02 16:33:12] detectron2 INFO: Inference done 7346/26446. 0.2710 s / img. ETA=1:26:58
[07/02 16:33:17] detectron2 INFO: Inference done 7366/26446. 0.2710 s / img. ETA=1:26:52
[07/02 16:33:22] detectron2 INFO: Inference done 7385/26446. 0.2710 s / img. ETA=1:26:46
[07/02 16:33:27] detectron2 INFO: Inference done 7404/26446. 0.2710 s / img. ETA=1:26:41
[07/02 16:33:32] detectron2 INFO: Inference done 7423/26446. 0.2710 s / img. ETA=1:26:35
[07/02 16:33:37] detectron2 INFO: Inference done 7442/26446. 0.2709 s / img. ETA=1:26:30
[07/02 16:33:43] detectron2 INFO: Inference done 7461/26446. 0.2709 s / img. ETA=1:26:24
[07/02 16:33:48] detectron2 INFO: Inference done 7480/26446. 0.2709 s / img. ETA=1:26:19
[07/02 16:33:53] detectron2 INFO: Inference done 7499/26446. 0.2709 s / img. ETA=1:26:14
[07/02 16:33:58] detectron2 INFO: Inference done 7518/26446. 0.2709 s / img. ETA=1:26:08
[07/02 16:34:03] detectron2 INFO: Inference done 7538/26446. 0.2709 s / img. ETA=1:26:02
[07/02 16:34:08] detectron2 INFO: Inference done 7557/26446. 0.2708 s / img. ETA=1:25:57
[07/02 16:34:13] detectron2 INFO: Inference done 7576/26446. 0.2708 s / img. ETA=1:25:51
[07/02 16:34:18] detectron2 INFO: Inference done 7596/26446. 0.2708 s / img. ETA=1:25:45
[07/02 16:34:24] detectron2 INFO: Inference done 7616/26446. 0.2708 s / img. ETA=1:25:39
[07/02 16:34:29] detectron2 INFO: Inference done 7636/26446. 0.2707 s / img. ETA=1:25:33
[07/02 16:34:34] detectron2 INFO: Inference done 7655/26446. 0.2707 s / img. ETA=1:25:27
[07/02 16:34:39] detectron2 INFO: Inference done 7674/26446. 0.2707 s / img. ETA=1:25:22
[07/02 16:34:44] detectron2 INFO: Inference done 7693/26446. 0.2707 s / img. ETA=1:25:17
[07/02 16:34:49] detectron2 INFO: Inference done 7712/26446. 0.2707 s / img. ETA=1:25:11
[07/02 16:34:54] detectron2 INFO: Inference done 7731/26446. 0.2707 s / img. ETA=1:25:06
[07/02 16:34:59] detectron2 INFO: Inference done 7750/26446. 0.2707 s / img. ETA=1:25:01
[07/02 16:35:05] detectron2 INFO: Inference done 7769/26446. 0.2707 s / img. ETA=1:24:55
[07/02 16:35:10] detectron2 INFO: Inference done 7788/26446. 0.2707 s / img. ETA=1:24:50
[07/02 16:35:15] detectron2 INFO: Inference done 7807/26446. 0.2706 s / img. ETA=1:24:45
[07/02 16:35:20] detectron2 INFO: Inference done 7826/26446. 0.2706 s / img. ETA=1:24:39
[07/02 16:35:25] detectron2 INFO: Inference done 7845/26446. 0.2706 s / img. ETA=1:24:34
[07/02 16:35:30] detectron2 INFO: Inference done 7864/26446. 0.2706 s / img. ETA=1:24:28
[07/02 16:35:35] detectron2 INFO: Inference done 7883/26446. 0.2706 s / img. ETA=1:24:23
[07/02 16:35:40] detectron2 INFO: Inference done 7903/26446. 0.2706 s / img. ETA=1:24:17
[07/02 16:35:46] detectron2 INFO: Inference done 7922/26446. 0.2706 s / img. ETA=1:24:12
[07/02 16:35:51] detectron2 INFO: Inference done 7941/26446. 0.2705 s / img. ETA=1:24:06
[07/02 16:35:56] detectron2 INFO: Inference done 7960/26446. 0.2705 s / img. ETA=1:24:01
[07/02 16:36:01] detectron2 INFO: Inference done 7979/26446. 0.2705 s / img. ETA=1:23:55
[07/02 16:36:06] detectron2 INFO: Inference done 7998/26446. 0.2705 s / img. ETA=1:23:50
[07/02 16:36:11] detectron2 INFO: Inference done 8017/26446. 0.2705 s / img. ETA=1:23:45
[07/02 16:36:16] detectron2 INFO: Inference done 8036/26446. 0.2705 s / img. ETA=1:23:39
[07/02 16:36:21] detectron2 INFO: Inference done 8052/26446. 0.2706 s / img. ETA=1:23:37
[07/02 16:36:27] detectron2 INFO: Inference done 8071/26446. 0.2706 s / img. ETA=1:23:32
[07/02 16:36:32] detectron2 INFO: Inference done 8090/26446. 0.2706 s / img. ETA=1:23:27
[07/02 16:36:37] detectron2 INFO: Inference done 8109/26446. 0.2706 s / img. ETA=1:23:22
[07/02 16:36:42] detectron2 INFO: Inference done 8128/26446. 0.2706 s / img. ETA=1:23:16
[07/02 16:36:47] detectron2 INFO: Inference done 8147/26446. 0.2706 s / img. ETA=1:23:11
[07/02 16:36:52] detectron2 INFO: Inference done 8167/26446. 0.2706 s / img. ETA=1:23:05
[07/02 16:36:58] detectron2 INFO: Inference done 8186/26446. 0.2706 s / img. ETA=1:23:00
[07/02 16:37:03] detectron2 INFO: Inference done 8205/26446. 0.2705 s / img. ETA=1:22:54
[07/02 16:37:08] detectron2 INFO: Inference done 8224/26446. 0.2705 s / img. ETA=1:22:49
[07/02 16:37:13] detectron2 INFO: Inference done 8243/26446. 0.2705 s / img. ETA=1:22:43
[07/02 16:37:18] detectron2 INFO: Inference done 8262/26446. 0.2705 s / img. ETA=1:22:38
[07/02 16:37:23] detectron2 INFO: Inference done 8281/26446. 0.2705 s / img. ETA=1:22:33
[07/02 16:37:28] detectron2 INFO: Inference done 8300/26446. 0.2705 s / img. ETA=1:22:27
[07/02 16:37:33] detectron2 INFO: Inference done 8319/26446. 0.2705 s / img. ETA=1:22:22
[07/02 16:37:38] detectron2 INFO: Inference done 8338/26446. 0.2705 s / img. ETA=1:22:17
[07/02 16:37:43] detectron2 INFO: Inference done 8357/26446. 0.2705 s / img. ETA=1:22:11
[07/02 16:37:48] detectron2 INFO: Inference done 8376/26446. 0.2705 s / img. ETA=1:22:06
[07/02 16:37:54] detectron2 INFO: Inference done 8395/26446. 0.2705 s / img. ETA=1:22:01
[07/02 16:37:59] detectron2 INFO: Inference done 8414/26446. 0.2704 s / img. ETA=1:21:55
[07/02 16:38:04] detectron2 INFO: Inference done 8434/26446. 0.2704 s / img. ETA=1:21:49
[07/02 16:38:09] detectron2 INFO: Inference done 8453/26446. 0.2704 s / img. ETA=1:21:44
[07/02 16:38:14] detectron2 INFO: Inference done 8472/26446. 0.2704 s / img. ETA=1:21:39
[07/02 16:38:19] detectron2 INFO: Inference done 8491/26446. 0.2704 s / img. ETA=1:21:33
[07/02 16:38:24] detectron2 INFO: Inference done 8511/26446. 0.2704 s / img. ETA=1:21:27
[07/02 16:38:30] detectron2 INFO: Inference done 8531/26446. 0.2703 s / img. ETA=1:21:22
[07/02 16:38:35] detectron2 INFO: Inference done 8550/26446. 0.2703 s / img. ETA=1:21:16
[07/02 16:38:40] detectron2 INFO: Inference done 8569/26446. 0.2703 s / img. ETA=1:21:11
[07/02 16:38:45] detectron2 INFO: Inference done 8588/26446. 0.2703 s / img. ETA=1:21:05
[07/02 16:38:50] detectron2 INFO: Inference done 8608/26446. 0.2703 s / img. ETA=1:20:59
[07/02 16:38:55] detectron2 INFO: Inference done 8627/26446. 0.2703 s / img. ETA=1:20:54
[07/02 16:39:00] detectron2 INFO: Inference done 8646/26446. 0.2703 s / img. ETA=1:20:49
[07/02 16:39:05] detectron2 INFO: Inference done 8665/26446. 0.2702 s / img. ETA=1:20:43
[07/02 16:39:10] detectron2 INFO: Inference done 8684/26446. 0.2702 s / img. ETA=1:20:38
[07/02 16:39:16] detectron2 INFO: Inference done 8703/26446. 0.2702 s / img. ETA=1:20:33
[07/02 16:39:21] detectron2 INFO: Inference done 8722/26446. 0.2702 s / img. ETA=1:20:27
[07/02 16:39:26] detectron2 INFO: Inference done 8741/26446. 0.2702 s / img. ETA=1:20:22
[07/02 16:39:31] detectron2 INFO: Inference done 8760/26446. 0.2702 s / img. ETA=1:20:17
[07/02 16:39:36] detectron2 INFO: Inference done 8779/26446. 0.2702 s / img. ETA=1:20:11
[07/02 16:39:41] detectron2 INFO: Inference done 8798/26446. 0.2702 s / img. ETA=1:20:06
[07/02 16:39:46] detectron2 INFO: Inference done 8817/26446. 0.2702 s / img. ETA=1:20:01
[07/02 16:39:51] detectron2 INFO: Inference done 8836/26446. 0.2702 s / img. ETA=1:19:55
[07/02 16:39:56] detectron2 INFO: Inference done 8855/26446. 0.2702 s / img. ETA=1:19:50
[07/02 16:40:02] detectron2 INFO: Inference done 8874/26446. 0.2702 s / img. ETA=1:19:45
[07/02 16:40:07] detectron2 INFO: Inference done 8893/26446. 0.2701 s / img. ETA=1:19:39
[07/02 16:40:12] detectron2 INFO: Inference done 8912/26446. 0.2701 s / img. ETA=1:19:34
[07/02 16:40:17] detectron2 INFO: Inference done 8931/26446. 0.2701 s / img. ETA=1:19:29
[07/02 16:40:22] detectron2 INFO: Inference done 8951/26446. 0.2701 s / img. ETA=1:19:23
[07/02 16:40:27] detectron2 INFO: Inference done 8970/26446. 0.2701 s / img. ETA=1:19:17
[07/02 16:40:32] detectron2 INFO: Inference done 8989/26446. 0.2701 s / img. ETA=1:19:12
[07/02 16:40:37] detectron2 INFO: Inference done 9008/26446. 0.2701 s / img. ETA=1:19:07
[07/02 16:40:42] detectron2 INFO: Inference done 9027/26446. 0.2700 s / img. ETA=1:19:01
[07/02 16:40:47] detectron2 INFO: Inference done 9046/26446. 0.2700 s / img. ETA=1:18:56
[07/02 16:40:52] detectron2 INFO: Inference done 9065/26446. 0.2700 s / img. ETA=1:18:51
[07/02 16:40:58] detectron2 INFO: Inference done 9085/26446. 0.2700 s / img. ETA=1:18:45
[07/02 16:41:03] detectron2 INFO: Inference done 9105/26446. 0.2700 s / img. ETA=1:18:39
[07/02 16:41:08] detectron2 INFO: Inference done 9125/26446. 0.2699 s / img. ETA=1:18:33
[07/02 16:41:13] detectron2 INFO: Inference done 9144/26446. 0.2699 s / img. ETA=1:18:27
[07/02 16:41:18] detectron2 INFO: Inference done 9163/26446. 0.2699 s / img. ETA=1:18:22
[07/02 16:41:23] detectron2 INFO: Inference done 9183/26446. 0.2699 s / img. ETA=1:18:16
[07/02 16:41:28] detectron2 INFO: Inference done 9202/26446. 0.2699 s / img. ETA=1:18:11
[07/02 16:41:33] detectron2 INFO: Inference done 9221/26446. 0.2699 s / img. ETA=1:18:06
[07/02 16:41:39] detectron2 INFO: Inference done 9241/26446. 0.2699 s / img. ETA=1:18:00
[07/02 16:41:44] detectron2 INFO: Inference done 9260/26446. 0.2698 s / img. ETA=1:17:54
[07/02 16:41:49] detectron2 INFO: Inference done 9279/26446. 0.2698 s / img. ETA=1:17:49
[07/02 16:41:54] detectron2 INFO: Inference done 9298/26446. 0.2698 s / img. ETA=1:17:44
[07/02 16:41:59] detectron2 INFO: Inference done 9317/26446. 0.2698 s / img. ETA=1:17:38
[07/02 16:42:04] detectron2 INFO: Inference done 9337/26446. 0.2698 s / img. ETA=1:17:32
[07/02 16:42:09] detectron2 INFO: Inference done 9356/26446. 0.2698 s / img. ETA=1:17:27
[07/02 16:42:14] detectron2 INFO: Inference done 9375/26446. 0.2697 s / img. ETA=1:17:21
[07/02 16:42:19] detectron2 INFO: Inference done 9395/26446. 0.2697 s / img. ETA=1:17:16
[07/02 16:42:25] detectron2 INFO: Inference done 9415/26446. 0.2697 s / img. ETA=1:17:10
[07/02 16:42:30] detectron2 INFO: Inference done 9435/26446. 0.2697 s / img. ETA=1:17:04
[07/02 16:42:35] detectron2 INFO: Inference done 9454/26446. 0.2697 s / img. ETA=1:16:59
[07/02 16:42:40] detectron2 INFO: Inference done 9474/26446. 0.2696 s / img. ETA=1:16:53
[07/02 16:42:45] detectron2 INFO: Inference done 9494/26446. 0.2696 s / img. ETA=1:16:47
[07/02 16:42:50] detectron2 INFO: Inference done 9514/26446. 0.2696 s / img. ETA=1:16:41
[07/02 16:42:55] detectron2 INFO: Inference done 9533/26446. 0.2696 s / img. ETA=1:16:36
[07/02 16:43:01] detectron2 INFO: Inference done 9552/26446. 0.2696 s / img. ETA=1:16:30
[07/02 16:43:06] detectron2 INFO: Inference done 9571/26446. 0.2696 s / img. ETA=1:16:25
[07/02 16:43:11] detectron2 INFO: Inference done 9590/26446. 0.2695 s / img. ETA=1:16:20
[07/02 16:43:16] detectron2 INFO: Inference done 9609/26446. 0.2695 s / img. ETA=1:16:14
[07/02 16:43:21] detectron2 INFO: Inference done 9629/26446. 0.2695 s / img. ETA=1:16:08
[07/02 16:43:26] detectron2 INFO: Inference done 9648/26446. 0.2695 s / img. ETA=1:16:03
[07/02 16:43:31] detectron2 INFO: Inference done 9668/26446. 0.2695 s / img. ETA=1:15:57
[07/02 16:43:36] detectron2 INFO: Inference done 9687/26446. 0.2695 s / img. ETA=1:15:52
[07/02 16:43:41] detectron2 INFO: Inference done 9706/26446. 0.2695 s / img. ETA=1:15:47
[07/02 16:43:46] detectron2 INFO: Inference done 9725/26446. 0.2695 s / img. ETA=1:15:41
[07/02 16:43:51] detectron2 INFO: Inference done 9744/26446. 0.2694 s / img. ETA=1:15:36
[07/02 16:43:56] detectron2 INFO: Inference done 9763/26446. 0.2694 s / img. ETA=1:15:31
[07/02 16:44:02] detectron2 INFO: Inference done 9782/26446. 0.2694 s / img. ETA=1:15:25
[07/02 16:44:07] detectron2 INFO: Inference done 9801/26446. 0.2694 s / img. ETA=1:15:20
[07/02 16:44:12] detectron2 INFO: Inference done 9820/26446. 0.2694 s / img. ETA=1:15:15
[07/02 16:44:17] detectron2 INFO: Inference done 9839/26446. 0.2694 s / img. ETA=1:15:10
[07/02 16:44:22] detectron2 INFO: Inference done 9858/26446. 0.2694 s / img. ETA=1:15:04
[07/02 16:44:27] detectron2 INFO: Inference done 9877/26446. 0.2694 s / img. ETA=1:14:59
[07/02 16:44:32] detectron2 INFO: Inference done 9896/26446. 0.2694 s / img. ETA=1:14:54
[07/02 16:44:37] detectron2 INFO: Inference done 9915/26446. 0.2694 s / img. ETA=1:14:49
[07/02 16:44:43] detectron2 INFO: Inference done 9934/26446. 0.2694 s / img. ETA=1:14:44
[07/02 16:44:48] detectron2 INFO: Inference done 9953/26446. 0.2694 s / img. ETA=1:14:38
[07/02 16:44:53] detectron2 INFO: Inference done 9972/26446. 0.2694 s / img. ETA=1:14:33
[07/02 16:44:58] detectron2 INFO: Inference done 9992/26446. 0.2694 s / img. ETA=1:14:27
[07/02 16:45:03] detectron2 INFO: Inference done 10011/26446. 0.2693 s / img. ETA=1:14:22
[07/02 16:45:08] detectron2 INFO: Inference done 10030/26446. 0.2693 s / img. ETA=1:14:16
[07/02 16:45:13] detectron2 INFO: Inference done 10050/26446. 0.2693 s / img. ETA=1:14:11
[07/02 16:45:18] detectron2 INFO: Inference done 10069/26446. 0.2693 s / img. ETA=1:14:05
[07/02 16:45:24] detectron2 INFO: Inference done 10089/26446. 0.2693 s / img. ETA=1:14:00
[07/02 16:45:29] detectron2 INFO: Inference done 10108/26446. 0.2693 s / img. ETA=1:13:54
[07/02 16:45:34] detectron2 INFO: Inference done 10127/26446. 0.2693 s / img. ETA=1:13:49
[07/02 16:45:39] detectron2 INFO: Inference done 10147/26446. 0.2692 s / img. ETA=1:13:43
[07/02 16:45:44] detectron2 INFO: Inference done 10167/26446. 0.2692 s / img. ETA=1:13:38
[07/02 16:45:49] detectron2 INFO: Inference done 10187/26446. 0.2692 s / img. ETA=1:13:32
[07/02 16:45:54] detectron2 INFO: Inference done 10206/26446. 0.2692 s / img. ETA=1:13:27
[07/02 16:46:00] detectron2 INFO: Inference done 10225/26446. 0.2692 s / img. ETA=1:13:21
[07/02 16:46:05] detectron2 INFO: Inference done 10244/26446. 0.2692 s / img. ETA=1:13:16
[07/02 16:46:10] detectron2 INFO: Inference done 10264/26446. 0.2692 s / img. ETA=1:13:10
[07/02 16:46:15] detectron2 INFO: Inference done 10283/26446. 0.2692 s / img. ETA=1:13:05
[07/02 16:46:20] detectron2 INFO: Inference done 10303/26446. 0.2691 s / img. ETA=1:12:59
[07/02 16:46:25] detectron2 INFO: Inference done 10322/26446. 0.2691 s / img. ETA=1:12:54
[07/02 16:46:30] detectron2 INFO: Inference done 10341/26446. 0.2691 s / img. ETA=1:12:49
[07/02 16:46:35] detectron2 INFO: Inference done 10360/26446. 0.2691 s / img. ETA=1:12:43
[07/02 16:46:40] detectron2 INFO: Inference done 10379/26446. 0.2691 s / img. ETA=1:12:38
[07/02 16:46:45] detectron2 INFO: Inference done 10398/26446. 0.2691 s / img. ETA=1:12:33
[07/02 16:46:51] detectron2 INFO: Inference done 10417/26446. 0.2691 s / img. ETA=1:12:27
[07/02 16:46:56] detectron2 INFO: Inference done 10436/26446. 0.2691 s / img. ETA=1:12:22
[07/02 16:47:01] detectron2 INFO: Inference done 10455/26446. 0.2691 s / img. ETA=1:12:17
[07/02 16:47:06] detectron2 INFO: Inference done 10474/26446. 0.2691 s / img. ETA=1:12:12
[07/02 16:47:11] detectron2 INFO: Inference done 10493/26446. 0.2691 s / img. ETA=1:12:07
[07/02 16:47:16] detectron2 INFO: Inference done 10512/26446. 0.2691 s / img. ETA=1:12:01
[07/02 16:47:21] detectron2 INFO: Inference done 10531/26446. 0.2691 s / img. ETA=1:11:56
[07/02 16:47:26] detectron2 INFO: Inference done 10550/26446. 0.2691 s / img. ETA=1:11:51
[07/02 16:47:31] detectron2 INFO: Inference done 10569/26446. 0.2691 s / img. ETA=1:11:46
[07/02 16:47:37] detectron2 INFO: Inference done 10589/26446. 0.2690 s / img. ETA=1:11:40
[07/02 16:47:42] detectron2 INFO: Inference done 10609/26446. 0.2690 s / img. ETA=1:11:34
[07/02 16:47:47] detectron2 INFO: Inference done 10628/26446. 0.2690 s / img. ETA=1:11:29
[07/02 16:47:52] detectron2 INFO: Inference done 10647/26446. 0.2690 s / img. ETA=1:11:24
[07/02 16:47:57] detectron2 INFO: Inference done 10667/26446. 0.2690 s / img. ETA=1:11:18
[07/02 16:48:02] detectron2 INFO: Inference done 10686/26446. 0.2690 s / img. ETA=1:11:13
[07/02 16:48:08] detectron2 INFO: Inference done 10705/26446. 0.2690 s / img. ETA=1:11:08
[07/02 16:48:13] detectron2 INFO: Inference done 10724/26446. 0.2690 s / img. ETA=1:11:02
[07/02 16:48:18] detectron2 INFO: Inference done 10743/26446. 0.2690 s / img. ETA=1:10:57
[07/02 16:48:23] detectron2 INFO: Inference done 10762/26446. 0.2690 s / img. ETA=1:10:52
[07/02 16:48:28] detectron2 INFO: Inference done 10782/26446. 0.2690 s / img. ETA=1:10:46
[07/02 16:48:33] detectron2 INFO: Inference done 10801/26446. 0.2690 s / img. ETA=1:10:41
[07/02 16:48:38] detectron2 INFO: Inference done 10820/26446. 0.2689 s / img. ETA=1:10:36
[07/02 16:48:43] detectron2 INFO: Inference done 10839/26446. 0.2689 s / img. ETA=1:10:31
[07/02 16:48:48] detectron2 INFO: Inference done 10858/26446. 0.2689 s / img. ETA=1:10:25
[07/02 16:48:54] detectron2 INFO: Inference done 10877/26446. 0.2689 s / img. ETA=1:10:20
[07/02 16:48:59] detectron2 INFO: Inference done 10897/26446. 0.2689 s / img. ETA=1:10:14
[07/02 16:49:04] detectron2 INFO: Inference done 10917/26446. 0.2689 s / img. ETA=1:10:09
[07/02 16:49:09] detectron2 INFO: Inference done 10936/26446. 0.2689 s / img. ETA=1:10:03
[07/02 16:49:14] detectron2 INFO: Inference done 10955/26446. 0.2689 s / img. ETA=1:09:58
[07/02 16:49:19] detectron2 INFO: Inference done 10974/26446. 0.2689 s / img. ETA=1:09:53
[07/02 16:49:24] detectron2 INFO: Inference done 10993/26446. 0.2689 s / img. ETA=1:09:48
[07/02 16:49:30] detectron2 INFO: Inference done 11012/26446. 0.2689 s / img. ETA=1:09:43
[07/02 16:49:35] detectron2 INFO: Inference done 11031/26446. 0.2689 s / img. ETA=1:09:38
[07/02 16:49:40] detectron2 INFO: Inference done 11050/26446. 0.2689 s / img. ETA=1:09:32
[07/02 16:49:45] detectron2 INFO: Inference done 11069/26446. 0.2689 s / img. ETA=1:09:27
[07/02 16:49:50] detectron2 INFO: Inference done 11088/26446. 0.2689 s / img. ETA=1:09:22
[07/02 16:49:55] detectron2 INFO: Inference done 11107/26446. 0.2689 s / img. ETA=1:09:17
[07/02 16:50:00] detectron2 INFO: Inference done 11125/26446. 0.2689 s / img. ETA=1:09:12
[07/02 16:50:06] detectron2 INFO: Inference done 11144/26446. 0.2689 s / img. ETA=1:09:07
[07/02 16:50:11] detectron2 INFO: Inference done 11162/26446. 0.2689 s / img. ETA=1:09:03
[07/02 16:50:16] detectron2 INFO: Inference done 11181/26446. 0.2689 s / img. ETA=1:08:58
[07/02 16:50:21] detectron2 INFO: Inference done 11200/26446. 0.2689 s / img. ETA=1:08:53
[07/02 16:50:26] detectron2 INFO: Inference done 11219/26446. 0.2689 s / img. ETA=1:08:48
[07/02 16:50:32] detectron2 INFO: Inference done 11238/26446. 0.2689 s / img. ETA=1:08:43
[07/02 16:50:37] detectron2 INFO: Inference done 11257/26446. 0.2689 s / img. ETA=1:08:37
[07/02 16:50:42] detectron2 INFO: Inference done 11276/26446. 0.2689 s / img. ETA=1:08:32
[07/02 16:50:47] detectron2 INFO: Inference done 11294/26446. 0.2690 s / img. ETA=1:08:28
[07/02 16:50:52] detectron2 INFO: Inference done 11312/26446. 0.2690 s / img. ETA=1:08:23
[07/02 16:50:57] detectron2 INFO: Inference done 11330/26446. 0.2690 s / img. ETA=1:08:18
[07/02 16:51:02] detectron2 INFO: Inference done 11348/26446. 0.2690 s / img. ETA=1:08:14
[07/02 16:51:07] detectron2 INFO: Inference done 11367/26446. 0.2690 s / img. ETA=1:08:09
[07/02 16:51:13] detectron2 INFO: Inference done 11386/26446. 0.2690 s / img. ETA=1:08:04
[07/02 16:51:18] detectron2 INFO: Inference done 11405/26446. 0.2690 s / img. ETA=1:07:59
[07/02 16:51:23] detectron2 INFO: Inference done 11425/26446. 0.2690 s / img. ETA=1:07:53
[07/02 16:51:28] detectron2 INFO: Inference done 11444/26446. 0.2690 s / img. ETA=1:07:48
[07/02 16:51:34] detectron2 INFO: Inference done 11463/26446. 0.2690 s / img. ETA=1:07:43
[07/02 16:51:39] detectron2 INFO: Inference done 11482/26446. 0.2690 s / img. ETA=1:07:37
[07/02 16:51:44] detectron2 INFO: Inference done 11502/26446. 0.2690 s / img. ETA=1:07:32
[07/02 16:51:49] detectron2 INFO: Inference done 11522/26446. 0.2690 s / img. ETA=1:07:26
[07/02 16:51:54] detectron2 INFO: Inference done 11542/26446. 0.2690 s / img. ETA=1:07:20
[07/02 16:51:59] detectron2 INFO: Inference done 11561/26446. 0.2690 s / img. ETA=1:07:15
[07/02 16:52:05] detectron2 INFO: Inference done 11581/26446. 0.2689 s / img. ETA=1:07:10
[07/02 16:52:10] detectron2 INFO: Inference done 11599/26446. 0.2690 s / img. ETA=1:07:05
[07/02 16:52:15] detectron2 INFO: Inference done 11617/26446. 0.2690 s / img. ETA=1:07:00
[07/02 16:52:20] detectron2 INFO: Inference done 11635/26446. 0.2690 s / img. ETA=1:06:56
[07/02 16:52:25] detectron2 INFO: Inference done 11654/26446. 0.2690 s / img. ETA=1:06:51
[07/02 16:52:30] detectron2 INFO: Inference done 11673/26446. 0.2690 s / img. ETA=1:06:45
[07/02 16:52:35] detectron2 INFO: Inference done 11692/26446. 0.2690 s / img. ETA=1:06:40
[07/02 16:52:40] detectron2 INFO: Inference done 11712/26446. 0.2690 s / img. ETA=1:06:34
[07/02 16:52:45] detectron2 INFO: Inference done 11731/26446. 0.2690 s / img. ETA=1:06:29
[07/02 16:52:51] detectron2 INFO: Inference done 11751/26446. 0.2689 s / img. ETA=1:06:23
[07/02 16:52:56] detectron2 INFO: Inference done 11771/26446. 0.2689 s / img. ETA=1:06:18
[07/02 16:53:01] detectron2 INFO: Inference done 11791/26446. 0.2689 s / img. ETA=1:06:12
[07/02 16:53:06] detectron2 INFO: Inference done 11810/26446. 0.2689 s / img. ETA=1:06:07
[07/02 16:53:11] detectron2 INFO: Inference done 11830/26446. 0.2689 s / img. ETA=1:06:01
[07/02 16:53:16] detectron2 INFO: Inference done 11850/26446. 0.2689 s / img. ETA=1:05:55
[07/02 16:53:22] detectron2 INFO: Inference done 11870/26446. 0.2688 s / img. ETA=1:05:50
[07/02 16:53:27] detectron2 INFO: Inference done 11889/26446. 0.2688 s / img. ETA=1:05:44
[07/02 16:53:32] detectron2 INFO: Inference done 11908/26446. 0.2688 s / img. ETA=1:05:39
[07/02 16:53:37] detectron2 INFO: Inference done 11927/26446. 0.2688 s / img. ETA=1:05:34
[07/02 16:53:42] detectron2 INFO: Inference done 11946/26446. 0.2688 s / img. ETA=1:05:29
[07/02 16:53:47] detectron2 INFO: Inference done 11965/26446. 0.2688 s / img. ETA=1:05:23
[07/02 16:53:52] detectron2 INFO: Inference done 11984/26446. 0.2688 s / img. ETA=1:05:18
[07/02 16:53:57] detectron2 INFO: Inference done 12004/26446. 0.2688 s / img. ETA=1:05:12
[07/02 16:54:02] detectron2 INFO: Inference done 12023/26446. 0.2688 s / img. ETA=1:05:07
[07/02 16:54:07] detectron2 INFO: Inference done 12042/26446. 0.2688 s / img. ETA=1:05:02
[07/02 16:54:12] detectron2 INFO: Inference done 12061/26446. 0.2687 s / img. ETA=1:04:57
[07/02 16:54:18] detectron2 INFO: Inference done 12081/26446. 0.2687 s / img. ETA=1:04:51
[07/02 16:54:23] detectron2 INFO: Inference done 12100/26446. 0.2687 s / img. ETA=1:04:46
[07/02 16:54:28] detectron2 INFO: Inference done 12119/26446. 0.2687 s / img. ETA=1:04:40
[07/02 16:54:33] detectron2 INFO: Inference done 12139/26446. 0.2687 s / img. ETA=1:04:35
[07/02 16:54:38] detectron2 INFO: Inference done 12158/26446. 0.2687 s / img. ETA=1:04:29
[07/02 16:54:43] detectron2 INFO: Inference done 12177/26446. 0.2687 s / img. ETA=1:04:24
[07/02 16:54:48] detectron2 INFO: Inference done 12197/26446. 0.2687 s / img. ETA=1:04:18
[07/02 16:54:53] detectron2 INFO: Inference done 12216/26446. 0.2687 s / img. ETA=1:04:13
[07/02 16:54:58] detectron2 INFO: Inference done 12236/26446. 0.2686 s / img. ETA=1:04:08
[07/02 16:55:03] detectron2 INFO: Inference done 12255/26446. 0.2686 s / img. ETA=1:04:02
[07/02 16:55:08] detectron2 INFO: Inference done 12274/26446. 0.2686 s / img. ETA=1:03:57
[07/02 16:55:13] detectron2 INFO: Inference done 12293/26446. 0.2686 s / img. ETA=1:03:52
[07/02 16:55:19] detectron2 INFO: Inference done 12312/26446. 0.2686 s / img. ETA=1:03:46
[07/02 16:55:24] detectron2 INFO: Inference done 12331/26446. 0.2686 s / img. ETA=1:03:41
[07/02 16:55:29] detectron2 INFO: Inference done 12350/26446. 0.2686 s / img. ETA=1:03:36
[07/02 16:55:34] detectron2 INFO: Inference done 12369/26446. 0.2686 s / img. ETA=1:03:31
[07/02 16:55:39] detectron2 INFO: Inference done 12389/26446. 0.2686 s / img. ETA=1:03:25
[07/02 16:55:44] detectron2 INFO: Inference done 12408/26446. 0.2686 s / img. ETA=1:03:20
[07/02 16:55:49] detectron2 INFO: Inference done 12428/26446. 0.2686 s / img. ETA=1:03:15
[07/02 16:55:55] detectron2 INFO: Inference done 12447/26446. 0.2686 s / img. ETA=1:03:09
[07/02 16:56:00] detectron2 INFO: Inference done 12467/26446. 0.2685 s / img. ETA=1:03:04
[07/02 16:56:05] detectron2 INFO: Inference done 12487/26446. 0.2685 s / img. ETA=1:02:58
[07/02 16:56:10] detectron2 INFO: Inference done 12506/26446. 0.2685 s / img. ETA=1:02:53
[07/02 16:56:15] detectron2 INFO: Inference done 12526/26446. 0.2685 s / img. ETA=1:02:47
[07/02 16:56:20] detectron2 INFO: Inference done 12545/26446. 0.2685 s / img. ETA=1:02:42
[07/02 16:56:26] detectron2 INFO: Inference done 12565/26446. 0.2685 s / img. ETA=1:02:36
[07/02 16:56:31] detectron2 INFO: Inference done 12584/26446. 0.2685 s / img. ETA=1:02:31
[07/02 16:56:36] detectron2 INFO: Inference done 12603/26446. 0.2685 s / img. ETA=1:02:26
[07/02 16:56:41] detectron2 INFO: Inference done 12623/26446. 0.2685 s / img. ETA=1:02:20
[07/02 16:56:46] detectron2 INFO: Inference done 12643/26446. 0.2684 s / img. ETA=1:02:15
[07/02 16:56:51] detectron2 INFO: Inference done 12662/26446. 0.2684 s / img. ETA=1:02:09
[07/02 16:56:56] detectron2 INFO: Inference done 12681/26446. 0.2684 s / img. ETA=1:02:04
[07/02 16:57:01] detectron2 INFO: Inference done 12700/26446. 0.2684 s / img. ETA=1:01:59
[07/02 16:57:06] detectron2 INFO: Inference done 12720/26446. 0.2684 s / img. ETA=1:01:53
[07/02 16:57:11] detectron2 INFO: Inference done 12739/26446. 0.2684 s / img. ETA=1:01:48
[07/02 16:57:17] detectron2 INFO: Inference done 12758/26446. 0.2684 s / img. ETA=1:01:43
[07/02 16:57:22] detectron2 INFO: Inference done 12777/26446. 0.2684 s / img. ETA=1:01:38
[07/02 16:57:27] detectron2 INFO: Inference done 12797/26446. 0.2684 s / img. ETA=1:01:32
[07/02 16:57:32] detectron2 INFO: Inference done 12816/26446. 0.2684 s / img. ETA=1:01:27
[07/02 16:57:37] detectron2 INFO: Inference done 12836/26446. 0.2683 s / img. ETA=1:01:21
[07/02 16:57:42] detectron2 INFO: Inference done 12855/26446. 0.2683 s / img. ETA=1:01:16
[07/02 16:57:47] detectron2 INFO: Inference done 12874/26446. 0.2683 s / img. ETA=1:01:11
[07/02 16:57:52] detectron2 INFO: Inference done 12893/26446. 0.2683 s / img. ETA=1:01:05
[07/02 16:57:57] detectron2 INFO: Inference done 12913/26446. 0.2683 s / img. ETA=1:01:00
[07/02 16:58:03] detectron2 INFO: Inference done 12933/26446. 0.2683 s / img. ETA=1:00:54
[07/02 16:58:08] detectron2 INFO: Inference done 12952/26446. 0.2683 s / img. ETA=1:00:49
[07/02 16:58:13] detectron2 INFO: Inference done 12972/26446. 0.2683 s / img. ETA=1:00:44
[07/02 16:58:18] detectron2 INFO: Inference done 12991/26446. 0.2683 s / img. ETA=1:00:38
[07/02 16:58:23] detectron2 INFO: Inference done 13010/26446. 0.2683 s / img. ETA=1:00:33
[07/02 16:58:28] detectron2 INFO: Inference done 13029/26446. 0.2683 s / img. ETA=1:00:28
[07/02 16:58:33] detectron2 INFO: Inference done 13048/26446. 0.2683 s / img. ETA=1:00:23
[07/02 16:58:39] detectron2 INFO: Inference done 13067/26446. 0.2683 s / img. ETA=1:00:18
[07/02 16:58:44] detectron2 INFO: Inference done 13086/26446. 0.2683 s / img. ETA=1:00:12
[07/02 16:58:49] detectron2 INFO: Inference done 13105/26446. 0.2683 s / img. ETA=1:00:07
[07/02 16:58:54] detectron2 INFO: Inference done 13124/26446. 0.2683 s / img. ETA=1:00:02
[07/02 16:58:59] detectron2 INFO: Inference done 13143/26446. 0.2682 s / img. ETA=0:59:57
[07/02 16:59:04] detectron2 INFO: Inference done 13162/26446. 0.2682 s / img. ETA=0:59:52
[07/02 16:59:09] detectron2 INFO: Inference done 13181/26446. 0.2682 s / img. ETA=0:59:46
[07/02 16:59:14] detectron2 INFO: Inference done 13200/26446. 0.2682 s / img. ETA=0:59:41
[07/02 16:59:19] detectron2 INFO: Inference done 13219/26446. 0.2682 s / img. ETA=0:59:36
[07/02 16:59:24] detectron2 INFO: Inference done 13238/26446. 0.2682 s / img. ETA=0:59:31
[07/02 16:59:29] detectron2 INFO: Inference done 13257/26446. 0.2682 s / img. ETA=0:59:25
[07/02 16:59:34] detectron2 INFO: Inference done 13276/26446. 0.2682 s / img. ETA=0:59:20
[07/02 16:59:39] detectron2 INFO: Inference done 13295/26446. 0.2682 s / img. ETA=0:59:15
[07/02 16:59:45] detectron2 INFO: Inference done 13314/26446. 0.2682 s / img. ETA=0:59:10
[07/02 16:59:50] detectron2 INFO: Inference done 13333/26446. 0.2682 s / img. ETA=0:59:05
[07/02 16:59:55] detectron2 INFO: Inference done 13352/26446. 0.2682 s / img. ETA=0:59:00
[07/02 17:00:00] detectron2 INFO: Inference done 13371/26446. 0.2682 s / img. ETA=0:58:55
[07/02 17:00:05] detectron2 INFO: Inference done 13390/26446. 0.2682 s / img. ETA=0:58:49
[07/02 17:00:10] detectron2 INFO: Inference done 13409/26446. 0.2682 s / img. ETA=0:58:44
[07/02 17:00:15] detectron2 INFO: Inference done 13427/26446. 0.2682 s / img. ETA=0:58:39
[07/02 17:00:20] detectron2 INFO: Inference done 13446/26446. 0.2682 s / img. ETA=0:58:34
[07/02 17:00:25] detectron2 INFO: Inference done 13465/26446. 0.2682 s / img. ETA=0:58:29
[07/02 17:00:31] detectron2 INFO: Inference done 13484/26446. 0.2682 s / img. ETA=0:58:24
[07/02 17:00:36] detectron2 INFO: Inference done 13503/26446. 0.2682 s / img. ETA=0:58:19
[07/02 17:00:41] detectron2 INFO: Inference done 13523/26446. 0.2682 s / img. ETA=0:58:13
[07/02 17:00:46] detectron2 INFO: Inference done 13542/26446. 0.2682 s / img. ETA=0:58:08
[07/02 17:00:51] detectron2 INFO: Inference done 13561/26446. 0.2682 s / img. ETA=0:58:03
[07/02 17:00:56] detectron2 INFO: Inference done 13581/26446. 0.2682 s / img. ETA=0:57:57
[07/02 17:01:01] detectron2 INFO: Inference done 13600/26446. 0.2681 s / img. ETA=0:57:52
[07/02 17:01:06] detectron2 INFO: Inference done 13620/26446. 0.2681 s / img. ETA=0:57:46
[07/02 17:01:11] detectron2 INFO: Inference done 13639/26446. 0.2681 s / img. ETA=0:57:41
[07/02 17:01:16] detectron2 INFO: Inference done 13658/26446. 0.2681 s / img. ETA=0:57:36
[07/02 17:01:22] detectron2 INFO: Inference done 13678/26446. 0.2681 s / img. ETA=0:57:30
[07/02 17:01:27] detectron2 INFO: Inference done 13698/26446. 0.2681 s / img. ETA=0:57:25
[07/02 17:01:32] detectron2 INFO: Inference done 13717/26446. 0.2681 s / img. ETA=0:57:19
[07/02 17:01:37] detectron2 INFO: Inference done 13736/26446. 0.2681 s / img. ETA=0:57:14
[07/02 17:01:42] detectron2 INFO: Inference done 13755/26446. 0.2681 s / img. ETA=0:57:09
[07/02 17:01:47] detectron2 INFO: Inference done 13774/26446. 0.2681 s / img. ETA=0:57:04
[07/02 17:01:52] detectron2 INFO: Inference done 13794/26446. 0.2680 s / img. ETA=0:56:58
[07/02 17:01:57] detectron2 INFO: Inference done 13814/26446. 0.2680 s / img. ETA=0:56:53
[07/02 17:02:03] detectron2 INFO: Inference done 13834/26446. 0.2680 s / img. ETA=0:56:47
[07/02 17:02:08] detectron2 INFO: Inference done 13853/26446. 0.2680 s / img. ETA=0:56:42
[07/02 17:02:13] detectron2 INFO: Inference done 13873/26446. 0.2680 s / img. ETA=0:56:36
[07/02 17:02:18] detectron2 INFO: Inference done 13892/26446. 0.2680 s / img. ETA=0:56:31
[07/02 17:02:23] detectron2 INFO: Inference done 13911/26446. 0.2680 s / img. ETA=0:56:26
[07/02 17:02:28] detectron2 INFO: Inference done 13930/26446. 0.2680 s / img. ETA=0:56:21
[07/02 17:02:33] detectron2 INFO: Inference done 13949/26446. 0.2680 s / img. ETA=0:56:15
[07/02 17:02:38] detectron2 INFO: Inference done 13968/26446. 0.2680 s / img. ETA=0:56:10
[07/02 17:02:43] detectron2 INFO: Inference done 13987/26446. 0.2680 s / img. ETA=0:56:05
[07/02 17:02:48] detectron2 INFO: Inference done 14006/26446. 0.2680 s / img. ETA=0:56:00
[07/02 17:02:53] detectron2 INFO: Inference done 14025/26446. 0.2680 s / img. ETA=0:55:55
[07/02 17:02:58] detectron2 INFO: Inference done 14044/26446. 0.2680 s / img. ETA=0:55:49
[07/02 17:03:03] detectron2 INFO: Inference done 14063/26446. 0.2679 s / img. ETA=0:55:44
[07/02 17:03:09] detectron2 INFO: Inference done 14082/26446. 0.2679 s / img. ETA=0:55:39
[07/02 17:03:14] detectron2 INFO: Inference done 14102/26446. 0.2679 s / img. ETA=0:55:34
[07/02 17:03:19] detectron2 INFO: Inference done 14121/26446. 0.2679 s / img. ETA=0:55:28
[07/02 17:03:24] detectron2 INFO: Inference done 14140/26446. 0.2679 s / img. ETA=0:55:23
[07/02 17:03:29] detectron2 INFO: Inference done 14159/26446. 0.2679 s / img. ETA=0:55:18
[07/02 17:03:34] detectron2 INFO: Inference done 14178/26446. 0.2679 s / img. ETA=0:55:13
[07/02 17:03:40] detectron2 INFO: Inference done 14197/26446. 0.2679 s / img. ETA=0:55:08
[07/02 17:03:45] detectron2 INFO: Inference done 14216/26446. 0.2680 s / img. ETA=0:55:03
[07/02 17:03:50] detectron2 INFO: Inference done 14235/26446. 0.2679 s / img. ETA=0:54:58
[07/02 17:03:55] detectron2 INFO: Inference done 14254/26446. 0.2679 s / img. ETA=0:54:53
[07/02 17:04:00] detectron2 INFO: Inference done 14273/26446. 0.2679 s / img. ETA=0:54:47
[07/02 17:04:05] detectron2 INFO: Inference done 14292/26446. 0.2679 s / img. ETA=0:54:42
[07/02 17:04:10] detectron2 INFO: Inference done 14311/26446. 0.2679 s / img. ETA=0:54:37
[07/02 17:04:15] detectron2 INFO: Inference done 14330/26446. 0.2679 s / img. ETA=0:54:32
[07/02 17:04:21] detectron2 INFO: Inference done 14349/26446. 0.2679 s / img. ETA=0:54:27
[07/02 17:04:26] detectron2 INFO: Inference done 14368/26446. 0.2679 s / img. ETA=0:54:22
[07/02 17:04:31] detectron2 INFO: Inference done 14387/26446. 0.2679 s / img. ETA=0:54:17
[07/02 17:04:36] detectron2 INFO: Inference done 14406/26446. 0.2679 s / img. ETA=0:54:11
[07/02 17:04:41] detectron2 INFO: Inference done 14425/26446. 0.2679 s / img. ETA=0:54:06
[07/02 17:04:46] detectron2 INFO: Inference done 14444/26446. 0.2679 s / img. ETA=0:54:01
[07/02 17:04:51] detectron2 INFO: Inference done 14463/26446. 0.2679 s / img. ETA=0:53:56
[07/02 17:04:56] detectron2 INFO: Inference done 14482/26446. 0.2679 s / img. ETA=0:53:51
[07/02 17:05:01] detectron2 INFO: Inference done 14501/26446. 0.2679 s / img. ETA=0:53:46
[07/02 17:05:07] detectron2 INFO: Inference done 14521/26446. 0.2679 s / img. ETA=0:53:40
[07/02 17:05:12] detectron2 INFO: Inference done 14540/26446. 0.2679 s / img. ETA=0:53:35
[07/02 17:05:17] detectron2 INFO: Inference done 14559/26446. 0.2679 s / img. ETA=0:53:30
[07/02 17:05:22] detectron2 INFO: Inference done 14578/26446. 0.2679 s / img. ETA=0:53:25
[07/02 17:05:27] detectron2 INFO: Inference done 14597/26446. 0.2679 s / img. ETA=0:53:20
[07/02 17:05:32] detectron2 INFO: Inference done 14616/26446. 0.2679 s / img. ETA=0:53:14
[07/02 17:05:37] detectron2 INFO: Inference done 14635/26446. 0.2679 s / img. ETA=0:53:09
[07/02 17:05:42] detectron2 INFO: Inference done 14654/26446. 0.2679 s / img. ETA=0:53:04
[07/02 17:05:48] detectron2 INFO: Inference done 14673/26446. 0.2679 s / img. ETA=0:52:59
[07/02 17:05:53] detectron2 INFO: Inference done 14692/26446. 0.2679 s / img. ETA=0:52:54
[07/02 17:05:58] detectron2 INFO: Inference done 14711/26446. 0.2679 s / img. ETA=0:52:49
[07/02 17:06:03] detectron2 INFO: Inference done 14730/26446. 0.2679 s / img. ETA=0:52:44
[07/02 17:06:08] detectron2 INFO: Inference done 14749/26446. 0.2679 s / img. ETA=0:52:39
[07/02 17:06:14] detectron2 INFO: Inference done 14768/26446. 0.2679 s / img. ETA=0:52:34
[07/02 17:06:19] detectron2 INFO: Inference done 14787/26446. 0.2679 s / img. ETA=0:52:29
[07/02 17:06:24] detectron2 INFO: Inference done 14806/26446. 0.2679 s / img. ETA=0:52:23
[07/02 17:06:29] detectron2 INFO: Inference done 14825/26446. 0.2679 s / img. ETA=0:52:18
[07/02 17:06:34] detectron2 INFO: Inference done 14844/26446. 0.2679 s / img. ETA=0:52:13
[07/02 17:06:39] detectron2 INFO: Inference done 14863/26446. 0.2679 s / img. ETA=0:52:08
[07/02 17:06:44] detectron2 INFO: Inference done 14882/26446. 0.2679 s / img. ETA=0:52:03
[07/02 17:06:49] detectron2 INFO: Inference done 14901/26446. 0.2679 s / img. ETA=0:51:57
[07/02 17:06:54] detectron2 INFO: Inference done 14920/26446. 0.2679 s / img. ETA=0:51:52
[07/02 17:06:59] detectron2 INFO: Inference done 14939/26446. 0.2679 s / img. ETA=0:51:47
[07/02 17:07:05] detectron2 INFO: Inference done 14958/26446. 0.2679 s / img. ETA=0:51:42
[07/02 17:07:10] detectron2 INFO: Inference done 14977/26446. 0.2679 s / img. ETA=0:51:37
[07/02 17:07:15] detectron2 INFO: Inference done 14996/26446. 0.2679 s / img. ETA=0:51:32
[07/02 17:07:20] detectron2 INFO: Inference done 15015/26446. 0.2679 s / img. ETA=0:51:27
[07/02 17:07:25] detectron2 INFO: Inference done 15034/26446. 0.2679 s / img. ETA=0:51:21
[07/02 17:07:30] detectron2 INFO: Inference done 15053/26446. 0.2679 s / img. ETA=0:51:16
[07/02 17:07:35] detectron2 INFO: Inference done 15072/26446. 0.2679 s / img. ETA=0:51:11
[07/02 17:07:40] detectron2 INFO: Inference done 15091/26446. 0.2679 s / img. ETA=0:51:06
[07/02 17:07:45] detectron2 INFO: Inference done 15110/26446. 0.2679 s / img. ETA=0:51:01
[07/02 17:07:51] detectron2 INFO: Inference done 15129/26446. 0.2679 s / img. ETA=0:50:56
[07/02 17:07:56] detectron2 INFO: Inference done 15148/26446. 0.2679 s / img. ETA=0:50:50
[07/02 17:08:01] detectron2 INFO: Inference done 15167/26446. 0.2679 s / img. ETA=0:50:45
[07/02 17:08:06] detectron2 INFO: Inference done 15186/26446. 0.2679 s / img. ETA=0:50:40
[07/02 17:08:11] detectron2 INFO: Inference done 15205/26446. 0.2679 s / img. ETA=0:50:35
[07/02 17:08:16] detectron2 INFO: Inference done 15224/26446. 0.2679 s / img. ETA=0:50:30
[07/02 17:08:21] detectron2 INFO: Inference done 15243/26446. 0.2679 s / img. ETA=0:50:25
[07/02 17:08:26] detectron2 INFO: Inference done 15262/26446. 0.2679 s / img. ETA=0:50:19
[07/02 17:08:31] detectron2 INFO: Inference done 15280/26446. 0.2679 s / img. ETA=0:50:15
[07/02 17:08:36] detectron2 INFO: Inference done 15298/26446. 0.2679 s / img. ETA=0:50:10
[07/02 17:08:41] detectron2 INFO: Inference done 15317/26446. 0.2679 s / img. ETA=0:50:05
[07/02 17:08:46] detectron2 INFO: Inference done 15336/26446. 0.2679 s / img. ETA=0:50:00
[07/02 17:08:51] detectron2 INFO: Inference done 15355/26446. 0.2679 s / img. ETA=0:49:55
[07/02 17:08:57] detectron2 INFO: Inference done 15374/26446. 0.2679 s / img. ETA=0:49:49
[07/02 17:09:02] detectron2 INFO: Inference done 15393/26446. 0.2679 s / img. ETA=0:49:44
[07/02 17:09:07] detectron2 INFO: Inference done 15412/26446. 0.2679 s / img. ETA=0:49:39
[07/02 17:09:12] detectron2 INFO: Inference done 15431/26446. 0.2679 s / img. ETA=0:49:34
[07/02 17:09:17] detectron2 INFO: Inference done 15450/26446. 0.2679 s / img. ETA=0:49:29
[07/02 17:09:22] detectron2 INFO: Inference done 15469/26446. 0.2679 s / img. ETA=0:49:24
[07/02 17:09:27] detectron2 INFO: Inference done 15488/26446. 0.2679 s / img. ETA=0:49:18
[07/02 17:09:32] detectron2 INFO: Inference done 15507/26446. 0.2679 s / img. ETA=0:49:13
[07/02 17:09:37] detectron2 INFO: Inference done 15525/26446. 0.2679 s / img. ETA=0:49:09
[07/02 17:09:42] detectron2 INFO: Inference done 15539/26446. 0.2680 s / img. ETA=0:49:06
[07/02 17:09:48] detectron2 INFO: Inference done 15558/26446. 0.2680 s / img. ETA=0:49:01
[07/02 17:09:53] detectron2 INFO: Inference done 15577/26446. 0.2680 s / img. ETA=0:48:56
[07/02 17:09:58] detectron2 INFO: Inference done 15596/26446. 0.2680 s / img. ETA=0:48:51
[07/02 17:10:03] detectron2 INFO: Inference done 15615/26446. 0.2680 s / img. ETA=0:48:45
[07/02 17:10:08] detectron2 INFO: Inference done 15634/26446. 0.2680 s / img. ETA=0:48:40
[07/02 17:10:13] detectron2 INFO: Inference done 15653/26446. 0.2680 s / img. ETA=0:48:35
[07/02 17:10:19] detectron2 INFO: Inference done 15672/26446. 0.2680 s / img. ETA=0:48:30
[07/02 17:10:24] detectron2 INFO: Inference done 15691/26446. 0.2680 s / img. ETA=0:48:25
[07/02 17:10:29] detectron2 INFO: Inference done 15710/26446. 0.2680 s / img. ETA=0:48:20
[07/02 17:10:34] detectron2 INFO: Inference done 15730/26446. 0.2680 s / img. ETA=0:48:14
[07/02 17:10:39] detectron2 INFO: Inference done 15749/26446. 0.2680 s / img. ETA=0:48:09
[07/02 17:10:44] detectron2 INFO: Inference done 15769/26446. 0.2679 s / img. ETA=0:48:03
[07/02 17:10:49] detectron2 INFO: Inference done 15789/26446. 0.2679 s / img. ETA=0:47:58
[07/02 17:10:54] detectron2 INFO: Inference done 15808/26446. 0.2679 s / img. ETA=0:47:53
[07/02 17:10:59] detectron2 INFO: Inference done 15828/26446. 0.2679 s / img. ETA=0:47:47
[07/02 17:11:05] detectron2 INFO: Inference done 15848/26446. 0.2679 s / img. ETA=0:47:42
[07/02 17:11:10] detectron2 INFO: Inference done 15868/26446. 0.2679 s / img. ETA=0:47:36
[07/02 17:11:15] detectron2 INFO: Inference done 15888/26446. 0.2679 s / img. ETA=0:47:30
[07/02 17:11:20] detectron2 INFO: Inference done 15908/26446. 0.2679 s / img. ETA=0:47:25
[07/02 17:11:25] detectron2 INFO: Inference done 15927/26446. 0.2679 s / img. ETA=0:47:20
[07/02 17:11:31] detectron2 INFO: Inference done 15947/26446. 0.2678 s / img. ETA=0:47:14
[07/02 17:11:36] detectron2 INFO: Inference done 15967/26446. 0.2678 s / img. ETA=0:47:09
[07/02 17:11:41] detectron2 INFO: Inference done 15986/26446. 0.2678 s / img. ETA=0:47:04
[07/02 17:11:46] detectron2 INFO: Inference done 16006/26446. 0.2678 s / img. ETA=0:46:58
[07/02 17:11:51] detectron2 INFO: Inference done 16025/26446. 0.2678 s / img. ETA=0:46:53
[07/02 17:11:56] detectron2 INFO: Inference done 16044/26446. 0.2678 s / img. ETA=0:46:48
[07/02 17:12:01] detectron2 INFO: Inference done 16063/26446. 0.2678 s / img. ETA=0:46:42
[07/02 17:12:06] detectron2 INFO: Inference done 16083/26446. 0.2678 s / img. ETA=0:46:37
[07/02 17:12:11] detectron2 INFO: Inference done 16102/26446. 0.2678 s / img. ETA=0:46:32
[07/02 17:12:17] detectron2 INFO: Inference done 16121/26446. 0.2678 s / img. ETA=0:46:27
[07/02 17:12:22] detectron2 INFO: Inference done 16140/26446. 0.2678 s / img. ETA=0:46:21
[07/02 17:12:27] detectron2 INFO: Inference done 16160/26446. 0.2678 s / img. ETA=0:46:16
[07/02 17:12:32] detectron2 INFO: Inference done 16179/26446. 0.2678 s / img. ETA=0:46:11
[07/02 17:12:37] detectron2 INFO: Inference done 16198/26446. 0.2678 s / img. ETA=0:46:06
[07/02 17:12:42] detectron2 INFO: Inference done 16218/26446. 0.2677 s / img. ETA=0:46:00
[07/02 17:12:47] detectron2 INFO: Inference done 16237/26446. 0.2677 s / img. ETA=0:45:55
[07/02 17:12:52] detectron2 INFO: Inference done 16256/26446. 0.2677 s / img. ETA=0:45:50
[07/02 17:12:57] detectron2 INFO: Inference done 16275/26446. 0.2677 s / img. ETA=0:45:45
[07/02 17:13:02] detectron2 INFO: Inference done 16294/26446. 0.2677 s / img. ETA=0:45:39
[07/02 17:13:07] detectron2 INFO: Inference done 16313/26446. 0.2677 s / img. ETA=0:45:34
[07/02 17:13:13] detectron2 INFO: Inference done 16333/26446. 0.2677 s / img. ETA=0:45:29
[07/02 17:13:18] detectron2 INFO: Inference done 16352/26446. 0.2677 s / img. ETA=0:45:24
[07/02 17:13:23] detectron2 INFO: Inference done 16371/26446. 0.2677 s / img. ETA=0:45:18
[07/02 17:13:28] detectron2 INFO: Inference done 16390/26446. 0.2677 s / img. ETA=0:45:13
[07/02 17:13:33] detectron2 INFO: Inference done 16409/26446. 0.2677 s / img. ETA=0:45:08
[07/02 17:13:38] detectron2 INFO: Inference done 16428/26446. 0.2677 s / img. ETA=0:45:03
[07/02 17:13:43] detectron2 INFO: Inference done 16447/26446. 0.2677 s / img. ETA=0:44:58
[07/02 17:13:48] detectron2 INFO: Inference done 16466/26446. 0.2677 s / img. ETA=0:44:53
[07/02 17:13:53] detectron2 INFO: Inference done 16485/26446. 0.2677 s / img. ETA=0:44:47
[07/02 17:13:58] detectron2 INFO: Inference done 16504/26446. 0.2677 s / img. ETA=0:44:42
[07/02 17:14:03] detectron2 INFO: Inference done 16523/26446. 0.2677 s / img. ETA=0:44:37
[07/02 17:14:08] detectron2 INFO: Inference done 16542/26446. 0.2677 s / img. ETA=0:44:32
[07/02 17:14:14] detectron2 INFO: Inference done 16561/26446. 0.2677 s / img. ETA=0:44:27
[07/02 17:14:19] detectron2 INFO: Inference done 16580/26446. 0.2677 s / img. ETA=0:44:22
[07/02 17:14:24] detectron2 INFO: Inference done 16599/26446. 0.2677 s / img. ETA=0:44:17
[07/02 17:14:29] detectron2 INFO: Inference done 16618/26446. 0.2677 s / img. ETA=0:44:11
[07/02 17:14:34] detectron2 INFO: Inference done 16637/26446. 0.2677 s / img. ETA=0:44:06
[07/02 17:14:39] detectron2 INFO: Inference done 16656/26446. 0.2677 s / img. ETA=0:44:01
[07/02 17:14:44] detectron2 INFO: Inference done 16675/26446. 0.2677 s / img. ETA=0:43:56
[07/02 17:14:49] detectron2 INFO: Inference done 16694/26446. 0.2677 s / img. ETA=0:43:51
[07/02 17:14:54] detectron2 INFO: Inference done 16713/26446. 0.2677 s / img. ETA=0:43:46
[07/02 17:14:59] detectron2 INFO: Inference done 16732/26446. 0.2677 s / img. ETA=0:43:40
[07/02 17:15:04] detectron2 INFO: Inference done 16751/26446. 0.2677 s / img. ETA=0:43:35
[07/02 17:15:10] detectron2 INFO: Inference done 16770/26446. 0.2677 s / img. ETA=0:43:30
[07/02 17:15:15] detectron2 INFO: Inference done 16789/26446. 0.2677 s / img. ETA=0:43:25
[07/02 17:15:20] detectron2 INFO: Inference done 16808/26446. 0.2676 s / img. ETA=0:43:20
[07/02 17:15:25] detectron2 INFO: Inference done 16828/26446. 0.2676 s / img. ETA=0:43:14
[07/02 17:15:30] detectron2 INFO: Inference done 16848/26446. 0.2676 s / img. ETA=0:43:09
[07/02 17:15:35] detectron2 INFO: Inference done 16867/26446. 0.2676 s / img. ETA=0:43:04
[07/02 17:15:40] detectron2 INFO: Inference done 16886/26446. 0.2676 s / img. ETA=0:42:59
[07/02 17:15:45] detectron2 INFO: Inference done 16905/26446. 0.2676 s / img. ETA=0:42:53
[07/02 17:15:50] detectron2 INFO: Inference done 16924/26446. 0.2676 s / img. ETA=0:42:48
[07/02 17:15:55] detectron2 INFO: Inference done 16943/26446. 0.2676 s / img. ETA=0:42:43
[07/02 17:16:01] detectron2 INFO: Inference done 16962/26446. 0.2676 s / img. ETA=0:42:38
[07/02 17:16:06] detectron2 INFO: Inference done 16981/26446. 0.2676 s / img. ETA=0:42:33
[07/02 17:16:11] detectron2 INFO: Inference done 17000/26446. 0.2676 s / img. ETA=0:42:28
[07/02 17:16:16] detectron2 INFO: Inference done 17019/26446. 0.2676 s / img. ETA=0:42:22
[07/02 17:16:21] detectron2 INFO: Inference done 17038/26446. 0.2676 s / img. ETA=0:42:17
[07/02 17:16:26] detectron2 INFO: Inference done 17057/26446. 0.2676 s / img. ETA=0:42:12
[07/02 17:16:31] detectron2 INFO: Inference done 17076/26446. 0.2676 s / img. ETA=0:42:07
[07/02 17:16:36] detectron2 INFO: Inference done 17095/26446. 0.2676 s / img. ETA=0:42:02
[07/02 17:16:41] detectron2 INFO: Inference done 17114/26446. 0.2676 s / img. ETA=0:41:57
[07/02 17:16:46] detectron2 INFO: Inference done 17133/26446. 0.2676 s / img. ETA=0:41:52
[07/02 17:16:51] detectron2 INFO: Inference done 17152/26446. 0.2676 s / img. ETA=0:41:46
[07/02 17:16:56] detectron2 INFO: Inference done 17171/26446. 0.2676 s / img. ETA=0:41:41
[07/02 17:17:02] detectron2 INFO: Inference done 17190/26446. 0.2676 s / img. ETA=0:41:36
[07/02 17:17:07] detectron2 INFO: Inference done 17209/26446. 0.2676 s / img. ETA=0:41:31
[07/02 17:17:12] detectron2 INFO: Inference done 17229/26446. 0.2676 s / img. ETA=0:41:25
[07/02 17:17:17] detectron2 INFO: Inference done 17248/26446. 0.2676 s / img. ETA=0:41:20
[07/02 17:17:22] detectron2 INFO: Inference done 17267/26446. 0.2676 s / img. ETA=0:41:15
[07/02 17:17:27] detectron2 INFO: Inference done 17286/26446. 0.2676 s / img. ETA=0:41:10
[07/02 17:17:32] detectron2 INFO: Inference done 17305/26446. 0.2676 s / img. ETA=0:41:05
[07/02 17:17:37] detectron2 INFO: Inference done 17324/26446. 0.2676 s / img. ETA=0:41:00
[07/02 17:17:42] detectron2 INFO: Inference done 17343/26446. 0.2676 s / img. ETA=0:40:55
[07/02 17:17:48] detectron2 INFO: Inference done 17362/26446. 0.2676 s / img. ETA=0:40:50
[07/02 17:17:53] detectron2 INFO: Inference done 17381/26446. 0.2676 s / img. ETA=0:40:45
[07/02 17:17:58] detectron2 INFO: Inference done 17401/26446. 0.2676 s / img. ETA=0:40:39
[07/02 17:18:03] detectron2 INFO: Inference done 17420/26446. 0.2676 s / img. ETA=0:40:34
[07/02 17:18:08] detectron2 INFO: Inference done 17439/26446. 0.2676 s / img. ETA=0:40:29
[07/02 17:18:13] detectron2 INFO: Inference done 17458/26446. 0.2676 s / img. ETA=0:40:24
[07/02 17:18:18] detectron2 INFO: Inference done 17477/26446. 0.2675 s / img. ETA=0:40:18
[07/02 17:18:24] detectron2 INFO: Inference done 17496/26446. 0.2675 s / img. ETA=0:40:13
[07/02 17:18:29] detectron2 INFO: Inference done 17515/26446. 0.2675 s / img. ETA=0:40:08
[07/02 17:18:34] detectron2 INFO: Inference done 17535/26446. 0.2675 s / img. ETA=0:40:03
[07/02 17:18:39] detectron2 INFO: Inference done 17554/26446. 0.2675 s / img. ETA=0:39:58
[07/02 17:18:44] detectron2 INFO: Inference done 17573/26446. 0.2675 s / img. ETA=0:39:52
[07/02 17:18:49] detectron2 INFO: Inference done 17592/26446. 0.2675 s / img. ETA=0:39:47
[07/02 17:18:55] detectron2 INFO: Inference done 17611/26446. 0.2675 s / img. ETA=0:39:42
[07/02 17:19:00] detectron2 INFO: Inference done 17630/26446. 0.2675 s / img. ETA=0:39:37
[07/02 17:19:05] detectron2 INFO: Inference done 17649/26446. 0.2675 s / img. ETA=0:39:32
[07/02 17:19:10] detectron2 INFO: Inference done 17668/26446. 0.2675 s / img. ETA=0:39:27
[07/02 17:19:15] detectron2 INFO: Inference done 17687/26446. 0.2675 s / img. ETA=0:39:22
[07/02 17:19:20] detectron2 INFO: Inference done 17706/26446. 0.2675 s / img. ETA=0:39:17
[07/02 17:19:25] detectron2 INFO: Inference done 17725/26446. 0.2675 s / img. ETA=0:39:12
[07/02 17:19:30] detectron2 INFO: Inference done 17743/26446. 0.2676 s / img. ETA=0:39:07
[07/02 17:19:36] detectron2 INFO: Inference done 17762/26446. 0.2676 s / img. ETA=0:39:02
[07/02 17:19:41] detectron2 INFO: Inference done 17781/26446. 0.2676 s / img. ETA=0:38:57
[07/02 17:19:46] detectron2 INFO: Inference done 17800/26446. 0.2676 s / img. ETA=0:38:51
[07/02 17:19:51] detectron2 INFO: Inference done 17818/26446. 0.2676 s / img. ETA=0:38:47
[07/02 17:19:56] detectron2 INFO: Inference done 17837/26446. 0.2676 s / img. ETA=0:38:42
[07/02 17:20:01] detectron2 INFO: Inference done 17856/26446. 0.2676 s / img. ETA=0:38:36
[07/02 17:20:06] detectron2 INFO: Inference done 17875/26446. 0.2676 s / img. ETA=0:38:31
[07/02 17:20:11] detectron2 INFO: Inference done 17894/26446. 0.2676 s / img. ETA=0:38:26
[07/02 17:20:17] detectron2 INFO: Inference done 17913/26446. 0.2676 s / img. ETA=0:38:21
[07/02 17:20:22] detectron2 INFO: Inference done 17930/26446. 0.2676 s / img. ETA=0:38:17
[07/02 17:20:27] detectron2 INFO: Inference done 17946/26446. 0.2677 s / img. ETA=0:38:13
[07/02 17:20:32] detectron2 INFO: Inference done 17964/26446. 0.2677 s / img. ETA=0:38:08
[07/02 17:20:37] detectron2 INFO: Inference done 17979/26446. 0.2677 s / img. ETA=0:38:05
[07/02 17:20:42] detectron2 INFO: Inference done 17995/26446. 0.2678 s / img. ETA=0:38:01
[07/02 17:20:47] detectron2 INFO: Inference done 18013/26446. 0.2678 s / img. ETA=0:37:56
[07/02 17:20:53] detectron2 INFO: Inference done 18032/26446. 0.2678 s / img. ETA=0:37:51
[07/02 17:20:58] detectron2 INFO: Inference done 18051/26446. 0.2678 s / img. ETA=0:37:46
[07/02 17:21:03] detectron2 INFO: Inference done 18070/26446. 0.2678 s / img. ETA=0:37:41
[07/02 17:21:08] detectron2 INFO: Inference done 18090/26446. 0.2678 s / img. ETA=0:37:35
[07/02 17:21:13] detectron2 INFO: Inference done 18109/26446. 0.2678 s / img. ETA=0:37:30
[07/02 17:21:18] detectron2 INFO: Inference done 18128/26446. 0.2678 s / img. ETA=0:37:25
[07/02 17:21:24] detectron2 INFO: Inference done 18147/26446. 0.2678 s / img. ETA=0:37:20
[07/02 17:21:29] detectron2 INFO: Inference done 18166/26446. 0.2678 s / img. ETA=0:37:15
[07/02 17:21:34] detectron2 INFO: Inference done 18185/26446. 0.2678 s / img. ETA=0:37:09
[07/02 17:21:39] detectron2 INFO: Inference done 18204/26446. 0.2678 s / img. ETA=0:37:04
[07/02 17:21:44] detectron2 INFO: Inference done 18222/26446. 0.2678 s / img. ETA=0:36:59
[07/02 17:21:49] detectron2 INFO: Inference done 18240/26446. 0.2678 s / img. ETA=0:36:55
[07/02 17:21:54] detectron2 INFO: Inference done 18259/26446. 0.2678 s / img. ETA=0:36:50
[07/02 17:21:59] detectron2 INFO: Inference done 18277/26446. 0.2678 s / img. ETA=0:36:45
[07/02 17:22:04] detectron2 INFO: Inference done 18296/26446. 0.2678 s / img. ETA=0:36:40
[07/02 17:22:09] detectron2 INFO: Inference done 18314/26446. 0.2678 s / img. ETA=0:36:35
[07/02 17:22:14] detectron2 INFO: Inference done 18332/26446. 0.2678 s / img. ETA=0:36:30
[07/02 17:22:19] detectron2 INFO: Inference done 18350/26446. 0.2678 s / img. ETA=0:36:25
[07/02 17:22:24] detectron2 INFO: Inference done 18369/26446. 0.2678 s / img. ETA=0:36:20
[07/02 17:22:30] detectron2 INFO: Inference done 18388/26446. 0.2678 s / img. ETA=0:36:15
[07/02 17:22:35] detectron2 INFO: Inference done 18407/26446. 0.2678 s / img. ETA=0:36:10
[07/02 17:22:40] detectron2 INFO: Inference done 18426/26446. 0.2678 s / img. ETA=0:36:05
[07/02 17:22:45] detectron2 INFO: Inference done 18446/26446. 0.2678 s / img. ETA=0:35:59
[07/02 17:22:50] detectron2 INFO: Inference done 18465/26446. 0.2678 s / img. ETA=0:35:54
[07/02 17:22:55] detectron2 INFO: Inference done 18484/26446. 0.2678 s / img. ETA=0:35:49
[07/02 17:23:00] detectron2 INFO: Inference done 18503/26446. 0.2678 s / img. ETA=0:35:44
[07/02 17:23:05] detectron2 INFO: Inference done 18522/26446. 0.2678 s / img. ETA=0:35:39
[07/02 17:23:10] detectron2 INFO: Inference done 18541/26446. 0.2678 s / img. ETA=0:35:34
[07/02 17:23:15] detectron2 INFO: Inference done 18560/26446. 0.2678 s / img. ETA=0:35:28
[07/02 17:23:20] detectron2 INFO: Inference done 18579/26446. 0.2678 s / img. ETA=0:35:23
[07/02 17:23:26] detectron2 INFO: Inference done 18599/26446. 0.2678 s / img. ETA=0:35:18
[07/02 17:23:31] detectron2 INFO: Inference done 18619/26446. 0.2678 s / img. ETA=0:35:12
[07/02 17:23:36] detectron2 INFO: Inference done 18638/26446. 0.2678 s / img. ETA=0:35:07
[07/02 17:23:41] detectron2 INFO: Inference done 18657/26446. 0.2678 s / img. ETA=0:35:02
[07/02 17:23:46] detectron2 INFO: Inference done 18676/26446. 0.2678 s / img. ETA=0:34:57
[07/02 17:23:51] detectron2 INFO: Inference done 18695/26446. 0.2678 s / img. ETA=0:34:52
[07/02 17:23:56] detectron2 INFO: Inference done 18714/26446. 0.2678 s / img. ETA=0:34:47
[07/02 17:24:01] detectron2 INFO: Inference done 18733/26446. 0.2678 s / img. ETA=0:34:41
[07/02 17:24:06] detectron2 INFO: Inference done 18752/26446. 0.2678 s / img. ETA=0:34:36
[07/02 17:24:12] detectron2 INFO: Inference done 18771/26446. 0.2678 s / img. ETA=0:34:31
[07/02 17:24:17] detectron2 INFO: Inference done 18791/26446. 0.2677 s / img. ETA=0:34:26
[07/02 17:24:22] detectron2 INFO: Inference done 18810/26446. 0.2677 s / img. ETA=0:34:20
[07/02 17:24:27] detectron2 INFO: Inference done 18829/26446. 0.2677 s / img. ETA=0:34:15
[07/02 17:24:32] detectron2 INFO: Inference done 18849/26446. 0.2677 s / img. ETA=0:34:10
[07/02 17:24:37] detectron2 INFO: Inference done 18868/26446. 0.2677 s / img. ETA=0:34:05
[07/02 17:24:42] detectron2 INFO: Inference done 18887/26446. 0.2677 s / img. ETA=0:34:00
[07/02 17:24:47] detectron2 INFO: Inference done 18906/26446. 0.2677 s / img. ETA=0:33:54
[07/02 17:24:52] detectron2 INFO: Inference done 18925/26446. 0.2677 s / img. ETA=0:33:49
[07/02 17:24:58] detectron2 INFO: Inference done 18944/26446. 0.2677 s / img. ETA=0:33:44
[07/02 17:25:03] detectron2 INFO: Inference done 18963/26446. 0.2677 s / img. ETA=0:33:39
[07/02 17:25:08] detectron2 INFO: Inference done 18982/26446. 0.2677 s / img. ETA=0:33:34
[07/02 17:25:13] detectron2 INFO: Inference done 19001/26446. 0.2677 s / img. ETA=0:33:29
[07/02 17:25:18] detectron2 INFO: Inference done 19020/26446. 0.2677 s / img. ETA=0:33:24
[07/02 17:25:23] detectron2 INFO: Inference done 19039/26446. 0.2677 s / img. ETA=0:33:18
[07/02 17:25:28] detectron2 INFO: Inference done 19058/26446. 0.2677 s / img. ETA=0:33:13
[07/02 17:25:33] detectron2 INFO: Inference done 19077/26446. 0.2677 s / img. ETA=0:33:08
[07/02 17:25:38] detectron2 INFO: Inference done 19096/26446. 0.2677 s / img. ETA=0:33:03
[07/02 17:25:43] detectron2 INFO: Inference done 19115/26446. 0.2677 s / img. ETA=0:32:58
[07/02 17:25:49] detectron2 INFO: Inference done 19134/26446. 0.2677 s / img. ETA=0:32:53
[07/02 17:25:54] detectron2 INFO: Inference done 19153/26446. 0.2677 s / img. ETA=0:32:48
[07/02 17:25:59] detectron2 INFO: Inference done 19172/26446. 0.2677 s / img. ETA=0:32:42
[07/02 17:26:04] detectron2 INFO: Inference done 19191/26446. 0.2677 s / img. ETA=0:32:37
[07/02 17:26:09] detectron2 INFO: Inference done 19210/26446. 0.2677 s / img. ETA=0:32:32
[07/02 17:26:14] detectron2 INFO: Inference done 19229/26446. 0.2677 s / img. ETA=0:32:27
[07/02 17:26:19] detectron2 INFO: Inference done 19248/26446. 0.2677 s / img. ETA=0:32:22
[07/02 17:26:24] detectron2 INFO: Inference done 19267/26446. 0.2677 s / img. ETA=0:32:17
[07/02 17:26:29] detectron2 INFO: Inference done 19286/26446. 0.2677 s / img. ETA=0:32:12
[07/02 17:26:34] detectron2 INFO: Inference done 19305/26446. 0.2677 s / img. ETA=0:32:06
[07/02 17:26:39] detectron2 INFO: Inference done 19325/26446. 0.2677 s / img. ETA=0:32:01
[07/02 17:26:44] detectron2 INFO: Inference done 19344/26446. 0.2677 s / img. ETA=0:31:56
[07/02 17:26:50] detectron2 INFO: Inference done 19364/26446. 0.2677 s / img. ETA=0:31:50
[07/02 17:26:55] detectron2 INFO: Inference done 19384/26446. 0.2676 s / img. ETA=0:31:45
[07/02 17:27:00] detectron2 INFO: Inference done 19403/26446. 0.2676 s / img. ETA=0:31:40
[07/02 17:27:05] detectron2 INFO: Inference done 19422/26446. 0.2676 s / img. ETA=0:31:35
[07/02 17:27:10] detectron2 INFO: Inference done 19441/26446. 0.2676 s / img. ETA=0:31:29
[07/02 17:27:15] detectron2 INFO: Inference done 19460/26446. 0.2676 s / img. ETA=0:31:24
[07/02 17:27:20] detectron2 INFO: Inference done 19480/26446. 0.2676 s / img. ETA=0:31:19
[07/02 17:27:26] detectron2 INFO: Inference done 19500/26446. 0.2676 s / img. ETA=0:31:13
[07/02 17:27:31] detectron2 INFO: Inference done 19520/26446. 0.2676 s / img. ETA=0:31:08
[07/02 17:27:36] detectron2 INFO: Inference done 19539/26446. 0.2676 s / img. ETA=0:31:03
[07/02 17:27:41] detectron2 INFO: Inference done 19559/26446. 0.2676 s / img. ETA=0:30:57
[07/02 17:27:46] detectron2 INFO: Inference done 19578/26446. 0.2676 s / img. ETA=0:30:52
[07/02 17:27:51] detectron2 INFO: Inference done 19597/26446. 0.2676 s / img. ETA=0:30:47
[07/02 17:27:56] detectron2 INFO: Inference done 19616/26446. 0.2676 s / img. ETA=0:30:42
[07/02 17:28:01] detectron2 INFO: Inference done 19636/26446. 0.2676 s / img. ETA=0:30:36
[07/02 17:28:06] detectron2 INFO: Inference done 19655/26446. 0.2676 s / img. ETA=0:30:31
[07/02 17:28:12] detectron2 INFO: Inference done 19675/26446. 0.2676 s / img. ETA=0:30:26
[07/02 17:28:17] detectron2 INFO: Inference done 19694/26446. 0.2676 s / img. ETA=0:30:21
[07/02 17:28:22] detectron2 INFO: Inference done 19713/26446. 0.2676 s / img. ETA=0:30:16
[07/02 17:28:27] detectron2 INFO: Inference done 19732/26446. 0.2675 s / img. ETA=0:30:10
[07/02 17:28:32] detectron2 INFO: Inference done 19752/26446. 0.2675 s / img. ETA=0:30:05
[07/02 17:28:37] detectron2 INFO: Inference done 19771/26446. 0.2675 s / img. ETA=0:30:00
[07/02 17:28:42] detectron2 INFO: Inference done 19790/26446. 0.2675 s / img. ETA=0:29:55
[07/02 17:28:48] detectron2 INFO: Inference done 19810/26446. 0.2675 s / img. ETA=0:29:49
[07/02 17:28:53] detectron2 INFO: Inference done 19829/26446. 0.2675 s / img. ETA=0:29:44
[07/02 17:28:58] detectron2 INFO: Inference done 19848/26446. 0.2675 s / img. ETA=0:29:39
[07/02 17:29:03] detectron2 INFO: Inference done 19867/26446. 0.2675 s / img. ETA=0:29:34
[07/02 17:29:08] detectron2 INFO: Inference done 19886/26446. 0.2675 s / img. ETA=0:29:29
[07/02 17:29:13] detectron2 INFO: Inference done 19906/26446. 0.2675 s / img. ETA=0:29:23
[07/02 17:29:18] detectron2 INFO: Inference done 19926/26446. 0.2675 s / img. ETA=0:29:18
[07/02 17:29:23] detectron2 INFO: Inference done 19946/26446. 0.2675 s / img. ETA=0:29:12
[07/02 17:29:28] detectron2 INFO: Inference done 19965/26446. 0.2675 s / img. ETA=0:29:07
[07/02 17:29:34] detectron2 INFO: Inference done 19984/26446. 0.2675 s / img. ETA=0:29:02
[07/02 17:29:39] detectron2 INFO: Inference done 20003/26446. 0.2675 s / img. ETA=0:28:57
[07/02 17:29:44] detectron2 INFO: Inference done 20022/26446. 0.2675 s / img. ETA=0:28:52
[07/02 17:29:49] detectron2 INFO: Inference done 20041/26446. 0.2675 s / img. ETA=0:28:47
[07/02 17:29:54] detectron2 INFO: Inference done 20060/26446. 0.2675 s / img. ETA=0:28:41
[07/02 17:29:59] detectron2 INFO: Inference done 20080/26446. 0.2675 s / img. ETA=0:28:36
[07/02 17:30:04] detectron2 INFO: Inference done 20099/26446. 0.2675 s / img. ETA=0:28:31
[07/02 17:30:09] detectron2 INFO: Inference done 20118/26446. 0.2675 s / img. ETA=0:28:26
[07/02 17:30:14] detectron2 INFO: Inference done 20137/26446. 0.2675 s / img. ETA=0:28:21
[07/02 17:30:19] detectron2 INFO: Inference done 20156/26446. 0.2675 s / img. ETA=0:28:15
[07/02 17:30:24] detectron2 INFO: Inference done 20175/26446. 0.2675 s / img. ETA=0:28:10
[07/02 17:30:30] detectron2 INFO: Inference done 20195/26446. 0.2674 s / img. ETA=0:28:05
[07/02 17:30:35] detectron2 INFO: Inference done 20214/26446. 0.2674 s / img. ETA=0:28:00
[07/02 17:30:40] detectron2 INFO: Inference done 20234/26446. 0.2674 s / img. ETA=0:27:54
[07/02 17:30:45] detectron2 INFO: Inference done 20253/26446. 0.2674 s / img. ETA=0:27:49
[07/02 17:30:50] detectron2 INFO: Inference done 20272/26446. 0.2674 s / img. ETA=0:27:44
[07/02 17:30:55] detectron2 INFO: Inference done 20291/26446. 0.2674 s / img. ETA=0:27:39
[07/02 17:31:00] detectron2 INFO: Inference done 20310/26446. 0.2674 s / img. ETA=0:27:34
[07/02 17:31:06] detectron2 INFO: Inference done 20330/26446. 0.2674 s / img. ETA=0:27:28
[07/02 17:31:11] detectron2 INFO: Inference done 20349/26446. 0.2674 s / img. ETA=0:27:23
[07/02 17:31:16] detectron2 INFO: Inference done 20368/26446. 0.2674 s / img. ETA=0:27:18
[07/02 17:31:21] detectron2 INFO: Inference done 20387/26446. 0.2674 s / img. ETA=0:27:13
[07/02 17:31:26] detectron2 INFO: Inference done 20406/26446. 0.2674 s / img. ETA=0:27:08
[07/02 17:31:31] detectron2 INFO: Inference done 20426/26446. 0.2674 s / img. ETA=0:27:02
[07/02 17:31:36] detectron2 INFO: Inference done 20445/26446. 0.2674 s / img. ETA=0:26:57
[07/02 17:31:41] detectron2 INFO: Inference done 20464/26446. 0.2674 s / img. ETA=0:26:52
[07/02 17:31:46] detectron2 INFO: Inference done 20483/26446. 0.2674 s / img. ETA=0:26:47
[07/02 17:31:52] detectron2 INFO: Inference done 20502/26446. 0.2674 s / img. ETA=0:26:42
[07/02 17:31:57] detectron2 INFO: Inference done 20521/26446. 0.2674 s / img. ETA=0:26:37
[07/02 17:32:02] detectron2 INFO: Inference done 20540/26446. 0.2674 s / img. ETA=0:26:31
[07/02 17:32:07] detectron2 INFO: Inference done 20559/26446. 0.2674 s / img. ETA=0:26:26
[07/02 17:32:12] detectron2 INFO: Inference done 20579/26446. 0.2674 s / img. ETA=0:26:21
[07/02 17:32:17] detectron2 INFO: Inference done 20598/26446. 0.2674 s / img. ETA=0:26:16
[07/02 17:32:22] detectron2 INFO: Inference done 20617/26446. 0.2674 s / img. ETA=0:26:11
[07/02 17:32:27] detectron2 INFO: Inference done 20637/26446. 0.2674 s / img. ETA=0:26:05
[07/02 17:32:32] detectron2 INFO: Inference done 20657/26446. 0.2673 s / img. ETA=0:26:00
[07/02 17:32:37] detectron2 INFO: Inference done 20676/26446. 0.2673 s / img. ETA=0:25:55
[07/02 17:32:43] detectron2 INFO: Inference done 20696/26446. 0.2673 s / img. ETA=0:25:49
[07/02 17:32:48] detectron2 INFO: Inference done 20715/26446. 0.2673 s / img. ETA=0:25:44
[07/02 17:32:53] detectron2 INFO: Inference done 20734/26446. 0.2673 s / img. ETA=0:25:39
[07/02 17:32:58] detectron2 INFO: Inference done 20753/26446. 0.2673 s / img. ETA=0:25:34
[07/02 17:33:03] detectron2 INFO: Inference done 20772/26446. 0.2673 s / img. ETA=0:25:29
[07/02 17:33:08] detectron2 INFO: Inference done 20792/26446. 0.2673 s / img. ETA=0:25:23
[07/02 17:33:13] detectron2 INFO: Inference done 20811/26446. 0.2673 s / img. ETA=0:25:18
[07/02 17:33:18] detectron2 INFO: Inference done 20830/26446. 0.2673 s / img. ETA=0:25:13
[07/02 17:33:24] detectron2 INFO: Inference done 20849/26446. 0.2673 s / img. ETA=0:25:08
[07/02 17:33:29] detectron2 INFO: Inference done 20868/26446. 0.2673 s / img. ETA=0:25:03
[07/02 17:33:34] detectron2 INFO: Inference done 20887/26446. 0.2673 s / img. ETA=0:24:58
[07/02 17:33:39] detectron2 INFO: Inference done 20906/26446. 0.2673 s / img. ETA=0:24:52
[07/02 17:33:44] detectron2 INFO: Inference done 20925/26446. 0.2673 s / img. ETA=0:24:47
[07/02 17:33:49] detectron2 INFO: Inference done 20944/26446. 0.2673 s / img. ETA=0:24:42
[07/02 17:33:54] detectron2 INFO: Inference done 20963/26446. 0.2673 s / img. ETA=0:24:37
[07/02 17:33:59] detectron2 INFO: Inference done 20982/26446. 0.2673 s / img. ETA=0:24:32
[07/02 17:34:04] detectron2 INFO: Inference done 21001/26446. 0.2673 s / img. ETA=0:24:27
[07/02 17:34:09] detectron2 INFO: Inference done 21020/26446. 0.2673 s / img. ETA=0:24:22
[07/02 17:34:14] detectron2 INFO: Inference done 21039/26446. 0.2673 s / img. ETA=0:24:17
[07/02 17:34:19] detectron2 INFO: Inference done 21059/26446. 0.2673 s / img. ETA=0:24:11
[07/02 17:34:25] detectron2 INFO: Inference done 21079/26446. 0.2673 s / img. ETA=0:24:06
[07/02 17:34:30] detectron2 INFO: Inference done 21098/26446. 0.2673 s / img. ETA=0:24:01
[07/02 17:34:35] detectron2 INFO: Inference done 21117/26446. 0.2673 s / img. ETA=0:23:55
[07/02 17:34:40] detectron2 INFO: Inference done 21136/26446. 0.2673 s / img. ETA=0:23:50
[07/02 17:34:45] detectron2 INFO: Inference done 21155/26446. 0.2673 s / img. ETA=0:23:45
[07/02 17:34:50] detectron2 INFO: Inference done 21174/26446. 0.2673 s / img. ETA=0:23:40
[07/02 17:34:55] detectron2 INFO: Inference done 21193/26446. 0.2673 s / img. ETA=0:23:35
[07/02 17:35:00] detectron2 INFO: Inference done 21212/26446. 0.2673 s / img. ETA=0:23:30
[07/02 17:35:05] detectron2 INFO: Inference done 21232/26446. 0.2673 s / img. ETA=0:23:24
[07/02 17:35:11] detectron2 INFO: Inference done 21252/26446. 0.2672 s / img. ETA=0:23:19
[07/02 17:35:16] detectron2 INFO: Inference done 21271/26446. 0.2672 s / img. ETA=0:23:14
[07/02 17:35:21] detectron2 INFO: Inference done 21290/26446. 0.2672 s / img. ETA=0:23:09
[07/02 17:35:26] detectron2 INFO: Inference done 21310/26446. 0.2672 s / img. ETA=0:23:03
[07/02 17:35:31] detectron2 INFO: Inference done 21329/26446. 0.2672 s / img. ETA=0:22:58
[07/02 17:35:36] detectron2 INFO: Inference done 21348/26446. 0.2672 s / img. ETA=0:22:53
[07/02 17:35:41] detectron2 INFO: Inference done 21367/26446. 0.2672 s / img. ETA=0:22:48
[07/02 17:35:46] detectron2 INFO: Inference done 21386/26446. 0.2672 s / img. ETA=0:22:43
[07/02 17:35:52] detectron2 INFO: Inference done 21406/26446. 0.2672 s / img. ETA=0:22:37
[07/02 17:35:57] detectron2 INFO: Inference done 21425/26446. 0.2672 s / img. ETA=0:22:32
[07/02 17:36:02] detectron2 INFO: Inference done 21444/26446. 0.2672 s / img. ETA=0:22:27
[07/02 17:36:07] detectron2 INFO: Inference done 21463/26446. 0.2672 s / img. ETA=0:22:22
[07/02 17:36:12] detectron2 INFO: Inference done 21483/26446. 0.2672 s / img. ETA=0:22:16
[07/02 17:36:17] detectron2 INFO: Inference done 21502/26446. 0.2672 s / img. ETA=0:22:11
[07/02 17:36:22] detectron2 INFO: Inference done 21521/26446. 0.2672 s / img. ETA=0:22:06
[07/02 17:36:27] detectron2 INFO: Inference done 21540/26446. 0.2672 s / img. ETA=0:22:01
[07/02 17:36:32] detectron2 INFO: Inference done 21559/26446. 0.2672 s / img. ETA=0:21:56
[07/02 17:36:38] detectron2 INFO: Inference done 21578/26446. 0.2672 s / img. ETA=0:21:51
[07/02 17:36:43] detectron2 INFO: Inference done 21597/26446. 0.2672 s / img. ETA=0:21:46
[07/02 17:36:48] detectron2 INFO: Inference done 21616/26446. 0.2672 s / img. ETA=0:21:41
[07/02 17:36:53] detectron2 INFO: Inference done 21635/26446. 0.2672 s / img. ETA=0:21:35
[07/02 17:36:58] detectron2 INFO: Inference done 21654/26446. 0.2672 s / img. ETA=0:21:30
[07/02 17:37:03] detectron2 INFO: Inference done 21673/26446. 0.2672 s / img. ETA=0:21:25
[07/02 17:37:08] detectron2 INFO: Inference done 21692/26446. 0.2672 s / img. ETA=0:21:20
[07/02 17:37:13] detectron2 INFO: Inference done 21712/26446. 0.2672 s / img. ETA=0:21:15
[07/02 17:37:18] detectron2 INFO: Inference done 21731/26446. 0.2672 s / img. ETA=0:21:10
[07/02 17:37:24] detectron2 INFO: Inference done 21751/26446. 0.2672 s / img. ETA=0:21:04
[07/02 17:37:29] detectron2 INFO: Inference done 21770/26446. 0.2672 s / img. ETA=0:20:59
[07/02 17:37:34] detectron2 INFO: Inference done 21789/26446. 0.2672 s / img. ETA=0:20:54
[07/02 17:37:39] detectron2 INFO: Inference done 21808/26446. 0.2672 s / img. ETA=0:20:49
[07/02 17:37:44] detectron2 INFO: Inference done 21827/26446. 0.2672 s / img. ETA=0:20:44
[07/02 17:37:49] detectron2 INFO: Inference done 21846/26446. 0.2672 s / img. ETA=0:20:38
[07/02 17:37:54] detectron2 INFO: Inference done 21865/26446. 0.2672 s / img. ETA=0:20:33
[07/02 17:37:59] detectron2 INFO: Inference done 21885/26446. 0.2672 s / img. ETA=0:20:28
[07/02 17:38:04] detectron2 INFO: Inference done 21905/26446. 0.2671 s / img. ETA=0:20:22
[07/02 17:38:10] detectron2 INFO: Inference done 21924/26446. 0.2671 s / img. ETA=0:20:17
[07/02 17:38:15] detectron2 INFO: Inference done 21944/26446. 0.2671 s / img. ETA=0:20:12
[07/02 17:38:20] detectron2 INFO: Inference done 21963/26446. 0.2671 s / img. ETA=0:20:07
[07/02 17:38:25] detectron2 INFO: Inference done 21983/26446. 0.2671 s / img. ETA=0:20:01
[07/02 17:38:30] detectron2 INFO: Inference done 22002/26446. 0.2671 s / img. ETA=0:19:56
[07/02 17:38:35] detectron2 INFO: Inference done 22021/26446. 0.2671 s / img. ETA=0:19:51
[07/02 17:38:40] detectron2 INFO: Inference done 22041/26446. 0.2671 s / img. ETA=0:19:46
[07/02 17:38:45] detectron2 INFO: Inference done 22060/26446. 0.2671 s / img. ETA=0:19:41
[07/02 17:38:51] detectron2 INFO: Inference done 22079/26446. 0.2671 s / img. ETA=0:19:35
[07/02 17:38:56] detectron2 INFO: Inference done 22099/26446. 0.2671 s / img. ETA=0:19:30
[07/02 17:39:01] detectron2 INFO: Inference done 22118/26446. 0.2671 s / img. ETA=0:19:25
[07/02 17:39:06] detectron2 INFO: Inference done 22137/26446. 0.2671 s / img. ETA=0:19:20
[07/02 17:39:11] detectron2 INFO: Inference done 22156/26446. 0.2671 s / img. ETA=0:19:15
[07/02 17:39:16] detectron2 INFO: Inference done 22175/26446. 0.2671 s / img. ETA=0:19:10
[07/02 17:39:21] detectron2 INFO: Inference done 22194/26446. 0.2671 s / img. ETA=0:19:04
[07/02 17:39:26] detectron2 INFO: Inference done 22213/26446. 0.2671 s / img. ETA=0:18:59
[07/02 17:39:31] detectron2 INFO: Inference done 22232/26446. 0.2671 s / img. ETA=0:18:54
[07/02 17:39:36] detectron2 INFO: Inference done 22251/26446. 0.2671 s / img. ETA=0:18:49
[07/02 17:39:41] detectron2 INFO: Inference done 22270/26446. 0.2671 s / img. ETA=0:18:44
[07/02 17:39:46] detectron2 INFO: Inference done 22289/26446. 0.2671 s / img. ETA=0:18:39
[07/02 17:39:51] detectron2 INFO: Inference done 22308/26446. 0.2671 s / img. ETA=0:18:34
[07/02 17:39:56] detectron2 INFO: Inference done 22327/26446. 0.2671 s / img. ETA=0:18:29
[07/02 17:40:02] detectron2 INFO: Inference done 22346/26446. 0.2671 s / img. ETA=0:18:23
[07/02 17:40:07] detectron2 INFO: Inference done 22365/26446. 0.2671 s / img. ETA=0:18:18
[07/02 17:40:12] detectron2 INFO: Inference done 22384/26446. 0.2671 s / img. ETA=0:18:13
[07/02 17:40:17] detectron2 INFO: Inference done 22403/26446. 0.2671 s / img. ETA=0:18:08
[07/02 17:40:22] detectron2 INFO: Inference done 22422/26446. 0.2671 s / img. ETA=0:18:03
[07/02 17:40:27] detectron2 INFO: Inference done 22441/26446. 0.2671 s / img. ETA=0:17:58
[07/02 17:40:32] detectron2 INFO: Inference done 22460/26446. 0.2671 s / img. ETA=0:17:53
[07/02 17:40:37] detectron2 INFO: Inference done 22479/26446. 0.2671 s / img. ETA=0:17:48
[07/02 17:40:42] detectron2 INFO: Inference done 22498/26446. 0.2671 s / img. ETA=0:17:42
[07/02 17:40:47] detectron2 INFO: Inference done 22517/26446. 0.2671 s / img. ETA=0:17:37
[07/02 17:40:53] detectron2 INFO: Inference done 22537/26446. 0.2670 s / img. ETA=0:17:32
[07/02 17:40:58] detectron2 INFO: Inference done 22557/26446. 0.2670 s / img. ETA=0:17:27
[07/02 17:41:03] detectron2 INFO: Inference done 22577/26446. 0.2670 s / img. ETA=0:17:21
[07/02 17:41:08] detectron2 INFO: Inference done 22597/26446. 0.2670 s / img. ETA=0:17:16
[07/02 17:41:13] detectron2 INFO: Inference done 22616/26446. 0.2670 s / img. ETA=0:17:11
[07/02 17:41:18] detectron2 INFO: Inference done 22635/26446. 0.2670 s / img. ETA=0:17:05
[07/02 17:41:23] detectron2 INFO: Inference done 22654/26446. 0.2670 s / img. ETA=0:17:00
[07/02 17:41:29] detectron2 INFO: Inference done 22674/26446. 0.2670 s / img. ETA=0:16:55
[07/02 17:41:34] detectron2 INFO: Inference done 22694/26446. 0.2670 s / img. ETA=0:16:49
[07/02 17:41:39] detectron2 INFO: Inference done 22713/26446. 0.2670 s / img. ETA=0:16:44
[07/02 17:41:44] detectron2 INFO: Inference done 22730/26446. 0.2670 s / img. ETA=0:16:40
[07/02 17:41:49] detectron2 INFO: Inference done 22750/26446. 0.2670 s / img. ETA=0:16:34
[07/02 17:41:54] detectron2 INFO: Inference done 22769/26446. 0.2670 s / img. ETA=0:16:29
[07/02 17:42:00] detectron2 INFO: Inference done 22789/26446. 0.2670 s / img. ETA=0:16:24
[07/02 17:42:05] detectron2 INFO: Inference done 22808/26446. 0.2670 s / img. ETA=0:16:19
[07/02 17:42:10] detectron2 INFO: Inference done 22827/26446. 0.2670 s / img. ETA=0:16:14
[07/02 17:42:15] detectron2 INFO: Inference done 22846/26446. 0.2670 s / img. ETA=0:16:09
[07/02 17:42:20] detectron2 INFO: Inference done 22865/26446. 0.2670 s / img. ETA=0:16:03
[07/02 17:42:25] detectron2 INFO: Inference done 22885/26446. 0.2670 s / img. ETA=0:15:58
[07/02 17:42:30] detectron2 INFO: Inference done 22904/26446. 0.2670 s / img. ETA=0:15:53
[07/02 17:42:35] detectron2 INFO: Inference done 22924/26446. 0.2670 s / img. ETA=0:15:48
[07/02 17:42:40] detectron2 INFO: Inference done 22943/26446. 0.2670 s / img. ETA=0:15:42
[07/02 17:42:46] detectron2 INFO: Inference done 22962/26446. 0.2670 s / img. ETA=0:15:37
[07/02 17:42:51] detectron2 INFO: Inference done 22982/26446. 0.2670 s / img. ETA=0:15:32
[07/02 17:42:56] detectron2 INFO: Inference done 23001/26446. 0.2670 s / img. ETA=0:15:27
[07/02 17:43:01] detectron2 INFO: Inference done 23021/26446. 0.2670 s / img. ETA=0:15:21
[07/02 17:43:06] detectron2 INFO: Inference done 23040/26446. 0.2670 s / img. ETA=0:15:16
[07/02 17:43:11] detectron2 INFO: Inference done 23057/26446. 0.2670 s / img. ETA=0:15:12
[07/02 17:43:16] detectron2 INFO: Inference done 23076/26446. 0.2670 s / img. ETA=0:15:07
[07/02 17:43:21] detectron2 INFO: Inference done 23095/26446. 0.2670 s / img. ETA=0:15:01
[07/02 17:43:26] detectron2 INFO: Inference done 23114/26446. 0.2670 s / img. ETA=0:14:56
[07/02 17:43:32] detectron2 INFO: Inference done 23133/26446. 0.2670 s / img. ETA=0:14:51
[07/02 17:43:37] detectron2 INFO: Inference done 23152/26446. 0.2670 s / img. ETA=0:14:46
[07/02 17:43:42] detectron2 INFO: Inference done 23171/26446. 0.2670 s / img. ETA=0:14:41
[07/02 17:43:47] detectron2 INFO: Inference done 23190/26446. 0.2670 s / img. ETA=0:14:36
[07/02 17:43:52] detectron2 INFO: Inference done 23209/26446. 0.2670 s / img. ETA=0:14:31
[07/02 17:43:57] detectron2 INFO: Inference done 23228/26446. 0.2670 s / img. ETA=0:14:26
[07/02 17:44:02] detectron2 INFO: Inference done 23247/26446. 0.2670 s / img. ETA=0:14:21
[07/02 17:44:07] detectron2 INFO: Inference done 23266/26446. 0.2670 s / img. ETA=0:14:15
[07/02 17:44:12] detectron2 INFO: Inference done 23285/26446. 0.2670 s / img. ETA=0:14:10
[07/02 17:44:17] detectron2 INFO: Inference done 23304/26446. 0.2670 s / img. ETA=0:14:05
[07/02 17:44:23] detectron2 INFO: Inference done 23323/26446. 0.2670 s / img. ETA=0:14:00
[07/02 17:44:28] detectron2 INFO: Inference done 23343/26446. 0.2670 s / img. ETA=0:13:55
[07/02 17:44:33] detectron2 INFO: Inference done 23362/26446. 0.2670 s / img. ETA=0:13:50
[07/02 17:44:38] detectron2 INFO: Inference done 23381/26446. 0.2670 s / img. ETA=0:13:44
[07/02 17:44:43] detectron2 INFO: Inference done 23400/26446. 0.2670 s / img. ETA=0:13:39
[07/02 17:44:48] detectron2 INFO: Inference done 23419/26446. 0.2670 s / img. ETA=0:13:34
[07/02 17:44:53] detectron2 INFO: Inference done 23439/26446. 0.2670 s / img. ETA=0:13:29
[07/02 17:44:58] detectron2 INFO: Inference done 23458/26446. 0.2670 s / img. ETA=0:13:24
[07/02 17:45:03] detectron2 INFO: Inference done 23477/26446. 0.2669 s / img. ETA=0:13:19
[07/02 17:45:09] detectron2 INFO: Inference done 23497/26446. 0.2669 s / img. ETA=0:13:13
[07/02 17:45:14] detectron2 INFO: Inference done 23516/26446. 0.2669 s / img. ETA=0:13:08
[07/02 17:45:19] detectron2 INFO: Inference done 23536/26446. 0.2669 s / img. ETA=0:13:03
[07/02 17:45:24] detectron2 INFO: Inference done 23555/26446. 0.2669 s / img. ETA=0:12:58
[07/02 17:45:29] detectron2 INFO: Inference done 23574/26446. 0.2669 s / img. ETA=0:12:52
[07/02 17:45:34] detectron2 INFO: Inference done 23593/26446. 0.2669 s / img. ETA=0:12:47
[07/02 17:45:39] detectron2 INFO: Inference done 23612/26446. 0.2669 s / img. ETA=0:12:42
[07/02 17:45:44] detectron2 INFO: Inference done 23631/26446. 0.2669 s / img. ETA=0:12:37
[07/02 17:45:49] detectron2 INFO: Inference done 23650/26446. 0.2669 s / img. ETA=0:12:32
[07/02 17:45:54] detectron2 INFO: Inference done 23669/26446. 0.2669 s / img. ETA=0:12:27
[07/02 17:45:59] detectron2 INFO: Inference done 23688/26446. 0.2669 s / img. ETA=0:12:22
[07/02 17:46:04] detectron2 INFO: Inference done 23707/26446. 0.2669 s / img. ETA=0:12:17
[07/02 17:46:10] detectron2 INFO: Inference done 23726/26446. 0.2669 s / img. ETA=0:12:11
[07/02 17:46:15] detectron2 INFO: Inference done 23745/26446. 0.2669 s / img. ETA=0:12:06
[07/02 17:46:20] detectron2 INFO: Inference done 23764/26446. 0.2669 s / img. ETA=0:12:01
[07/02 17:46:25] detectron2 INFO: Inference done 23783/26446. 0.2669 s / img. ETA=0:11:56
[07/02 17:46:30] detectron2 INFO: Inference done 23802/26446. 0.2669 s / img. ETA=0:11:51
[07/02 17:46:35] detectron2 INFO: Inference done 23821/26446. 0.2669 s / img. ETA=0:11:46
[07/02 17:46:40] detectron2 INFO: Inference done 23840/26446. 0.2669 s / img. ETA=0:11:41
[07/02 17:46:45] detectron2 INFO: Inference done 23859/26446. 0.2669 s / img. ETA=0:11:36
[07/02 17:46:50] detectron2 INFO: Inference done 23878/26446. 0.2669 s / img. ETA=0:11:31
[07/02 17:46:55] detectron2 INFO: Inference done 23897/26446. 0.2669 s / img. ETA=0:11:25
[07/02 17:47:01] detectron2 INFO: Inference done 23917/26446. 0.2669 s / img. ETA=0:11:20
[07/02 17:47:06] detectron2 INFO: Inference done 23936/26446. 0.2669 s / img. ETA=0:11:15
[07/02 17:47:11] detectron2 INFO: Inference done 23955/26446. 0.2669 s / img. ETA=0:11:10
[07/02 17:47:16] detectron2 INFO: Inference done 23974/26446. 0.2669 s / img. ETA=0:11:05
[07/02 17:47:21] detectron2 INFO: Inference done 23993/26446. 0.2669 s / img. ETA=0:11:00
[07/02 17:47:26] detectron2 INFO: Inference done 24012/26446. 0.2669 s / img. ETA=0:10:54
[07/02 17:47:31] detectron2 INFO: Inference done 24031/26446. 0.2669 s / img. ETA=0:10:49
[07/02 17:47:36] detectron2 INFO: Inference done 24050/26446. 0.2669 s / img. ETA=0:10:44
[07/02 17:47:41] detectron2 INFO: Inference done 24069/26446. 0.2669 s / img. ETA=0:10:39
[07/02 17:47:46] detectron2 INFO: Inference done 24088/26446. 0.2669 s / img. ETA=0:10:34
[07/02 17:47:51] detectron2 INFO: Inference done 24107/26446. 0.2669 s / img. ETA=0:10:29
[07/02 17:47:56] detectron2 INFO: Inference done 24126/26446. 0.2669 s / img. ETA=0:10:24
[07/02 17:48:02] detectron2 INFO: Inference done 24145/26446. 0.2669 s / img. ETA=0:10:19
[07/02 17:48:07] detectron2 INFO: Inference done 24164/26446. 0.2669 s / img. ETA=0:10:14
[07/02 17:48:12] detectron2 INFO: Inference done 24183/26446. 0.2669 s / img. ETA=0:10:08
[07/02 17:48:17] detectron2 INFO: Inference done 24202/26446. 0.2669 s / img. ETA=0:10:03
[07/02 17:48:22] detectron2 INFO: Inference done 24221/26446. 0.2669 s / img. ETA=0:09:58
[07/02 17:48:27] detectron2 INFO: Inference done 24240/26446. 0.2669 s / img. ETA=0:09:53
[07/02 17:48:32] detectron2 INFO: Inference done 24259/26446. 0.2669 s / img. ETA=0:09:48
[07/02 17:48:37] detectron2 INFO: Inference done 24278/26446. 0.2669 s / img. ETA=0:09:43
[07/02 17:48:42] detectron2 INFO: Inference done 24298/26446. 0.2669 s / img. ETA=0:09:37
[07/02 17:48:47] detectron2 INFO: Inference done 24317/26446. 0.2669 s / img. ETA=0:09:32
[07/02 17:48:52] detectron2 INFO: Inference done 24336/26446. 0.2669 s / img. ETA=0:09:27
[07/02 17:48:57] detectron2 INFO: Inference done 24355/26446. 0.2669 s / img. ETA=0:09:22
[07/02 17:49:03] detectron2 INFO: Inference done 24375/26446. 0.2668 s / img. ETA=0:09:17
[07/02 17:49:08] detectron2 INFO: Inference done 24394/26446. 0.2668 s / img. ETA=0:09:12
[07/02 17:49:13] detectron2 INFO: Inference done 24413/26446. 0.2668 s / img. ETA=0:09:06
[07/02 17:49:18] detectron2 INFO: Inference done 24432/26446. 0.2668 s / img. ETA=0:09:01
[07/02 17:49:23] detectron2 INFO: Inference done 24451/26446. 0.2668 s / img. ETA=0:08:56
[07/02 17:49:28] detectron2 INFO: Inference done 24470/26446. 0.2669 s / img. ETA=0:08:51
[07/02 17:49:33] detectron2 INFO: Inference done 24489/26446. 0.2669 s / img. ETA=0:08:46
[07/02 17:49:39] detectron2 INFO: Inference done 24508/26446. 0.2669 s / img. ETA=0:08:41
[07/02 17:49:44] detectron2 INFO: Inference done 24527/26446. 0.2669 s / img. ETA=0:08:36
[07/02 17:49:49] detectron2 INFO: Inference done 24546/26446. 0.2669 s / img. ETA=0:08:31
[07/02 17:49:54] detectron2 INFO: Inference done 24565/26446. 0.2669 s / img. ETA=0:08:26
[07/02 17:49:59] detectron2 INFO: Inference done 24584/26446. 0.2669 s / img. ETA=0:08:20
[07/02 17:50:05] detectron2 INFO: Inference done 24603/26446. 0.2669 s / img. ETA=0:08:15
[07/02 17:50:10] detectron2 INFO: Inference done 24622/26446. 0.2669 s / img. ETA=0:08:10
[07/02 17:50:15] detectron2 INFO: Inference done 24641/26446. 0.2669 s / img. ETA=0:08:05
[07/02 17:50:20] detectron2 INFO: Inference done 24660/26446. 0.2669 s / img. ETA=0:08:00
[07/02 17:50:25] detectron2 INFO: Inference done 24679/26446. 0.2669 s / img. ETA=0:07:55
[07/02 17:50:30] detectron2 INFO: Inference done 24698/26446. 0.2669 s / img. ETA=0:07:50
[07/02 17:50:35] detectron2 INFO: Inference done 24717/26446. 0.2669 s / img. ETA=0:07:45
[07/02 17:50:40] detectron2 INFO: Inference done 24736/26446. 0.2669 s / img. ETA=0:07:40
[07/02 17:50:45] detectron2 INFO: Inference done 24755/26446. 0.2669 s / img. ETA=0:07:34
[07/02 17:50:50] detectron2 INFO: Inference done 24768/26446. 0.2669 s / img. ETA=0:07:31
[07/02 17:50:55] detectron2 INFO: Inference done 24787/26446. 0.2669 s / img. ETA=0:07:26
[07/02 17:51:01] detectron2 INFO: Inference done 24807/26446. 0.2669 s / img. ETA=0:07:21
[07/02 17:51:06] detectron2 INFO: Inference done 24826/26446. 0.2669 s / img. ETA=0:07:15
[07/02 17:51:11] detectron2 INFO: Inference done 24845/26446. 0.2669 s / img. ETA=0:07:10
[07/02 17:51:16] detectron2 INFO: Inference done 24864/26446. 0.2669 s / img. ETA=0:07:05
[07/02 17:51:21] detectron2 INFO: Inference done 24883/26446. 0.2669 s / img. ETA=0:07:00
[07/02 17:51:26] detectron2 INFO: Inference done 24903/26446. 0.2669 s / img. ETA=0:06:55
[07/02 17:51:31] detectron2 INFO: Inference done 24922/26446. 0.2669 s / img. ETA=0:06:50
[07/02 17:51:36] detectron2 INFO: Inference done 24941/26446. 0.2669 s / img. ETA=0:06:44
[07/02 17:51:42] detectron2 INFO: Inference done 24960/26446. 0.2669 s / img. ETA=0:06:39
[07/02 17:51:47] detectron2 INFO: Inference done 24979/26446. 0.2669 s / img. ETA=0:06:34
[07/02 17:51:52] detectron2 INFO: Inference done 24999/26446. 0.2669 s / img. ETA=0:06:29
[07/02 17:51:57] detectron2 INFO: Inference done 25018/26446. 0.2669 s / img. ETA=0:06:24
[07/02 17:52:02] detectron2 INFO: Inference done 25037/26446. 0.2669 s / img. ETA=0:06:19
[07/02 17:52:07] detectron2 INFO: Inference done 25056/26446. 0.2669 s / img. ETA=0:06:14
[07/02 17:52:12] detectron2 INFO: Inference done 25075/26446. 0.2669 s / img. ETA=0:06:08
[07/02 17:52:17] detectron2 INFO: Inference done 25094/26446. 0.2669 s / img. ETA=0:06:03
[07/02 17:52:22] detectron2 INFO: Inference done 25113/26446. 0.2669 s / img. ETA=0:05:58
[07/02 17:52:28] detectron2 INFO: Inference done 25132/26446. 0.2669 s / img. ETA=0:05:53
[07/02 17:52:33] detectron2 INFO: Inference done 25151/26446. 0.2669 s / img. ETA=0:05:48
[07/02 17:52:38] detectron2 INFO: Inference done 25170/26446. 0.2669 s / img. ETA=0:05:43
[07/02 17:52:43] detectron2 INFO: Inference done 25189/26446. 0.2669 s / img. ETA=0:05:38
[07/02 17:52:48] detectron2 INFO: Inference done 25208/26446. 0.2669 s / img. ETA=0:05:33
[07/02 17:52:53] detectron2 INFO: Inference done 25227/26446. 0.2669 s / img. ETA=0:05:28
[07/02 17:52:58] detectron2 INFO: Inference done 25246/26446. 0.2669 s / img. ETA=0:05:22
[07/02 17:53:03] detectron2 INFO: Inference done 25265/26446. 0.2669 s / img. ETA=0:05:17
[07/02 17:53:08] detectron2 INFO: Inference done 25284/26446. 0.2669 s / img. ETA=0:05:12
[07/02 17:53:14] detectron2 INFO: Inference done 25303/26446. 0.2669 s / img. ETA=0:05:07
[07/02 17:53:19] detectron2 INFO: Inference done 25322/26446. 0.2669 s / img. ETA=0:05:02
[07/02 17:53:24] detectron2 INFO: Inference done 25341/26446. 0.2669 s / img. ETA=0:04:57
[07/02 17:53:29] detectron2 INFO: Inference done 25360/26446. 0.2669 s / img. ETA=0:04:52
[07/02 17:53:34] detectron2 INFO: Inference done 25379/26446. 0.2669 s / img. ETA=0:04:47
[07/02 17:53:39] detectron2 INFO: Inference done 25398/26446. 0.2669 s / img. ETA=0:04:41
[07/02 17:53:44] detectron2 INFO: Inference done 25417/26446. 0.2669 s / img. ETA=0:04:36
[07/02 17:53:49] detectron2 INFO: Inference done 25436/26446. 0.2669 s / img. ETA=0:04:31
[07/02 17:53:54] detectron2 INFO: Inference done 25455/26446. 0.2669 s / img. ETA=0:04:26
[07/02 17:54:00] detectron2 INFO: Inference done 25474/26446. 0.2669 s / img. ETA=0:04:21
[07/02 17:54:05] detectron2 INFO: Inference done 25494/26446. 0.2669 s / img. ETA=0:04:16
[07/02 17:54:10] detectron2 INFO: Inference done 25513/26446. 0.2669 s / img. ETA=0:04:11
[07/02 17:54:15] detectron2 INFO: Inference done 25532/26446. 0.2669 s / img. ETA=0:04:05
[07/02 17:54:20] detectron2 INFO: Inference done 25551/26446. 0.2669 s / img. ETA=0:04:00
[07/02 17:54:25] detectron2 INFO: Inference done 25570/26446. 0.2669 s / img. ETA=0:03:55
[07/02 17:54:30] detectron2 INFO: Inference done 25589/26446. 0.2669 s / img. ETA=0:03:50
[07/02 17:54:36] detectron2 INFO: Inference done 25609/26446. 0.2669 s / img. ETA=0:03:45
[07/02 17:54:41] detectron2 INFO: Inference done 25629/26446. 0.2669 s / img. ETA=0:03:39
[07/02 17:54:46] detectron2 INFO: Inference done 25648/26446. 0.2669 s / img. ETA=0:03:34
[07/02 17:54:51] detectron2 INFO: Inference done 25667/26446. 0.2669 s / img. ETA=0:03:29
[07/02 17:54:56] detectron2 INFO: Inference done 25686/26446. 0.2669 s / img. ETA=0:03:24
[07/02 17:55:01] detectron2 INFO: Inference done 25705/26446. 0.2669 s / img. ETA=0:03:19
[07/02 17:55:06] detectron2 INFO: Inference done 25724/26446. 0.2669 s / img. ETA=0:03:14
[07/02 17:55:11] detectron2 INFO: Inference done 25743/26446. 0.2669 s / img. ETA=0:03:09
[07/02 17:55:17] detectron2 INFO: Inference done 25762/26446. 0.2669 s / img. ETA=0:03:04
[07/02 17:55:22] detectron2 INFO: Inference done 25781/26446. 0.2669 s / img. ETA=0:02:58
[07/02 17:55:27] detectron2 INFO: Inference done 25800/26446. 0.2669 s / img. ETA=0:02:53
[07/02 17:55:32] detectron2 INFO: Inference done 25819/26446. 0.2669 s / img. ETA=0:02:48
[07/02 17:55:37] detectron2 INFO: Inference done 25838/26446. 0.2669 s / img. ETA=0:02:43
[07/02 17:55:42] detectron2 INFO: Inference done 25857/26446. 0.2669 s / img. ETA=0:02:38
[07/02 17:55:47] detectron2 INFO: Inference done 25876/26446. 0.2669 s / img. ETA=0:02:33
[07/02 17:55:52] detectron2 INFO: Inference done 25895/26446. 0.2669 s / img. ETA=0:02:28
[07/02 17:55:57] detectron2 INFO: Inference done 25914/26446. 0.2669 s / img. ETA=0:02:23
[07/02 17:56:02] detectron2 INFO: Inference done 25933/26446. 0.2669 s / img. ETA=0:02:18
[07/02 17:56:07] detectron2 INFO: Inference done 25953/26446. 0.2669 s / img. ETA=0:02:12
[07/02 17:56:13] detectron2 INFO: Inference done 25972/26446. 0.2669 s / img. ETA=0:02:07
[07/02 17:56:18] detectron2 INFO: Inference done 25991/26446. 0.2669 s / img. ETA=0:02:02
[07/02 17:56:23] detectron2 INFO: Inference done 26010/26446. 0.2669 s / img. ETA=0:01:57
[07/02 17:56:28] detectron2 INFO: Inference done 26029/26446. 0.2669 s / img. ETA=0:01:52
[07/02 17:56:33] detectron2 INFO: Inference done 26048/26446. 0.2669 s / img. ETA=0:01:47
[07/02 17:56:38] detectron2 INFO: Inference done 26067/26446. 0.2669 s / img. ETA=0:01:41
[07/02 17:56:43] detectron2 INFO: Inference done 26086/26446. 0.2669 s / img. ETA=0:01:36
[07/02 17:56:48] detectron2 INFO: Inference done 26105/26446. 0.2669 s / img. ETA=0:01:31
[07/02 17:56:53] detectron2 INFO: Inference done 26124/26446. 0.2669 s / img. ETA=0:01:26
[07/02 17:56:59] detectron2 INFO: Inference done 26144/26446. 0.2669 s / img. ETA=0:01:21
[07/02 17:57:04] detectron2 INFO: Inference done 26163/26446. 0.2668 s / img. ETA=0:01:16
[07/02 17:57:09] detectron2 INFO: Inference done 26182/26446. 0.2668 s / img. ETA=0:01:11
[07/02 17:57:14] detectron2 INFO: Inference done 26202/26446. 0.2668 s / img. ETA=0:01:05
[07/02 17:57:19] detectron2 INFO: Inference done 26221/26446. 0.2668 s / img. ETA=0:01:00
[07/02 17:57:24] detectron2 INFO: Inference done 26240/26446. 0.2668 s / img. ETA=0:00:55
[07/02 17:57:29] detectron2 INFO: Inference done 26260/26446. 0.2668 s / img. ETA=0:00:50
[07/02 17:57:34] detectron2 INFO: Inference done 26279/26446. 0.2668 s / img. ETA=0:00:44
[07/02 17:57:40] detectron2 INFO: Inference done 26298/26446. 0.2668 s / img. ETA=0:00:39
[07/02 17:57:45] detectron2 INFO: Inference done 26317/26446. 0.2668 s / img. ETA=0:00:34
[07/02 17:57:50] detectron2 INFO: Inference done 26336/26446. 0.2668 s / img. ETA=0:00:29
[07/02 17:57:55] detectron2 INFO: Inference done 26355/26446. 0.2668 s / img. ETA=0:00:24
[07/02 17:58:00] detectron2 INFO: Inference done 26375/26446. 0.2668 s / img. ETA=0:00:19
[07/02 17:58:05] detectron2 INFO: Inference done 26394/26446. 0.2668 s / img. ETA=0:00:13
[07/02 17:58:10] detectron2 INFO: Inference done 26413/26446. 0.2668 s / img. ETA=0:00:08
[07/02 17:58:15] detectron2 INFO: Inference done 26433/26446. 0.2668 s / img. ETA=0:00:03
[07/02 17:58:19] detectron2 INFO: Total inference time: 1:58:33.108867 (0.269018 s / img per device, on 1 devices)
[07/02 17:58:19] detectron2 INFO: Total inference pure compute time: 1:57:34 (0.266798 s / img per device, on 1 devices)
[07/02 17:58:26] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/02 17:58:26] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[07/02 17:58:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[07/02 18:02:21] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.068 | 24.935 | 11.681 | 3.457 | 9.047 | 18.142 |
[07/02 18:02:21] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| airplane   | 1.112  | animal     | 1.156  | arm        | 2.943  |
| bag        | 4.171  | banana     | 8.043  | basket     | 7.694  |
| beach      | 28.780 | bear       | 31.095 | bed        | 39.407 |
| bench      | 20.489 | bike       | 18.167 | bird       | 20.919 |
| board      | 2.848  | boat       | 16.182 | book       | 4.030  |
| boot       | 6.869  | bottle     | 13.217 | bowl       | 19.882 |
| box        | 5.221  | boy        | 17.525 | branch     | 0.554  |
| building   | 20.895 | bus        | 40.507 | cabinet    | 4.686  |
| cap        | 4.319  | car        | 20.752 | cat        | 39.634 |
| chair      | 16.094 | child      | 3.165  | clock      | 19.754 |
| coat       | 3.140  | counter    | 9.731  | cow        | 29.000 |
| cup        | 14.000 | curtain    | 11.530 | desk       | 15.150 |
| dog        | 32.770 | door       | 7.810  | drawer     | 5.399  |
| ear        | 15.919 | elephant   | 37.853 | engine     | 14.657 |
| eye        | 10.305 | face       | 7.709  | fence      | 17.615 |
| finger     | 1.265  | flag       | 6.020  | flower     | 5.357  |
| food       | 11.661 | fork       | 19.748 | fruit      | 1.883  |
| giraffe    | 36.296 | girl       | 10.503 | glass      | 13.834 |
| glove      | 10.172 | guy        | 0.000  | hair       | 21.683 |
| hand       | 10.888 | handle     | 2.896  | hat        | 18.070 |
| head       | 9.265  | helmet     | 21.362 | hill       | 4.175  |
| horse      | 33.051 | house      | 6.868  | jacket     | 16.724 |
| jean       | 18.315 | kid        | 0.292  | kite       | 16.225 |
| lady       | 0.000  | lamp       | 11.848 | laptop     | 34.290 |
| leaf       | 0.833  | leg        | 4.816  | letter     | 0.925  |
| light      | 1.962  | logo       | 2.470  | man        | 31.376 |
| men        | 0.878  | motorcycle | 23.855 | mountain   | 8.744  |
| mouth      | 5.832  | neck       | 5.436  | nose       | 12.088 |
| number     | 2.786  | orange     | 12.611 | pant       | 18.828 |
| paper      | 3.265  | paw        | 6.732  | people     | 1.085  |
| person     | 5.310  | phone      | 7.119  | pillow     | 14.784 |
| pizza      | 30.231 | plane      | 28.474 | plant      | 4.677  |
| plate      | 29.968 | player     | 4.640  | pole       | 5.604  |
| post       | 1.098  | pot        | 4.701  | racket     | 22.850 |
| railing    | 1.126  | rock       | 4.878  | roof       | 6.414  |
| room       | 20.614 | screen     | 19.796 | seat       | 6.858  |
| sheep      | 21.750 | shelf      | 2.695  | shirt      | 26.515 |
| shoe       | 12.090 | short      | 27.713 | sidewalk   | 9.490  |
| sign       | 16.215 | sink       | 14.949 | skateboard | 23.932 |
| ski        | 10.786 | skier      | 4.222  | sneaker    | 0.330  |
| snow       | 19.231 | sock       | 8.841  | stand      | 1.569  |
| street     | 16.836 | surfboard  | 15.908 | table      | 27.016 |
| tail       | 13.113 | tie        | 18.283 | tile       | 0.361  |
| tire       | 12.080 | toilet     | 34.616 | towel      | 7.656  |
| tower      | 19.156 | track      | 10.811 | train      | 34.071 |
| tree       | 8.997  | truck      | 23.362 | trunk      | 10.447 |
| umbrella   | 18.173 | vase       | 20.904 | vegetable  | 1.547  |
| vehicle    | 0.494  | wave       | 10.998 | wheel      | 9.043  |
| window     | 6.314  | windshield | 11.064 | wing       | 10.488 |
| wire       | 0.729  | woman      | 21.799 | zebra      | 16.587 |
[07/02 18:02:25] detectron2 INFO: Gathering data
[07/02 18:02:25] detectron2 INFO: Predictions Gathered
[07/02 18:02:39] detectron2 INFO: Saving output prediction
[07/02 18:02:39] detectron2 INFO: Computing Scene Graph Metrics
[07/02 18:02:39] detectron2 INFO: Preparing Global Container
[07/02 18:09:47] detectron2 INFO: Scene Graph Metric Evaluation Complete. Computing recall statistics...
[07/02 18:10:44] detectron2 INFO: Scene Graph Results for mode: sgdet
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: 13.0682,24.9352,11.6806,3.4574,9.0470,18.1422
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: Task: SG
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: SGMeanRecall@20,SGMeanRecall@50,SGMeanRecall@100,SGRecall@20,SGRecall@50,SGRecall@100
[07/02 18:10:49] d2.evaluation.testing INFO: copypaste: 0.0951,0.1400,0.1617,0.2306,0.2964,0.3287
