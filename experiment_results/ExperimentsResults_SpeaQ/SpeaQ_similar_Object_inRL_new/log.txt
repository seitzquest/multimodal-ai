[07/04 19:32:39] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 19:32:40] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 19:32:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 19:32:40] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 19:32:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 19:32:40] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 19:32:41] d2.utils.env INFO: Using a generated random seed 41140544
[07/04 19:32:45] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 19:32:45] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 19:32:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 19:32:48] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 19:32:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 19:32:48] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 19:32:50] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 19:32:50] detectron2 INFO: Following metrics will be use for evaluation
[07/04 19:32:50] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 19:32:50] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 19:32:50] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 19:32:50] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 19:32:50] d2.data.datasets.coco INFO: Converting annotations of dataset 'VG_test' to COCO format ...)
[07/04 19:32:50] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[07/04 19:33:37] d2.data.datasets.coco INFO: Conversion finished, #images: 26446, #annotations: 325570
[07/04 19:33:37] d2.data.datasets.coco INFO: Caching COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json' ...
[07/04 19:33:44] detectron2 INFO: Loading zero shot triplets
[07/04 19:33:44] detectron2 INFO: Start inference on 26446 images
[07/04 19:34:09] detectron2 INFO: Inference done 1/26446. 5.9254 s / img. ETA=7 days, 13:10:23
[07/04 20:18:47] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 20:18:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 20:18:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 20:18:47] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 20:18:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 20:18:47] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 20:18:48] d2.utils.env INFO: Using a generated random seed 48093769
[07/04 20:18:52] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 20:18:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 20:18:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 20:18:54] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 20:18:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 20:18:54] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 20:18:55] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 20:18:55] detectron2 INFO: Following metrics will be use for evaluation
[07/04 20:18:55] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 20:18:55] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 20:18:55] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 20:18:55] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 20:18:55] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/04 20:18:57] detectron2 INFO: Loading zero shot triplets
[07/04 20:18:57] detectron2 INFO: Start inference on 26446 images
[07/04 20:20:17] detectron2 INFO: Inference done 8/26446. 21.2006 s / img. ETA=6 days, 11:42:43
[07/04 20:43:47] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 20:43:48] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 20:43:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 20:43:48] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 20:43:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 20:43:48] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 20:43:48] d2.utils.env INFO: Using a generated random seed 48875623
[07/04 20:43:53] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 20:43:53] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 20:43:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 20:43:55] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 20:43:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 20:43:55] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 20:43:56] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 20:43:56] detectron2 INFO: Following metrics will be use for evaluation
[07/04 20:43:56] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 20:43:56] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 20:43:56] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 20:43:56] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 20:43:56] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/04 20:43:58] detectron2 INFO: Loading zero shot triplets
[07/04 20:43:58] detectron2 INFO: Start inference on 26446 images
[07/04 20:44:16] detectron2 INFO: Inference done 1/26446. 6.0800 s / img. ETA=5 days, 8:13:12
[07/04 20:46:30] detectron2 INFO: Inference done 10/26446. 26.6272 s / img. ETA=8 days, 3:32:54
[07/04 20:48:22] detectron2 INFO: Inference done 11/26446. 40.8448 s / img. ETA=12 days, 11:56:35
[07/04 20:50:12] detectron2 INFO: Inference done 12/26446. 50.7239 s / img. ETA=15 days, 12:28:20
[07/04 20:51:59] detectron2 INFO: Inference done 13/26446. 57.7853 s / img. ETA=17 days, 16:18:24
[07/04 20:53:32] detectron2 INFO: Inference done 14/26446. 61.7268 s / img. ETA=18 days, 21:13:52
[07/04 20:54:44] detectron2 INFO: Inference done 15/26446. 62.7176 s / img. ETA=19 days, 4:29:19
[07/04 20:56:44] detectron2 INFO: Inference done 16/26446. 67.9610 s / img. ETA=20 days, 18:58:01
[07/04 20:58:19] detectron2 INFO: Inference done 17/26446. 70.1700 s / img. ETA=21 days, 11:09:55
[07/04 20:59:46] detectron2 INFO: Inference done 18/26446. 71.5102 s / img. ETA=21 days, 20:59:03
[07/04 21:08:35] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 21:08:35] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 21:08:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 21:08:35] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 21:08:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 21:08:36] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 21:08:36] d2.utils.env INFO: Using a generated random seed 36192844
[07/04 21:08:40] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 21:08:40] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 21:08:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 21:08:42] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 21:08:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 21:08:42] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 21:08:43] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 21:08:43] detectron2 INFO: Following metrics will be use for evaluation
[07/04 21:08:43] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 21:08:43] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 21:08:43] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 21:08:43] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 21:08:43] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/04 21:08:45] detectron2 INFO: Loading zero shot triplets
[07/04 21:08:45] detectron2 INFO: Start inference on 26446 images
[07/04 21:09:03] detectron2 INFO: Inference done 11/26446. 0.1724 s / img. ETA=1:17:02
[07/04 21:10:16] detectron2 INFO: Inference done 20/26446. 4.9377 s / img. ETA=1 day, 12:15:45
[07/04 21:11:33] detectron2 INFO: Inference done 21/26446. 9.4478 s / img. ETA=2 days, 21:22:02
[07/04 21:13:45] detectron2 INFO: Inference done 22/26446. 16.6700 s / img. ETA=5 days, 2:22:35
[07/04 21:15:28] detectron2 INFO: Inference done 23/26446. 21.4574 s / img. ETA=6 days, 13:30:34
[07/04 21:16:45] detectron2 INFO: Inference done 24/26446. 24.3701 s / img. ETA=7 days, 10:52:53
[07/04 21:18:33] detectron2 INFO: Inference done 25/26446. 28.5513 s / img. ETA=8 days, 17:33:41
[07/04 21:20:45] detectron2 INFO: Inference done 26/26446. 33.5119 s / img. ETA=10 days, 5:57:31
[07/04 21:22:34] detectron2 INFO: Inference done 27/26446. 36.9266 s / img. ETA=11 days, 7:00:30
[07/04 21:24:08] detectron2 INFO: Inference done 28/26446. 39.3985 s / img. ETA=12 days, 1:08:17
[07/04 21:26:02] detectron2 INFO: Inference done 29/26446. 42.5179 s / img. ETA=13 days, 0:01:02
[07/04 21:27:10] detectron2 INFO: Inference done 30/26446. 43.5470 s / img. ETA=13 days, 7:33:24
[07/04 21:28:33] detectron2 INFO: Inference done 31/26446. 45.0583 s / img. ETA=13 days, 18:38:04
[07/04 21:33:37] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 21:33:37] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 21:33:37] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 21:33:37] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 21:33:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 21:33:37] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 21:33:37] d2.utils.env INFO: Using a generated random seed 38037397
[07/04 21:33:40] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 21:33:40] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 21:33:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 21:33:42] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 21:33:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 21:33:42] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 21:33:44] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 21:33:44] detectron2 INFO: Following metrics will be use for evaluation
[07/04 21:33:44] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 21:33:44] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 21:33:44] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 21:33:44] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 21:33:44] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/04 21:33:46] detectron2 INFO: Loading zero shot triplets
[07/04 21:33:46] detectron2 INFO: Start inference on 26446 images
[07/04 21:34:03] detectron2 INFO: Inference done 11/26446. 0.1690 s / img. ETA=1:15:27
[07/04 21:36:09] detectron2 INFO: Inference done 33/26446. 4.5204 s / img. ETA=1 day, 9:10:57
[07/04 21:38:34] detectron2 INFO: Inference done 34/26446. 9.3731 s / img. ETA=2 days, 20:47:05
[07/04 21:40:12] detectron2 INFO: Inference done 35/26446. 12.3453 s / img. ETA=3 days, 18:35:14
[07/04 21:40:56] detectron2 INFO: Inference done 36/26446. 13.3405 s / img. ETA=4 days, 1:53:06
[07/04 21:43:57] detectron2 INFO: Inference done 37/26446. 18.5894 s / img. ETA=5 days, 16:23:12
[07/04 21:46:07] detectron2 INFO: Inference done 38/26446. 21.9690 s / img. ETA=6 days, 17:10:22
[07/04 21:48:30] detectron2 INFO: Inference done 39/26446. 25.5350 s / img. ETA=7 days, 19:19:27
[07/04 21:49:24] detectron2 INFO: Inference done 40/26446. 26.3499 s / img. ETA=8 days, 1:17:41
[07/04 21:51:35] detectron2 INFO: Inference done 41/26446. 29.2531 s / img. ETA=8 days, 22:34:54
[07/04 21:53:03] detectron2 INFO: Inference done 42/26446. 30.8396 s / img. ETA=9 days, 10:12:35
[07/04 21:53:44] detectron2 INFO: Inference done 43/26446. 31.1039 s / img. ETA=9 days, 12:08:24
[07/04 21:55:39] detectron2 INFO: Inference done 44/26446. 33.2504 s / img. ETA=10 days, 3:52:24
[07/04 21:57:17] detectron2 INFO: Inference done 45/26446. 34.8844 s / img. ETA=10 days, 15:50:53
[07/04 22:51:52] detectron2 INFO: Rank of current process: 0. World size: 1
[07/04 22:51:53] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/04 22:51:53] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/04 22:51:53] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/04 22:51:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/04 22:51:53] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/04 22:51:53] d2.utils.env INFO: Using a generated random seed 53786390
[07/04 22:51:57] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/04 22:51:57] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 22:51:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/04 22:51:59] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/04 22:51:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/04 22:51:59] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/04 22:52:00] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/04 22:52:00] detectron2 INFO: Following metrics will be use for evaluation
[07/04 22:52:00] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/04 22:52:00] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/04 22:52:00] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/04 22:52:00] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/04 22:52:01] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/04 22:52:02] detectron2 INFO: Loading zero shot triplets
[07/04 22:52:02] detectron2 INFO: Start inference on 26446 images
[07/04 22:52:20] detectron2 INFO: Inference done 11/26446. 0.1611 s / img. ETA=1:11:54
[07/04 22:52:25] detectron2 INFO: Inference done 41/26446. 0.1648 s / img. ETA=1:13:30
[07/04 22:54:47] detectron2 INFO: Inference done 47/26446. 3.5094 s / img. ETA=1 day, 1:45:03
[07/04 22:56:23] detectron2 INFO: Inference done 48/26446. 5.6595 s / img. ETA=1 day, 17:30:57
[07/04 22:57:47] detectron2 INFO: Inference done 49/26446. 7.4592 s / img. ETA=2 days, 6:42:40
[07/04 22:59:14] detectron2 INFO: Inference done 50/26446. 9.2080 s / img. ETA=2 days, 19:31:53
[07/04 23:00:18] detectron2 INFO: Inference done 51/26446. 10.4105 s / img. ETA=3 days, 4:20:43
[07/04 23:02:01] detectron2 INFO: Inference done 52/26446. 12.3701 s / img. ETA=3 days, 18:42:35
[07/04 23:03:32] detectron2 INFO: Inference done 53/26446. 14.0260 s / img. ETA=4 days, 6:50:47
[07/04 23:05:14] detectron2 INFO: Inference done 54/26446. 15.8056 s / img. ETA=4 days, 19:53:22
[07/05 10:31:46] detectron2 INFO: Rank of current process: 0. World size: 1
[07/05 10:31:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/05 10:31:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/05 10:31:47] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/05 10:31:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/05 10:31:47] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/05 10:31:47] d2.utils.env INFO: Using a generated random seed 47722309
[07/05 10:31:52] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/05 10:31:52] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:31:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:31:53] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/05 10:31:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/05 10:31:53] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/05 10:31:55] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/05 10:31:55] detectron2 INFO: Following metrics will be use for evaluation
[07/05 10:31:55] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/05 10:31:55] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/05 10:31:55] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/05 10:31:55] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/05 10:31:55] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/05 10:31:57] detectron2 INFO: Loading zero shot triplets
[07/05 10:31:57] detectron2 INFO: Start inference on 26446 images
[07/05 10:33:40] detectron2 INFO: Rank of current process: 0. World size: 1
[07/05 10:33:41] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/05 10:33:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/05 10:33:41] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/05 10:33:41] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/05 10:33:41] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/05 10:33:41] d2.utils.env INFO: Using a generated random seed 41534211
[07/05 10:33:44] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/05 10:33:44] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:33:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:33:46] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/05 10:33:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/05 10:33:46] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/05 10:33:47] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/05 10:33:47] detectron2 INFO: Following metrics will be use for evaluation
[07/05 10:33:47] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/05 10:33:47] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/05 10:33:47] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/05 10:33:47] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/05 10:33:47] d2.data.datasets.coco WARNING: Using previously cached COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[07/05 10:33:49] detectron2 INFO: Loading zero shot triplets
[07/05 10:33:49] detectron2 INFO: Start inference on 26446 images
[07/05 10:34:16] detectron2 INFO: Inference done 1/26446. 16.0161 s / img. ETA=8 days, 3:30:47
[07/05 10:34:27] detectron2 INFO: Inference done 3/26446. 8.9855 s / img. ETA=3 days, 19:57:55
[07/05 10:34:36] detectron2 INFO: Inference done 5/26446. 7.3138 s / img. ETA=2 days, 21:18:04
[07/05 10:34:49] detectron2 INFO: Inference done 7/26446. 6.0973 s / img. ETA=1 day, 20:47:25
[07/05 10:34:54] detectron2 INFO: Inference done 8/26446. 5.9268 s / img. ETA=1 day, 19:32:15
[07/05 10:35:03] detectron2 INFO: Inference done 10/26446. 5.2782 s / img. ETA=1 day, 14:46:19
[07/05 10:35:16] detectron2 INFO: Inference done 11/26446. 6.5744 s / img. ETA=2 days, 0:17:19
[07/05 10:35:23] detectron2 INFO: Inference done 12/26446. 6.6890 s / img. ETA=2 days, 1:07:43
[07/05 10:35:29] detectron2 INFO: Inference done 13/26446. 6.5586 s / img. ETA=2 days, 0:10:12
[07/05 10:35:37] detectron2 INFO: Inference done 15/26446. 6.0370 s / img. ETA=1 day, 20:20:15
[07/05 10:35:54] detectron2 INFO: Inference done 17/26446. 6.4326 s / img. ETA=1 day, 23:14:18
[07/05 10:37:29] detectron2 INFO: Rank of current process: 0. World size: 1
[07/05 10:37:30] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------------------
sys.platform                     win32
Python                           3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
numpy                            1.26.4
detectron2                       0.6 @D:\Anaconda\envs\SpeaQ\lib\site-packages\detectron2
detectron2._C                    not built correctly: DLL load failed while importing _C: The specified procedure could not be found.
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 3070 Laptop GPU (arch=8.6)
Driver version                   527.54
CUDA_HOME                        None - invalid!
Pillow                           10.3.0
torchvision                      0.11.0+cu113 @D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision
torchvision arch flags           D:\Anaconda\envs\SpeaQ\lib\site-packages\torchvision\_C.pyd
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

[07/05 10:37:30] detectron2 INFO: Command line arguments: Namespace(config_file='configs/speaq_test.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:tcp://127.0.0.1:49153', opts=['OUTPUT_DIR', './speaq_checkpoints/', 'DATASETS.VISUAL_GENOME.IMAGES', './data/datasets/VG/VG_100K/', 'DATASETS.VISUAL_GENOME.MAPPING_DICTIONARY', './data/datasets/VG/VG-SGG-dicts-with-attri.json', 'DATASETS.VISUAL_GENOME.IMAGE_DATA', './data/datasets/VG/image_data.json', 'DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5', './data/datasets/VG/VG-SGG-with-attri.h5', 'MODEL.DETR.OVERSAMPLE_PARAM', '0.07', 'MODEL.DETR.UNDERSAMPLE_PARAM', '1.5', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.DETR.ONE2MANY_SCHEME', 'dynamic', 'MODEL.DETR.MULTIPLY_QUERY', '2', 'MODEL.DETR.ONLY_PREDICATE_MULTIPLY', 'True', 'MODEL.DETR.ONE2MANY_K', '4', 'MODEL.DETR.ONE2MANY_DYNAMIC_SCHEME', 'max', 'MODEL.DETR.USE_GROUP_MASK', 'True', 'MODEL.DETR.MATCH_INDEPENDENT', 'True', 'MODEL.DETR.NUM_GROUPS', '4', 'MODEL.DETR.ONE2MANY_PREDICATE_SCORE', 'True', 'MODEL.DETR.ONE2MANY_PREDICATE_WEIGHT', '-0.5'])
[07/05 10:37:30] detectron2 INFO: Contents of args.config_file=configs/speaq_test.yaml:
MODEL:
  META_ARCHITECTURE: "IterativeRelationDetr"
  WEIGHTS: './checkpoint/vg_objectdetector_pretrained.pth'
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: False
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  DETR:
    NAME: 'IterativeRelationDETR'
    TRANSFORMER: 'IterativeRelationTransformer'
    CRITERION: 'IterativeRelationCriterion'
    MATCHER: 'SpeaQHungarianMatcher'
    ONE2MANY_SCHEME: 'dynamic'
    ONE2MANY_DYNAMIC_SCHEME: 'max'
    ONE2MANY_K: 4
    MULTIPLY_QUERY: 2
    MATCH_INDEPENDENT: True
    USE_GROUP_MASK: True
    ONLY_PREDICATE_MULTIPLY: True
    GIOU_WEIGHT: 2.0
    L1_WEIGHT: 5.0
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_QUERIES: 300
    NUM_CLASSES: 150
    OBJECT_DEC_LAYERS: 6
    REWEIGHT_RELATIONS: True
    REWEIGHT_REL_EOS_COEF: 0.1
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    OVERSAMPLE_PARAM: 0.07
    UNDERSAMPLE_PARAM: 1.5
    NUM_GROUPS: 4
    ONE2MANY_PREDICATE_SCORE: True
    ONE2MANY_PREDICATE_WEIGHT: -0.5
DATASETS:
  TYPE: "VISUAL GENOME"
  TRAIN: ('VG_train',)
  TEST: ('VG_test',)
  VISUAL_GENOME:
    TRAIN_MASKS: ""
    VAL_MASKS: ""
    TEST_MASKS: ""
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    IMAGES: './data/datasets/VG/VG_100K/'
    MAPPING_DICTIONARY: './data/datasets/VG/VG-SGG-dicts-with-attri.json'
    IMAGE_DATA: './data/datasets/VG/image_data.json'
    VG_ATTRIBUTE_H5: './data/datasets/VG/VG-SGG-with-attri.h5'
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.0001
  STEPS: (96000,)
  MAX_ITER: 150000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 6000
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 1
VERSION: 2

[07/05 10:37:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 1
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  ACTION_GENOME:
    ANNOTATIONS: ''
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: true
    FORMAT_VID_WISE: false
    FRAMES: ''
    NUM_VIDEOS_TRAIN: -1
    NUM_VIDEOS_VAL: 400
    VAL_SET_RANDOMIZED: false
    VIDEOS: ''
  MASK_TEST:
  - coco_val_2017
  MASK_TRAIN:
  - coco_train_2017
  MSCOCO:
    ANNOTATIONS: ''
    DATAROOT: ''
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEG_DATA_DIVISOR: 1
  TEST:
  - VG_test
  TRAIN:
  - VG_train
  TRANSFER:
  - coco_train_2014
  TYPE: VISUAL GENOME
  VISUAL_GENOME:
    BGNN: false
    BOX_SCALE: 1024
    CLIPPED: false
    EXCLUDE_LEFT_RIGHT: false
    FILTER_DUPLICATE_RELATIONS: true
    FILTER_EMPTY_RELATIONS: true
    FILTER_NON_OVERLAP: false
    IMAGES: ./data/datasets/VG/VG_100K/
    IMAGE_DATA: ./data/datasets/VG/image_data.json
    MAPPING_DICTIONARY: ./data/datasets/VG/VG-SGG-dicts-with-attri.json
    MAX_NUM_OBJECTS: -1
    MAX_NUM_RELATIONS: -1
    NUMBER_OF_VALIDATION_IMAGES: 5000
    OVERSAMPLE_PARAM: 0.07
    PER_CLASS_DATASET: false
    SG_MAPPER: ''
    SG_TRAIN_DATA: ''
    SG_VAL_DATA: ''
    TEST_MASKS: ''
    TRAIN_MASKS: ''
    UNDERSAMPLE_PARAM: 0.7
    VAL_MASKS: ''
    VG_ATTRIBUTE_H5: ./data/datasets/VG/VG-SGG-with-attri.h5
DEV_RUN: false
GLOBAL:
  HACK: 1.0
GLOVE_DIR: glove/
INPUT:
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DETR:
    BETA: 1000
    CLASS_AGNOSTIC_NMS: true
    CLS_WEIGHT: 2.0
    COST_CLASS: 1.0
    COST_SELECTION: 1.0
    CREATE_BG_PAIRS: false
    CRITERION: IterativeRelationCriterion
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    FREEZE: false
    FREEZE_LAYERS: []
    FROZEN_WEIGHTS: ''
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INTERSECTION_IOU_LAMBDA: 1.0
    INTERSECTION_IOU_THRESHOLD: 0.3
    INTERSECTION_LOSS: false
    L1_WEIGHT: 5.0
    LATER_NMS_THRESHOLD: 0.3
    MATCHER: SpeaQHungarianMatcher
    MATCHER_TOPK: 1
    MATCH_INDEPENDENT: true
    MAX_RELATION_PAIRS: 16
    MULTIPLY_QUERY: 2
    NAME: IterativeRelationDETR
    NEGATIVE_RELATION_FRACTION: 3.0
    NHEADS: 8
    NMS_WEIGHT: 0.2
    NO_OBJECT_WEIGHT: 0.1
    NO_REL_WEIGHT: 0.1
    NUM_CLASSES: 150
    NUM_FEATURE_LEVELS: 4
    NUM_GROUPS: 4
    NUM_OBJECT_QUERIES: 300
    NUM_RELATION_CLASSES: 50
    NUM_RELATION_QUERIES: 300
    OBJECT_DEC_LAYERS: 6
    ONE2MANY_DYNAMIC_SCHEME: max
    ONE2MANY_K: 4
    ONE2MANY_PREDICATE_SCORE: true
    ONE2MANY_PREDICATE_WEIGHT: -0.5
    ONE2MANY_SCHEME: dynamic
    ONE_TO_MANY: false
    ONLY_PREDICATE_MULTIPLY: true
    OVERSAMPLE_PARAM: 0.07
    POSITION_EMBEDDING: PositionEmbeddingSine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    REWEIGHT_RELATIONS: true
    REWEIGHT_REL_EOS_COEF: 0.1
    REWEIGHT_USE_LOG: true
    SGDET_USE_GT: false
    TEST_INDEX: -1
    TRANSFORMER: IterativeRelationTransformer
    TWO_STAGE: false
    TWO_STAGE_NUM_PROPOSALS: 300
    UNDERSAMPLE_PARAM: 1.5
    USE_FREQ_BIAS: true
    USE_GROUP_MASK: true
    WITH_BOX_REFINE: false
  DEVICE: cuda
  DF_DETR:
    BACKBONE: resnet50
    BBOX_LOSS_WEIGHT: 5.0
    CLS_LOSS_WEIGHT: 2.0
    DEC_LAYERS: 6
    DEEP_SUPERVISION: true
    DILATION: false
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    FOCAL_ALPHA: 0.25
    GIOU_LOSS_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NHEADS: 8
    NUM_CLASSES: 80
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    POSITIONAL_EMBEDDING: sine
    PRE_NORM: false
    RELATION_DEC_LAYERS: 4
    RELATION_HEAD: true
    RELATION_LOSS_WEIGHT: 1.0
    SET_COST_BBOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TWO_STAGE: false
    WITH_BOX_REFINE: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  FREEZE_LAYERS:
    META_ARCH: []
    ROI_HEADS: []
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: IterativeRelationDetr
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_FEATURE_EXTRACTORS:
    BOX_FEATURE_MASK: true
    CLASS_LOGITS_WITH_MASK: false
    NAME: BoxFeatureExtractor
    POOLER_RESOLUTION: 28
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: true
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    EMBEDDINGS_PATH: ''
    EMBEDDINGS_PATH_COCO: ''
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LINGUAL_MATRIX_THRESHOLD: 0.05
    MASK_NUM_CLASSES: 80
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_OUTPUT_CLASSES: 80
    OBJECTNESS_THRESH: 0.3
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REFINE_SEG_MASKS: true
    SCORE_THRESH_TEST: 0.05
    SEGMENTATION_STEP_MASK_REFINE: true
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_RELATION_FEATURE_EXTRACTORS:
    MULTIPLY_LOGITS_WITH_MASKS: true
    NAME: RelationFeatureExtractor
    USE_MASK_COMBINER: false
  ROI_SCENEGRAPH_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: true
    BATCH_SIZE_PER_IMAGE: 64
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    LABEL_SMOOTHING_LOSS: false
    MASK_ATTENTION_TYPE: Self
    MODE: predcls
    NAME: SceneGraphHead
    NMS_FILTER_DUPLICATES: true
    NUM_CLASSES: 50
    NUM_SAMPLE_PER_GT_REL: 4
    POSITIVE_FRACTION: 0.25
    PREDICTOR: MotifPredictor
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_PROP:
    - 0.01858
    - 0.00057
    - 0.00051
    - 0.00109
    - 0.0015
    - 0.00489
    - 0.00432
    - 0.02913
    - 0.00245
    - 0.00121
    - 0.00404
    - 0.0011
    - 0.00132
    - 0.00172
    - 5.0e-05
    - 0.00242
    - 0.0005
    - 0.00048
    - 0.00208
    - 0.15608
    - 0.0265
    - 0.06091
    - 0.009
    - 0.00183
    - 0.00225
    - 0.0009
    - 0.00028
    - 0.00077
    - 0.04844
    - 0.08645
    - 0.31621
    - 0.00088
    - 0.00301
    - 0.00042
    - 0.00186
    - 0.001
    - 0.00027
    - 0.01012
    - 0.0001
    - 0.01286
    - 0.00647
    - 0.00084
    - 0.01077
    - 0.00132
    - 0.00069
    - 0.00376
    - 0.00214
    - 0.11424
    - 0.01205
    - 0.02958
    REQUIRE_BOX_OVERLAP: true
    RETURN_SEG_ANNOS: false
    RETURN_SEG_MASKS: false
    SEG_BBOX_LOSS_MULTIPLIER: 1.0
    SIGMOID_ATTENTION: true
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: false
    USE_GT_OBJECT_LABEL: false
    USE_MASK_ATTENTION: false
    USE_ONLY_FG_PROPOSALS: true
    ZERO_SHOT_TRIPLETS: evaluation/datasets/vg/zeroshot_triplet.pytorch
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SCENEGRAPH_LOSS:
    NAME: TransformerRelatonLoss
  SCENEGRAPH_ON: true
  SCENEGRAPH_POST_PROCESSOR:
    NAME: TransformerRelationPostProcesser
  SCENEGRAPH_SAMPLER:
    NAME: TransformerRelationSampler
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  USE_MASK_ON_NODE: false
  WEIGHTS: ./checkpoint/vg_objectdetector_pretrained.pth
OUTPUT_DIR: ./speaq_checkpoints/
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  ENTITY_MULTIPLIER: 1.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 150000
  MAX_TO_KEEP: 2
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RELATION_MULTIPLIER: 1.0
  RESCALE_INTERVAL: false
  STEPS:
  - 96000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 6000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  NUM_REL: 1
  PNMS: false
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: true
VERSION: 2
VIS_PERIOD: 0
WANDB:
  ENTITY: your_entity
  EXP_NAME: default_exp_name
  GROUP: speaq
  PROJECT: speaq
  USE_WANDB: false

[07/05 10:37:30] detectron2 INFO: Full config saved to ./speaq_checkpoints/config.yaml
[07/05 10:37:30] d2.utils.env INFO: Using a generated random seed 30579464
[07/05 10:37:33] d2.engine.defaults INFO: Model:
IterativeRelationDetr(
  (detr): IterativeRelationDETR(
    (transformer): IterativeRelationTransformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): IterativeRelationDecoder(
        (subject_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (object_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (relation_layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=2048, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=2048, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (subject_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (relation_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (object_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (relation_pos_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (5): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_pos_linear): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_pos_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
          (5): Dropout(p=0.1, inplace=False)
        )
        (subject_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (subject_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (subject_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (subject_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (object_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (object_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (object_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (object_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
        (relation_graph_query_attn): ModuleList(
          (0): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (1): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (2): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (3): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (4): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
        )
        (relation_graph_query_residual): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): Linear(in_features=256, out_features=256, bias=True)
        )
        (relation_graph_query_norm): ModuleList(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (relation_graph_query_dropout): ModuleList(
          (0): Dropout(p=0.1, inplace=False)
          (1): Dropout(p=0.1, inplace=False)
          (2): Dropout(p=0.1, inplace=False)
          (3): Dropout(p=0.1, inplace=False)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (object_embed): Linear(in_features=256, out_features=151, bias=True)
      (object_bbox_coords): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
      (relation_embed): Linear(in_features=256, out_features=51, bias=True)
    )
    (query_embed): Embedding(300, 256)
    (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (backbone): Joiner(
      (0): MaskedBackbone(
        (backbone): ResNet(
          (stem): BasicStem(
            (conv1): Conv2d(
              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
          )
          (res2): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv1): Conv2d(
                64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv2): Conv2d(
                64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
              )
              (conv3): Conv2d(
                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
            )
          )
          (res3): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv1): Conv2d(
                256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv2): Conv2d(
                128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
              )
              (conv3): Conv2d(
                128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
            )
          )
          (res4): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
              (conv1): Conv2d(
                512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (3): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (4): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (5): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (6): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (7): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (8): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (9): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (10): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (11): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (12): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (13): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (14): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (15): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (16): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (17): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (18): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (19): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (20): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (21): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
            (22): BottleneckBlock(
              (conv1): Conv2d(
                1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv2): Conv2d(
                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
              )
              (conv3): Conv2d(
                256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
              )
            )
          )
          (res5): Sequential(
            (0): BottleneckBlock(
              (shortcut): Conv2d(
                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
              (conv1): Conv2d(
                1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (1): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
            (2): BottleneckBlock(
              (conv1): Conv2d(
                2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv2): Conv2d(
                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
              )
              (conv3): Conv2d(
                512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
              )
            )
          )
        )
      )
      (1): PositionEmbeddingSine()
    )
    (relation_query_embed): Embedding(600, 256)
    (object_query_embed): Embedding(300, 256)
  )
  (criterion): IterativeRelationCriterion(
    (matcher): SpeaQHungarianMatcher()
  )
)
[07/05 10:37:33] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:37:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./speaq_checkpoints/model_final.pth ...
[07/05 10:37:35] d2.data.build INFO: Distribution of instances among all 150 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|  airplane  | 460          |   animal   | 897          |    arm     | 3387         |
|    bag     | 1906         |   banana   | 1352         |   basket   | 645          |
|   beach    | 1090         |    bear    | 1036         |    bed     | 929          |
|   bench    | 1542         |    bike    | 1445         |    bird    | 1261         |
|   board    | 1376         |    boat    | 1407         |    book    | 1105         |
|    boot    | 749          |   bottle   | 1679         |    bowl    | 1303         |
|    box     | 1436         |    boy     | 2110         |   branch   | 1766         |
|  building  | 7373         |    bus     | 1412         |  cabinet   | 1011         |
|    cap     | 1073         |    car     | 4150         |    cat     | 1188         |
|   chair    | 2893         |   child    | 895          |   clock    | 1327         |
|    coat    | 1094         |  counter   | 1159         |    cow     | 1192         |
|    cup     | 1087         |  curtain   | 763          |    desk    | 667          |
|    dog     | 1406         |    door    | 3383         |   drawer   | 618          |
|    ear     | 3770         |  elephant  | 1353         |   engine   | 757          |
|    eye     | 1965         |    face    | 2462         |   fence    | 3079         |
|   finger   | 1034         |    flag    | 903          |   flower   | 2299         |
|    food    | 1781         |    fork    | 649          |   fruit    | 660          |
|  giraffe   | 1562         |    girl    | 1792         |   glass    | 2983         |
|   glove    | 1228         |    guy     | 544          |    hair    | 4915         |
|    hand    | 5566         |   handle   | 1931         |    hat     | 2435         |
|    head    | 7112         |   helmet   | 1792         |    hill    | 1045         |
|   horse    | 1590         |   house    | 1113         |   jacket   | 2959         |
|    jean    | 1467         |    kid     | 564          |    kite    | 995          |
|    lady    | 657          |    lamp    | 942          |   laptop   | 927          |
|    leaf    | 3971         |    leg     | 7752         |   letter   | 2399         |
|   light    | 3604         |    logo    | 1267         |    man     | 16310        |
|    men     | 485          | motorcycle | 1088         |  mountain  | 1064         |
|   mouth    | 1139         |    neck    | 1379         |    nose    | 1892         |
|   number   | 1077         |   orange   | 749          |    pant    | 3834         |
|   paper    | 1119         |    paw     | 883          |   people   | 3751         |
|   person   | 12808        |   phone    | 839          |   pillow   | 1468         |
|   pizza    | 1000         |   plane    | 1641         |   plant    | 1714         |
|   plate    | 3203         |   player   | 1314         |    pole    | 5765         |
|    post    | 1596         |    pot     | 679          |   racket   | 840          |
|  railing   | 694          |    rock    | 2095         |    roof    | 1534         |
|    room    | 633          |   screen   | 676          |    seat    | 1076         |
|   sheep    | 1201         |   shelf    | 1477         |   shirt    | 9368         |
|    shoe    | 3725         |   short    | 2229         |  sidewalk  | 2263         |
|    sign    | 6306         |    sink    | 767          | skateboard | 1190         |
|    ski     | 1063         |   skier    | 590          |  sneaker   | 658          |
|    snow    | 2994         |    sock    | 935          |   stand    | 762          |
|   street   | 3007         | surfboard  | 1285         |   table    | 5216         |
|    tail    | 2589         |    tie     | 837          |    tile    | 1841         |
|    tire    | 1727         |   toilet   | 571          |   towel    | 807          |
|   tower    | 688          |   track    | 2287         |   train    | 1932         |
|    tree    | 12679        |   truck    | 1153         |   trunk    | 1386         |
|  umbrella  | 1838         |    vase    | 841          | vegetable  | 646          |
|  vehicle   | 858          |    wave    | 1710         |   wheel    | 2840         |
|   window   | 11751        | windshield | 866          |    wing    | 1400         |
|    wire    | 1030         |   woman    | 7212         |   zebra    | 1304         |
|            |              |            |              |            |              |
|   total    | 325570       |            |              |            |              |
[07/05 10:37:35] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[07/05 10:37:35] d2.data.common INFO: Serializing 26446 elements to byte tensors and concatenating them all ...
[07/05 10:37:36] d2.data.common INFO: Serialized dataset takes 69.66 MiB
[07/05 10:37:36] detectron2 INFO: Following metrics will be use for evaluation
[07/05 10:37:36] detectron2 INFO: ('SGRecall', 'SGNoGraphConstraintRecall', 'SGZeroShotRecall', 'SGPairAccuracy', 'SGMeanRecall', 'query_count_per_rel_class', 'rel_class_info_per_query', 'recall_per_class')
[07/05 10:37:36] d2.evaluation.coco_evaluation INFO: Fast COCO eval is not built. Falling back to official COCO eval.
[07/05 10:37:36] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[07/05 10:37:36] d2.evaluation.coco_evaluation INFO: Trying to convert 'VG_test' to COCO format ...
[07/05 10:37:36] d2.data.datasets.coco INFO: Converting annotations of dataset 'VG_test' to COCO format ...)
[07/05 10:37:36] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[07/05 10:38:18] d2.data.datasets.coco INFO: Conversion finished, #images: 26446, #annotations: 325570
[07/05 10:38:18] d2.data.datasets.coco INFO: Caching COCO format annotations at './speaq_checkpoints/inference\VG_test_coco_format.json' ...
[07/05 10:38:25] detectron2 INFO: Loading zero shot triplets
[07/05 10:38:25] detectron2 INFO: Start inference on 26446 images
[07/05 10:38:41] detectron2 INFO: Inference done 1/26446. 5.0470 s / img. ETA=4 days, 18:58:07
[07/05 10:38:46] detectron2 INFO: Inference done 25/26446. 0.2007 s / img. ETA=1:29:16
[07/05 10:38:51] detectron2 INFO: Inference done 50/26446. 0.2006 s / img. ETA=1:29:07
[07/05 10:38:56] detectron2 INFO: Inference done 75/26446. 0.2001 s / img. ETA=1:28:50
[07/05 10:39:01] detectron2 INFO: Inference done 100/26446. 0.2002 s / img. ETA=1:28:48
[07/05 10:39:06] detectron2 INFO: Inference done 125/26446. 0.2001 s / img. ETA=1:28:40
[07/05 10:39:11] detectron2 INFO: Inference done 151/26446. 0.1998 s / img. ETA=1:28:25
[07/05 10:39:16] detectron2 INFO: Inference done 176/26446. 0.1999 s / img. ETA=1:28:23
[07/05 10:39:21] detectron2 INFO: Inference done 201/26446. 0.1997 s / img. ETA=1:28:13
[07/05 10:39:26] detectron2 INFO: Inference done 226/26446. 0.1997 s / img. ETA=1:28:07
[07/05 10:39:31] detectron2 INFO: Inference done 251/26446. 0.1995 s / img. ETA=1:27:58
[07/05 10:39:36] detectron2 INFO: Inference done 277/26446. 0.1991 s / img. ETA=1:27:41
[07/05 10:39:41] detectron2 INFO: Inference done 302/26446. 0.1991 s / img. ETA=1:27:36
[07/05 10:39:47] detectron2 INFO: Inference done 327/26446. 0.1991 s / img. ETA=1:27:33
[07/05 10:39:52] detectron2 INFO: Inference done 352/26446. 0.1994 s / img. ETA=1:27:35
[07/05 10:39:57] detectron2 INFO: Inference done 378/26446. 0.1993 s / img. ETA=1:27:26
[07/05 10:40:02] detectron2 INFO: Inference done 404/26446. 0.1989 s / img. ETA=1:27:10
[07/05 10:40:07] detectron2 INFO: Inference done 429/26446. 0.1989 s / img. ETA=1:27:06
[07/05 10:40:12] detectron2 INFO: Inference done 454/26446. 0.1990 s / img. ETA=1:27:03
[07/05 10:40:17] detectron2 INFO: Inference done 480/26446. 0.1985 s / img. ETA=1:26:46
[07/05 10:40:22] detectron2 INFO: Inference done 506/26446. 0.1984 s / img. ETA=1:26:39
[07/05 10:40:27] detectron2 INFO: Inference done 532/26446. 0.1983 s / img. ETA=1:26:30
[07/05 10:40:32] detectron2 INFO: Inference done 557/26446. 0.1985 s / img. ETA=1:26:30
[07/05 10:40:38] detectron2 INFO: Inference done 583/26446. 0.1985 s / img. ETA=1:26:24
[07/05 10:40:43] detectron2 INFO: Inference done 608/26446. 0.1986 s / img. ETA=1:26:23
[07/05 10:40:48] detectron2 INFO: Inference done 633/26446. 0.1987 s / img. ETA=1:26:20
[07/05 10:40:53] detectron2 INFO: Inference done 658/26446. 0.1987 s / img. ETA=1:26:15
[07/05 10:40:58] detectron2 INFO: Inference done 684/26446. 0.1986 s / img. ETA=1:26:08
[07/05 10:41:03] detectron2 INFO: Inference done 709/26446. 0.1986 s / img. ETA=1:26:03
[07/05 10:41:08] detectron2 INFO: Inference done 734/26446. 0.1986 s / img. ETA=1:25:58
[07/05 10:41:13] detectron2 INFO: Inference done 760/26446. 0.1986 s / img. ETA=1:25:51
[07/05 10:41:18] detectron2 INFO: Inference done 786/26446. 0.1985 s / img. ETA=1:25:43
[07/05 10:41:23] detectron2 INFO: Inference done 811/26446. 0.1985 s / img. ETA=1:25:39
[07/05 10:41:28] detectron2 INFO: Inference done 837/26446. 0.1983 s / img. ETA=1:25:28
[07/05 10:41:33] detectron2 INFO: Inference done 862/26446. 0.1983 s / img. ETA=1:25:25
[07/05 10:41:38] detectron2 INFO: Inference done 887/26446. 0.1983 s / img. ETA=1:25:20
[07/05 10:41:44] detectron2 INFO: Inference done 913/26446. 0.1983 s / img. ETA=1:25:14
[07/05 10:41:49] detectron2 INFO: Inference done 939/26446. 0.1982 s / img. ETA=1:25:07
[07/05 10:41:54] detectron2 INFO: Inference done 965/26446. 0.1981 s / img. ETA=1:24:58
[07/05 10:41:59] detectron2 INFO: Inference done 990/26446. 0.1981 s / img. ETA=1:24:54
[07/05 10:42:04] detectron2 INFO: Inference done 1015/26446. 0.1982 s / img. ETA=1:24:50
[07/05 10:42:09] detectron2 INFO: Inference done 1041/26446. 0.1981 s / img. ETA=1:24:44
[07/05 10:42:14] detectron2 INFO: Inference done 1066/26446. 0.1982 s / img. ETA=1:24:40
[07/05 10:42:19] detectron2 INFO: Inference done 1092/26446. 0.1981 s / img. ETA=1:24:31
[07/05 10:42:24] detectron2 INFO: Inference done 1118/26446. 0.1980 s / img. ETA=1:24:24
[07/05 10:42:29] detectron2 INFO: Inference done 1144/26446. 0.1979 s / img. ETA=1:24:17
[07/05 10:42:35] detectron2 INFO: Inference done 1169/26446. 0.1980 s / img. ETA=1:24:14
[07/05 10:42:40] detectron2 INFO: Inference done 1195/26446. 0.1979 s / img. ETA=1:24:07
[07/05 10:42:45] detectron2 INFO: Inference done 1220/26446. 0.1979 s / img. ETA=1:24:03
[07/05 10:42:50] detectron2 INFO: Inference done 1246/26446. 0.1979 s / img. ETA=1:23:57
[07/05 10:42:55] detectron2 INFO: Inference done 1271/26446. 0.1981 s / img. ETA=1:23:56
[07/05 10:43:00] detectron2 INFO: Inference done 1296/26446. 0.1982 s / img. ETA=1:23:54
[07/05 10:43:05] detectron2 INFO: Inference done 1321/26446. 0.1982 s / img. ETA=1:23:50
[07/05 10:43:10] detectron2 INFO: Inference done 1346/26446. 0.1982 s / img. ETA=1:23:45
[07/05 10:43:15] detectron2 INFO: Inference done 1372/26446. 0.1982 s / img. ETA=1:23:39
[07/05 10:43:21] detectron2 INFO: Inference done 1398/26446. 0.1981 s / img. ETA=1:23:33
[07/05 10:43:26] detectron2 INFO: Inference done 1423/26446. 0.1982 s / img. ETA=1:23:30
[07/05 10:43:31] detectron2 INFO: Inference done 1448/26446. 0.1983 s / img. ETA=1:23:27
[07/05 10:43:36] detectron2 INFO: Inference done 1473/26446. 0.1984 s / img. ETA=1:23:24
[07/05 10:43:41] detectron2 INFO: Inference done 1498/26446. 0.1984 s / img. ETA=1:23:19
[07/05 10:43:46] detectron2 INFO: Inference done 1524/26446. 0.1983 s / img. ETA=1:23:11
[07/05 10:43:51] detectron2 INFO: Inference done 1550/26446. 0.1982 s / img. ETA=1:23:05
[07/05 10:43:56] detectron2 INFO: Inference done 1575/26446. 0.1982 s / img. ETA=1:23:00
[07/05 10:44:01] detectron2 INFO: Inference done 1601/26446. 0.1983 s / img. ETA=1:22:55
[07/05 10:44:06] detectron2 INFO: Inference done 1626/26446. 0.1983 s / img. ETA=1:22:51
[07/05 10:44:12] detectron2 INFO: Inference done 1651/26446. 0.1983 s / img. ETA=1:22:47
[07/05 10:44:17] detectron2 INFO: Inference done 1677/26446. 0.1983 s / img. ETA=1:22:41
[07/05 10:44:22] detectron2 INFO: Inference done 1703/26446. 0.1983 s / img. ETA=1:22:35
[07/05 10:44:27] detectron2 INFO: Inference done 1729/26446. 0.1983 s / img. ETA=1:22:30
[07/05 10:44:32] detectron2 INFO: Inference done 1754/26446. 0.1983 s / img. ETA=1:22:26
[07/05 10:44:37] detectron2 INFO: Inference done 1780/26446. 0.1983 s / img. ETA=1:22:20
[07/05 10:44:42] detectron2 INFO: Inference done 1806/26446. 0.1983 s / img. ETA=1:22:14
[07/05 10:44:48] detectron2 INFO: Inference done 1832/26446. 0.1982 s / img. ETA=1:22:07
[07/05 10:44:53] detectron2 INFO: Inference done 1857/26446. 0.1983 s / img. ETA=1:22:04
[07/05 10:44:58] detectron2 INFO: Inference done 1882/26446. 0.1983 s / img. ETA=1:21:59
[07/05 10:45:03] detectron2 INFO: Inference done 1908/26446. 0.1982 s / img. ETA=1:21:53
[07/05 10:45:08] detectron2 INFO: Inference done 1933/26446. 0.1983 s / img. ETA=1:21:49
[07/05 10:45:13] detectron2 INFO: Inference done 1959/26446. 0.1982 s / img. ETA=1:21:43
[07/05 10:45:18] detectron2 INFO: Inference done 1985/26446. 0.1981 s / img. ETA=1:21:35
[07/05 10:45:23] detectron2 INFO: Inference done 2010/26446. 0.1982 s / img. ETA=1:21:31
[07/05 10:45:28] detectron2 INFO: Inference done 2035/26446. 0.1982 s / img. ETA=1:21:26
[07/05 10:45:33] detectron2 INFO: Inference done 2061/26446. 0.1982 s / img. ETA=1:21:20
[07/05 10:45:38] detectron2 INFO: Inference done 2086/26446. 0.1982 s / img. ETA=1:21:16
[07/05 10:45:43] detectron2 INFO: Inference done 2111/26446. 0.1982 s / img. ETA=1:21:12
[07/05 10:45:48] detectron2 INFO: Inference done 2136/26446. 0.1982 s / img. ETA=1:21:07
[07/05 10:45:53] detectron2 INFO: Inference done 2161/26446. 0.1982 s / img. ETA=1:21:02
[07/05 10:45:59] detectron2 INFO: Inference done 2186/26446. 0.1983 s / img. ETA=1:20:58
[07/05 10:46:04] detectron2 INFO: Inference done 2212/26446. 0.1982 s / img. ETA=1:20:52
[07/05 10:46:09] detectron2 INFO: Inference done 2238/26446. 0.1982 s / img. ETA=1:20:47
[07/05 10:46:14] detectron2 INFO: Inference done 2263/26446. 0.1983 s / img. ETA=1:20:43
[07/05 10:46:19] detectron2 INFO: Inference done 2288/26446. 0.1983 s / img. ETA=1:20:38
[07/05 10:46:24] detectron2 INFO: Inference done 2314/26446. 0.1983 s / img. ETA=1:20:32
[07/05 10:46:29] detectron2 INFO: Inference done 2340/26446. 0.1982 s / img. ETA=1:20:26
[07/05 10:46:34] detectron2 INFO: Inference done 2366/26446. 0.1982 s / img. ETA=1:20:20
[07/05 10:46:39] detectron2 INFO: Inference done 2391/26446. 0.1982 s / img. ETA=1:20:15
[07/05 10:46:45] detectron2 INFO: Inference done 2411/26446. 0.1987 s / img. ETA=1:20:23
[07/05 10:46:50] detectron2 INFO: Inference done 2436/26446. 0.1987 s / img. ETA=1:20:18
[07/05 10:46:55] detectron2 INFO: Inference done 2461/26446. 0.1987 s / img. ETA=1:20:14
[07/05 10:47:00] detectron2 INFO: Inference done 2486/26446. 0.1987 s / img. ETA=1:20:08
[07/05 10:47:05] detectron2 INFO: Inference done 2511/26446. 0.1987 s / img. ETA=1:20:03
[07/05 10:47:10] detectron2 INFO: Inference done 2537/26446. 0.1987 s / img. ETA=1:19:58
[07/05 10:47:15] detectron2 INFO: Inference done 2563/26446. 0.1987 s / img. ETA=1:19:52
[07/05 10:47:20] detectron2 INFO: Inference done 2588/26446. 0.1987 s / img. ETA=1:19:47
[07/05 10:47:25] detectron2 INFO: Inference done 2613/26446. 0.1987 s / img. ETA=1:19:42
[07/05 10:47:30] detectron2 INFO: Inference done 2638/26446. 0.1987 s / img. ETA=1:19:37
[07/05 10:47:35] detectron2 INFO: Inference done 2664/26446. 0.1986 s / img. ETA=1:19:31
[07/05 10:47:40] detectron2 INFO: Inference done 2689/26446. 0.1987 s / img. ETA=1:19:27
[07/05 10:47:45] detectron2 INFO: Inference done 2714/26446. 0.1987 s / img. ETA=1:19:22
[07/05 10:47:51] detectron2 INFO: Inference done 2740/26446. 0.1987 s / img. ETA=1:19:16
[07/05 10:47:56] detectron2 INFO: Inference done 2765/26446. 0.1987 s / img. ETA=1:19:12
[07/05 10:48:01] detectron2 INFO: Inference done 2791/26446. 0.1987 s / img. ETA=1:19:06
[07/05 10:48:06] detectron2 INFO: Inference done 2817/26446. 0.1987 s / img. ETA=1:19:01
[07/05 10:48:11] detectron2 INFO: Inference done 2842/26446. 0.1987 s / img. ETA=1:18:56
[07/05 10:48:16] detectron2 INFO: Inference done 2868/26446. 0.1987 s / img. ETA=1:18:51
[07/05 10:48:21] detectron2 INFO: Inference done 2893/26446. 0.1987 s / img. ETA=1:18:46
[07/05 10:48:26] detectron2 INFO: Inference done 2918/26446. 0.1987 s / img. ETA=1:18:41
[07/05 10:48:31] detectron2 INFO: Inference done 2943/26446. 0.1987 s / img. ETA=1:18:36
[07/05 10:48:36] detectron2 INFO: Inference done 2969/26446. 0.1986 s / img. ETA=1:18:29
[07/05 10:48:41] detectron2 INFO: Inference done 2994/26446. 0.1986 s / img. ETA=1:18:25
[07/05 10:48:47] detectron2 INFO: Inference done 3019/26446. 0.1987 s / img. ETA=1:18:21
[07/05 10:48:52] detectron2 INFO: Inference done 3045/26446. 0.1987 s / img. ETA=1:18:15
[07/05 10:48:57] detectron2 INFO: Inference done 3070/26446. 0.1987 s / img. ETA=1:18:10
[07/05 10:49:02] detectron2 INFO: Inference done 3095/26446. 0.1987 s / img. ETA=1:18:06
[07/05 10:49:07] detectron2 INFO: Inference done 3120/26446. 0.1987 s / img. ETA=1:18:01
[07/05 10:49:12] detectron2 INFO: Inference done 3146/26446. 0.1987 s / img. ETA=1:17:56
[07/05 10:49:17] detectron2 INFO: Inference done 3171/26446. 0.1987 s / img. ETA=1:17:51
[07/05 10:49:22] detectron2 INFO: Inference done 3197/26446. 0.1987 s / img. ETA=1:17:45
[07/05 10:49:27] detectron2 INFO: Inference done 3222/26446. 0.1987 s / img. ETA=1:17:41
[07/05 10:49:33] detectron2 INFO: Inference done 3247/26446. 0.1987 s / img. ETA=1:17:36
[07/05 10:49:38] detectron2 INFO: Inference done 3272/26446. 0.1988 s / img. ETA=1:17:32
[07/05 10:49:43] detectron2 INFO: Inference done 3297/26446. 0.1988 s / img. ETA=1:17:28
[07/05 10:49:48] detectron2 INFO: Inference done 3322/26446. 0.1988 s / img. ETA=1:17:23
[07/05 10:49:53] detectron2 INFO: Inference done 3347/26446. 0.1988 s / img. ETA=1:17:19
[07/05 10:49:58] detectron2 INFO: Inference done 3373/26446. 0.1988 s / img. ETA=1:17:13
[07/05 10:50:03] detectron2 INFO: Inference done 3398/26446. 0.1988 s / img. ETA=1:17:09
[07/05 10:50:08] detectron2 INFO: Inference done 3423/26446. 0.1989 s / img. ETA=1:17:04
[07/05 10:50:13] detectron2 INFO: Inference done 3448/26446. 0.1989 s / img. ETA=1:16:59
[07/05 10:50:18] detectron2 INFO: Inference done 3473/26446. 0.1989 s / img. ETA=1:16:54
[07/05 10:50:24] detectron2 INFO: Inference done 3498/26446. 0.1989 s / img. ETA=1:16:50
[07/05 10:50:29] detectron2 INFO: Inference done 3522/26446. 0.1989 s / img. ETA=1:16:46
[07/05 10:50:34] detectron2 INFO: Inference done 3547/26446. 0.1990 s / img. ETA=1:16:42
[07/05 10:50:39] detectron2 INFO: Inference done 3572/26446. 0.1990 s / img. ETA=1:16:37
[07/05 10:50:44] detectron2 INFO: Inference done 3597/26446. 0.1990 s / img. ETA=1:16:33
[07/05 10:50:49] detectron2 INFO: Inference done 3622/26446. 0.1990 s / img. ETA=1:16:28
[07/05 10:50:54] detectron2 INFO: Inference done 3647/26446. 0.1991 s / img. ETA=1:16:24
[07/05 10:50:59] detectron2 INFO: Inference done 3671/26446. 0.1991 s / img. ETA=1:16:20
[07/05 10:51:04] detectron2 INFO: Inference done 3697/26446. 0.1991 s / img. ETA=1:16:15
[07/05 10:51:09] detectron2 INFO: Inference done 3722/26446. 0.1991 s / img. ETA=1:16:10
[07/05 10:51:14] detectron2 INFO: Inference done 3748/26446. 0.1991 s / img. ETA=1:16:04
[07/05 10:51:20] detectron2 INFO: Inference done 3773/26446. 0.1991 s / img. ETA=1:15:59
[07/05 10:51:25] detectron2 INFO: Inference done 3799/26446. 0.1991 s / img. ETA=1:15:53
[07/05 10:51:30] detectron2 INFO: Inference done 3824/26446. 0.1991 s / img. ETA=1:15:49
[07/05 10:51:35] detectron2 INFO: Inference done 3850/26446. 0.1991 s / img. ETA=1:15:43
[07/05 10:51:40] detectron2 INFO: Inference done 3875/26446. 0.1991 s / img. ETA=1:15:38
[07/05 10:51:45] detectron2 INFO: Inference done 3900/26446. 0.1991 s / img. ETA=1:15:33
[07/05 10:51:50] detectron2 INFO: Inference done 3926/26446. 0.1990 s / img. ETA=1:15:27
[07/05 10:51:55] detectron2 INFO: Inference done 3952/26446. 0.1990 s / img. ETA=1:15:22
[07/05 10:52:00] detectron2 INFO: Inference done 3978/26446. 0.1990 s / img. ETA=1:15:16
[07/05 10:52:06] detectron2 INFO: Inference done 4004/26446. 0.1990 s / img. ETA=1:15:10
[07/05 10:52:11] detectron2 INFO: Inference done 4030/26446. 0.1990 s / img. ETA=1:15:04
[07/05 10:52:16] detectron2 INFO: Inference done 4056/26446. 0.1989 s / img. ETA=1:14:58
[07/05 10:52:21] detectron2 INFO: Inference done 4081/26446. 0.1989 s / img. ETA=1:14:54
[07/05 10:52:26] detectron2 INFO: Inference done 4106/26446. 0.1989 s / img. ETA=1:14:48
[07/05 10:52:31] detectron2 INFO: Inference done 4131/26446. 0.1989 s / img. ETA=1:14:43
[07/05 10:52:36] detectron2 INFO: Inference done 4157/26446. 0.1989 s / img. ETA=1:14:38
[07/05 10:52:41] detectron2 INFO: Inference done 4182/26446. 0.1990 s / img. ETA=1:14:34
[07/05 10:52:46] detectron2 INFO: Inference done 4207/26446. 0.1990 s / img. ETA=1:14:29
[07/05 10:52:51] detectron2 INFO: Inference done 4232/26446. 0.1990 s / img. ETA=1:14:24
[07/05 10:52:56] detectron2 INFO: Inference done 4257/26446. 0.1990 s / img. ETA=1:14:19
[07/05 10:53:02] detectron2 INFO: Inference done 4283/26446. 0.1990 s / img. ETA=1:14:14
[07/05 10:53:07] detectron2 INFO: Inference done 4308/26446. 0.1990 s / img. ETA=1:14:09
[07/05 10:53:12] detectron2 INFO: Inference done 4334/26446. 0.1990 s / img. ETA=1:14:03
[07/05 10:53:17] detectron2 INFO: Inference done 4359/26446. 0.1990 s / img. ETA=1:13:58
[07/05 10:53:22] detectron2 INFO: Inference done 4385/26446. 0.1989 s / img. ETA=1:13:52
[07/05 10:53:27] detectron2 INFO: Inference done 4410/26446. 0.1989 s / img. ETA=1:13:47
[07/05 10:53:32] detectron2 INFO: Inference done 4436/26446. 0.1989 s / img. ETA=1:13:41
[07/05 10:53:37] detectron2 INFO: Inference done 4462/26446. 0.1989 s / img. ETA=1:13:35
[07/05 10:53:42] detectron2 INFO: Inference done 4488/26446. 0.1988 s / img. ETA=1:13:29
[07/05 10:53:47] detectron2 INFO: Inference done 4513/26446. 0.1988 s / img. ETA=1:13:24
[07/05 10:53:52] detectron2 INFO: Inference done 4538/26446. 0.1988 s / img. ETA=1:13:20
[07/05 10:53:57] detectron2 INFO: Inference done 4563/26446. 0.1988 s / img. ETA=1:13:14
[07/05 10:54:02] detectron2 INFO: Inference done 4589/26446. 0.1988 s / img. ETA=1:13:09
[07/05 10:54:07] detectron2 INFO: Inference done 4615/26446. 0.1988 s / img. ETA=1:13:03
[07/05 10:54:13] detectron2 INFO: Inference done 4640/26446. 0.1988 s / img. ETA=1:12:58
[07/05 10:54:18] detectron2 INFO: Inference done 4665/26446. 0.1988 s / img. ETA=1:12:53
[07/05 10:54:23] detectron2 INFO: Inference done 4691/26446. 0.1988 s / img. ETA=1:12:48
[07/05 10:54:28] detectron2 INFO: Inference done 4717/26446. 0.1988 s / img. ETA=1:12:42
[07/05 10:54:33] detectron2 INFO: Inference done 4742/26446. 0.1988 s / img. ETA=1:12:37
[07/05 10:54:38] detectron2 INFO: Inference done 4767/26446. 0.1988 s / img. ETA=1:12:32
[07/05 10:54:43] detectron2 INFO: Inference done 4793/26446. 0.1987 s / img. ETA=1:12:26
[07/05 10:54:48] detectron2 INFO: Inference done 4818/26446. 0.1987 s / img. ETA=1:12:21
[07/05 10:54:53] detectron2 INFO: Inference done 4843/26446. 0.1987 s / img. ETA=1:12:16
[07/05 10:54:58] detectron2 INFO: Inference done 4868/26446. 0.1988 s / img. ETA=1:12:12
[07/05 10:55:03] detectron2 INFO: Inference done 4892/26446. 0.1989 s / img. ETA=1:12:09
[07/05 10:55:08] detectron2 INFO: Inference done 4917/26446. 0.1989 s / img. ETA=1:12:04
[07/05 10:55:14] detectron2 INFO: Inference done 4941/26446. 0.1989 s / img. ETA=1:12:01
[07/05 10:55:19] detectron2 INFO: Inference done 4962/26446. 0.1991 s / img. ETA=1:12:00
[07/05 10:55:24] detectron2 INFO: Inference done 4986/26446. 0.1991 s / img. ETA=1:11:56
[07/05 10:55:29] detectron2 INFO: Inference done 5010/26446. 0.1992 s / img. ETA=1:11:52
[07/05 10:55:34] detectron2 INFO: Inference done 5035/26446. 0.1992 s / img. ETA=1:11:48
[07/05 10:55:39] detectron2 INFO: Inference done 5059/26446. 0.1992 s / img. ETA=1:11:44
[07/05 10:55:44] detectron2 INFO: Inference done 5084/26446. 0.1993 s / img. ETA=1:11:39
[07/05 10:55:49] detectron2 INFO: Inference done 5108/26446. 0.1993 s / img. ETA=1:11:35
[07/05 10:55:54] detectron2 INFO: Inference done 5133/26446. 0.1993 s / img. ETA=1:11:30
[07/05 10:55:59] detectron2 INFO: Inference done 5158/26446. 0.1993 s / img. ETA=1:11:25
[07/05 10:56:04] detectron2 INFO: Inference done 5184/26446. 0.1993 s / img. ETA=1:11:19
[07/05 10:56:09] detectron2 INFO: Inference done 5209/26446. 0.1993 s / img. ETA=1:11:15
[07/05 10:56:15] detectron2 INFO: Inference done 5235/26446. 0.1993 s / img. ETA=1:11:09
[07/05 10:56:20] detectron2 INFO: Inference done 5260/26446. 0.1993 s / img. ETA=1:11:05
[07/05 10:56:25] detectron2 INFO: Inference done 5285/26446. 0.1993 s / img. ETA=1:11:00
[07/05 10:56:30] detectron2 INFO: Inference done 5310/26446. 0.1993 s / img. ETA=1:10:55
[07/05 10:56:35] detectron2 INFO: Inference done 5335/26446. 0.1994 s / img. ETA=1:10:51
[07/05 10:56:40] detectron2 INFO: Inference done 5360/26446. 0.1994 s / img. ETA=1:10:46
[07/05 10:56:45] detectron2 INFO: Inference done 5385/26446. 0.1994 s / img. ETA=1:10:42
[07/05 10:56:51] detectron2 INFO: Inference done 5410/26446. 0.1994 s / img. ETA=1:10:37
[07/05 10:56:56] detectron2 INFO: Inference done 5435/26446. 0.1994 s / img. ETA=1:10:32
[07/05 10:57:01] detectron2 INFO: Inference done 5461/26446. 0.1994 s / img. ETA=1:10:27
[07/05 10:57:06] detectron2 INFO: Inference done 5486/26446. 0.1994 s / img. ETA=1:10:22
[07/05 10:57:11] detectron2 INFO: Inference done 5511/26446. 0.1994 s / img. ETA=1:10:17
[07/05 10:57:16] detectron2 INFO: Inference done 5536/26446. 0.1995 s / img. ETA=1:10:12
[07/05 10:57:21] detectron2 INFO: Inference done 5561/26446. 0.1995 s / img. ETA=1:10:08
[07/05 10:57:26] detectron2 INFO: Inference done 5586/26446. 0.1995 s / img. ETA=1:10:03
[07/05 10:57:32] detectron2 INFO: Inference done 5611/26446. 0.1995 s / img. ETA=1:09:58
[07/05 10:57:37] detectron2 INFO: Inference done 5636/26446. 0.1995 s / img. ETA=1:09:54
[07/05 10:57:42] detectron2 INFO: Inference done 5661/26446. 0.1996 s / img. ETA=1:09:49
[07/05 10:57:47] detectron2 INFO: Inference done 5686/26446. 0.1996 s / img. ETA=1:09:45
[07/05 10:57:52] detectron2 INFO: Inference done 5711/26446. 0.1996 s / img. ETA=1:09:40
[07/05 10:57:57] detectron2 INFO: Inference done 5736/26446. 0.1996 s / img. ETA=1:09:35
[07/05 10:58:02] detectron2 INFO: Inference done 5761/26446. 0.1996 s / img. ETA=1:09:31
[07/05 10:58:07] detectron2 INFO: Inference done 5786/26446. 0.1996 s / img. ETA=1:09:26
[07/05 10:58:13] detectron2 INFO: Inference done 5811/26446. 0.1997 s / img. ETA=1:09:21
[07/05 10:58:18] detectron2 INFO: Inference done 5836/26446. 0.1997 s / img. ETA=1:09:16
[07/05 10:58:23] detectron2 INFO: Inference done 5860/26446. 0.1997 s / img. ETA=1:09:12
[07/05 10:58:28] detectron2 INFO: Inference done 5884/26446. 0.1997 s / img. ETA=1:09:08
[07/05 10:58:33] detectron2 INFO: Inference done 5909/26446. 0.1997 s / img. ETA=1:09:03
[07/05 10:58:38] detectron2 INFO: Inference done 5934/26446. 0.1998 s / img. ETA=1:08:59
[07/05 10:58:43] detectron2 INFO: Inference done 5958/26446. 0.1998 s / img. ETA=1:08:54
[07/05 10:58:48] detectron2 INFO: Inference done 5982/26446. 0.1998 s / img. ETA=1:08:50
[07/05 10:58:53] detectron2 INFO: Inference done 6006/26446. 0.1999 s / img. ETA=1:08:46
[07/05 10:58:58] detectron2 INFO: Inference done 6030/26446. 0.1999 s / img. ETA=1:08:42
[07/05 10:59:03] detectron2 INFO: Inference done 6054/26446. 0.1999 s / img. ETA=1:08:38
[07/05 10:59:08] detectron2 INFO: Inference done 6078/26446. 0.2000 s / img. ETA=1:08:34
[07/05 10:59:14] detectron2 INFO: Inference done 6103/26446. 0.2000 s / img. ETA=1:08:29
[07/05 10:59:19] detectron2 INFO: Inference done 6128/26446. 0.2000 s / img. ETA=1:08:24
[07/05 10:59:24] detectron2 INFO: Inference done 6153/26446. 0.2000 s / img. ETA=1:08:19
[07/05 10:59:29] detectron2 INFO: Inference done 6179/26446. 0.2000 s / img. ETA=1:08:14
[07/05 10:59:34] detectron2 INFO: Inference done 6204/26446. 0.2000 s / img. ETA=1:08:09
[07/05 10:59:39] detectron2 INFO: Inference done 6229/26446. 0.2000 s / img. ETA=1:08:04
[07/05 10:59:44] detectron2 INFO: Inference done 6253/26446. 0.2000 s / img. ETA=1:08:00
[07/05 10:59:49] detectron2 INFO: Inference done 6278/26446. 0.2001 s / img. ETA=1:07:55
[07/05 10:59:55] detectron2 INFO: Inference done 6303/26446. 0.2001 s / img. ETA=1:07:50
[07/05 11:00:00] detectron2 INFO: Inference done 6328/26446. 0.2001 s / img. ETA=1:07:45
[07/05 11:00:05] detectron2 INFO: Inference done 6351/26446. 0.2001 s / img. ETA=1:07:42
[07/05 11:00:10] detectron2 INFO: Inference done 6375/26446. 0.2002 s / img. ETA=1:07:37
[07/05 11:00:15] detectron2 INFO: Inference done 6400/26446. 0.2001 s / img. ETA=1:07:32
[07/05 11:00:20] detectron2 INFO: Inference done 6424/26446. 0.2002 s / img. ETA=1:07:28
[07/05 11:00:25] detectron2 INFO: Inference done 6449/26446. 0.2002 s / img. ETA=1:07:24
[07/05 11:00:30] detectron2 INFO: Inference done 6474/26446. 0.2002 s / img. ETA=1:07:19
[07/05 11:00:35] detectron2 INFO: Inference done 6499/26446. 0.2002 s / img. ETA=1:07:14
[07/05 11:00:40] detectron2 INFO: Inference done 6523/26446. 0.2003 s / img. ETA=1:07:10
[07/05 11:00:45] detectron2 INFO: Inference done 6548/26446. 0.2003 s / img. ETA=1:07:05
[07/05 11:00:50] detectron2 INFO: Inference done 6572/26446. 0.2003 s / img. ETA=1:07:00
[07/05 11:00:56] detectron2 INFO: Inference done 6597/26446. 0.2003 s / img. ETA=1:06:56
[07/05 11:01:01] detectron2 INFO: Inference done 6621/26446. 0.2003 s / img. ETA=1:06:51
[07/05 11:01:06] detectron2 INFO: Inference done 6646/26446. 0.2003 s / img. ETA=1:06:46
[07/05 11:01:11] detectron2 INFO: Inference done 6670/26446. 0.2004 s / img. ETA=1:06:42
[07/05 11:01:16] detectron2 INFO: Inference done 6695/26446. 0.2004 s / img. ETA=1:06:37
[07/05 11:01:21] detectron2 INFO: Inference done 6720/26446. 0.2004 s / img. ETA=1:06:32
[07/05 11:01:26] detectron2 INFO: Inference done 6745/26446. 0.2004 s / img. ETA=1:06:27
[07/05 11:01:31] detectron2 INFO: Inference done 6771/26446. 0.2004 s / img. ETA=1:06:22
[07/05 11:01:36] detectron2 INFO: Inference done 6796/26446. 0.2004 s / img. ETA=1:06:17
[07/05 11:01:41] detectron2 INFO: Inference done 6820/26446. 0.2004 s / img. ETA=1:06:13
[07/05 11:01:46] detectron2 INFO: Inference done 6844/26446. 0.2004 s / img. ETA=1:06:08
[07/05 11:01:51] detectron2 INFO: Inference done 6869/26446. 0.2004 s / img. ETA=1:06:03
[07/05 11:01:57] detectron2 INFO: Inference done 6895/26446. 0.2004 s / img. ETA=1:05:57
[07/05 11:02:02] detectron2 INFO: Inference done 6921/26446. 0.2004 s / img. ETA=1:05:52
[07/05 11:02:07] detectron2 INFO: Inference done 6946/26446. 0.2004 s / img. ETA=1:05:47
[07/05 11:02:12] detectron2 INFO: Inference done 6971/26446. 0.2004 s / img. ETA=1:05:42
[07/05 11:02:17] detectron2 INFO: Inference done 6996/26446. 0.2004 s / img. ETA=1:05:37
[07/05 11:02:22] detectron2 INFO: Inference done 7020/26446. 0.2005 s / img. ETA=1:05:33
[07/05 11:02:27] detectron2 INFO: Inference done 7045/26446. 0.2005 s / img. ETA=1:05:28
[07/05 11:02:33] detectron2 INFO: Inference done 7069/26446. 0.2005 s / img. ETA=1:05:24
[07/05 11:02:38] detectron2 INFO: Inference done 7094/26446. 0.2005 s / img. ETA=1:05:19
[07/05 11:02:43] detectron2 INFO: Inference done 7118/26446. 0.2005 s / img. ETA=1:05:15
[07/05 11:02:48] detectron2 INFO: Inference done 7143/26446. 0.2006 s / img. ETA=1:05:10
[07/05 11:02:53] detectron2 INFO: Inference done 7168/26446. 0.2006 s / img. ETA=1:05:05
[07/05 11:02:58] detectron2 INFO: Inference done 7193/26446. 0.2006 s / img. ETA=1:05:00
[07/05 11:03:03] detectron2 INFO: Inference done 7218/26446. 0.2006 s / img. ETA=1:04:55
[07/05 11:03:08] detectron2 INFO: Inference done 7243/26446. 0.2006 s / img. ETA=1:04:50
[07/05 11:03:13] detectron2 INFO: Inference done 7268/26446. 0.2006 s / img. ETA=1:04:45
[07/05 11:03:18] detectron2 INFO: Inference done 7292/26446. 0.2006 s / img. ETA=1:04:41
[07/05 11:03:24] detectron2 INFO: Inference done 7317/26446. 0.2006 s / img. ETA=1:04:36
[07/05 11:03:29] detectron2 INFO: Inference done 7341/26446. 0.2007 s / img. ETA=1:04:32
[07/05 11:03:34] detectron2 INFO: Inference done 7365/26446. 0.2007 s / img. ETA=1:04:27
[07/05 11:03:39] detectron2 INFO: Inference done 7390/26446. 0.2007 s / img. ETA=1:04:23
[07/05 11:03:44] detectron2 INFO: Inference done 7415/26446. 0.2007 s / img. ETA=1:04:18
[07/05 11:03:49] detectron2 INFO: Inference done 7440/26446. 0.2007 s / img. ETA=1:04:13
[07/05 11:03:54] detectron2 INFO: Inference done 7464/26446. 0.2007 s / img. ETA=1:04:08
[07/05 11:03:59] detectron2 INFO: Inference done 7489/26446. 0.2007 s / img. ETA=1:04:04
[07/05 11:04:05] detectron2 INFO: Inference done 7514/26446. 0.2008 s / img. ETA=1:03:59
[07/05 11:04:10] detectron2 INFO: Inference done 7539/26446. 0.2008 s / img. ETA=1:03:54
[07/05 11:04:15] detectron2 INFO: Inference done 7563/26446. 0.2008 s / img. ETA=1:03:49
[07/05 11:04:20] detectron2 INFO: Inference done 7587/26446. 0.2008 s / img. ETA=1:03:45
[07/05 11:04:25] detectron2 INFO: Inference done 7612/26446. 0.2008 s / img. ETA=1:03:40
[07/05 11:04:30] detectron2 INFO: Inference done 7637/26446. 0.2008 s / img. ETA=1:03:35
[07/05 11:04:35] detectron2 INFO: Inference done 7661/26446. 0.2009 s / img. ETA=1:03:31
[07/05 11:04:40] detectron2 INFO: Inference done 7685/26446. 0.2009 s / img. ETA=1:03:27
[07/05 11:04:46] detectron2 INFO: Inference done 7710/26446. 0.2009 s / img. ETA=1:03:22
[07/05 11:04:51] detectron2 INFO: Inference done 7735/26446. 0.2009 s / img. ETA=1:03:17
[07/05 11:04:56] detectron2 INFO: Inference done 7759/26446. 0.2009 s / img. ETA=1:03:13
[07/05 11:05:01] detectron2 INFO: Inference done 7784/26446. 0.2010 s / img. ETA=1:03:08
[07/05 11:05:06] detectron2 INFO: Inference done 7809/26446. 0.2010 s / img. ETA=1:03:03
[07/05 11:05:11] detectron2 INFO: Inference done 7833/26446. 0.2010 s / img. ETA=1:02:59
[07/05 11:05:16] detectron2 INFO: Inference done 7858/26446. 0.2010 s / img. ETA=1:02:54
[07/05 11:05:21] detectron2 INFO: Inference done 7883/26446. 0.2010 s / img. ETA=1:02:49
[07/05 11:05:26] detectron2 INFO: Inference done 7908/26446. 0.2010 s / img. ETA=1:02:44
[07/05 11:05:32] detectron2 INFO: Inference done 7933/26446. 0.2010 s / img. ETA=1:02:39
[07/05 11:05:37] detectron2 INFO: Inference done 7958/26446. 0.2010 s / img. ETA=1:02:34
[07/05 11:05:42] detectron2 INFO: Inference done 7983/26446. 0.2010 s / img. ETA=1:02:29
[07/05 11:05:47] detectron2 INFO: Inference done 8007/26446. 0.2011 s / img. ETA=1:02:25
[07/05 11:05:52] detectron2 INFO: Inference done 8030/26446. 0.2011 s / img. ETA=1:02:21
[07/05 11:05:57] detectron2 INFO: Inference done 8054/26446. 0.2012 s / img. ETA=1:02:17
[07/05 11:06:02] detectron2 INFO: Inference done 8079/26446. 0.2012 s / img. ETA=1:02:12
[07/05 11:06:07] detectron2 INFO: Inference done 8103/26446. 0.2012 s / img. ETA=1:02:07
[07/05 11:06:12] detectron2 INFO: Inference done 8127/26446. 0.2012 s / img. ETA=1:02:03
[07/05 11:06:18] detectron2 INFO: Inference done 8152/26446. 0.2012 s / img. ETA=1:01:58
[07/05 11:06:23] detectron2 INFO: Inference done 8177/26446. 0.2012 s / img. ETA=1:01:53
[07/05 11:06:28] detectron2 INFO: Inference done 8201/26446. 0.2012 s / img. ETA=1:01:48
[07/05 11:06:33] detectron2 INFO: Inference done 8225/26446. 0.2013 s / img. ETA=1:01:44
[07/05 11:06:38] detectron2 INFO: Inference done 8249/26446. 0.2013 s / img. ETA=1:01:39
[07/05 11:06:43] detectron2 INFO: Inference done 8273/26446. 0.2013 s / img. ETA=1:01:35
[07/05 11:06:48] detectron2 INFO: Inference done 8298/26446. 0.2013 s / img. ETA=1:01:30
[07/05 11:06:53] detectron2 INFO: Inference done 8323/26446. 0.2013 s / img. ETA=1:01:25
[07/05 11:06:58] detectron2 INFO: Inference done 8348/26446. 0.2013 s / img. ETA=1:01:20
[07/05 11:07:04] detectron2 INFO: Inference done 8373/26446. 0.2013 s / img. ETA=1:01:15
[07/05 11:07:09] detectron2 INFO: Inference done 8397/26446. 0.2014 s / img. ETA=1:01:11
[07/05 11:07:14] detectron2 INFO: Inference done 8423/26446. 0.2013 s / img. ETA=1:01:05
[07/05 11:07:19] detectron2 INFO: Inference done 8447/26446. 0.2014 s / img. ETA=1:01:01
[07/05 11:07:24] detectron2 INFO: Inference done 8472/26446. 0.2014 s / img. ETA=1:00:56
[07/05 11:07:29] detectron2 INFO: Inference done 8496/26446. 0.2014 s / img. ETA=1:00:51
[07/05 11:07:34] detectron2 INFO: Inference done 8521/26446. 0.2014 s / img. ETA=1:00:46
[07/05 11:07:39] detectron2 INFO: Inference done 8546/26446. 0.2014 s / img. ETA=1:00:41
[07/05 11:07:44] detectron2 INFO: Inference done 8570/26446. 0.2014 s / img. ETA=1:00:36
[07/05 11:07:49] detectron2 INFO: Inference done 8595/26446. 0.2014 s / img. ETA=1:00:31
[07/05 11:07:54] detectron2 INFO: Inference done 8620/26446. 0.2014 s / img. ETA=1:00:26
[07/05 11:08:00] detectron2 INFO: Inference done 8639/26446. 0.2016 s / img. ETA=1:00:25
[07/05 11:08:05] detectron2 INFO: Inference done 8664/26446. 0.2016 s / img. ETA=1:00:20
[07/05 11:08:10] detectron2 INFO: Inference done 8689/26446. 0.2016 s / img. ETA=1:00:15
[07/05 11:08:15] detectron2 INFO: Inference done 8713/26446. 0.2016 s / img. ETA=1:00:10
[07/05 11:08:20] detectron2 INFO: Inference done 8738/26446. 0.2016 s / img. ETA=1:00:06
[07/05 11:08:25] detectron2 INFO: Inference done 8762/26446. 0.2016 s / img. ETA=1:00:01
[07/05 11:08:30] detectron2 INFO: Inference done 8787/26446. 0.2016 s / img. ETA=0:59:56
[07/05 11:08:36] detectron2 INFO: Inference done 8812/26446. 0.2016 s / img. ETA=0:59:51
[07/05 11:08:41] detectron2 INFO: Inference done 8837/26446. 0.2016 s / img. ETA=0:59:46
[07/05 11:08:46] detectron2 INFO: Inference done 8862/26446. 0.2016 s / img. ETA=0:59:41
[07/05 11:08:51] detectron2 INFO: Inference done 8887/26446. 0.2016 s / img. ETA=0:59:36
[07/05 11:08:56] detectron2 INFO: Inference done 8911/26446. 0.2017 s / img. ETA=0:59:31
[07/05 11:09:01] detectron2 INFO: Inference done 8935/26446. 0.2017 s / img. ETA=0:59:27
[07/05 11:09:06] detectron2 INFO: Inference done 8960/26446. 0.2017 s / img. ETA=0:59:22
[07/05 11:09:11] detectron2 INFO: Inference done 8985/26446. 0.2017 s / img. ETA=0:59:17
[07/05 11:09:16] detectron2 INFO: Inference done 9010/26446. 0.2017 s / img. ETA=0:59:12
[07/05 11:09:21] detectron2 INFO: Inference done 9034/26446. 0.2017 s / img. ETA=0:59:07
[07/05 11:09:27] detectron2 INFO: Inference done 9059/26446. 0.2017 s / img. ETA=0:59:02
[07/05 11:09:32] detectron2 INFO: Inference done 9084/26446. 0.2017 s / img. ETA=0:58:57
[07/05 11:09:37] detectron2 INFO: Inference done 9109/26446. 0.2017 s / img. ETA=0:58:52
[07/05 11:09:42] detectron2 INFO: Inference done 9134/26446. 0.2017 s / img. ETA=0:58:47
[07/05 11:09:47] detectron2 INFO: Inference done 9158/26446. 0.2018 s / img. ETA=0:58:43
[07/05 11:09:52] detectron2 INFO: Inference done 9181/26446. 0.2018 s / img. ETA=0:58:39
[07/05 11:09:57] detectron2 INFO: Inference done 9205/26446. 0.2018 s / img. ETA=0:58:34
[07/05 11:10:02] detectron2 INFO: Inference done 9230/26446. 0.2018 s / img. ETA=0:58:29
[07/05 11:10:07] detectron2 INFO: Inference done 9255/26446. 0.2018 s / img. ETA=0:58:24
[07/05 11:10:13] detectron2 INFO: Inference done 9280/26446. 0.2018 s / img. ETA=0:58:19
[07/05 11:10:18] detectron2 INFO: Inference done 9304/26446. 0.2018 s / img. ETA=0:58:15
[07/05 11:10:23] detectron2 INFO: Inference done 9328/26446. 0.2018 s / img. ETA=0:58:10
[07/05 11:10:28] detectron2 INFO: Inference done 9352/26446. 0.2019 s / img. ETA=0:58:05
[07/05 11:10:33] detectron2 INFO: Inference done 9373/26446. 0.2020 s / img. ETA=0:58:03
[07/05 11:10:38] detectron2 INFO: Inference done 9398/26446. 0.2020 s / img. ETA=0:57:58
[07/05 11:10:43] detectron2 INFO: Inference done 9423/26446. 0.2020 s / img. ETA=0:57:53
[07/05 11:10:48] detectron2 INFO: Inference done 9448/26446. 0.2020 s / img. ETA=0:57:47
[07/05 11:10:53] detectron2 INFO: Inference done 9473/26446. 0.2020 s / img. ETA=0:57:42
[07/05 11:10:59] detectron2 INFO: Inference done 9499/26446. 0.2019 s / img. ETA=0:57:37
[07/05 11:11:04] detectron2 INFO: Inference done 9524/26446. 0.2020 s / img. ETA=0:57:32
[07/05 11:11:09] detectron2 INFO: Inference done 9550/26446. 0.2019 s / img. ETA=0:57:26
[07/05 11:11:14] detectron2 INFO: Inference done 9576/26446. 0.2019 s / img. ETA=0:57:21
[07/05 11:11:19] detectron2 INFO: Inference done 9602/26446. 0.2019 s / img. ETA=0:57:15
[07/05 11:11:24] detectron2 INFO: Inference done 9628/26446. 0.2019 s / img. ETA=0:57:09
[07/05 11:11:29] detectron2 INFO: Inference done 9653/26446. 0.2019 s / img. ETA=0:57:04
[07/05 11:11:35] detectron2 INFO: Inference done 9679/26446. 0.2019 s / img. ETA=0:56:59
[07/05 11:11:40] detectron2 INFO: Inference done 9704/26446. 0.2019 s / img. ETA=0:56:54
[07/05 11:11:45] detectron2 INFO: Inference done 9729/26446. 0.2019 s / img. ETA=0:56:49
[07/05 11:11:50] detectron2 INFO: Inference done 9755/26446. 0.2019 s / img. ETA=0:56:43
[07/05 11:11:55] detectron2 INFO: Inference done 9781/26446. 0.2018 s / img. ETA=0:56:37
[07/05 11:12:00] detectron2 INFO: Inference done 9807/26446. 0.2018 s / img. ETA=0:56:32
[07/05 11:12:05] detectron2 INFO: Inference done 9831/26446. 0.2018 s / img. ETA=0:56:27
[07/05 11:12:10] detectron2 INFO: Inference done 9855/26446. 0.2019 s / img. ETA=0:56:23
[07/05 11:12:15] detectron2 INFO: Inference done 9880/26446. 0.2018 s / img. ETA=0:56:17
[07/05 11:12:20] detectron2 INFO: Inference done 9905/26446. 0.2019 s / img. ETA=0:56:12
[07/05 11:12:25] detectron2 INFO: Inference done 9929/26446. 0.2019 s / img. ETA=0:56:08
[07/05 11:12:31] detectron2 INFO: Inference done 9954/26446. 0.2019 s / img. ETA=0:56:02
[07/05 11:12:36] detectron2 INFO: Inference done 9979/26446. 0.2019 s / img. ETA=0:55:58
[07/05 11:12:41] detectron2 INFO: Inference done 10004/26446. 0.2019 s / img. ETA=0:55:52
[07/05 11:12:46] detectron2 INFO: Inference done 10028/26446. 0.2019 s / img. ETA=0:55:48
[07/05 11:12:51] detectron2 INFO: Inference done 10052/26446. 0.2019 s / img. ETA=0:55:43
[07/05 11:12:56] detectron2 INFO: Inference done 10078/26446. 0.2019 s / img. ETA=0:55:37
[07/05 11:13:01] detectron2 INFO: Inference done 10103/26446. 0.2019 s / img. ETA=0:55:32
[07/05 11:13:06] detectron2 INFO: Inference done 10128/26446. 0.2019 s / img. ETA=0:55:27
[07/05 11:13:11] detectron2 INFO: Inference done 10153/26446. 0.2019 s / img. ETA=0:55:22
[07/05 11:13:16] detectron2 INFO: Inference done 10179/26446. 0.2019 s / img. ETA=0:55:16
[07/05 11:13:21] detectron2 INFO: Inference done 10205/26446. 0.2018 s / img. ETA=0:55:11
[07/05 11:13:27] detectron2 INFO: Inference done 10230/26446. 0.2018 s / img. ETA=0:55:06
[07/05 11:13:32] detectron2 INFO: Inference done 10254/26446. 0.2019 s / img. ETA=0:55:01
[07/05 11:13:37] detectron2 INFO: Inference done 10278/26446. 0.2019 s / img. ETA=0:54:57
[07/05 11:13:42] detectron2 INFO: Inference done 10303/26446. 0.2019 s / img. ETA=0:54:52
[07/05 11:13:47] detectron2 INFO: Inference done 10328/26446. 0.2019 s / img. ETA=0:54:46
[07/05 11:13:52] detectron2 INFO: Inference done 10353/26446. 0.2019 s / img. ETA=0:54:42
[07/05 11:13:57] detectron2 INFO: Inference done 10377/26446. 0.2019 s / img. ETA=0:54:37
[07/05 11:14:02] detectron2 INFO: Inference done 10402/26446. 0.2019 s / img. ETA=0:54:32
[07/05 11:14:07] detectron2 INFO: Inference done 10427/26446. 0.2019 s / img. ETA=0:54:27
[07/05 11:14:13] detectron2 INFO: Inference done 10452/26446. 0.2019 s / img. ETA=0:54:22
[07/05 11:14:18] detectron2 INFO: Inference done 10476/26446. 0.2019 s / img. ETA=0:54:17
[07/05 11:14:23] detectron2 INFO: Inference done 10500/26446. 0.2019 s / img. ETA=0:54:12
[07/05 11:14:28] detectron2 INFO: Inference done 10524/26446. 0.2019 s / img. ETA=0:54:08
[07/05 11:14:33] detectron2 INFO: Inference done 10548/26446. 0.2020 s / img. ETA=0:54:03
[07/05 11:14:38] detectron2 INFO: Inference done 10573/26446. 0.2020 s / img. ETA=0:53:58
[07/05 11:14:43] detectron2 INFO: Inference done 10597/26446. 0.2020 s / img. ETA=0:53:53
[07/05 11:14:48] detectron2 INFO: Inference done 10622/26446. 0.2020 s / img. ETA=0:53:48
[07/05 11:14:53] detectron2 INFO: Inference done 10646/26446. 0.2020 s / img. ETA=0:53:44
[07/05 11:14:58] detectron2 INFO: Inference done 10670/26446. 0.2020 s / img. ETA=0:53:39
[07/05 11:15:03] detectron2 INFO: Inference done 10694/26446. 0.2020 s / img. ETA=0:53:34
[07/05 11:15:08] detectron2 INFO: Inference done 10718/26446. 0.2021 s / img. ETA=0:53:30
[07/05 11:15:14] detectron2 INFO: Inference done 10743/26446. 0.2021 s / img. ETA=0:53:25
[07/05 11:15:19] detectron2 INFO: Inference done 10768/26446. 0.2021 s / img. ETA=0:53:19
[07/05 11:15:24] detectron2 INFO: Inference done 10793/26446. 0.2021 s / img. ETA=0:53:14
[07/05 11:15:29] detectron2 INFO: Inference done 10817/26446. 0.2021 s / img. ETA=0:53:10
[07/05 11:15:34] detectron2 INFO: Inference done 10842/26446. 0.2021 s / img. ETA=0:53:05
[07/05 11:15:39] detectron2 INFO: Inference done 10867/26446. 0.2021 s / img. ETA=0:52:59
[07/05 11:15:44] detectron2 INFO: Inference done 10893/26446. 0.2021 s / img. ETA=0:52:54
[07/05 11:15:49] detectron2 INFO: Inference done 10917/26446. 0.2021 s / img. ETA=0:52:49
[07/05 11:15:54] detectron2 INFO: Inference done 10941/26446. 0.2021 s / img. ETA=0:52:44
[07/05 11:15:59] detectron2 INFO: Inference done 10966/26446. 0.2021 s / img. ETA=0:52:39
[07/05 11:16:04] detectron2 INFO: Inference done 10990/26446. 0.2021 s / img. ETA=0:52:35
[07/05 11:16:09] detectron2 INFO: Inference done 11014/26446. 0.2021 s / img. ETA=0:52:30
[07/05 11:16:14] detectron2 INFO: Inference done 11040/26446. 0.2021 s / img. ETA=0:52:24
[07/05 11:16:20] detectron2 INFO: Inference done 11065/26446. 0.2021 s / img. ETA=0:52:19
[07/05 11:16:25] detectron2 INFO: Inference done 11090/26446. 0.2021 s / img. ETA=0:52:14
[07/05 11:16:30] detectron2 INFO: Inference done 11115/26446. 0.2021 s / img. ETA=0:52:09
[07/05 11:16:35] detectron2 INFO: Inference done 11139/26446. 0.2021 s / img. ETA=0:52:05
[07/05 11:16:40] detectron2 INFO: Inference done 11165/26446. 0.2021 s / img. ETA=0:51:59
[07/05 11:16:45] detectron2 INFO: Inference done 11189/26446. 0.2021 s / img. ETA=0:51:54
[07/05 11:16:50] detectron2 INFO: Inference done 11213/26446. 0.2021 s / img. ETA=0:51:50
[07/05 11:16:56] detectron2 INFO: Inference done 11238/26446. 0.2021 s / img. ETA=0:51:45
[07/05 11:17:01] detectron2 INFO: Inference done 11263/26446. 0.2021 s / img. ETA=0:51:40
[07/05 11:17:06] detectron2 INFO: Inference done 11288/26446. 0.2021 s / img. ETA=0:51:35
[07/05 11:17:11] detectron2 INFO: Inference done 11312/26446. 0.2022 s / img. ETA=0:51:30
[07/05 11:17:16] detectron2 INFO: Inference done 11337/26446. 0.2022 s / img. ETA=0:51:25
[07/05 11:17:21] detectron2 INFO: Inference done 11362/26446. 0.2021 s / img. ETA=0:51:20
[07/05 11:17:26] detectron2 INFO: Inference done 11386/26446. 0.2022 s / img. ETA=0:51:15
[07/05 11:17:31] detectron2 INFO: Inference done 11411/26446. 0.2022 s / img. ETA=0:51:10
[07/05 11:17:36] detectron2 INFO: Inference done 11436/26446. 0.2022 s / img. ETA=0:51:05
[07/05 11:17:41] detectron2 INFO: Inference done 11461/26446. 0.2022 s / img. ETA=0:51:00
[07/05 11:17:47] detectron2 INFO: Inference done 11486/26446. 0.2022 s / img. ETA=0:50:55
[07/05 11:17:52] detectron2 INFO: Inference done 11511/26446. 0.2022 s / img. ETA=0:50:50
[07/05 11:17:57] detectron2 INFO: Inference done 11536/26446. 0.2022 s / img. ETA=0:50:45
[07/05 11:18:02] detectron2 INFO: Inference done 11560/26446. 0.2022 s / img. ETA=0:50:40
[07/05 11:18:07] detectron2 INFO: Inference done 11586/26446. 0.2022 s / img. ETA=0:50:34
[07/05 11:18:12] detectron2 INFO: Inference done 11612/26446. 0.2022 s / img. ETA=0:50:29
[07/05 11:18:17] detectron2 INFO: Inference done 11637/26446. 0.2022 s / img. ETA=0:50:24
[07/05 11:18:22] detectron2 INFO: Inference done 11662/26446. 0.2022 s / img. ETA=0:50:19
[07/05 11:18:27] detectron2 INFO: Inference done 11686/26446. 0.2022 s / img. ETA=0:50:14
[07/05 11:18:33] detectron2 INFO: Inference done 11711/26446. 0.2022 s / img. ETA=0:50:09
[07/05 11:18:38] detectron2 INFO: Inference done 11735/26446. 0.2022 s / img. ETA=0:50:04
[07/05 11:18:43] detectron2 INFO: Inference done 11760/26446. 0.2022 s / img. ETA=0:49:59
[07/05 11:18:48] detectron2 INFO: Inference done 11785/26446. 0.2022 s / img. ETA=0:49:54
[07/05 11:18:53] detectron2 INFO: Inference done 11810/26446. 0.2022 s / img. ETA=0:49:49
[07/05 11:18:58] detectron2 INFO: Inference done 11835/26446. 0.2022 s / img. ETA=0:49:44
[07/05 11:19:03] detectron2 INFO: Inference done 11860/26446. 0.2022 s / img. ETA=0:49:39
[07/05 11:19:08] detectron2 INFO: Inference done 11884/26446. 0.2022 s / img. ETA=0:49:34
[07/05 11:19:14] detectron2 INFO: Inference done 11909/26446. 0.2022 s / img. ETA=0:49:29
[07/05 11:19:19] detectron2 INFO: Inference done 11934/26446. 0.2022 s / img. ETA=0:49:24
[07/05 11:19:24] detectron2 INFO: Inference done 11959/26446. 0.2022 s / img. ETA=0:49:19
[07/05 11:19:29] detectron2 INFO: Inference done 11984/26446. 0.2022 s / img. ETA=0:49:14
[07/05 11:19:34] detectron2 INFO: Inference done 12009/26446. 0.2022 s / img. ETA=0:49:09
[07/05 11:19:39] detectron2 INFO: Inference done 12033/26446. 0.2022 s / img. ETA=0:49:04
[07/05 11:19:44] detectron2 INFO: Inference done 12059/26446. 0.2022 s / img. ETA=0:48:59
[07/05 11:19:49] detectron2 INFO: Inference done 12084/26446. 0.2022 s / img. ETA=0:48:53
[07/05 11:19:54] detectron2 INFO: Inference done 12108/26446. 0.2022 s / img. ETA=0:48:49
[07/05 11:19:59] detectron2 INFO: Inference done 12133/26446. 0.2022 s / img. ETA=0:48:44
[07/05 11:20:05] detectron2 INFO: Inference done 12158/26446. 0.2023 s / img. ETA=0:48:39
[07/05 11:20:10] detectron2 INFO: Inference done 12183/26446. 0.2023 s / img. ETA=0:48:34
[07/05 11:20:15] detectron2 INFO: Inference done 12208/26446. 0.2023 s / img. ETA=0:48:29
[07/05 11:20:20] detectron2 INFO: Inference done 12232/26446. 0.2023 s / img. ETA=0:48:24
[07/05 11:20:25] detectron2 INFO: Inference done 12258/26446. 0.2023 s / img. ETA=0:48:18
[07/05 11:20:30] detectron2 INFO: Inference done 12282/26446. 0.2023 s / img. ETA=0:48:14
[07/05 11:20:35] detectron2 INFO: Inference done 12307/26446. 0.2023 s / img. ETA=0:48:08
[07/05 11:20:41] detectron2 INFO: Inference done 12332/26446. 0.2023 s / img. ETA=0:48:03
[07/05 11:20:46] detectron2 INFO: Inference done 12358/26446. 0.2023 s / img. ETA=0:47:58
[07/05 11:20:51] detectron2 INFO: Inference done 12382/26446. 0.2023 s / img. ETA=0:47:53
[07/05 11:20:56] detectron2 INFO: Inference done 12406/26446. 0.2023 s / img. ETA=0:47:49
[07/05 11:21:01] detectron2 INFO: Inference done 12431/26446. 0.2023 s / img. ETA=0:47:44
[07/05 11:21:06] detectron2 INFO: Inference done 12455/26446. 0.2023 s / img. ETA=0:47:39
[07/05 11:21:11] detectron2 INFO: Inference done 12479/26446. 0.2023 s / img. ETA=0:47:34
[07/05 11:21:16] detectron2 INFO: Inference done 12503/26446. 0.2023 s / img. ETA=0:47:29
[07/05 11:21:21] detectron2 INFO: Inference done 12528/26446. 0.2023 s / img. ETA=0:47:24
[07/05 11:21:27] detectron2 INFO: Inference done 12553/26446. 0.2023 s / img. ETA=0:47:19
[07/05 11:21:32] detectron2 INFO: Inference done 12577/26446. 0.2024 s / img. ETA=0:47:14
[07/05 11:21:37] detectron2 INFO: Inference done 12601/26446. 0.2024 s / img. ETA=0:47:10
[07/05 11:21:42] detectron2 INFO: Inference done 12627/26446. 0.2023 s / img. ETA=0:47:04
[07/05 11:21:47] detectron2 INFO: Inference done 12652/26446. 0.2023 s / img. ETA=0:46:59
[07/05 11:21:52] detectron2 INFO: Inference done 12676/26446. 0.2024 s / img. ETA=0:46:54
[07/05 11:21:57] detectron2 INFO: Inference done 12700/26446. 0.2024 s / img. ETA=0:46:50
[07/05 11:22:02] detectron2 INFO: Inference done 12724/26446. 0.2024 s / img. ETA=0:46:45
[07/05 11:22:07] detectron2 INFO: Inference done 12749/26446. 0.2024 s / img. ETA=0:46:40
[07/05 11:22:12] detectron2 INFO: Inference done 12774/26446. 0.2024 s / img. ETA=0:46:35
[07/05 11:22:17] detectron2 INFO: Inference done 12799/26446. 0.2024 s / img. ETA=0:46:30
[07/05 11:22:22] detectron2 INFO: Inference done 12823/26446. 0.2024 s / img. ETA=0:46:25
[07/05 11:22:28] detectron2 INFO: Inference done 12848/26446. 0.2024 s / img. ETA=0:46:20
[07/05 11:22:33] detectron2 INFO: Inference done 12873/26446. 0.2024 s / img. ETA=0:46:15
[07/05 11:22:38] detectron2 INFO: Inference done 12897/26446. 0.2024 s / img. ETA=0:46:10
[07/05 11:22:43] detectron2 INFO: Inference done 12923/26446. 0.2024 s / img. ETA=0:46:04
[07/05 11:22:48] detectron2 INFO: Inference done 12947/26446. 0.2024 s / img. ETA=0:46:00
[07/05 11:22:53] detectron2 INFO: Inference done 12972/26446. 0.2024 s / img. ETA=0:45:55
[07/05 11:22:58] detectron2 INFO: Inference done 12996/26446. 0.2024 s / img. ETA=0:45:50
[07/05 11:23:03] detectron2 INFO: Inference done 13021/26446. 0.2024 s / img. ETA=0:45:45
[07/05 11:23:09] detectron2 INFO: Inference done 13046/26446. 0.2024 s / img. ETA=0:45:40
[07/05 11:23:14] detectron2 INFO: Inference done 13070/26446. 0.2025 s / img. ETA=0:45:35
[07/05 11:23:19] detectron2 INFO: Inference done 13095/26446. 0.2025 s / img. ETA=0:45:30
[07/05 11:23:24] detectron2 INFO: Inference done 13119/26446. 0.2025 s / img. ETA=0:45:25
[07/05 11:23:29] detectron2 INFO: Inference done 13144/26446. 0.2025 s / img. ETA=0:45:20
[07/05 11:23:34] detectron2 INFO: Inference done 13168/26446. 0.2025 s / img. ETA=0:45:15
[07/05 11:23:39] detectron2 INFO: Inference done 13194/26446. 0.2025 s / img. ETA=0:45:10
[07/05 11:23:44] detectron2 INFO: Inference done 13219/26446. 0.2025 s / img. ETA=0:45:05
[07/05 11:23:49] detectron2 INFO: Inference done 13244/26446. 0.2025 s / img. ETA=0:45:00
[07/05 11:23:54] detectron2 INFO: Inference done 13267/26446. 0.2025 s / img. ETA=0:44:55
[07/05 11:24:00] detectron2 INFO: Inference done 13292/26446. 0.2025 s / img. ETA=0:44:50
[07/05 11:24:05] detectron2 INFO: Inference done 13316/26446. 0.2025 s / img. ETA=0:44:45
[07/05 11:24:10] detectron2 INFO: Inference done 13340/26446. 0.2025 s / img. ETA=0:44:41
[07/05 11:24:15] detectron2 INFO: Inference done 13365/26446. 0.2025 s / img. ETA=0:44:35
[07/05 11:24:20] detectron2 INFO: Inference done 13389/26446. 0.2025 s / img. ETA=0:44:31
[07/05 11:24:25] detectron2 INFO: Inference done 13413/26446. 0.2025 s / img. ETA=0:44:26
[07/05 11:24:30] detectron2 INFO: Inference done 13438/26446. 0.2026 s / img. ETA=0:44:21
[07/05 11:24:35] detectron2 INFO: Inference done 13463/26446. 0.2026 s / img. ETA=0:44:16
[07/05 11:24:41] detectron2 INFO: Inference done 13487/26446. 0.2026 s / img. ETA=0:44:11
[07/05 11:24:46] detectron2 INFO: Inference done 13511/26446. 0.2026 s / img. ETA=0:44:06
[07/05 11:24:51] detectron2 INFO: Inference done 13536/26446. 0.2026 s / img. ETA=0:44:01
[07/05 11:24:56] detectron2 INFO: Inference done 13561/26446. 0.2026 s / img. ETA=0:43:56
[07/05 11:25:01] detectron2 INFO: Inference done 13585/26446. 0.2026 s / img. ETA=0:43:52
[07/05 11:25:06] detectron2 INFO: Inference done 13610/26446. 0.2026 s / img. ETA=0:43:46
[07/05 11:25:11] detectron2 INFO: Inference done 13635/26446. 0.2026 s / img. ETA=0:43:41
[07/05 11:25:16] detectron2 INFO: Inference done 13659/26446. 0.2026 s / img. ETA=0:43:37
[07/05 11:25:22] detectron2 INFO: Inference done 13683/26446. 0.2026 s / img. ETA=0:43:32
[07/05 11:25:27] detectron2 INFO: Inference done 13706/26446. 0.2027 s / img. ETA=0:43:28
[07/05 11:25:32] detectron2 INFO: Inference done 13731/26446. 0.2027 s / img. ETA=0:43:23
[07/05 11:25:37] detectron2 INFO: Inference done 13755/26446. 0.2027 s / img. ETA=0:43:18
[07/05 11:25:42] detectron2 INFO: Inference done 13780/26446. 0.2027 s / img. ETA=0:43:13
[07/05 11:25:47] detectron2 INFO: Inference done 13805/26446. 0.2027 s / img. ETA=0:43:08
[07/05 11:25:52] detectron2 INFO: Inference done 13830/26446. 0.2027 s / img. ETA=0:43:02
[07/05 11:25:57] detectron2 INFO: Inference done 13854/26446. 0.2027 s / img. ETA=0:42:58
[07/05 11:26:03] detectron2 INFO: Inference done 13879/26446. 0.2027 s / img. ETA=0:42:53
[07/05 11:26:08] detectron2 INFO: Inference done 13904/26446. 0.2027 s / img. ETA=0:42:48
[07/05 11:26:13] detectron2 INFO: Inference done 13930/26446. 0.2027 s / img. ETA=0:42:42
[07/05 11:26:18] detectron2 INFO: Inference done 13955/26446. 0.2027 s / img. ETA=0:42:37
[07/05 11:26:23] detectron2 INFO: Inference done 13980/26446. 0.2027 s / img. ETA=0:42:32
[07/05 11:26:28] detectron2 INFO: Inference done 14005/26446. 0.2027 s / img. ETA=0:42:27
[07/05 11:26:33] detectron2 INFO: Inference done 14030/26446. 0.2027 s / img. ETA=0:42:22
[07/05 11:26:38] detectron2 INFO: Inference done 14055/26446. 0.2027 s / img. ETA=0:42:17
[07/05 11:26:44] detectron2 INFO: Inference done 14081/26446. 0.2027 s / img. ETA=0:42:11
[07/05 11:26:49] detectron2 INFO: Inference done 14106/26446. 0.2027 s / img. ETA=0:42:06
[07/05 11:26:54] detectron2 INFO: Inference done 14130/26446. 0.2027 s / img. ETA=0:42:01
[07/05 11:26:59] detectron2 INFO: Inference done 14155/26446. 0.2027 s / img. ETA=0:41:56
[07/05 11:27:04] detectron2 INFO: Inference done 14180/26446. 0.2027 s / img. ETA=0:41:51
[07/05 11:27:09] detectron2 INFO: Inference done 14205/26446. 0.2027 s / img. ETA=0:41:46
[07/05 11:27:14] detectron2 INFO: Inference done 14230/26446. 0.2027 s / img. ETA=0:41:41
[07/05 11:27:20] detectron2 INFO: Inference done 14255/26446. 0.2027 s / img. ETA=0:41:36
[07/05 11:27:25] detectron2 INFO: Inference done 14280/26446. 0.2027 s / img. ETA=0:41:31
[07/05 11:27:30] detectron2 INFO: Inference done 14304/26446. 0.2027 s / img. ETA=0:41:26
[07/05 11:27:35] detectron2 INFO: Inference done 14329/26446. 0.2027 s / img. ETA=0:41:21
[07/05 11:27:40] detectron2 INFO: Inference done 14355/26446. 0.2027 s / img. ETA=0:41:15
[07/05 11:27:45] detectron2 INFO: Inference done 14380/26446. 0.2027 s / img. ETA=0:41:10
[07/05 11:27:50] detectron2 INFO: Inference done 14405/26446. 0.2027 s / img. ETA=0:41:05
[07/05 11:27:55] detectron2 INFO: Inference done 14430/26446. 0.2027 s / img. ETA=0:41:00
[07/05 11:28:00] detectron2 INFO: Inference done 14454/26446. 0.2027 s / img. ETA=0:40:55
[07/05 11:28:05] detectron2 INFO: Inference done 14479/26446. 0.2027 s / img. ETA=0:40:50
[07/05 11:28:10] detectron2 INFO: Inference done 14504/26446. 0.2027 s / img. ETA=0:40:45
[07/05 11:28:16] detectron2 INFO: Inference done 14529/26446. 0.2027 s / img. ETA=0:40:39
[07/05 11:28:21] detectron2 INFO: Inference done 14553/26446. 0.2027 s / img. ETA=0:40:35
[07/05 11:28:26] detectron2 INFO: Inference done 14577/26446. 0.2027 s / img. ETA=0:40:30
[07/05 11:28:31] detectron2 INFO: Inference done 14602/26446. 0.2027 s / img. ETA=0:40:25
[07/05 11:28:36] detectron2 INFO: Inference done 14627/26446. 0.2027 s / img. ETA=0:40:20
[07/05 11:28:41] detectron2 INFO: Inference done 14651/26446. 0.2027 s / img. ETA=0:40:15
[07/05 11:28:46] detectron2 INFO: Inference done 14675/26446. 0.2027 s / img. ETA=0:40:10
[07/05 11:28:51] detectron2 INFO: Inference done 14700/26446. 0.2027 s / img. ETA=0:40:05
[07/05 11:28:56] detectron2 INFO: Inference done 14724/26446. 0.2027 s / img. ETA=0:40:00
[07/05 11:29:01] detectron2 INFO: Inference done 14748/26446. 0.2027 s / img. ETA=0:39:55
[07/05 11:29:06] detectron2 INFO: Inference done 14772/26446. 0.2028 s / img. ETA=0:39:50
[07/05 11:29:11] detectron2 INFO: Inference done 14797/26446. 0.2028 s / img. ETA=0:39:45
[07/05 11:29:16] detectron2 INFO: Inference done 14822/26446. 0.2028 s / img. ETA=0:39:40
[07/05 11:29:22] detectron2 INFO: Inference done 14848/26446. 0.2027 s / img. ETA=0:39:35
[07/05 11:29:27] detectron2 INFO: Inference done 14873/26446. 0.2027 s / img. ETA=0:39:30
[07/05 11:29:32] detectron2 INFO: Inference done 14898/26446. 0.2027 s / img. ETA=0:39:24
[07/05 11:29:37] detectron2 INFO: Inference done 14923/26446. 0.2027 s / img. ETA=0:39:19
[07/05 11:29:42] detectron2 INFO: Inference done 14948/26446. 0.2027 s / img. ETA=0:39:14
[07/05 11:29:47] detectron2 INFO: Inference done 14974/26446. 0.2027 s / img. ETA=0:39:09
[07/05 11:29:52] detectron2 INFO: Inference done 14999/26446. 0.2027 s / img. ETA=0:39:04
[07/05 11:29:57] detectron2 INFO: Inference done 15024/26446. 0.2027 s / img. ETA=0:38:58
[07/05 11:30:02] detectron2 INFO: Inference done 15048/26446. 0.2027 s / img. ETA=0:38:54
[07/05 11:30:07] detectron2 INFO: Inference done 15073/26446. 0.2027 s / img. ETA=0:38:48
[07/05 11:30:12] detectron2 INFO: Inference done 15098/26446. 0.2027 s / img. ETA=0:38:43
[07/05 11:30:18] detectron2 INFO: Inference done 15124/26446. 0.2027 s / img. ETA=0:38:38
[07/05 11:30:23] detectron2 INFO: Inference done 15149/26446. 0.2027 s / img. ETA=0:38:33
[07/05 11:30:28] detectron2 INFO: Inference done 15175/26446. 0.2027 s / img. ETA=0:38:27
[07/05 11:30:33] detectron2 INFO: Inference done 15200/26446. 0.2027 s / img. ETA=0:38:22
[07/05 11:30:38] detectron2 INFO: Inference done 15225/26446. 0.2027 s / img. ETA=0:38:17
[07/05 11:30:43] detectron2 INFO: Inference done 15250/26446. 0.2027 s / img. ETA=0:38:12
[07/05 11:30:48] detectron2 INFO: Inference done 15275/26446. 0.2027 s / img. ETA=0:38:07
[07/05 11:30:54] detectron2 INFO: Inference done 15300/26446. 0.2027 s / img. ETA=0:38:02
[07/05 11:30:59] detectron2 INFO: Inference done 15326/26446. 0.2027 s / img. ETA=0:37:56
[07/05 11:31:04] detectron2 INFO: Inference done 15352/26446. 0.2027 s / img. ETA=0:37:51
[07/05 11:31:09] detectron2 INFO: Inference done 15377/26446. 0.2027 s / img. ETA=0:37:46
[07/05 11:31:14] detectron2 INFO: Inference done 15402/26446. 0.2027 s / img. ETA=0:37:41
[07/05 11:31:19] detectron2 INFO: Inference done 15427/26446. 0.2027 s / img. ETA=0:37:36
[07/05 11:31:24] detectron2 INFO: Inference done 15452/26446. 0.2027 s / img. ETA=0:37:30
[07/05 11:31:29] detectron2 INFO: Inference done 15477/26446. 0.2027 s / img. ETA=0:37:25
[07/05 11:31:34] detectron2 INFO: Inference done 15502/26446. 0.2027 s / img. ETA=0:37:20
[07/05 11:31:40] detectron2 INFO: Inference done 15527/26446. 0.2027 s / img. ETA=0:37:15
[07/05 11:31:45] detectron2 INFO: Inference done 15552/26446. 0.2027 s / img. ETA=0:37:10
[07/05 11:31:50] detectron2 INFO: Inference done 15577/26446. 0.2027 s / img. ETA=0:37:05
[07/05 11:31:55] detectron2 INFO: Inference done 15603/26446. 0.2027 s / img. ETA=0:36:59
[07/05 11:32:00] detectron2 INFO: Inference done 15628/26446. 0.2027 s / img. ETA=0:36:54
[07/05 11:32:05] detectron2 INFO: Inference done 15653/26446. 0.2027 s / img. ETA=0:36:49
[07/05 11:32:10] detectron2 INFO: Inference done 15678/26446. 0.2026 s / img. ETA=0:36:44
[07/05 11:32:15] detectron2 INFO: Inference done 15703/26446. 0.2026 s / img. ETA=0:36:39
[07/05 11:32:20] detectron2 INFO: Inference done 15728/26446. 0.2026 s / img. ETA=0:36:33
[07/05 11:32:25] detectron2 INFO: Inference done 15753/26446. 0.2026 s / img. ETA=0:36:28
[07/05 11:32:31] detectron2 INFO: Inference done 15777/26446. 0.2027 s / img. ETA=0:36:24
[07/05 11:32:36] detectron2 INFO: Inference done 15803/26446. 0.2026 s / img. ETA=0:36:18
[07/05 11:32:41] detectron2 INFO: Inference done 15829/26446. 0.2026 s / img. ETA=0:36:13
[07/05 11:32:46] detectron2 INFO: Inference done 15854/26446. 0.2026 s / img. ETA=0:36:08
[07/05 11:32:51] detectron2 INFO: Inference done 15879/26446. 0.2026 s / img. ETA=0:36:02
[07/05 11:32:56] detectron2 INFO: Inference done 15904/26446. 0.2026 s / img. ETA=0:35:57
[07/05 11:33:01] detectron2 INFO: Inference done 15930/26446. 0.2026 s / img. ETA=0:35:52
[07/05 11:33:06] detectron2 INFO: Inference done 15956/26446. 0.2026 s / img. ETA=0:35:46
[07/05 11:33:11] detectron2 INFO: Inference done 15981/26446. 0.2026 s / img. ETA=0:35:41
[07/05 11:33:16] detectron2 INFO: Inference done 16006/26446. 0.2026 s / img. ETA=0:35:36
[07/05 11:33:22] detectron2 INFO: Inference done 16031/26446. 0.2026 s / img. ETA=0:35:31
[07/05 11:33:27] detectron2 INFO: Inference done 16055/26446. 0.2026 s / img. ETA=0:35:26
[07/05 11:33:32] detectron2 INFO: Inference done 16081/26446. 0.2026 s / img. ETA=0:35:21
[07/05 11:33:37] detectron2 INFO: Inference done 16106/26446. 0.2026 s / img. ETA=0:35:16
[07/05 11:33:42] detectron2 INFO: Inference done 16132/26446. 0.2026 s / img. ETA=0:35:10
[07/05 11:33:47] detectron2 INFO: Inference done 16157/26446. 0.2026 s / img. ETA=0:35:05
[07/05 11:33:52] detectron2 INFO: Inference done 16182/26446. 0.2026 s / img. ETA=0:35:00
[07/05 11:33:57] detectron2 INFO: Inference done 16207/26446. 0.2026 s / img. ETA=0:34:55
[07/05 11:34:03] detectron2 INFO: Inference done 16232/26446. 0.2026 s / img. ETA=0:34:50
[07/05 11:34:08] detectron2 INFO: Inference done 16257/26446. 0.2026 s / img. ETA=0:34:45
[07/05 11:34:13] detectron2 INFO: Inference done 16282/26446. 0.2026 s / img. ETA=0:34:39
[07/05 11:34:18] detectron2 INFO: Inference done 16307/26446. 0.2026 s / img. ETA=0:34:34
[07/05 11:34:24] detectron2 INFO: Inference done 16332/26446. 0.2026 s / img. ETA=0:34:30
[07/05 11:34:29] detectron2 INFO: Inference done 16357/26446. 0.2026 s / img. ETA=0:34:25
[07/05 11:34:34] detectron2 INFO: Inference done 16382/26446. 0.2026 s / img. ETA=0:34:20
[07/05 11:34:39] detectron2 INFO: Inference done 16406/26446. 0.2026 s / img. ETA=0:34:15
[07/05 11:34:45] detectron2 INFO: Inference done 16431/26446. 0.2026 s / img. ETA=0:34:10
[07/05 11:34:50] detectron2 INFO: Inference done 16455/26446. 0.2026 s / img. ETA=0:34:05
[07/05 11:34:55] detectron2 INFO: Inference done 16479/26446. 0.2026 s / img. ETA=0:34:00
[07/05 11:35:00] detectron2 INFO: Inference done 16504/26446. 0.2026 s / img. ETA=0:33:55
[07/05 11:35:05] detectron2 INFO: Inference done 16528/26446. 0.2026 s / img. ETA=0:33:50
[07/05 11:35:10] detectron2 INFO: Inference done 16552/26446. 0.2026 s / img. ETA=0:33:45
[07/05 11:35:15] detectron2 INFO: Inference done 16576/26446. 0.2026 s / img. ETA=0:33:41
[07/05 11:35:20] detectron2 INFO: Inference done 16601/26446. 0.2026 s / img. ETA=0:33:36
[07/05 11:35:25] detectron2 INFO: Inference done 16625/26446. 0.2026 s / img. ETA=0:33:31
[07/05 11:35:30] detectron2 INFO: Inference done 16649/26446. 0.2027 s / img. ETA=0:33:26
[07/05 11:35:36] detectron2 INFO: Inference done 16673/26446. 0.2027 s / img. ETA=0:33:21
[07/05 11:35:41] detectron2 INFO: Inference done 16697/26446. 0.2027 s / img. ETA=0:33:16
[07/05 11:35:46] detectron2 INFO: Inference done 16722/26446. 0.2027 s / img. ETA=0:33:11
[07/05 11:35:51] detectron2 INFO: Inference done 16747/26446. 0.2027 s / img. ETA=0:33:06
[07/05 11:35:56] detectron2 INFO: Inference done 16772/26446. 0.2027 s / img. ETA=0:33:01
[07/05 11:36:01] detectron2 INFO: Inference done 16797/26446. 0.2027 s / img. ETA=0:32:56
[07/05 11:36:06] detectron2 INFO: Inference done 16822/26446. 0.2027 s / img. ETA=0:32:51
[07/05 11:36:11] detectron2 INFO: Inference done 16847/26446. 0.2027 s / img. ETA=0:32:46
[07/05 11:36:17] detectron2 INFO: Inference done 16872/26446. 0.2027 s / img. ETA=0:32:41
[07/05 11:36:22] detectron2 INFO: Inference done 16897/26446. 0.2027 s / img. ETA=0:32:35
[07/05 11:36:27] detectron2 INFO: Inference done 16922/26446. 0.2027 s / img. ETA=0:32:30
[07/05 11:36:32] detectron2 INFO: Inference done 16947/26446. 0.2027 s / img. ETA=0:32:25
[07/05 11:36:37] detectron2 INFO: Inference done 16971/26446. 0.2027 s / img. ETA=0:32:20
[07/05 11:36:42] detectron2 INFO: Inference done 16995/26446. 0.2027 s / img. ETA=0:32:16
[07/05 11:36:48] detectron2 INFO: Inference done 17020/26446. 0.2027 s / img. ETA=0:32:11
[07/05 11:36:53] detectron2 INFO: Inference done 17045/26446. 0.2027 s / img. ETA=0:32:06
[07/05 11:36:58] detectron2 INFO: Inference done 17070/26446. 0.2027 s / img. ETA=0:32:00
[07/05 11:37:03] detectron2 INFO: Inference done 17095/26446. 0.2027 s / img. ETA=0:31:55
[07/05 11:37:08] detectron2 INFO: Inference done 17120/26446. 0.2027 s / img. ETA=0:31:50
[07/05 11:37:13] detectron2 INFO: Inference done 17145/26446. 0.2027 s / img. ETA=0:31:45
[07/05 11:37:18] detectron2 INFO: Inference done 17170/26446. 0.2027 s / img. ETA=0:31:40
[07/05 11:37:23] detectron2 INFO: Inference done 17194/26446. 0.2027 s / img. ETA=0:31:35
[07/05 11:37:28] detectron2 INFO: Inference done 17219/26446. 0.2027 s / img. ETA=0:31:30
[07/05 11:37:33] detectron2 INFO: Inference done 17244/26446. 0.2027 s / img. ETA=0:31:25
[07/05 11:37:38] detectron2 INFO: Inference done 17269/26446. 0.2027 s / img. ETA=0:31:19
[07/05 11:37:44] detectron2 INFO: Inference done 17294/26446. 0.2027 s / img. ETA=0:31:14
[07/05 11:37:49] detectron2 INFO: Inference done 17319/26446. 0.2027 s / img. ETA=0:31:09
[07/05 11:37:54] detectron2 INFO: Inference done 17343/26446. 0.2027 s / img. ETA=0:31:04
[07/05 11:37:59] detectron2 INFO: Inference done 17367/26446. 0.2027 s / img. ETA=0:31:00
[07/05 11:38:04] detectron2 INFO: Inference done 17393/26446. 0.2027 s / img. ETA=0:30:54
[07/05 11:38:09] detectron2 INFO: Inference done 17418/26446. 0.2027 s / img. ETA=0:30:49
[07/05 11:38:14] detectron2 INFO: Inference done 17443/26446. 0.2027 s / img. ETA=0:30:44
[07/05 11:38:19] detectron2 INFO: Inference done 17468/26446. 0.2027 s / img. ETA=0:30:39
[07/05 11:38:25] detectron2 INFO: Inference done 17493/26446. 0.2027 s / img. ETA=0:30:34
[07/05 11:38:30] detectron2 INFO: Inference done 17518/26446. 0.2027 s / img. ETA=0:30:29
[07/05 11:38:35] detectron2 INFO: Inference done 17543/26446. 0.2027 s / img. ETA=0:30:23
[07/05 11:38:40] detectron2 INFO: Inference done 17567/26446. 0.2027 s / img. ETA=0:30:19
[07/05 11:38:45] detectron2 INFO: Inference done 17592/26446. 0.2027 s / img. ETA=0:30:14
[07/05 11:38:50] detectron2 INFO: Inference done 17617/26446. 0.2027 s / img. ETA=0:30:08
[07/05 11:38:55] detectron2 INFO: Inference done 17642/26446. 0.2027 s / img. ETA=0:30:03
[07/05 11:39:00] detectron2 INFO: Inference done 17667/26446. 0.2027 s / img. ETA=0:29:58
[07/05 11:39:05] detectron2 INFO: Inference done 17691/26446. 0.2027 s / img. ETA=0:29:53
[07/05 11:39:10] detectron2 INFO: Inference done 17715/26446. 0.2027 s / img. ETA=0:29:48
[07/05 11:39:16] detectron2 INFO: Inference done 17740/26446. 0.2028 s / img. ETA=0:29:43
[07/05 11:39:21] detectron2 INFO: Inference done 17764/26446. 0.2028 s / img. ETA=0:29:38
[07/05 11:39:26] detectron2 INFO: Inference done 17789/26446. 0.2028 s / img. ETA=0:29:33
[07/05 11:39:31] detectron2 INFO: Inference done 17814/26446. 0.2028 s / img. ETA=0:29:28
[07/05 11:39:36] detectron2 INFO: Inference done 17839/26446. 0.2028 s / img. ETA=0:29:23
[07/05 11:39:41] detectron2 INFO: Inference done 17864/26446. 0.2028 s / img. ETA=0:29:18
[07/05 11:39:46] detectron2 INFO: Inference done 17889/26446. 0.2028 s / img. ETA=0:29:13
[07/05 11:39:52] detectron2 INFO: Inference done 17914/26446. 0.2028 s / img. ETA=0:29:08
[07/05 11:39:57] detectron2 INFO: Inference done 17939/26446. 0.2028 s / img. ETA=0:29:03
[07/05 11:40:02] detectron2 INFO: Inference done 17963/26446. 0.2028 s / img. ETA=0:28:58
[07/05 11:40:07] detectron2 INFO: Inference done 17988/26446. 0.2028 s / img. ETA=0:28:53
[07/05 11:40:12] detectron2 INFO: Inference done 18013/26446. 0.2028 s / img. ETA=0:28:48
[07/05 11:40:17] detectron2 INFO: Inference done 18038/26446. 0.2028 s / img. ETA=0:28:43
[07/05 11:40:22] detectron2 INFO: Inference done 18063/26446. 0.2028 s / img. ETA=0:28:37
[07/05 11:40:27] detectron2 INFO: Inference done 18087/26446. 0.2028 s / img. ETA=0:28:33
[07/05 11:40:32] detectron2 INFO: Inference done 18110/26446. 0.2028 s / img. ETA=0:28:28
[07/05 11:40:37] detectron2 INFO: Inference done 18134/26446. 0.2028 s / img. ETA=0:28:23
[07/05 11:40:43] detectron2 INFO: Inference done 18158/26446. 0.2028 s / img. ETA=0:28:18
[07/05 11:40:48] detectron2 INFO: Inference done 18182/26446. 0.2028 s / img. ETA=0:28:13
[07/05 11:40:53] detectron2 INFO: Inference done 18206/26446. 0.2028 s / img. ETA=0:28:09
[07/05 11:40:58] detectron2 INFO: Inference done 18231/26446. 0.2028 s / img. ETA=0:28:03
[07/05 11:41:03] detectron2 INFO: Inference done 18256/26446. 0.2029 s / img. ETA=0:27:58
[07/05 11:41:08] detectron2 INFO: Inference done 18280/26446. 0.2029 s / img. ETA=0:27:54
[07/05 11:41:13] detectron2 INFO: Inference done 18305/26446. 0.2029 s / img. ETA=0:27:48
[07/05 11:41:18] detectron2 INFO: Inference done 18329/26446. 0.2029 s / img. ETA=0:27:44
[07/05 11:41:23] detectron2 INFO: Inference done 18353/26446. 0.2029 s / img. ETA=0:27:39
[07/05 11:41:29] detectron2 INFO: Inference done 18378/26446. 0.2029 s / img. ETA=0:27:34
[07/05 11:41:34] detectron2 INFO: Inference done 18403/26446. 0.2029 s / img. ETA=0:27:28
[07/05 11:41:39] detectron2 INFO: Inference done 18427/26446. 0.2029 s / img. ETA=0:27:24
[07/05 11:41:44] detectron2 INFO: Inference done 18452/26446. 0.2029 s / img. ETA=0:27:18
[07/05 11:41:49] detectron2 INFO: Inference done 18476/26446. 0.2029 s / img. ETA=0:27:14
[07/05 11:41:54] detectron2 INFO: Inference done 18501/26446. 0.2029 s / img. ETA=0:27:08
[07/05 11:41:59] detectron2 INFO: Inference done 18525/26446. 0.2029 s / img. ETA=0:27:04
[07/05 11:42:04] detectron2 INFO: Inference done 18549/26446. 0.2029 s / img. ETA=0:26:59
[07/05 11:42:09] detectron2 INFO: Inference done 18573/26446. 0.2029 s / img. ETA=0:26:54
[07/05 11:42:14] detectron2 INFO: Inference done 18597/26446. 0.2029 s / img. ETA=0:26:49
[07/05 11:42:19] detectron2 INFO: Inference done 18622/26446. 0.2029 s / img. ETA=0:26:44
[07/05 11:42:24] detectron2 INFO: Inference done 18646/26446. 0.2029 s / img. ETA=0:26:39
[07/05 11:42:30] detectron2 INFO: Inference done 18670/26446. 0.2029 s / img. ETA=0:26:34
[07/05 11:42:35] detectron2 INFO: Inference done 18695/26446. 0.2029 s / img. ETA=0:26:29
[07/05 11:42:40] detectron2 INFO: Inference done 18719/26446. 0.2030 s / img. ETA=0:26:24
[07/05 11:42:45] detectron2 INFO: Inference done 18743/26446. 0.2030 s / img. ETA=0:26:19
[07/05 11:42:50] detectron2 INFO: Inference done 18768/26446. 0.2030 s / img. ETA=0:26:14
[07/05 11:42:55] detectron2 INFO: Inference done 18792/26446. 0.2030 s / img. ETA=0:26:09
[07/05 11:43:00] detectron2 INFO: Inference done 18816/26446. 0.2030 s / img. ETA=0:26:05
[07/05 11:43:05] detectron2 INFO: Inference done 18841/26446. 0.2030 s / img. ETA=0:25:59
[07/05 11:43:11] detectron2 INFO: Inference done 18866/26446. 0.2030 s / img. ETA=0:25:54
[07/05 11:43:16] detectron2 INFO: Inference done 18891/26446. 0.2030 s / img. ETA=0:25:49
[07/05 11:43:21] detectron2 INFO: Inference done 18916/26446. 0.2030 s / img. ETA=0:25:44
[07/05 11:43:26] detectron2 INFO: Inference done 18942/26446. 0.2030 s / img. ETA=0:25:39
[07/05 11:43:31] detectron2 INFO: Inference done 18968/26446. 0.2030 s / img. ETA=0:25:33
[07/05 11:43:36] detectron2 INFO: Inference done 18993/26446. 0.2030 s / img. ETA=0:25:28
[07/05 11:43:41] detectron2 INFO: Inference done 19017/26446. 0.2030 s / img. ETA=0:25:23
[07/05 11:43:47] detectron2 INFO: Inference done 19041/26446. 0.2030 s / img. ETA=0:25:19
[07/05 11:43:52] detectron2 INFO: Inference done 19066/26446. 0.2030 s / img. ETA=0:25:13
[07/05 11:43:57] detectron2 INFO: Inference done 19090/26446. 0.2030 s / img. ETA=0:25:08
[07/05 11:44:02] detectron2 INFO: Inference done 19114/26446. 0.2030 s / img. ETA=0:25:04
[07/05 11:44:07] detectron2 INFO: Inference done 19138/26446. 0.2030 s / img. ETA=0:24:59
[07/05 11:44:12] detectron2 INFO: Inference done 19162/26446. 0.2030 s / img. ETA=0:24:54
[07/05 11:44:17] detectron2 INFO: Inference done 19187/26446. 0.2030 s / img. ETA=0:24:49
[07/05 11:44:22] detectron2 INFO: Inference done 19211/26446. 0.2030 s / img. ETA=0:24:44
[07/05 11:44:27] detectron2 INFO: Inference done 19235/26446. 0.2030 s / img. ETA=0:24:39
[07/05 11:44:32] detectron2 INFO: Inference done 19260/26446. 0.2030 s / img. ETA=0:24:34
[07/05 11:44:38] detectron2 INFO: Inference done 19285/26446. 0.2030 s / img. ETA=0:24:29
[07/05 11:44:43] detectron2 INFO: Inference done 19310/26446. 0.2030 s / img. ETA=0:24:24
[07/05 11:44:48] detectron2 INFO: Inference done 19334/26446. 0.2030 s / img. ETA=0:24:19
[07/05 11:44:53] detectron2 INFO: Inference done 19359/26446. 0.2030 s / img. ETA=0:24:14
[07/05 11:44:58] detectron2 INFO: Inference done 19383/26446. 0.2030 s / img. ETA=0:24:09
[07/05 11:45:03] detectron2 INFO: Inference done 19407/26446. 0.2031 s / img. ETA=0:24:04
[07/05 11:45:08] detectron2 INFO: Inference done 19431/26446. 0.2031 s / img. ETA=0:23:59
[07/05 11:45:13] detectron2 INFO: Inference done 19456/26446. 0.2031 s / img. ETA=0:23:54
[07/05 11:45:18] detectron2 INFO: Inference done 19482/26446. 0.2031 s / img. ETA=0:23:49
[07/05 11:45:24] detectron2 INFO: Inference done 19506/26446. 0.2031 s / img. ETA=0:23:44
[07/05 11:45:29] detectron2 INFO: Inference done 19530/26446. 0.2031 s / img. ETA=0:23:39
[07/05 11:45:34] detectron2 INFO: Inference done 19554/26446. 0.2031 s / img. ETA=0:23:34
[07/05 11:45:39] detectron2 INFO: Inference done 19579/26446. 0.2031 s / img. ETA=0:23:29
[07/05 11:45:44] detectron2 INFO: Inference done 19604/26446. 0.2031 s / img. ETA=0:23:24
[07/05 11:45:49] detectron2 INFO: Inference done 19629/26446. 0.2031 s / img. ETA=0:23:19
[07/05 11:45:54] detectron2 INFO: Inference done 19653/26446. 0.2031 s / img. ETA=0:23:14
[07/05 11:45:59] detectron2 INFO: Inference done 19677/26446. 0.2031 s / img. ETA=0:23:09
[07/05 11:46:04] detectron2 INFO: Inference done 19701/26446. 0.2031 s / img. ETA=0:23:04
[07/05 11:46:09] detectron2 INFO: Inference done 19726/26446. 0.2031 s / img. ETA=0:22:59
[07/05 11:46:15] detectron2 INFO: Inference done 19751/26446. 0.2031 s / img. ETA=0:22:54
[07/05 11:46:20] detectron2 INFO: Inference done 19776/26446. 0.2031 s / img. ETA=0:22:48
[07/05 11:46:25] detectron2 INFO: Inference done 19801/26446. 0.2031 s / img. ETA=0:22:43
[07/05 11:46:30] detectron2 INFO: Inference done 19826/26446. 0.2031 s / img. ETA=0:22:38
[07/05 11:46:35] detectron2 INFO: Inference done 19851/26446. 0.2031 s / img. ETA=0:22:33
[07/05 11:46:40] detectron2 INFO: Inference done 19876/26446. 0.2031 s / img. ETA=0:22:28
[07/05 11:46:45] detectron2 INFO: Inference done 19901/26446. 0.2031 s / img. ETA=0:22:23
[07/05 11:46:51] detectron2 INFO: Inference done 19927/26446. 0.2031 s / img. ETA=0:22:17
[07/05 11:46:56] detectron2 INFO: Inference done 19952/26446. 0.2031 s / img. ETA=0:22:12
[07/05 11:47:01] detectron2 INFO: Inference done 19978/26446. 0.2031 s / img. ETA=0:22:07
[07/05 11:47:06] detectron2 INFO: Inference done 20003/26446. 0.2031 s / img. ETA=0:22:02
[07/05 11:47:11] detectron2 INFO: Inference done 20028/26446. 0.2031 s / img. ETA=0:21:57
[07/05 11:47:16] detectron2 INFO: Inference done 20052/26446. 0.2031 s / img. ETA=0:21:52
[07/05 11:47:21] detectron2 INFO: Inference done 20077/26446. 0.2031 s / img. ETA=0:21:47
[07/05 11:47:26] detectron2 INFO: Inference done 20102/26446. 0.2031 s / img. ETA=0:21:42
[07/05 11:47:32] detectron2 INFO: Inference done 20127/26446. 0.2031 s / img. ETA=0:21:36
[07/05 11:47:37] detectron2 INFO: Inference done 20152/26446. 0.2031 s / img. ETA=0:21:31
[07/05 11:47:42] detectron2 INFO: Inference done 20177/26446. 0.2031 s / img. ETA=0:21:26
[07/05 11:47:47] detectron2 INFO: Inference done 20202/26446. 0.2031 s / img. ETA=0:21:21
[07/05 11:47:52] detectron2 INFO: Inference done 20226/26446. 0.2031 s / img. ETA=0:21:16
[07/05 11:47:57] detectron2 INFO: Inference done 20251/26446. 0.2031 s / img. ETA=0:21:11
[07/05 11:48:02] detectron2 INFO: Inference done 20276/26446. 0.2031 s / img. ETA=0:21:06
[07/05 11:48:08] detectron2 INFO: Inference done 20301/26446. 0.2031 s / img. ETA=0:21:01
[07/05 11:48:13] detectron2 INFO: Inference done 20326/26446. 0.2031 s / img. ETA=0:20:56
[07/05 11:48:18] detectron2 INFO: Inference done 20351/26446. 0.2031 s / img. ETA=0:20:51
[07/05 11:48:23] detectron2 INFO: Inference done 20375/26446. 0.2031 s / img. ETA=0:20:46
[07/05 11:48:28] detectron2 INFO: Inference done 20399/26446. 0.2031 s / img. ETA=0:20:41
[07/05 11:48:33] detectron2 INFO: Inference done 20424/26446. 0.2031 s / img. ETA=0:20:36
[07/05 11:48:38] detectron2 INFO: Inference done 20449/26446. 0.2031 s / img. ETA=0:20:31
[07/05 11:48:43] detectron2 INFO: Inference done 20473/26446. 0.2031 s / img. ETA=0:20:26
[07/05 11:48:48] detectron2 INFO: Inference done 20498/26446. 0.2031 s / img. ETA=0:20:20
[07/05 11:48:54] detectron2 INFO: Inference done 20523/26446. 0.2031 s / img. ETA=0:20:15
[07/05 11:48:59] detectron2 INFO: Inference done 20547/26446. 0.2031 s / img. ETA=0:20:10
[07/05 11:49:04] detectron2 INFO: Inference done 20571/26446. 0.2032 s / img. ETA=0:20:06
[07/05 11:49:09] detectron2 INFO: Inference done 20597/26446. 0.2031 s / img. ETA=0:20:00
[07/05 11:49:14] detectron2 INFO: Inference done 20622/26446. 0.2031 s / img. ETA=0:19:55
[07/05 11:49:19] detectron2 INFO: Inference done 20647/26446. 0.2031 s / img. ETA=0:19:50
[07/05 11:49:24] detectron2 INFO: Inference done 20672/26446. 0.2031 s / img. ETA=0:19:45
[07/05 11:49:29] detectron2 INFO: Inference done 20697/26446. 0.2031 s / img. ETA=0:19:40
[07/05 11:49:34] detectron2 INFO: Inference done 20721/26446. 0.2031 s / img. ETA=0:19:35
[07/05 11:49:39] detectron2 INFO: Inference done 20745/26446. 0.2031 s / img. ETA=0:19:30
[07/05 11:49:44] detectron2 INFO: Inference done 20769/26446. 0.2032 s / img. ETA=0:19:25
[07/05 11:49:49] detectron2 INFO: Inference done 20794/26446. 0.2031 s / img. ETA=0:19:20
[07/05 11:49:54] detectron2 INFO: Inference done 20818/26446. 0.2032 s / img. ETA=0:19:15
[07/05 11:50:00] detectron2 INFO: Inference done 20844/26446. 0.2031 s / img. ETA=0:19:09
[07/05 11:50:05] detectron2 INFO: Inference done 20869/26446. 0.2031 s / img. ETA=0:19:04
[07/05 11:50:10] detectron2 INFO: Inference done 20893/26446. 0.2032 s / img. ETA=0:18:59
[07/05 11:50:15] detectron2 INFO: Inference done 20918/26446. 0.2031 s / img. ETA=0:18:54
[07/05 11:50:20] detectron2 INFO: Inference done 20944/26446. 0.2031 s / img. ETA=0:18:49
[07/05 11:50:25] detectron2 INFO: Inference done 20969/26446. 0.2031 s / img. ETA=0:18:44
[07/05 11:50:30] detectron2 INFO: Inference done 20994/26446. 0.2031 s / img. ETA=0:18:39
[07/05 11:50:35] detectron2 INFO: Inference done 21018/26446. 0.2031 s / img. ETA=0:18:34
[07/05 11:50:41] detectron2 INFO: Inference done 21043/26446. 0.2031 s / img. ETA=0:18:29
[07/05 11:50:46] detectron2 INFO: Inference done 21068/26446. 0.2031 s / img. ETA=0:18:24
[07/05 11:50:51] detectron2 INFO: Inference done 21093/26446. 0.2031 s / img. ETA=0:18:18
[07/05 11:50:56] detectron2 INFO: Inference done 21117/26446. 0.2031 s / img. ETA=0:18:13
[07/05 11:51:01] detectron2 INFO: Inference done 21142/26446. 0.2031 s / img. ETA=0:18:08
[07/05 11:51:06] detectron2 INFO: Inference done 21166/26446. 0.2032 s / img. ETA=0:18:03
[07/05 11:51:11] detectron2 INFO: Inference done 21191/26446. 0.2032 s / img. ETA=0:17:58
[07/05 11:51:16] detectron2 INFO: Inference done 21215/26446. 0.2032 s / img. ETA=0:17:53
[07/05 11:51:21] detectron2 INFO: Inference done 21240/26446. 0.2032 s / img. ETA=0:17:48
[07/05 11:51:26] detectron2 INFO: Inference done 21265/26446. 0.2032 s / img. ETA=0:17:43
[07/05 11:51:31] detectron2 INFO: Inference done 21289/26446. 0.2032 s / img. ETA=0:17:38
[07/05 11:51:36] detectron2 INFO: Inference done 21314/26446. 0.2032 s / img. ETA=0:17:33
[07/05 11:51:42] detectron2 INFO: Inference done 21339/26446. 0.2032 s / img. ETA=0:17:28
[07/05 11:51:47] detectron2 INFO: Inference done 21364/26446. 0.2032 s / img. ETA=0:17:23
[07/05 11:51:52] detectron2 INFO: Inference done 21389/26446. 0.2032 s / img. ETA=0:17:18
[07/05 11:51:57] detectron2 INFO: Inference done 21413/26446. 0.2032 s / img. ETA=0:17:13
[07/05 11:52:02] detectron2 INFO: Inference done 21438/26446. 0.2032 s / img. ETA=0:17:08
[07/05 11:52:07] detectron2 INFO: Inference done 21463/26446. 0.2032 s / img. ETA=0:17:03
[07/05 11:52:12] detectron2 INFO: Inference done 21488/26446. 0.2032 s / img. ETA=0:16:57
[07/05 11:52:18] detectron2 INFO: Inference done 21513/26446. 0.2032 s / img. ETA=0:16:52
[07/05 11:52:23] detectron2 INFO: Inference done 21537/26446. 0.2032 s / img. ETA=0:16:47
[07/05 11:52:28] detectron2 INFO: Inference done 21562/26446. 0.2032 s / img. ETA=0:16:42
[07/05 11:52:33] detectron2 INFO: Inference done 21586/26446. 0.2032 s / img. ETA=0:16:37
[07/05 11:52:38] detectron2 INFO: Inference done 21612/26446. 0.2032 s / img. ETA=0:16:32
[07/05 11:52:43] detectron2 INFO: Inference done 21637/26446. 0.2032 s / img. ETA=0:16:27
[07/05 11:52:48] detectron2 INFO: Inference done 21662/26446. 0.2032 s / img. ETA=0:16:22
[07/05 11:52:54] detectron2 INFO: Inference done 21687/26446. 0.2032 s / img. ETA=0:16:17
[07/05 11:52:59] detectron2 INFO: Inference done 21712/26446. 0.2032 s / img. ETA=0:16:12
[07/05 11:53:04] detectron2 INFO: Inference done 21737/26446. 0.2032 s / img. ETA=0:16:06
[07/05 11:53:09] detectron2 INFO: Inference done 21762/26446. 0.2032 s / img. ETA=0:16:01
[07/05 11:53:14] detectron2 INFO: Inference done 21786/26446. 0.2032 s / img. ETA=0:15:56
[07/05 11:53:19] detectron2 INFO: Inference done 21811/26446. 0.2032 s / img. ETA=0:15:51
[07/05 11:53:24] detectron2 INFO: Inference done 21836/26446. 0.2032 s / img. ETA=0:15:46
[07/05 11:53:30] detectron2 INFO: Inference done 21860/26446. 0.2032 s / img. ETA=0:15:41
[07/05 11:53:35] detectron2 INFO: Inference done 21885/26446. 0.2032 s / img. ETA=0:15:36
[07/05 11:53:40] detectron2 INFO: Inference done 21910/26446. 0.2032 s / img. ETA=0:15:31
[07/05 11:53:45] detectron2 INFO: Inference done 21934/26446. 0.2032 s / img. ETA=0:15:26
[07/05 11:53:50] detectron2 INFO: Inference done 21958/26446. 0.2032 s / img. ETA=0:15:21
[07/05 11:53:55] detectron2 INFO: Inference done 21982/26446. 0.2032 s / img. ETA=0:15:16
[07/05 11:54:00] detectron2 INFO: Inference done 22006/26446. 0.2032 s / img. ETA=0:15:11
[07/05 11:54:05] detectron2 INFO: Inference done 22030/26446. 0.2032 s / img. ETA=0:15:06
[07/05 11:54:10] detectron2 INFO: Inference done 22055/26446. 0.2032 s / img. ETA=0:15:01
[07/05 11:54:15] detectron2 INFO: Inference done 22079/26446. 0.2032 s / img. ETA=0:14:56
[07/05 11:54:20] detectron2 INFO: Inference done 22103/26446. 0.2032 s / img. ETA=0:14:51
[07/05 11:54:25] detectron2 INFO: Inference done 22128/26446. 0.2032 s / img. ETA=0:14:46
[07/05 11:54:30] detectron2 INFO: Inference done 22153/26446. 0.2032 s / img. ETA=0:14:41
[07/05 11:54:35] detectron2 INFO: Inference done 22178/26446. 0.2032 s / img. ETA=0:14:36
[07/05 11:54:40] detectron2 INFO: Inference done 22203/26446. 0.2032 s / img. ETA=0:14:31
[07/05 11:54:45] detectron2 INFO: Inference done 22228/26446. 0.2032 s / img. ETA=0:14:26
[07/05 11:54:51] detectron2 INFO: Inference done 22253/26446. 0.2032 s / img. ETA=0:14:21
[07/05 11:54:56] detectron2 INFO: Inference done 22278/26446. 0.2032 s / img. ETA=0:14:15
[07/05 11:55:01] detectron2 INFO: Inference done 22303/26446. 0.2032 s / img. ETA=0:14:10
[07/05 11:55:06] detectron2 INFO: Inference done 22328/26446. 0.2032 s / img. ETA=0:14:05
[07/05 11:55:11] detectron2 INFO: Inference done 22353/26446. 0.2032 s / img. ETA=0:14:00
[07/05 11:55:16] detectron2 INFO: Inference done 22378/26446. 0.2032 s / img. ETA=0:13:55
[07/05 11:55:21] detectron2 INFO: Inference done 22402/26446. 0.2032 s / img. ETA=0:13:50
[07/05 11:55:26] detectron2 INFO: Inference done 22427/26446. 0.2032 s / img. ETA=0:13:45
[07/05 11:55:32] detectron2 INFO: Inference done 22453/26446. 0.2032 s / img. ETA=0:13:39
[07/05 11:55:37] detectron2 INFO: Inference done 22477/26446. 0.2032 s / img. ETA=0:13:35
[07/05 11:55:42] detectron2 INFO: Inference done 22502/26446. 0.2032 s / img. ETA=0:13:29
[07/05 11:55:47] detectron2 INFO: Inference done 22527/26446. 0.2032 s / img. ETA=0:13:24
[07/05 11:55:52] detectron2 INFO: Inference done 22552/26446. 0.2032 s / img. ETA=0:13:19
[07/05 11:55:57] detectron2 INFO: Inference done 22577/26446. 0.2032 s / img. ETA=0:13:14
[07/05 11:56:02] detectron2 INFO: Inference done 22602/26446. 0.2032 s / img. ETA=0:13:09
[07/05 11:56:07] detectron2 INFO: Inference done 22627/26446. 0.2032 s / img. ETA=0:13:04
[07/05 11:56:13] detectron2 INFO: Inference done 22652/26446. 0.2032 s / img. ETA=0:12:59
[07/05 11:56:18] detectron2 INFO: Inference done 22677/26446. 0.2032 s / img. ETA=0:12:54
[07/05 11:56:23] detectron2 INFO: Inference done 22701/26446. 0.2032 s / img. ETA=0:12:49
[07/05 11:56:28] detectron2 INFO: Inference done 22726/26446. 0.2032 s / img. ETA=0:12:43
[07/05 11:56:33] detectron2 INFO: Inference done 22750/26446. 0.2032 s / img. ETA=0:12:39
[07/05 11:56:38] detectron2 INFO: Inference done 22775/26446. 0.2032 s / img. ETA=0:12:33
[07/05 11:56:43] detectron2 INFO: Inference done 22799/26446. 0.2032 s / img. ETA=0:12:29
[07/05 11:56:48] detectron2 INFO: Inference done 22824/26446. 0.2032 s / img. ETA=0:12:23
[07/05 11:56:53] detectron2 INFO: Inference done 22850/26446. 0.2032 s / img. ETA=0:12:18
[07/05 11:56:59] detectron2 INFO: Inference done 22875/26446. 0.2032 s / img. ETA=0:12:13
[07/05 11:57:04] detectron2 INFO: Inference done 22900/26446. 0.2032 s / img. ETA=0:12:08
[07/05 11:57:09] detectron2 INFO: Inference done 22925/26446. 0.2032 s / img. ETA=0:12:03
[07/05 11:57:14] detectron2 INFO: Inference done 22949/26446. 0.2032 s / img. ETA=0:11:58
[07/05 11:57:19] detectron2 INFO: Inference done 22974/26446. 0.2032 s / img. ETA=0:11:53
[07/05 11:57:24] detectron2 INFO: Inference done 22999/26446. 0.2032 s / img. ETA=0:11:47
[07/05 11:57:29] detectron2 INFO: Inference done 23024/26446. 0.2032 s / img. ETA=0:11:42
[07/05 11:57:34] detectron2 INFO: Inference done 23049/26446. 0.2032 s / img. ETA=0:11:37
[07/05 11:57:39] detectron2 INFO: Inference done 23074/26446. 0.2032 s / img. ETA=0:11:32
[07/05 11:57:44] detectron2 INFO: Inference done 23098/26446. 0.2032 s / img. ETA=0:11:27
[07/05 11:57:49] detectron2 INFO: Inference done 23123/26446. 0.2032 s / img. ETA=0:11:22
[07/05 11:57:55] detectron2 INFO: Inference done 23148/26446. 0.2032 s / img. ETA=0:11:17
[07/05 11:58:00] detectron2 INFO: Inference done 23172/26446. 0.2032 s / img. ETA=0:11:12
[07/05 11:58:05] detectron2 INFO: Inference done 23197/26446. 0.2032 s / img. ETA=0:11:07
[07/05 11:58:10] detectron2 INFO: Inference done 23222/26446. 0.2032 s / img. ETA=0:11:02
[07/05 11:58:15] detectron2 INFO: Inference done 23247/26446. 0.2032 s / img. ETA=0:10:56
[07/05 11:58:20] detectron2 INFO: Inference done 23271/26446. 0.2032 s / img. ETA=0:10:52
[07/05 11:58:25] detectron2 INFO: Inference done 23296/26446. 0.2032 s / img. ETA=0:10:46
[07/05 11:58:30] detectron2 INFO: Inference done 23320/26446. 0.2032 s / img. ETA=0:10:41
[07/05 11:58:35] detectron2 INFO: Inference done 23346/26446. 0.2032 s / img. ETA=0:10:36
[07/05 11:58:40] detectron2 INFO: Inference done 23370/26446. 0.2032 s / img. ETA=0:10:31
[07/05 11:58:45] detectron2 INFO: Inference done 23395/26446. 0.2032 s / img. ETA=0:10:26
[07/05 11:58:50] detectron2 INFO: Inference done 23419/26446. 0.2032 s / img. ETA=0:10:21
[07/05 11:58:55] detectron2 INFO: Inference done 23443/26446. 0.2032 s / img. ETA=0:10:16
[07/05 11:59:00] detectron2 INFO: Inference done 23467/26446. 0.2032 s / img. ETA=0:10:11
[07/05 11:59:05] detectron2 INFO: Inference done 23491/26446. 0.2032 s / img. ETA=0:10:06
[07/05 11:59:10] detectron2 INFO: Inference done 23516/26446. 0.2032 s / img. ETA=0:10:01
[07/05 11:59:16] detectron2 INFO: Inference done 23541/26446. 0.2032 s / img. ETA=0:09:56
[07/05 11:59:21] detectron2 INFO: Inference done 23565/26446. 0.2032 s / img. ETA=0:09:51
[07/05 11:59:26] detectron2 INFO: Inference done 23589/26446. 0.2033 s / img. ETA=0:09:46
[07/05 11:59:31] detectron2 INFO: Inference done 23614/26446. 0.2033 s / img. ETA=0:09:41
[07/05 11:59:36] detectron2 INFO: Inference done 23639/26446. 0.2033 s / img. ETA=0:09:36
[07/05 11:59:41] detectron2 INFO: Inference done 23664/26446. 0.2033 s / img. ETA=0:09:31
[07/05 11:59:46] detectron2 INFO: Inference done 23688/26446. 0.2033 s / img. ETA=0:09:26
[07/05 11:59:51] detectron2 INFO: Inference done 23713/26446. 0.2033 s / img. ETA=0:09:21
[07/05 11:59:56] detectron2 INFO: Inference done 23738/26446. 0.2033 s / img. ETA=0:09:16
[07/05 12:00:01] detectron2 INFO: Inference done 23763/26446. 0.2033 s / img. ETA=0:09:11
[07/05 12:00:07] detectron2 INFO: Inference done 23788/26446. 0.2033 s / img. ETA=0:09:05
[07/05 12:00:12] detectron2 INFO: Inference done 23813/26446. 0.2033 s / img. ETA=0:09:00
[07/05 12:00:17] detectron2 INFO: Inference done 23838/26446. 0.2033 s / img. ETA=0:08:55
[07/05 12:00:22] detectron2 INFO: Inference done 23863/26446. 0.2033 s / img. ETA=0:08:50
[07/05 12:00:27] detectron2 INFO: Inference done 23888/26446. 0.2033 s / img. ETA=0:08:45
[07/05 12:00:32] detectron2 INFO: Inference done 23914/26446. 0.2032 s / img. ETA=0:08:40
[07/05 12:00:37] detectron2 INFO: Inference done 23939/26446. 0.2032 s / img. ETA=0:08:34
[07/05 12:00:43] detectron2 INFO: Inference done 23964/26446. 0.2032 s / img. ETA=0:08:29
[07/05 12:00:48] detectron2 INFO: Inference done 23989/26446. 0.2032 s / img. ETA=0:08:24
[07/05 12:00:53] detectron2 INFO: Inference done 24014/26446. 0.2032 s / img. ETA=0:08:19
[07/05 12:00:58] detectron2 INFO: Inference done 24038/26446. 0.2033 s / img. ETA=0:08:14
[07/05 12:01:03] detectron2 INFO: Inference done 24063/26446. 0.2032 s / img. ETA=0:08:09
[07/05 12:01:08] detectron2 INFO: Inference done 24088/26446. 0.2032 s / img. ETA=0:08:04
[07/05 12:01:13] detectron2 INFO: Inference done 24113/26446. 0.2032 s / img. ETA=0:07:59
[07/05 12:01:18] detectron2 INFO: Inference done 24138/26446. 0.2032 s / img. ETA=0:07:54
[07/05 12:01:23] detectron2 INFO: Inference done 24163/26446. 0.2032 s / img. ETA=0:07:48
[07/05 12:01:29] detectron2 INFO: Inference done 24187/26446. 0.2033 s / img. ETA=0:07:43
[07/05 12:01:34] detectron2 INFO: Inference done 24212/26446. 0.2033 s / img. ETA=0:07:38
[07/05 12:01:39] detectron2 INFO: Inference done 24236/26446. 0.2033 s / img. ETA=0:07:33
[07/05 12:01:44] detectron2 INFO: Inference done 24261/26446. 0.2033 s / img. ETA=0:07:28
[07/05 12:01:49] detectron2 INFO: Inference done 24285/26446. 0.2033 s / img. ETA=0:07:23
[07/05 12:01:54] detectron2 INFO: Inference done 24310/26446. 0.2033 s / img. ETA=0:07:18
[07/05 12:01:59] detectron2 INFO: Inference done 24335/26446. 0.2033 s / img. ETA=0:07:13
[07/05 12:02:04] detectron2 INFO: Inference done 24359/26446. 0.2033 s / img. ETA=0:07:08
[07/05 12:02:09] detectron2 INFO: Inference done 24384/26446. 0.2033 s / img. ETA=0:07:03
[07/05 12:02:14] detectron2 INFO: Inference done 24409/26446. 0.2033 s / img. ETA=0:06:58
[07/05 12:02:19] detectron2 INFO: Inference done 24434/26446. 0.2033 s / img. ETA=0:06:53
[07/05 12:02:24] detectron2 INFO: Inference done 24459/26446. 0.2033 s / img. ETA=0:06:48
[07/05 12:02:30] detectron2 INFO: Inference done 24484/26446. 0.2033 s / img. ETA=0:06:42
[07/05 12:02:35] detectron2 INFO: Inference done 24509/26446. 0.2033 s / img. ETA=0:06:37
[07/05 12:02:40] detectron2 INFO: Inference done 24534/26446. 0.2032 s / img. ETA=0:06:32
[07/05 12:02:45] detectron2 INFO: Inference done 24558/26446. 0.2033 s / img. ETA=0:06:27
[07/05 12:02:50] detectron2 INFO: Inference done 24583/26446. 0.2033 s / img. ETA=0:06:22
[07/05 12:02:55] detectron2 INFO: Inference done 24608/26446. 0.2033 s / img. ETA=0:06:17
[07/05 12:03:00] detectron2 INFO: Inference done 24633/26446. 0.2033 s / img. ETA=0:06:12
[07/05 12:03:05] detectron2 INFO: Inference done 24657/26446. 0.2033 s / img. ETA=0:06:07
[07/05 12:03:10] detectron2 INFO: Inference done 24682/26446. 0.2033 s / img. ETA=0:06:02
[07/05 12:03:15] detectron2 INFO: Inference done 24706/26446. 0.2033 s / img. ETA=0:05:57
[07/05 12:03:20] detectron2 INFO: Inference done 24730/26446. 0.2033 s / img. ETA=0:05:52
[07/05 12:03:25] detectron2 INFO: Inference done 24754/26446. 0.2033 s / img. ETA=0:05:47
[07/05 12:03:31] detectron2 INFO: Inference done 24778/26446. 0.2033 s / img. ETA=0:05:42
[07/05 12:03:36] detectron2 INFO: Inference done 24803/26446. 0.2033 s / img. ETA=0:05:37
[07/05 12:03:41] detectron2 INFO: Inference done 24828/26446. 0.2033 s / img. ETA=0:05:32
[07/05 12:03:46] detectron2 INFO: Inference done 24852/26446. 0.2033 s / img. ETA=0:05:27
[07/05 12:03:51] detectron2 INFO: Inference done 24877/26446. 0.2033 s / img. ETA=0:05:22
[07/05 12:03:56] detectron2 INFO: Inference done 24902/26446. 0.2033 s / img. ETA=0:05:17
[07/05 12:04:01] detectron2 INFO: Inference done 24927/26446. 0.2033 s / img. ETA=0:05:12
[07/05 12:04:06] detectron2 INFO: Inference done 24952/26446. 0.2033 s / img. ETA=0:05:06
[07/05 12:04:11] detectron2 INFO: Inference done 24976/26446. 0.2033 s / img. ETA=0:05:01
[07/05 12:04:16] detectron2 INFO: Inference done 25002/26446. 0.2033 s / img. ETA=0:04:56
[07/05 12:04:22] detectron2 INFO: Inference done 25027/26446. 0.2033 s / img. ETA=0:04:51
[07/05 12:04:27] detectron2 INFO: Inference done 25053/26446. 0.2033 s / img. ETA=0:04:46
[07/05 12:04:32] detectron2 INFO: Inference done 25078/26446. 0.2033 s / img. ETA=0:04:40
[07/05 12:04:37] detectron2 INFO: Inference done 25102/26446. 0.2033 s / img. ETA=0:04:36
[07/05 12:04:42] detectron2 INFO: Inference done 25122/26446. 0.2033 s / img. ETA=0:04:32
[07/05 12:04:47] detectron2 INFO: Inference done 25146/26446. 0.2033 s / img. ETA=0:04:27
[07/05 12:04:52] detectron2 INFO: Inference done 25170/26446. 0.2033 s / img. ETA=0:04:22
[07/05 12:04:57] detectron2 INFO: Inference done 25194/26446. 0.2033 s / img. ETA=0:04:17
[07/05 12:05:03] detectron2 INFO: Inference done 25219/26446. 0.2033 s / img. ETA=0:04:12
[07/05 12:05:08] detectron2 INFO: Inference done 25244/26446. 0.2033 s / img. ETA=0:04:06
[07/05 12:05:13] detectron2 INFO: Inference done 25268/26446. 0.2033 s / img. ETA=0:04:02
[07/05 12:05:18] detectron2 INFO: Inference done 25292/26446. 0.2033 s / img. ETA=0:03:57
[07/05 12:05:23] detectron2 INFO: Inference done 25317/26446. 0.2033 s / img. ETA=0:03:51
[07/05 12:05:28] detectron2 INFO: Inference done 25342/26446. 0.2033 s / img. ETA=0:03:46
[07/05 12:05:33] detectron2 INFO: Inference done 25366/26446. 0.2033 s / img. ETA=0:03:41
[07/05 12:05:38] detectron2 INFO: Inference done 25391/26446. 0.2033 s / img. ETA=0:03:36
[07/05 12:05:43] detectron2 INFO: Inference done 25414/26446. 0.2034 s / img. ETA=0:03:32
[07/05 12:05:48] detectron2 INFO: Inference done 25438/26446. 0.2034 s / img. ETA=0:03:27
[07/05 12:05:54] detectron2 INFO: Inference done 25462/26446. 0.2034 s / img. ETA=0:03:22
[07/05 12:05:59] detectron2 INFO: Inference done 25486/26446. 0.2034 s / img. ETA=0:03:17
[07/05 12:06:04] detectron2 INFO: Inference done 25511/26446. 0.2034 s / img. ETA=0:03:12
[07/05 12:06:09] detectron2 INFO: Inference done 25536/26446. 0.2034 s / img. ETA=0:03:07
[07/05 12:06:14] detectron2 INFO: Inference done 25561/26446. 0.2034 s / img. ETA=0:03:01
[07/05 12:06:19] detectron2 INFO: Inference done 25585/26446. 0.2034 s / img. ETA=0:02:56
[07/05 12:06:24] detectron2 INFO: Inference done 25610/26446. 0.2034 s / img. ETA=0:02:51
[07/05 12:06:29] detectron2 INFO: Inference done 25635/26446. 0.2034 s / img. ETA=0:02:46
[07/05 12:06:34] detectron2 INFO: Inference done 25659/26446. 0.2034 s / img. ETA=0:02:41
[07/05 12:06:39] detectron2 INFO: Inference done 25684/26446. 0.2034 s / img. ETA=0:02:36
[07/05 12:06:45] detectron2 INFO: Inference done 25708/26446. 0.2034 s / img. ETA=0:02:31
[07/05 12:06:50] detectron2 INFO: Inference done 25733/26446. 0.2034 s / img. ETA=0:02:26
[07/05 12:06:55] detectron2 INFO: Inference done 25758/26446. 0.2034 s / img. ETA=0:02:21
[07/05 12:07:00] detectron2 INFO: Inference done 25783/26446. 0.2034 s / img. ETA=0:02:16
[07/05 12:07:05] detectron2 INFO: Inference done 25807/26446. 0.2034 s / img. ETA=0:02:11
[07/05 12:07:10] detectron2 INFO: Inference done 25832/26446. 0.2034 s / img. ETA=0:02:06
[07/05 12:07:15] detectron2 INFO: Inference done 25857/26446. 0.2034 s / img. ETA=0:02:01
[07/05 12:07:20] detectron2 INFO: Inference done 25874/26446. 0.2035 s / img. ETA=0:01:57
[07/05 12:07:25] detectron2 INFO: Inference done 25899/26446. 0.2034 s / img. ETA=0:01:52
[07/05 12:07:30] detectron2 INFO: Inference done 25924/26446. 0.2034 s / img. ETA=0:01:47
[07/05 12:07:36] detectron2 INFO: Inference done 25949/26446. 0.2034 s / img. ETA=0:01:42
[07/05 12:07:41] detectron2 INFO: Inference done 25973/26446. 0.2035 s / img. ETA=0:01:37
[07/05 12:07:46] detectron2 INFO: Inference done 25997/26446. 0.2035 s / img. ETA=0:01:32
[07/05 12:07:51] detectron2 INFO: Inference done 26022/26446. 0.2035 s / img. ETA=0:01:27
[07/05 12:07:56] detectron2 INFO: Inference done 26047/26446. 0.2035 s / img. ETA=0:01:22
[07/05 12:08:01] detectron2 INFO: Inference done 26071/26446. 0.2035 s / img. ETA=0:01:17
[07/05 12:08:06] detectron2 INFO: Inference done 26095/26446. 0.2035 s / img. ETA=0:01:12
[07/05 12:08:11] detectron2 INFO: Inference done 26120/26446. 0.2035 s / img. ETA=0:01:07
[07/05 12:08:17] detectron2 INFO: Inference done 26145/26446. 0.2035 s / img. ETA=0:01:01
[07/05 12:08:22] detectron2 INFO: Inference done 26170/26446. 0.2035 s / img. ETA=0:00:56
[07/05 12:08:27] detectron2 INFO: Inference done 26195/26446. 0.2035 s / img. ETA=0:00:51
[07/05 12:08:32] detectron2 INFO: Inference done 26219/26446. 0.2035 s / img. ETA=0:00:46
[07/05 12:08:37] detectron2 INFO: Inference done 26244/26446. 0.2035 s / img. ETA=0:00:41
[07/05 12:08:42] detectron2 INFO: Inference done 26269/26446. 0.2035 s / img. ETA=0:00:36
[07/05 12:08:47] detectron2 INFO: Inference done 26294/26446. 0.2035 s / img. ETA=0:00:31
[07/05 12:08:52] detectron2 INFO: Inference done 26319/26446. 0.2035 s / img. ETA=0:00:26
[07/05 12:08:58] detectron2 INFO: Inference done 26344/26446. 0.2035 s / img. ETA=0:00:20
[07/05 12:09:03] detectron2 INFO: Inference done 26368/26446. 0.2035 s / img. ETA=0:00:16
[07/05 12:09:08] detectron2 INFO: Inference done 26392/26446. 0.2035 s / img. ETA=0:00:11
[07/05 12:09:13] detectron2 INFO: Inference done 26417/26446. 0.2035 s / img. ETA=0:00:05
[07/05 12:09:18] detectron2 INFO: Inference done 26442/26446. 0.2035 s / img. ETA=0:00:00
[07/05 12:09:19] detectron2 INFO: Total inference time: 1:30:37.198152 (0.205635 s / img per device, on 1 devices)
[07/05 12:09:19] detectron2 INFO: Total inference pure compute time: 1:29:40 (0.203475 s / img per device, on 1 devices)
[07/05 12:09:25] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[07/05 12:09:25] d2.evaluation.coco_evaluation INFO: Saving results to ./speaq_checkpoints/inference\coco_instances_results.json
[07/05 12:09:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with official COCO API...
[07/05 12:13:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.204 | 25.261 | 11.840 | 3.356 | 8.968 | 18.494 |
[07/05 12:13:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|:-----------|:-------|
| airplane   | 1.016  | animal     | 1.336  | arm        | 2.622  |
| bag        | 6.613  | banana     | 8.988  | basket     | 9.240  |
| beach      | 28.936 | bear       | 30.301 | bed        | 41.766 |
| bench      | 19.887 | bike       | 18.610 | bird       | 22.269 |
| board      | 2.454  | boat       | 16.744 | book       | 4.372  |
| boot       | 6.931  | bottle     | 13.768 | bowl       | 20.594 |
| box        | 5.787  | boy        | 17.273 | branch     | 0.577  |
| building   | 20.335 | bus        | 41.042 | cabinet    | 5.961  |
| cap        | 3.849  | car        | 19.787 | cat        | 37.010 |
| chair      | 17.278 | child      | 3.025  | clock      | 20.214 |
| coat       | 2.820  | counter    | 10.492 | cow        | 29.596 |
| cup        | 14.878 | curtain    | 13.093 | desk       | 16.016 |
| dog        | 33.841 | door       | 7.998  | drawer     | 5.658  |
| ear        | 15.004 | elephant   | 28.816 | engine     | 14.935 |
| eye        | 9.448  | face       | 7.208  | fence      | 17.456 |
| finger     | 1.391  | flag       | 6.338  | flower     | 5.828  |
| food       | 12.202 | fork       | 22.164 | fruit      | 1.999  |
| giraffe    | 30.421 | girl       | 10.893 | glass      | 14.714 |
| glove      | 9.592  | guy        | 0.000  | hair       | 20.099 |
| hand       | 10.833 | handle     | 3.833  | hat        | 18.322 |
| head       | 12.888 | helmet     | 22.568 | hill       | 4.149  |
| horse      | 33.288 | house      | 6.423  | jacket     | 15.365 |
| jean       | 17.768 | kid        | 0.240  | kite       | 17.319 |
| lady       | 0.000  | lamp       | 12.295 | laptop     | 36.186 |
| leaf       | 0.868  | leg        | 4.667  | letter     | 1.027  |
| light      | 1.996  | logo       | 2.663  | man        | 29.756 |
| men        | 1.176  | motorcycle | 23.755 | mountain   | 7.654  |
| mouth      | 5.446  | neck       | 5.721  | nose       | 11.736 |
| number     | 2.690  | orange     | 14.401 | pant       | 16.126 |
| paper      | 3.986  | paw        | 6.520  | people     | 1.251  |
| person     | 5.389  | phone      | 9.137  | pillow     | 16.210 |
| pizza      | 32.166 | plane      | 30.703 | plant      | 4.737  |
| plate      | 29.548 | player     | 6.543  | pole       | 5.231  |
| post       | 1.333  | pot        | 4.505  | racket     | 23.685 |
| railing    | 1.207  | rock       | 4.851  | roof       | 6.034  |
| room       | 20.678 | screen     | 20.856 | seat       | 7.962  |
| sheep      | 22.778 | shelf      | 2.172  | shirt      | 25.699 |
| shoe       | 11.508 | short      | 27.276 | sidewalk   | 9.850  |
| sign       | 16.110 | sink       | 15.065 | skateboard | 23.755 |
| ski        | 10.224 | skier      | 4.244  | sneaker    | 0.033  |
| snow       | 18.608 | sock       | 8.920  | stand      | 2.148  |
| street     | 16.646 | surfboard  | 16.291 | table      | 27.441 |
| tail       | 13.620 | tie        | 19.212 | tile       | 0.699  |
| tire       | 10.750 | toilet     | 34.655 | towel      | 7.089  |
| tower      | 17.963 | track      | 10.549 | train      | 31.701 |
| tree       | 8.353  | truck      | 22.929 | trunk      | 7.773  |
| umbrella   | 18.464 | vase       | 20.947 | vegetable  | 1.546  |
| vehicle    | 0.489  | wave       | 11.433 | wheel      | 8.461  |
| window     | 5.689  | windshield | 10.718 | wing       | 10.754 |
| wire       | 0.672  | woman      | 21.104 | zebra      | 31.044 |
[07/05 12:13:20] detectron2 INFO: Gathering data
[07/05 12:13:20] detectron2 INFO: Predictions Gathered
[07/05 12:13:37] detectron2 INFO: Saving output prediction
[07/05 12:13:37] detectron2 INFO: Computing Scene Graph Metrics
[07/05 12:13:37] detectron2 INFO: Preparing Global Container
[07/05 12:20:41] detectron2 INFO: Scene Graph Metric Evaluation Complete. Computing recall statistics...
[07/05 12:21:38] detectron2 INFO: Scene Graph Results for mode: sgdet
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: 13.2037,25.2607,11.8401,3.3560,8.9685,18.4941
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: Task: SG
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: SGMeanRecall@20,SGMeanRecall@50,SGMeanRecall@100,SGRecall@20,SGRecall@50,SGRecall@100
[07/05 12:21:45] d2.evaluation.testing INFO: copypaste: 0.0903,0.1385,0.1620,0.2333,0.2986,0.3322
